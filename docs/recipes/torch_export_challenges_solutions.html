
<!DOCTYPE html>


<html lang="ko" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <meta property="article:modified_time" content="2022-11-30T07:09:41+00:00" /><meta property="og:title" content="Demonstration of torch.export flow, common challenges and the solutions to address them" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://tutorials.pytorch.kr/recipes/torch_export_challenges_solutions.html" />
<meta property="og:site_name" content="PyTorch Tutorials KR" />
<meta property="og:description" content="Authors: Ankith Gunapal, Jordi Ramon, Marcos Carranza In the Introduction to torch.export Tutorial, we learned how to use torch.export. This tutorial expands on the previous one and explores the process of exporting popular models with code, as well as addresses common challenges that may arise w..." />
<meta property="og:image" content="https://tutorials.pytorch.kr/_static/logos/logo-kr-sm-dark.png" />
<meta property="og:image:alt" content="PyTorch Tutorials KR" />
<meta name="description" content="Authors: Ankith Gunapal, Jordi Ramon, Marcos Carranza In the Introduction to torch.export Tutorial, we learned how to use torch.export. This tutorial expands on the previous one and explores the process of exporting popular models with code, as well as addresses common challenges that may arise w..." />
<meta property="og:ignore_canonical" content="true" />

    <title>Demonstration of torch.export flow, common challenges and the solutions to address them &#8212; 파이토치 한국어 튜토리얼 (PyTorch tutorials in Korean)</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=536c50fe" />
    <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=4d2595e5" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/katex-math.css?v=91adb8b6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/pytorch_theme.css?v=c326296f" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css?v=097efa9c" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom2.css?v=b169ea90" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=725a5b95"></script>
    <script src="../_static/doctools.js?v=92e14aea"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/translations.js?v=b5f768d8"></script>
    <script src="../_static/katex.min.js?v=be8ff15f"></script>
    <script src="../_static/auto-render.min.js?v=ad136472"></script>
    <script src="../_static/katex_autorenderer.js?v=bebc588a"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'recipes/torch_export_challenges_solutions';</script>
    <link rel="canonical" href="https://tutorials.pytorch.kr/recipes/torch_export_challenges_solutions.html" />
    <link rel="icon" href="../_static/favicon.ico"/>
    <link rel="index" title="색인" href="../genindex.html" />
    <link rel="search" title="검색" href="../search.html" />
    <link rel="next" title="(beta) Compiling the optimizer with torch.compile" href="compiling_optimizer.html" />
    <link rel="prev" title="Dynamic Compilation Control with torch.compiler.set_stance" href="torch_compiler_set_stance_tutorial.html" />

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="ko"/>
    <meta name="docbuild:last-update" content="2022년 11월 30일"/>
<script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/2.3.1/list.min.js"></script>
<script>
  if (window.location.hostname === 'docs.pytorch.org' || window.location.hostname === 'docs-preview.pytorch.org') {
    const script = document.createElement('script');
    script.src = 'https://cmp.osano.com/16A0DbT9yDNIaQkvZ/31b1b91a-e0b6-47ea-bde2-7f2bd13dbe5c/osano.js?variant=one';
    document.head.appendChild(script);
  }
</script>
<script>
  // Cookie banner for non-LF projects
  document.addEventListener('DOMContentLoaded', function () {
    // Hide cookie banner on local environments and LF owned docs
    if (window.location.hostname === 'localhost' ||
      window.location.hostname === '0.0.0.0' ||
      window.location.hostname === '127.0.0.1' ||
      window.location.hostname === 'docs.pytorch.org' ||
      window.location.hostname === 'docs-preview.pytorch.org' ||
      window.location.hostname.startsWith('192.168.')) {
      const banner = document.querySelector('.cookie-banner-wrapper');
      if (banner) {
        banner.style.display = 'none';
      }
    }
  });
</script>
<!-- Conditional CSS for header and footer height adjustment -->

<link rel="stylesheet" type="text/css" href="../_static/css/theme.css" crossorigin="anonymous">
<script type="text/javascript" src="../_static/js/theme.js"></script>
<script type="text/javascript" src="../_static/js/dropdown-menu.js"></script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Nanum+Gothic:wght@400;700&family=Nanum+Gothic+Coding:wght@400;700&family=Montserrat:wght@300;400&display=swap" rel="stylesheet">
<meta property="og:image" content="../_static/img/pytorch_seo.png" />
<link rel="stylesheet" href="../_static/webfonts/all.min.css" crossorigin="anonymous">
<meta http-equiv="Content-Security-Policy"
  content="default-src * 'unsafe-inline' 'unsafe-eval' data: blob:; style-src * 'unsafe-inline'; script-src * 'unsafe-inline' 'unsafe-eval' blob:;">
<meta name="pytorch_project" content="tutorials">
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=G-LZRD6GXDLF" height="0" width="0"
    style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
<!-- Google Tag Manager -->
<script>(function (w, d, s, l, i) {
    w[l] = w[l] || []; w[l].push({
      'gtm.start':
        new Date().getTime(), event: 'gtm.js'
    }); var f = d.getElementsByTagName(s)[0],
      j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : ''; j.async = true; j.src =
        'https://www.googletagmanager.com/gtm.js?id=' + i + dl; f.parentNode.insertBefore(j, f);
    j.onload = function () {
      window.dispatchEvent(new Event('gtm_loaded'));
      console.log('GTM loaded successfully');
    };
  })(window, document, 'script', 'dataLayer', 'G-LZRD6GXDLF');
</script>
<!-- End Google Tag Manager -->
<!-- Facebook Pixel Code -->
<script>
  !function (f, b, e, v, n, t, s) {
    if (f.fbq) return; n = f.fbq = function () {
      n.callMethod ?
        n.callMethod.apply(n, arguments) : n.queue.push(arguments)
    };
    if (!f._fbq) f._fbq = n; n.push = n; n.loaded = !0; n.version = '2.0';
    n.queue = []; t = b.createElement(e); t.async = !0;
    t.src = v; s = b.getElementsByTagName(e)[0];
    s.parentNode.insertBefore(t, s)
  }(window, document, 'script',
    'https://connect.facebook.net/en_US/fbevents.js');
  fbq('init', '243028289693773');
  fbq('track', 'PageView');
</script>
<script>
  document.documentElement.setAttribute('data-version', 'v2.8.0+cu128');
</script>
<noscript>
  <img height="1" width="1" src="https://www.facebook.com/tr?id=243028289693773&ev=PageView&noscript=1" />
</noscript>
<script>
  function gtag() {
    window.dataLayer.push(arguments);
  }
</script>
<!-- End Facebook Pixel Code -->
<!-- Script to Fix scrolling -->
<script>
  document.addEventListener('DOMContentLoaded', function () {
    // Fix anchor scrolling
    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener('click', function (e) {
        e.preventDefault();
        const targetId = this.getAttribute('href').substring(1);
        const targetElement = document.getElementById(targetId);

        if (targetElement) {
          const headerHeight =
            (document.querySelector('.header-holder') ? document.querySelector('.header-holder').offsetHeight : 0) +
            (document.querySelector('.bd-header') ? document.querySelector('.bd-header').offsetHeight : 0) + 20;

          const targetPosition = targetElement.getBoundingClientRect().top + window.pageYOffset - headerHeight;
          window.scrollTo({
            top: targetPosition,
            behavior: 'smooth'
          });

          // Update URL hash without scrolling
          history.pushState(null, null, '#' + targetId);
        }
      });
    });
  });
</script>

<script async src="https://cse.google.com/cse.js?cx=e65585f8c3ea1440e"></script>


  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="ko"/>
    <meta name="docbuild:last-update" content="2022년 11월 30일"/>

  </head>

<body data-feedback-url="https://github.com/PyTorchKorea/tutorials-kr" class="pytorch-body">
  
    <div class="container-fluid header-holder tutorials-header" id="header-holder">
   <div class="header-container-wrapper">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.kr/" aria-label="PyTorchKR"></a>

      <div class="main-menu">
        <ul>

          <li class="main-menu-item">
          <div id="learnDropdownButton" data-toggle="learn-dropdown" class="learn-dropdown">
              <a class="with-down-arrow">
                <span>배우기</span>
              </a>
              <div class="learn-dropdown-menu dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.kr/get-started/locally/">
                  <span class="dropdown-title">PyTorch 시작하기</span>
                </a>
                <a class="nav-dropdown-item" href="https://tutorials.pytorch.kr/beginner/basics/intro.html">
                  <span class="dropdown-title">기본 익히기</span>
                </a>
                <a class="nav-dropdown-item" href="https://tutorials.pytorch.kr/" target="_self">
                  <span class="dropdown-title">한국어 튜토리얼</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.kr/hub/">
                  <span class="dropdown-title">한국어 모델 허브</span>
                </a>
                <a class="nav-dropdown-item" href="https://docs.pytorch.org/tutorials/" target="_blank">
                  <span class="dropdown-title">Official Tutorials</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <a href="https://pytorch.kr/blog/">
              <span>블로그</span>
            </a>
          </li>

          <li class="main-menu-item">
          <div id="docsDropdownButton" data-toggle="docs-dropdown" class="docs-dropdown">
              <a class="with-down-arrow">
              <span>문서</span>
              </a>
              <div class="docs-dropdown-menu dropdown-menu">
                <a class="nav-dropdown-item" href="https://docs.pytorch.org/docs/" target="_blank">
                  <span class="dropdown-title">PyTorch API</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.kr/domains/">
                  <span class="dropdown-title">Domain API 소개</span>
                </a>
                <a class="nav-dropdown-item" href="https://tutorials.pytorch.kr/" target="_self">
                  <span class="dropdown-title">한국어 튜토리얼</span>
                </a>
                <a class="nav-dropdown-item" href="https://docs.pytorch.org/tutorials/" target="_blank">
                  <span class="dropdown-title">Official Tutorials</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
          <div id="communityDropdownButton" data-toggle="community-dropdown" class="community-dropdown">
              <a class="with-down-arrow">
              <span>커뮤니티</span>
              </a>
              <div class="community-dropdown-menu dropdown-menu">
                <a class="nav-dropdown-item" href="https://discuss.pytorch.kr/" target="_self">
                  <span class="dropdown-title">한국어 커뮤니티</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.kr/resources/">
                  <span class="dropdown-title">개발자 정보</span>
                </a>
                <a class="nav-dropdown-item" href="https://landscape.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Landscape</span>
                </a>
              </div>
            </div>
          </li>

        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu">
        <i class="fa-solid fa-ellipsis"></i>
      </a>
    </div>
  </div>
 </div>

 <!-- Begin Mobile Menu -->

<div class="mobile-main-menu">
  <div class="container-fluid">
    <div class="header-container-wrapper">
      <div class="mobile-main-menu-header-container">
        <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu">
          <i class="fa-solid fa-xmark"></i>
        </a>
      </div>
    </div>
  </div>

  <div class="mobile-main-menu-links-container">
    <div class="main-menu">
      <ul>
         <li class="resources-mobile-menu-title">
           <a>배우기</a>
         </li>
         <ul class="resources-mobile-menu-items">
           <li>
             <a href="https://pytorch.kr/get-started/locally/">PyTorch 시작하기</a>
           </li>
           <li>
             <a href="https://tutorials.pytorch.kr/beginner/basics/intro.html">기본 익히기</a>
           </li>
           <li>
             <a href="https://tutorials.pytorch.kr/">한국어 튜토리얼</a>
           </li>
           <li>
             <a href="https://pytorch.kr/hub/">한국어 모델 허브</a>
           </li>
           <li>
             <a href="https://docs.pytorch.org/tutorials/" target="_blank">Official Tutorials</a>
           </li>
        </ul>
         <li class="resources-mobile-menu-title">
           <a href="https://pytorch.kr/blog/">블로그</a>
         </li>
         <li class="resources-mobile-menu-title">
           <a>문서</a>
         </li>
         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://docs.pytorch.org/docs/" target="_blank">PyTorch API</a>
          </li>
          <li>
            <a href="https://pytorch.kr/domains/">Domain API 소개</a>
          </li>
          <li>
            <a href="https://tutorials.pytorch.kr/">한국어 튜토리얼</a>
          </li>
          <li>
            <a href="https://docs.pytorch.org/tutorials/" target="_blank">Official Tutorials</a>
          </li>
        </ul>
        <li class="resources-mobile-menu-title">
          <a>커뮤니티</a>
        </li>
         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://discuss.pytorch.kr/">한국어 커뮤니티</a>
          </li>
          <li>
            <a href="https://pytorch.kr/resources/">개발자 정보</a>
          </li>
          <li>
            <a href="https://landscape.pytorch.org/" target="_blank">Landscape</a>
          </li>
        </ul>
      </ul>
    </div>
  </div>
</div>

<!-- End Mobile Menu -->
  
  
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">
  <a href="../index.html" class="version">v2.8.0+cu128</a>
</div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../intro.html">
    Intro
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../compilers_index.html">
    Compilers
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../domains.html">
    Domains
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../distributed.html">
    Distributed
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../deep-dive.html">
    Deep Dive
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../extension.html">
    Extension
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../ecosystem.html">
    Ecosystem
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../recipes_index.html">
    Recipes
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
      
        <div class="navbar-item">
<div class="search-container-wrapper">
  <div id="sphinx-search" class="search-container">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </div>

  <div id="google-search" class="search-container" style="display:none;">
    <div class="gcse-search-wrapper">
      <i class="fa-solid fa-magnifying-glass" aria-hidden="true"></i>
      <div class="gcse-search"></div>
    </div>
  </div>

  <div class="search-toggle-container" data-bs-title="Google Search Off" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <div class="search-toggle-inner">
      <label class="switch">
        <input type="checkbox" id="search-toggle">
        <span class="slider round"></span>
      </label>
    </div>
  </div>
</div>

<script>
  document.addEventListener('DOMContentLoaded', function() {
  // Define the search callback
  const myWebSearchStartingCallback = (gname, query) => {
    if (typeof dataLayer !== 'undefined' && query) {
      window.dataLayer = window.dataLayer || [];
      dataLayer.push({
        'event': 'google_search',
        'search_term': query,
        'event_category': 'Search',
        'event_label': 'Google Search'
      });
    }
    return '';
  };

  // Set up the GCSE search callbacks
  window.__gcse || (window.__gcse = {});
  window.__gcse.searchCallbacks = {
    web: { starting: myWebSearchStartingCallback }
  };

  if (window.location.pathname.includes('/search.html')) {
    document.body.classList.add('search-page');
  }

  // Function to reinitialize Google CSE
  function reinitializeGoogleSearch() {
    if (window.__gcse && window.__gcse.initializationCallback) {
      window.__gcse.initializationCallback();
    }
  }

  // Function to handle search toggle
  function handleSearchToggle(toggle, sphinxSearch, googleSearch) {
    if (!toggle || !sphinxSearch || !googleSearch) return;

    // Check if the URL contains /stable/ or /tutorials/
    const currentUrl = window.location.href;
    // TODO: We've had reports that the google programmable search is returning stale documentation,
    //       Simple reproduction is to turn google search on and search for multinomial which will
    //       result in returning 1.8.1 documentation.
    //       We should turn this back on when we resolve that bug.
    const shouldDefaultToGoogle = false;
    const savedPreference = localStorage.getItem('searchPreference');

    // Set initial state
    if (savedPreference === 'google' || (savedPreference === null && shouldDefaultToGoogle)) {
      toggle.checked = true;
      sphinxSearch.style.display = 'none';
      googleSearch.style.display = 'block';
      if (savedPreference === null) {
        localStorage.setItem('searchPreference', 'google');
      }
      reinitializeGoogleSearch();
    } else {
      toggle.checked = false;
      sphinxSearch.style.display = 'block';
      googleSearch.style.display = 'none';
    }

    // Update tooltip
    updateTooltip(toggle.checked);

    // Skip if already initialized
    if (toggle.hasAttribute('data-initialized')) return;
    toggle.setAttribute('data-initialized', 'true');

    toggle.addEventListener('change', function() {
      if (this.checked) {
        sphinxSearch.style.display = 'none';
        googleSearch.style.display = 'block';
        localStorage.setItem('searchPreference', 'google');
        reinitializeGoogleSearch();
        trackSearchEngineSwitch('Google');
      } else {
        sphinxSearch.style.display = 'block';
        googleSearch.style.display = 'none';
        localStorage.setItem('searchPreference', 'sphinx');
        trackSearchEngineSwitch('Sphinx');
      }

      updateTooltip(this.checked);
      updateMobileSearch();
    });
  }

  // Update tooltip based on toggle state
  function updateTooltip(isChecked) {
    const tooltipElement = document.querySelector('.search-toggle-container');
    if (!tooltipElement) return;

    tooltipElement.setAttribute('data-bs-title', isChecked ? 'Google Search On' : 'Google Search Off');

    if (bootstrap && bootstrap.Tooltip) {
      const tooltipInstance = bootstrap.Tooltip.getInstance(tooltipElement);
      if (tooltipInstance) tooltipInstance.dispose();
      new bootstrap.Tooltip(tooltipElement);
    }
  }

  // Track search engine switch
  function trackSearchEngineSwitch(engine) {
    if (typeof dataLayer !== 'undefined') {
      window.dataLayer = window.dataLayer || [];
      dataLayer.push({
        'event': 'search_engine_switch',
        'event_category': 'Search',
        'event_label': engine
      });
    }
  }

  // Function to update mobile search based on current toggle state
  function updateMobileSearch() {
    const toggle = document.getElementById('search-toggle');
    if (!toggle) return;

    const mobileSearchContainer = document.querySelector('.sidebar-header-items__end .navbar-item .search-container-wrapper');
    if (!mobileSearchContainer) return;

    const mobileSphinxSearch = mobileSearchContainer.querySelector('#sphinx-search');
    const mobileGoogleSearch = mobileSearchContainer.querySelector('#google-search');

    if (mobileSphinxSearch && mobileGoogleSearch) {
      mobileSphinxSearch.style.display = toggle.checked ? 'none' : 'block';
      mobileGoogleSearch.style.display = toggle.checked ? 'block' : 'none';

      if (toggle.checked) {
        reinitializeGoogleSearch();
      }
    }
  }

  // Initialize desktop search toggle
  const toggle = document.getElementById('search-toggle');
  const sphinxSearch = document.getElementById('sphinx-search');
  const googleSearch = document.getElementById('google-search');
  handleSearchToggle(toggle, sphinxSearch, googleSearch);

  // Set placeholder text for Google search input
  const observer = new MutationObserver(function() {
    document.querySelectorAll('.gsc-input input').forEach(input => {
      if (input && !input.hasAttribute('data-placeholder-set')) {
        input.setAttribute('placeholder', 'Search the docs ...');
        input.setAttribute('data-placeholder-set', 'true');
      }
    });
  });

  observer.observe(document.body, { childList: true, subtree: true });

  // Fix for scroll jump issue - improved approach
  function setupSearchInputHandlers(input) {
    if (input.hasAttribute('data-scroll-fixed')) return;
    input.setAttribute('data-scroll-fixed', 'true');

    let lastScrollPosition = 0;
    let isTyping = false;
    let scrollTimeout;

    // Save position before typing starts
    input.addEventListener('keydown', () => {
      lastScrollPosition = window.scrollY;
      isTyping = true;

      // Reset typing state after a short delay
      clearTimeout(scrollTimeout);
      scrollTimeout = setTimeout(() => {
        isTyping = false;
      }, 100);
    });

    // Only maintain scroll position during typing
    function maintainScroll() {
      if (document.activeElement === input && isTyping) {
        window.scrollTo(0, lastScrollPosition);
        requestAnimationFrame(maintainScroll);
      }
    }

    input.addEventListener('focus', () => {
      // Just store initial position but don't force it
      lastScrollPosition = window.scrollY;
    });

    input.addEventListener('input', () => {
      isTyping = true;
      window.scrollTo(0, lastScrollPosition);

      // Reset typing state after a short delay
      clearTimeout(scrollTimeout);
      scrollTimeout = setTimeout(() => {
        isTyping = false;
      }, 100);

      requestAnimationFrame(maintainScroll);
    });
  }

  // Apply to all search inputs and observe for new ones
  function applyToSearchInputs() {
    document.querySelectorAll('.search-container input, .gsc-input input').forEach(setupSearchInputHandlers);
  }

  applyToSearchInputs();

  const searchObserver = new MutationObserver(applyToSearchInputs);
  searchObserver.observe(document.body, { childList: true, subtree: true });

  // Watch for mobile menu creation
  const mobileMenuObserver = new MutationObserver(function(mutations) {
    for (const mutation of mutations) {
      if (!mutation.addedNodes.length) continue;

      // Style mobile search inputs
      document.querySelectorAll('.sidebar-header-items__end .navbar-item .search-container-wrapper .gsc-input input').forEach(input => {
        if (input) {
          input.setAttribute('placeholder', 'Search the docs ...');
          input.style.paddingLeft = '36px';
        }
      });

      // Check for mobile search container
      const mobileSearchContainer = document.querySelector('.sidebar-header-items__end .navbar-item .search-container-wrapper');
      if (!mobileSearchContainer) continue;

      const mobileToggle = mobileSearchContainer.querySelector('#search-toggle');
      if (mobileToggle && toggle) {
        // Sync mobile toggle with desktop toggle
        mobileToggle.checked = toggle.checked;
        updateMobileSearch();

        // Add event listener to mobile toggle if not already added
        if (!mobileToggle.hasAttribute('data-initialized')) {
          mobileToggle.setAttribute('data-initialized', 'true');
          mobileToggle.addEventListener('change', function() {
            // Sync desktop toggle with mobile toggle
            toggle.checked = this.checked;
            // Trigger change event on desktop toggle to update both
            toggle.dispatchEvent(new Event('change'));
          });
        }
      }
    }
  });

  mobileMenuObserver.observe(document.body, { childList: true, subtree: true });

  // Ensure Google CSE is properly loaded
  if (window.__gcse) {
    window.__gcse.callback = function() {
      // This will run after Google CSE is fully loaded
      if (toggle && toggle.checked) {
        reinitializeGoogleSearch();
      }
    };
  } else {
    window.__gcse = {
      callback: function() {
        if (toggle && toggle.checked) {
          reinitializeGoogleSearch();
        }
      }
    };
  }
});
</script>
</div>
      
        <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/PyTorchKorea/tutorials-kr" title="한국어 튜토리얼 GitHub 저장소" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">한국어 튜토리얼 GitHub 저장소</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discuss.pytorch.kr/" title="파이토치 한국어 커뮤니티" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">파이토치 한국어 커뮤니티</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../intro.html">
    Intro
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../compilers_index.html">
    Compilers
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../domains.html">
    Domains
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../distributed.html">
    Distributed
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../deep-dive.html">
    Deep Dive
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../extension.html">
    Extension
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../ecosystem.html">
    Ecosystem
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../recipes_index.html">
    Recipes
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
<div class="search-container-wrapper">
  <div id="sphinx-search" class="search-container">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </div>

  <div id="google-search" class="search-container" style="display:none;">
    <div class="gcse-search-wrapper">
      <i class="fa-solid fa-magnifying-glass" aria-hidden="true"></i>
      <div class="gcse-search"></div>
    </div>
  </div>

  <div class="search-toggle-container" data-bs-title="Google Search Off" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <div class="search-toggle-inner">
      <label class="switch">
        <input type="checkbox" id="search-toggle">
        <span class="slider round"></span>
      </label>
    </div>
  </div>
</div>

<script>
  document.addEventListener('DOMContentLoaded', function() {
  // Define the search callback
  const myWebSearchStartingCallback = (gname, query) => {
    if (typeof dataLayer !== 'undefined' && query) {
      window.dataLayer = window.dataLayer || [];
      dataLayer.push({
        'event': 'google_search',
        'search_term': query,
        'event_category': 'Search',
        'event_label': 'Google Search'
      });
    }
    return '';
  };

  // Set up the GCSE search callbacks
  window.__gcse || (window.__gcse = {});
  window.__gcse.searchCallbacks = {
    web: { starting: myWebSearchStartingCallback }
  };

  if (window.location.pathname.includes('/search.html')) {
    document.body.classList.add('search-page');
  }

  // Function to reinitialize Google CSE
  function reinitializeGoogleSearch() {
    if (window.__gcse && window.__gcse.initializationCallback) {
      window.__gcse.initializationCallback();
    }
  }

  // Function to handle search toggle
  function handleSearchToggle(toggle, sphinxSearch, googleSearch) {
    if (!toggle || !sphinxSearch || !googleSearch) return;

    // Check if the URL contains /stable/ or /tutorials/
    const currentUrl = window.location.href;
    // TODO: We've had reports that the google programmable search is returning stale documentation,
    //       Simple reproduction is to turn google search on and search for multinomial which will
    //       result in returning 1.8.1 documentation.
    //       We should turn this back on when we resolve that bug.
    const shouldDefaultToGoogle = false;
    const savedPreference = localStorage.getItem('searchPreference');

    // Set initial state
    if (savedPreference === 'google' || (savedPreference === null && shouldDefaultToGoogle)) {
      toggle.checked = true;
      sphinxSearch.style.display = 'none';
      googleSearch.style.display = 'block';
      if (savedPreference === null) {
        localStorage.setItem('searchPreference', 'google');
      }
      reinitializeGoogleSearch();
    } else {
      toggle.checked = false;
      sphinxSearch.style.display = 'block';
      googleSearch.style.display = 'none';
    }

    // Update tooltip
    updateTooltip(toggle.checked);

    // Skip if already initialized
    if (toggle.hasAttribute('data-initialized')) return;
    toggle.setAttribute('data-initialized', 'true');

    toggle.addEventListener('change', function() {
      if (this.checked) {
        sphinxSearch.style.display = 'none';
        googleSearch.style.display = 'block';
        localStorage.setItem('searchPreference', 'google');
        reinitializeGoogleSearch();
        trackSearchEngineSwitch('Google');
      } else {
        sphinxSearch.style.display = 'block';
        googleSearch.style.display = 'none';
        localStorage.setItem('searchPreference', 'sphinx');
        trackSearchEngineSwitch('Sphinx');
      }

      updateTooltip(this.checked);
      updateMobileSearch();
    });
  }

  // Update tooltip based on toggle state
  function updateTooltip(isChecked) {
    const tooltipElement = document.querySelector('.search-toggle-container');
    if (!tooltipElement) return;

    tooltipElement.setAttribute('data-bs-title', isChecked ? 'Google Search On' : 'Google Search Off');

    if (bootstrap && bootstrap.Tooltip) {
      const tooltipInstance = bootstrap.Tooltip.getInstance(tooltipElement);
      if (tooltipInstance) tooltipInstance.dispose();
      new bootstrap.Tooltip(tooltipElement);
    }
  }

  // Track search engine switch
  function trackSearchEngineSwitch(engine) {
    if (typeof dataLayer !== 'undefined') {
      window.dataLayer = window.dataLayer || [];
      dataLayer.push({
        'event': 'search_engine_switch',
        'event_category': 'Search',
        'event_label': engine
      });
    }
  }

  // Function to update mobile search based on current toggle state
  function updateMobileSearch() {
    const toggle = document.getElementById('search-toggle');
    if (!toggle) return;

    const mobileSearchContainer = document.querySelector('.sidebar-header-items__end .navbar-item .search-container-wrapper');
    if (!mobileSearchContainer) return;

    const mobileSphinxSearch = mobileSearchContainer.querySelector('#sphinx-search');
    const mobileGoogleSearch = mobileSearchContainer.querySelector('#google-search');

    if (mobileSphinxSearch && mobileGoogleSearch) {
      mobileSphinxSearch.style.display = toggle.checked ? 'none' : 'block';
      mobileGoogleSearch.style.display = toggle.checked ? 'block' : 'none';

      if (toggle.checked) {
        reinitializeGoogleSearch();
      }
    }
  }

  // Initialize desktop search toggle
  const toggle = document.getElementById('search-toggle');
  const sphinxSearch = document.getElementById('sphinx-search');
  const googleSearch = document.getElementById('google-search');
  handleSearchToggle(toggle, sphinxSearch, googleSearch);

  // Set placeholder text for Google search input
  const observer = new MutationObserver(function() {
    document.querySelectorAll('.gsc-input input').forEach(input => {
      if (input && !input.hasAttribute('data-placeholder-set')) {
        input.setAttribute('placeholder', 'Search the docs ...');
        input.setAttribute('data-placeholder-set', 'true');
      }
    });
  });

  observer.observe(document.body, { childList: true, subtree: true });

  // Fix for scroll jump issue - improved approach
  function setupSearchInputHandlers(input) {
    if (input.hasAttribute('data-scroll-fixed')) return;
    input.setAttribute('data-scroll-fixed', 'true');

    let lastScrollPosition = 0;
    let isTyping = false;
    let scrollTimeout;

    // Save position before typing starts
    input.addEventListener('keydown', () => {
      lastScrollPosition = window.scrollY;
      isTyping = true;

      // Reset typing state after a short delay
      clearTimeout(scrollTimeout);
      scrollTimeout = setTimeout(() => {
        isTyping = false;
      }, 100);
    });

    // Only maintain scroll position during typing
    function maintainScroll() {
      if (document.activeElement === input && isTyping) {
        window.scrollTo(0, lastScrollPosition);
        requestAnimationFrame(maintainScroll);
      }
    }

    input.addEventListener('focus', () => {
      // Just store initial position but don't force it
      lastScrollPosition = window.scrollY;
    });

    input.addEventListener('input', () => {
      isTyping = true;
      window.scrollTo(0, lastScrollPosition);

      // Reset typing state after a short delay
      clearTimeout(scrollTimeout);
      scrollTimeout = setTimeout(() => {
        isTyping = false;
      }, 100);

      requestAnimationFrame(maintainScroll);
    });
  }

  // Apply to all search inputs and observe for new ones
  function applyToSearchInputs() {
    document.querySelectorAll('.search-container input, .gsc-input input').forEach(setupSearchInputHandlers);
  }

  applyToSearchInputs();

  const searchObserver = new MutationObserver(applyToSearchInputs);
  searchObserver.observe(document.body, { childList: true, subtree: true });

  // Watch for mobile menu creation
  const mobileMenuObserver = new MutationObserver(function(mutations) {
    for (const mutation of mutations) {
      if (!mutation.addedNodes.length) continue;

      // Style mobile search inputs
      document.querySelectorAll('.sidebar-header-items__end .navbar-item .search-container-wrapper .gsc-input input').forEach(input => {
        if (input) {
          input.setAttribute('placeholder', 'Search the docs ...');
          input.style.paddingLeft = '36px';
        }
      });

      // Check for mobile search container
      const mobileSearchContainer = document.querySelector('.sidebar-header-items__end .navbar-item .search-container-wrapper');
      if (!mobileSearchContainer) continue;

      const mobileToggle = mobileSearchContainer.querySelector('#search-toggle');
      if (mobileToggle && toggle) {
        // Sync mobile toggle with desktop toggle
        mobileToggle.checked = toggle.checked;
        updateMobileSearch();

        // Add event listener to mobile toggle if not already added
        if (!mobileToggle.hasAttribute('data-initialized')) {
          mobileToggle.setAttribute('data-initialized', 'true');
          mobileToggle.addEventListener('change', function() {
            // Sync desktop toggle with mobile toggle
            toggle.checked = this.checked;
            // Trigger change event on desktop toggle to update both
            toggle.dispatchEvent(new Event('change'));
          });
        }
      }
    }
  });

  mobileMenuObserver.observe(document.body, { childList: true, subtree: true });

  // Ensure Google CSE is properly loaded
  if (window.__gcse) {
    window.__gcse.callback = function() {
      // This will run after Google CSE is fully loaded
      if (toggle && toggle.checked) {
        reinitializeGoogleSearch();
      }
    };
  } else {
    window.__gcse = {
      callback: function() {
        if (toggle && toggle.checked) {
          reinitializeGoogleSearch();
        }
      }
    };
  }
});
</script>
</div>
        
          <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/PyTorchKorea/tutorials-kr" title="한국어 튜토리얼 GitHub 저장소" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">한국어 튜토리얼 GitHub 저장소</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discuss.pytorch.kr/" title="파이토치 한국어 커뮤니티" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">파이토치 한국어 커뮤니티</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="recipes/defining_a_neural_network.html">Pytorch를 사용해 신경망 정의하기</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_logs.html">(beta) torch.compile과 함께 TORCH_LOGS 파이썬 API 사용하기</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/what_is_state_dict.html">PyTorch에서 state_dict란 무엇인가요?</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/warmstarting_model_using_parameters_from_a_different_model.html">PyTorch에서 다른 모델의 매개변수를 사용하여 빠르게 모델 시작하기(warmstart)</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/zeroing_out_gradients.html">PyTorch에서 변화도를 0으로 만들기</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/profiler_recipe.html">PyTorch 프로파일러(Profiler)</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/Captum_Recipe.html">Captum을 사용하여 모델 해석하기</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/tensorboard_with_pytorch.html">PyTorch로 TensorBoard 사용하기</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/amp_recipe.html">자동 혼합 정밀도(Automatic Mixed Precision) 가이드</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/tuning_guide.html">성능 튜닝 가이드</a></li>
<li class="toctree-l1"><a class="reference internal" href="compiling_optimizer.html">(beta) Compiling the optimizer with torch.compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/timer_quick_start.html">Timer 빠르게 시작하기</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_compile_backend_ipex.html">Intel® CPU에서의 Intel® Extension for PyTorch* 백엔드</a></li>
<li class="toctree-l1"><a class="reference internal" href="zero_redundancy_optimizer.html">Shard Optimizer States with ZeroRedundancyOptimizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="cuda_rpc.html">Direct Device-to-Device Communication with TensorPipe CUDA RPC</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_comm_debug_mode.html">Getting Started with <code class="docutils literal notranslate"><span class="pre">CommDebugMode</span></code></a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Demonstration of torch.export flow, common challenges and the solutions to address them</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/benchmark.html">PyTorch Benchmark</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/module_load_state_dict_tips.html">Tips for Loading an <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> from a Checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/reasoning_about_shapes.html">PyTorch의 Shape들에 대한 추론</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/swap_tensors.html">Extension points in <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> for <code class="docutils literal notranslate"><span class="pre">load_state_dict</span></code> and tensor subclasses</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_export_aoti_python.html"><code class="docutils literal notranslate"><span class="pre">torch.export</span></code> AOTInductor Tutorial for Python runtime (Beta)</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/tensorboard_with_pytorch.html">PyTorch로 TensorBoard 사용하기</a></li>
<li class="toctree-l1"><a class="reference internal" href="inference_tuning_on_aws_graviton.html">(Beta) PyTorch Inference Performance Tuning on AWS Graviton Processors</a></li>
<li class="toctree-l1"><a class="reference internal" href="amx.html">Leverage Intel® Advanced Matrix Extensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_compile_torch_function_modes.html">(beta) Utilizing Torch Function modes with torch.compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="compiling_optimizer_lr_scheduler.html">(beta) Running the compiled optimizer with an LR Scheduler</a></li>
<li class="toctree-l1"><a class="reference internal" href="foreach_map.html">Explicit horizontal fusion with foreach_map and torch.compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_compile_user_defined_triton_kernel_tutorial.html">사용자 정의 Triton 커널을 ``torch.compile``과 함께 사용하기</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_compile_caching_tutorial.html">Compile Time Caching in <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_compile_caching_configuration_tutorial.html">Compile Time Caching Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="regional_compilation.html">Reducing torch.compile cold start compilation time with regional compilation</a></li>
<li class="toctree-l1"><a class="reference internal" href="regional_aot.html">Reducing AoT cold start compilation time with regional compilation</a></li>
<li class="toctree-l1"><a class="reference internal" href="intel_neural_compressor_for_pytorch.html">Ease-of-use quantization for PyTorch with Intel® Neural Compressor</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_device_mesh.html">Getting Started with DeviceMesh</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_checkpoint_recipe.html">Getting Started with Distributed Checkpoint (DCP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_async_checkpoint_recipe.html">Asynchronous Saving with Distributed Checkpoint (DCP)</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../compilers_index.html" class="nav-link">Compilers</a></li>
    
    <li class="breadcrumb-item active" aria-current="page">Demonstratio...</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
        
    </div>
</div>
</div>
      
    </div>
  
</div>
</div>
              
              
  
<div id="searchbox"></div>
  <article class="bd-article" id="pytorch-article">
    <!-- Hidden breadcrumb schema for SEO only -->
    <div style="display:none;" itemscope itemtype="https://schema.org/BreadcrumbList">
      
      <div itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <link itemprop="item" href="../compilers_index.html">
        <meta itemprop="name" content="Compilers">
        <meta itemprop="position" content="1">
      </div>
      
      <div itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <meta itemprop="name" content="Demonstration of torch.export flow, common challenges and the solutions to address them">
        <meta itemprop="position" content="2">
      </div>
    </div>

    
    <script>
      if ((window.location.href.indexOf("/unstable/") != -1) && (window.location.href.indexOf("/unstable/unstable_index") < 1)) {
        var div = '<div class="prototype-banner"><i class="fa fa-flask" aria-hidden="true"></i> <strong>Unstable feature:</strong> Not typically available in binary distributions like PyPI. Early stage for feedback and testing.</div>'
        document.addEventListener('DOMContentLoaded', function () {
          document.getElementById("pytorch-article").insertAdjacentHTML('afterBegin', div);
        });
      }
    </script>
    
    
    <div class="pytorch-call-to-action-links">
      <div id="tutorial-type">recipes/torch_export_challenges_solutions</div>
      <a id="colab-link" data-behavior="call-to-action-event" data-response="Run in Google Colab" target="_blank">
        <div id="google-colab-link">
          <img class="call-to-action-img" src="../_static/img/pytorch-colab.svg" />
          <div class="call-to-action-desktop-view">Run in Google Colab</div>
          <div class="call-to-action-mobile-view">Colab</div>
        </div>
      </a>
      <a id="notebook-link" data-behavior="call-to-action-event" data-response="Download Notebook">
        <div id="download-notebook-link">
          <img class="call-to-action-notebook-img" src="../_static/img/pytorch-download.svg" />
          <div class="call-to-action-desktop-view">Download Notebook</div>
          <div class="call-to-action-mobile-view">Notebook</div>
        </div>
      </a>
      <a id="github-link" data-behavior="call-to-action-event" data-response="View on Github" target="_blank">
        <div id="github-view-link">
          <img class="call-to-action-img" src="../_static/img/pytorch-github.svg" />
          <div class="call-to-action-desktop-view">View on GitHub</div>
          <div class="call-to-action-mobile-view">GitHub</div>
        </div>
      </a>
    </div>
    

    
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="demonstration-of-torch-export-flow-common-challenges-and-the-solutions-to-address-them">
<h1>Demonstration of torch.export flow, common challenges and the solutions to address them<a class="headerlink" href="#demonstration-of-torch-export-flow-common-challenges-and-the-solutions-to-address-them" title="Link to this heading">#</a></h1>
<p><strong>Authors:</strong> <a class="reference external" href="https://github.com/agunapal">Ankith Gunapal</a>, <a class="reference external" href="https://github.com/JordiFB">Jordi Ramon</a>, <a class="reference external" href="https://github.com/macarran">Marcos Carranza</a></p>
<p>In the <a class="reference external" href="https://tutorials.pytorch.kr/intermediate/torch_export_tutorial.html">Introduction to torch.export Tutorial</a> , we learned how to use <a class="reference external" href="https://pytorch.org/docs/stable/export.html">torch.export</a>.
This tutorial expands on the previous one and explores the process of exporting popular models with code, as well as addresses common challenges that may arise with <code class="docutils literal notranslate"><span class="pre">torch.export</span></code>.</p>
<p>In this tutorial, you will learn how to export models for these use cases:</p>
<ul class="simple">
<li><p>Video classifier (<a class="reference external" href="https://pytorch.org/vision/main/models/video_mvit.html">MViT</a>)</p></li>
<li><p>Automatic Speech Recognition (<a class="reference external" href="https://huggingface.co/openai/whisper-tiny">OpenAI Whisper-Tiny</a>)</p></li>
<li><p>Image Captioning (<a class="reference external" href="https://github.com/salesforce/BLIP">BLIP</a>)</p></li>
<li><p>Promptable Image Segmentation (<a class="reference external" href="https://ai.meta.com/sam2/">SAM2</a>)</p></li>
</ul>
<p>Each of the four models were chosen to demonstrate unique features of <cite>torch.export</cite>, as well as some practical considerations
and issues faced in the implementation.</p>
<section id="prerequisites">
<h2>Prerequisites<a class="headerlink" href="#prerequisites" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>PyTorch 2.4 or later</p></li>
<li><p>Basic understanding of <code class="docutils literal notranslate"><span class="pre">torch.export</span></code> and PyTorch Eager inference.</p></li>
</ul>
</section>
<section id="key-requirement-for-torch-export-no-graph-break">
<h2>Key requirement for <code class="docutils literal notranslate"><span class="pre">torch.export</span></code>: No graph break<a class="headerlink" href="#key-requirement-for-torch-export-no-graph-break" title="Link to this heading">#</a></h2>
<p><a class="reference external" href="https://tutorials.pytorch.kr/intermediate/torch_compile_tutorial.html">torch.compile</a> speeds up PyTorch code by using JIT to compile PyTorch code into optimized kernels. It optimizes the given model
using <code class="docutils literal notranslate"><span class="pre">TorchDynamo</span></code> and creates an optimized graph , which is then lowered into the hardware using the backend specified in the API.
When TorchDynamo encounters unsupported Python features, it breaks the computation graph, lets the default Python interpreter
handle the unsupported code, and then resumes capturing the graph. This break in the computation graph is called a <a class="reference external" href="https://tutorials.pytorch.kr/intermediate/torch_compile_tutorial.html#torchdynamo-and-fx-graphs">graph break</a>.</p>
<p>One of the key differences between <code class="docutils literal notranslate"><span class="pre">torch.export</span></code> and <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code> is that <code class="docutils literal notranslate"><span class="pre">torch.export</span></code> doesn’t support graph breaks
which means that the entire model or part of the model that you are exporting needs to be a single graph. This is because handling graph breaks
involves interpreting the unsupported operation with default Python evaluation, which is incompatible with what <code class="docutils literal notranslate"><span class="pre">torch.export</span></code> is
designed for. You can read details about the differences between the various PyTorch frameworks in this <a class="reference external" href="https://pytorch.org/docs/main/export.html#existing-frameworks">link</a></p>
<p>You can identify graph breaks in your program by using the following command:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="nv">TORCH_LOGS</span><span class="o">=</span><span class="s2">&quot;graph_breaks&quot;</span><span class="w"> </span>python<span class="w"> </span>&lt;file_name&gt;.py
</pre></div>
</div>
<p>You will need to modify your program to get rid of graph breaks. Once resolved, you are ready to export the model.
PyTorch runs <a class="reference external" href="https://hud.pytorch.org/benchmark/compilers">nightly benchmarks</a> for <cite>torch.compile</cite> on popular HuggingFace and TIMM models.
Most of these models have no graph breaks.</p>
<p>The models in this recipe have no graph breaks, but fail with <cite>torch.export</cite>.</p>
</section>
<section id="video-classification">
<h2>Video Classification<a class="headerlink" href="#video-classification" title="Link to this heading">#</a></h2>
<p>MViT is a class of models based on <a class="reference external" href="https://arxiv.org/abs/2104.11227">MultiScale Vision Transformers</a>. This model has been trained for video classification using the <a class="reference external" href="https://arxiv.org/abs/1705.06950">Kinetics-400 Dataset</a>.
This model with a relevant dataset can be used for action recognition in the context of gaming.</p>
<p>The code below exports MViT by tracing with <code class="docutils literal notranslate"><span class="pre">batch_size=2</span></code> and then checks if the ExportedProgram can run with <code class="docutils literal notranslate"><span class="pre">batch_size=4</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchvision.models.video</span><span class="w"> </span><span class="kn">import</span> <span class="n">MViT_V1_B_Weights</span><span class="p">,</span> <span class="n">mvit_v1_b</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">traceback</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">tb</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">mvit_v1_b</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">MViT_V1_B_Weights</span><span class="o">.</span><span class="n">DEFAULT</span><span class="p">)</span>

<span class="c1"># Create a batch of 2 videos, each with 16 frames of shape 224x224x3.</span>
<span class="n">input_frames</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">16</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="c1"># Transpose to get [1, 3, num_clips, height, width].</span>
<span class="n">input_frames</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">input_frames</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>

<span class="c1"># Export the model.</span>
<span class="n">exported_program</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">export</span><span class="o">.</span><span class="n">export</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="p">(</span><span class="n">input_frames</span><span class="p">,),</span>
<span class="p">)</span>

<span class="c1"># Create a batch of 4 videos, each with 16 frames of shape 224x224x3.</span>
<span class="n">input_frames</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">16</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">input_frames</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">input_frames</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">exported_program</span><span class="o">.</span><span class="n">module</span><span class="p">()(</span><span class="n">input_frames</span><span class="p">)</span>
<span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
    <span class="n">tb</span><span class="o">.</span><span class="n">print_exc</span><span class="p">()</span>
</pre></div>
</div>
<section id="error-static-batch-size">
<h3>Error: Static batch size<a class="headerlink" href="#error-static-batch-size" title="Link to this heading">#</a></h3>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="w">    </span>raise<span class="w"> </span>RuntimeError<span class="o">(</span>
RuntimeError:<span class="w"> </span>Expected<span class="w"> </span>input<span class="w"> </span>at<span class="w"> </span>*args<span class="o">[</span><span class="m">0</span><span class="o">]</span>.shape<span class="o">[</span><span class="m">0</span><span class="o">]</span><span class="w"> </span>to<span class="w"> </span>be<span class="w"> </span>equal<span class="w"> </span>to<span class="w"> </span><span class="m">2</span>,<span class="w"> </span>but<span class="w"> </span>got<span class="w"> </span><span class="m">4</span>
</pre></div>
</div>
<p>By default, the exporting flow will trace the program assuming that all input shapes are static, so if you run the program with
input shapes that are different than the ones you used while tracing, you will run into an error.</p>
</section>
<section id="solution">
<h3>Solution<a class="headerlink" href="#solution" title="Link to this heading">#</a></h3>
<p>To address the error, we specify the first dimension of the input (<code class="docutils literal notranslate"><span class="pre">batch_size</span></code>) to be dynamic , specifying the expected range of <code class="docutils literal notranslate"><span class="pre">batch_size</span></code>.
In the corrected example shown below, we specify that the expected <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> can range from 1 to 16.
One detail to notice that <code class="docutils literal notranslate"><span class="pre">min=2</span></code>  is not a bug and is explained in <a class="reference external" href="https://docs.google.com/document/d/16VPOa3d-Liikf48teAOmxLc92rgvJdfosIy-yoT38Io/edit?fbclid=IwAR3HNwmmexcitV0pbZm_x1a4ykdXZ9th_eJWK-3hBtVgKnrkmemz6Pm5jRQ#heading=h.ez923tomjvyk">The 0/1 Specialization Problem</a>. A detailed description of dynamic shapes
for <code class="docutils literal notranslate"><span class="pre">torch.export</span></code> can be found in the export tutorial. The code shown below demonstrates how to export mViT with dynamic batch sizes:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchvision.models.video</span><span class="w"> </span><span class="kn">import</span> <span class="n">MViT_V1_B_Weights</span><span class="p">,</span> <span class="n">mvit_v1_b</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">traceback</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">tb</span>


<span class="n">model</span> <span class="o">=</span> <span class="n">mvit_v1_b</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">MViT_V1_B_Weights</span><span class="o">.</span><span class="n">DEFAULT</span><span class="p">)</span>

<span class="c1"># Create a batch of 2 videos, each with 16 frames of shape 224x224x3.</span>
<span class="n">input_frames</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">16</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="c1"># Transpose to get [1, 3, num_clips, height, width].</span>
<span class="n">input_frames</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">input_frames</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>

<span class="c1"># Export the model.</span>
<span class="n">batch_dim</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">export</span><span class="o">.</span><span class="n">Dim</span><span class="p">(</span><span class="s2">&quot;batch&quot;</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">exported_program</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">export</span><span class="o">.</span><span class="n">export</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="p">(</span><span class="n">input_frames</span><span class="p">,),</span>
    <span class="c1"># Specify the first dimension of the input x as dynamic</span>
    <span class="n">dynamic_shapes</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;x&quot;</span><span class="p">:</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="n">batch_dim</span><span class="p">}},</span>
<span class="p">)</span>

<span class="c1"># Create a batch of 4 videos, each with 16 frames of shape 224x224x3.</span>
<span class="n">input_frames</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">16</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">input_frames</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">input_frames</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">exported_program</span><span class="o">.</span><span class="n">module</span><span class="p">()(</span><span class="n">input_frames</span><span class="p">)</span>
<span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
    <span class="n">tb</span><span class="o">.</span><span class="n">print_exc</span><span class="p">()</span>
</pre></div>
</div>
</section>
</section>
<section id="automatic-speech-recognition">
<h2>Automatic Speech Recognition<a class="headerlink" href="#automatic-speech-recognition" title="Link to this heading">#</a></h2>
<p><strong>Automatic Speech Recognition</strong> (ASR) is the use of machine learning to transcribe spoken language into text.
<a class="reference external" href="https://arxiv.org/abs/2212.04356">Whisper</a> is a Transformer based encoder-decoder model from OpenAI, which was trained on 680k hours of labelled data for ASR and speech translation.
The code below tries to export <code class="docutils literal notranslate"><span class="pre">whisper-tiny</span></code> model for ASR.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">WhisperProcessor</span><span class="p">,</span> <span class="n">WhisperForConditionalGeneration</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>

<span class="c1"># load model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">WhisperForConditionalGeneration</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;openai/whisper-tiny&quot;</span><span class="p">)</span>

<span class="c1"># dummy inputs for exporting the model</span>
<span class="n">input_features</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">80</span><span class="p">,</span> <span class="mi">3000</span><span class="p">)</span>
<span class="n">attention_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3000</span><span class="p">)</span>
<span class="n">decoder_input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span> <span class="p">,</span> <span class="mi">1</span><span class="p">]])</span> <span class="o">*</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">decoder_start_token_id</span>

<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="n">exported_program</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">export</span><span class="o">.</span><span class="n">ExportedProgram</span><span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">export</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">input_features</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">decoder_input_ids</span><span class="p">,))</span>
</pre></div>
</div>
<section id="error-strict-tracing-with-torchdynamo">
<h3>Error: strict tracing with TorchDynamo<a class="headerlink" href="#error-strict-tracing-with-torchdynamo" title="Link to this heading">#</a></h3>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">torch._dynamo.exc.InternalTorchDynamoError: AttributeError: &#39;DynamicCache&#39; object has no attribute &#39;key_cache&#39;</span>
</pre></div>
</div>
<p>By default <code class="docutils literal notranslate"><span class="pre">torch.export</span></code> traces your code using <a class="reference external" href="https://pytorch.org/docs/stable/torch.compiler_dynamo_overview.html">TorchDynamo</a>, a byte-code analysis engine,  which symbolically analyzes your code and builds a graph.
This analysis provides a stronger guarantee about safety but not all Python code is supported. When we export the <code class="docutils literal notranslate"><span class="pre">whisper-tiny</span></code> model  using the
default strict mode, it typically returns an error in Dynamo due to an unsupported feature. To understand why this errors in Dynamo, you can refer to this <a class="reference external" href="https://github.com/pytorch/pytorch/issues/144906">GitHub issue</a>.</p>
</section>
<section id="id1">
<h3>Solution<a class="headerlink" href="#id1" title="Link to this heading">#</a></h3>
<p>To address the above error , <code class="docutils literal notranslate"><span class="pre">torch.export</span></code> supports  the <code class="docutils literal notranslate"><span class="pre">non_strict</span></code> mode where the program is traced using the Python interpreter, which works similar to
PyTorch eager execution. The only difference is that all <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> objects will be replaced by <code class="docutils literal notranslate"><span class="pre">ProxyTensors</span></code>, which will record all their operations into
a graph. By using <code class="docutils literal notranslate"><span class="pre">strict=False</span></code>, we are able to export the program.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">WhisperProcessor</span><span class="p">,</span> <span class="n">WhisperForConditionalGeneration</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>

<span class="c1"># load model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">WhisperForConditionalGeneration</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;openai/whisper-tiny&quot;</span><span class="p">)</span>

<span class="c1"># dummy inputs for exporting the model</span>
<span class="n">input_features</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">80</span><span class="p">,</span> <span class="mi">3000</span><span class="p">)</span>
<span class="n">attention_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3000</span><span class="p">)</span>
<span class="n">decoder_input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span> <span class="p">,</span> <span class="mi">1</span><span class="p">]])</span> <span class="o">*</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">decoder_start_token_id</span>

<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="n">exported_program</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">export</span><span class="o">.</span><span class="n">ExportedProgram</span><span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">export</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">input_features</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">decoder_input_ids</span><span class="p">,),</span> <span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="image-captioning">
<h2>Image Captioning<a class="headerlink" href="#image-captioning" title="Link to this heading">#</a></h2>
<p><strong>Image Captioning</strong> is the task of defining the contents of an image in words. In the context of gaming, Image Captioning can be used to enhance the
gameplay experience by dynamically generating text description of the various game objects in the scene, thereby providing the gamer with additional
details. <a class="reference external" href="https://arxiv.org/pdf/2201.12086">BLIP</a> is a popular model for Image Captioning <a class="reference external" href="https://github.com/salesforce/BLIP">released by SalesForce Research</a>. The code below tries to export BLIP with <code class="docutils literal notranslate"><span class="pre">batch_size=1</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">models.blip</span><span class="w"> </span><span class="kn">import</span> <span class="n">blip_decoder</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
<span class="n">image_size</span> <span class="o">=</span> <span class="mi">384</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span><span class="mi">384</span><span class="p">,</span><span class="mi">384</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">caption_input</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>

<span class="n">model_url</span> <span class="o">=</span> <span class="s1">&#39;https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_capfilt_large.pth&#39;</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">blip_decoder</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="n">model_url</span><span class="p">,</span> <span class="n">image_size</span><span class="o">=</span><span class="n">image_size</span><span class="p">,</span> <span class="n">vit</span><span class="o">=</span><span class="s1">&#39;base&#39;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="n">exported_program</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">export</span><span class="o">.</span><span class="n">ExportedProgram</span><span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">export</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">caption_input</span><span class="p">,),</span> <span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<section id="error-cannot-mutate-tensors-with-frozen-storage">
<h3>Error: Cannot mutate tensors with frozen storage<a class="headerlink" href="#error-cannot-mutate-tensors-with-frozen-storage" title="Link to this heading">#</a></h3>
<p>While exporting a model, it might fail because the model implementation might contain certain Python operations which are not yet supported by <code class="docutils literal notranslate"><span class="pre">torch.export</span></code>.
Some of these failures may have a workaround. BLIP is an example where the original model errors, which can be resolved by making a small change in the code.
<code class="docutils literal notranslate"><span class="pre">torch.export</span></code> lists the common cases of supported and unsupported operations in <a class="reference external" href="https://pytorch.org/docs/main/generated/exportdb/index.html">ExportDB</a> and shows how you can modify your code to make it export compatible.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">File &quot;/BLIP/models/blip.py&quot;, line 112, in forward</span>
<span class="go">    text.input_ids[:,0] = self.tokenizer.bos_token_id</span>
<span class="go">  File &quot;/anaconda3/envs/export/lib/python3.10/site-packages/torch/_subclasses/functional_tensor.py&quot;, line 545, in __torch_dispatch__</span>
<span class="go">    outs_unwrapped = func._op_dk(</span>
<span class="go">RuntimeError: cannot mutate tensors with frozen storage</span>
</pre></div>
</div>
</section>
<section id="id2">
<h3>Solution<a class="headerlink" href="#id2" title="Link to this heading">#</a></h3>
<p>Clone the <a class="reference external" href="https://github.com/salesforce/BLIP/blob/main/models/blip.py#L112">tensor</a> where export fails.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">text</span><span class="o">.</span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">input_ids</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="c1"># clone the tensor</span>
<span class="n">text</span><span class="o">.</span><span class="n">input_ids</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">bos_token_id</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">참고</p>
<p>This constraint has been relaxed in PyTorch 2.7 nightlies. This should work out-of-the-box in PyTorch 2.7</p>
</div>
</section>
</section>
<section id="promptable-image-segmentation">
<h2>Promptable Image Segmentation<a class="headerlink" href="#promptable-image-segmentation" title="Link to this heading">#</a></h2>
<p><strong>Image segmentation</strong> is a computer vision technique that divides a digital image into distinct groups of pixels, or segments, based on their characteristics.
<a class="reference external" href="https://ai.meta.com/blog/segment-anything-foundation-model-image-segmentation/">Segment Anything Model (SAM)</a>) introduced promptable image segmentation, which predicts object masks given prompts that indicate the desired object. <a class="reference external" href="https://ai.meta.com/sam2/">SAM 2</a> is
the first unified model for segmenting objects across images and videos. The <a class="reference external" href="https://github.com/facebookresearch/sam2/blob/main/sam2/sam2_image_predictor.py#L20">SAM2ImagePredictor</a> class provides an easy interface to the model for prompting
the model. The model can take as input both point and box prompts, as well as masks from the previous iteration of prediction. Since SAM2 provides strong
zero-shot performance for object tracking, it can be used for tracking game objects in a scene.</p>
<p>The tensor operations in the predict method of <a class="reference external" href="https://github.com/facebookresearch/sam2/blob/main/sam2/sam2_image_predictor.py#L20">SAM2ImagePredictor</a>  are happening in the <a class="reference external" href="https://github.com/facebookresearch/sam2/blob/main/sam2/sam2_image_predictor.py#L291">_predict</a> method. So, we try to export like this.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ep</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">export</span><span class="o">.</span><span class="n">export</span><span class="p">(</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_predict</span><span class="p">,</span>
    <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">unnorm_coords</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">unnorm_box</span><span class="p">,</span> <span class="n">mask_input</span><span class="p">,</span> <span class="n">multimask_output</span><span class="p">),</span>
    <span class="n">kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;return_logits&quot;</span><span class="p">:</span> <span class="n">return_logits</span><span class="p">},</span>
    <span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<section id="error-model-is-not-of-type-torch-nn-module">
<h3>Error: Model is not of type <code class="docutils literal notranslate"><span class="pre">torch.nn.Module</span></code><a class="headerlink" href="#error-model-is-not-of-type-torch-nn-module" title="Link to this heading">#</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">torch.export</span></code> expects the module to be of type <code class="docutils literal notranslate"><span class="pre">torch.nn.Module</span></code>. However, the module we are trying to export is a class method. Hence it errors.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">Traceback (most recent call last):</span>
<span class="go">  File &quot;/sam2/image_predict.py&quot;, line 20, in &lt;module&gt;</span>
<span class="go">    masks, scores, _ = predictor.predict(</span>
<span class="go">  File &quot;/sam2/sam2/sam2_image_predictor.py&quot;, line 312, in predict</span>
<span class="go">    ep = torch.export.export(</span>
<span class="go">  File &quot;python3.10/site-packages/torch/export/__init__.py&quot;, line 359, in export</span>
<span class="go">    raise ValueError(</span>
<span class="go">ValueError: Expected `mod` to be an instance of `torch.nn.Module`, got &lt;class &#39;method&#39;&gt;.</span>
</pre></div>
</div>
</section>
<section id="id3">
<h3>Solution<a class="headerlink" href="#id3" title="Link to this heading">#</a></h3>
<p>We write a helper class, which inherits from <code class="docutils literal notranslate"><span class="pre">torch.nn.Module</span></code> and call the <code class="docutils literal notranslate"><span class="pre">_predict</span> <span class="pre">method</span></code> in the <code class="docutils literal notranslate"><span class="pre">forward</span></code> method of the class. The complete code can be found <a class="reference external" href="https://github.com/anijain2305/sam2/blob/ued/sam2/sam2_image_predictor.py#L293-L311">here</a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">ExportHelper</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_predict</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

 <span class="n">model_to_export</span> <span class="o">=</span> <span class="n">ExportHelper</span><span class="p">()</span>
 <span class="n">ep</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">export</span><span class="o">.</span><span class="n">export</span><span class="p">(</span>
      <span class="n">model_to_export</span><span class="p">,</span>
      <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">unnorm_coords</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">unnorm_box</span><span class="p">,</span> <span class="n">mask_input</span><span class="p">,</span>  <span class="n">multimask_output</span><span class="p">),</span>
      <span class="n">kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;return_logits&quot;</span><span class="p">:</span> <span class="n">return_logits</span><span class="p">},</span>
      <span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
      <span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="conclusion">
<h2>Conclusion<a class="headerlink" href="#conclusion" title="Link to this heading">#</a></h2>
<p>In this tutorial, we have learned how to use <code class="docutils literal notranslate"><span class="pre">torch.export</span></code> to export models for popular use cases by addressing challenges through correct configuration and simple code modifications.
Once you are able to export a model, you can lower the <code class="docutils literal notranslate"><span class="pre">ExportedProgram</span></code> into your hardware using <a class="reference external" href="https://pytorch.org/docs/stable/torch.compiler_aot_inductor.html">AOTInductor</a> in case of servers and <a class="reference external" href="https://pytorch.org/executorch/stable/index.html">ExecuTorch</a> in case of edge device.
To learn more about <code class="docutils literal notranslate"><span class="pre">AOTInductor</span></code> (AOTI), please refer to the <a class="reference external" href="https://tutorials.pytorch.kr/recipes/torch_export_aoti_python.html">AOTI tutorial</a>.
To learn more about <code class="docutils literal notranslate"><span class="pre">ExecuTorch</span></code> , please refer to the <a class="reference external" href="https://pytorch.org/executorch/stable/tutorials/export-to-executorch-tutorial.html">ExecuTorch tutorial</a>.</p>
</section>
</section>


                </article>
              
  </article>
  
              
              
                <footer class="bd-footer-article">
                  <div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item">
<div class="feedback">
  
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
        
    </div>
</div>

  <div class="feedback-send">
    <button class="feedback-btn"
            onclick="openGitHubIssue()"
            data-bs-title="Create a GitHub Issue"
            data-bs-placement="bottom"
            data-bs-toggle="tooltip"
            data-gtm="feedback-btn-click">Send Feedback
    </button>
  </div>
</div>

<div class="prev-next-area">
    <a class="left-prev"
       href="torch_compiler_set_stance_tutorial.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">이전</p>
        <p class="prev-next-title">Dynamic Compilation Control with <code class="docutils literal notranslate"><span class="pre">torch.compiler.set_stance</span></code></p>
      </div>
    </a>
    <a class="right-next"
       href="compiling_optimizer.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">다음</p>
        <p class="prev-next-title">(beta) Compiling the optimizer with torch.compile</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>

<div class="footer-info">
  <p class="copyright">
    
      
        © Copyright 2018-2025, PyTorch &amp; 파이토치 한국 사용자 모임(PyTorchKR).
      
      <br/>
    
  </p>

  <p class="theme-version">
    Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
  </p>
</div>
</div>
  
</div>
                </footer>
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="torch_compiler_set_stance_tutorial.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">이전</p>
        <p class="prev-next-title">Dynamic Compilation Control with <code class="docutils literal notranslate"><span class="pre">torch.compiler.set_stance</span></code></p>
      </div>
    </a>
    <a class="right-next"
       href="compiling_optimizer.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">다음</p>
        <p class="prev-next-title">(beta) Compiling the optimizer with torch.compile</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc">
<div class="sidebar-secondary-items sidebar-secondary__inner">
    
       <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prerequisites">Prerequisites</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#key-requirement-for-torch-export-no-graph-break">Key requirement for <code class="docutils literal notranslate"><span class="pre">torch.export</span></code>: No graph break</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#video-classification">Video Classification</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#error-static-batch-size">Error: Static batch size</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#solution">Solution</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#automatic-speech-recognition">Automatic Speech Recognition</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#error-strict-tracing-with-torchdynamo">Error: strict tracing with TorchDynamo</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Solution</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#image-captioning">Image Captioning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#error-cannot-mutate-tensors-with-frozen-storage">Error: Cannot mutate tensors with frozen storage</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Solution</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#promptable-image-segmentation">Promptable Image Segmentation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#error-model-is-not-of-type-torch-nn-module">Error: Model is not of type <code class="docutils literal notranslate"><span class="pre">torch.nn.Module</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">Solution</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">Conclusion</a></li>
</ul>
  </nav></div>
    




<div class="sidebar-secondary-item">
  <div class="sidebar-heading">PyTorch Libraries</div>
  <ul style="list-style-type: none; padding: 0; padding-bottom: 80px;">
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/ao" style="color: var(--pst-color-text-muted)">torchao</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchrec" style="color: var(--pst-color-text-muted)">torchrec</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchft" style="color: var(--pst-color-text-muted)">torchft</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchcodec" style="color: var(--pst-color-text-muted)">TorchCodec</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/vision" style="color: var(--pst-color-text-muted)">torchvision</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/executorch" style="color: var(--pst-color-text-muted)">ExecuTorch</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/xla" style="color: var(--pst-color-text-muted)">PyTorch on XLA Devices</a></li>
  
  </ul>
</div>

</div>
</div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <div class="container-fluid docs-tutorials-resources">
  <div class="container">
    <div class="row">
      <div class="col-md-4 text-center">
        <h2>PyTorchKorea @ GitHub</h2>
        <p>파이토치 한국 사용자 모임을 GitHub에서 만나보세요.</p>
        <a class="with-right-arrow" href="https://github.com/PyTorchKorea">GitHub로 이동</a>
      </div>

      <div class="col-md-4 text-center">
        <h2>한국어 튜토리얼</h2>
        <p>한국어로 번역 중인 파이토치 튜토리얼을 만나보세요.</p>
        <a class="with-right-arrow" href="https://tutorials.pytorch.kr/">튜토리얼로 이동</a>
      </div>

      <div class="col-md-4 text-center">
        <h2>한국어 커뮤니티</h2>
        <p>다른 사용자들과 의견을 나누고, 도와주세요!</p>
        <a class="with-right-arrow" href="https://discuss.pytorch.kr/">커뮤니티로 이동</a>
      </div>
    </div>
  </div>
</div>

<footer class="site-footer">
  <div class="container footer-container">
    <div class="footer-logo-wrapper">
      <a href="https://pytorch.kr/" class="footer-logo"></a>
    </div>

    <div class="footer-links-wrapper">
      <div class="footer-links-col">
        <ul>
          <li class="list-title"><a href="https://pytorch.kr/">파이토치 한국 사용자 모임</a></li>
          <li><a href="https://pytorch.kr/about">사용자 모임 소개</a></li>
          <li><a href="https://pytorch.kr/contributors">기여해주신 분들</a></li>
          <li><a href="https://pytorch.kr/resources/">리소스</a></li>
          <li><a href="https://pytorch.kr/coc">행동 강령</a></li>
        </ul>
      </div>
    </div>

    <div class="trademark-disclaimer">
      <ul>
        <li>이 사이트는 독립적인 파이토치 사용자 커뮤니티로, 최신 버전이 아니거나 잘못된 내용이 포함되어 있을 수 있습니다. This site is an independent user community and may be out of date or contain incorrect information.</li>
        <li><a href="https://pytorch.kr/coc">행동 강령</a>을 읽고 지켜주세요. PyTorch 공식 로고 사용 규정은 <a href="https://www.linuxfoundation.org/policies/">Linux Foundation의 정책</a>을 따릅니다. Please read and follow <a href="https://pytorch.kr/coc">our code of conduct</a>. All PyTorch trademark policy applicable to <a href="https://www.linuxfoundation.org/policies/">Linux Foundation's policies</a>.</li>
      </ul>
    </div>
  </div>
</footer>

<div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../_static/img/pytorch-x.svg">
  </div>
</div>
  
  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2018-2025, PyTorch &amp; 파이토치 한국 사용자 모임(PyTorchKR).
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.2.6 버전으로 생성되었습니다.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
</p></div>
      
    </div>
  
</div>

  </footer>
  <script type="application/ld+json">
    {
       "@context": "https://schema.org",
       "@type": "Article",
       "name": "Demonstration of torch.export flow, common challenges and the solutions to address them",
       "headline": "Demonstration of torch.export flow, common challenges and the solutions to address them",
       "description": "PyTorch Documentation. Explore PyTorch, an open-source machine learning library that accelerates the path from research prototyping to production deployment. Discover tutorials, API references, and guides to help you build and deploy deep learning models efficiently.",
       "url": "/recipes/torch_export_challenges_solutions.html",
       "articleBody": "Demonstration of torch.export flow, common challenges and the solutions to address them# Authors: Ankith Gunapal, Jordi Ramon, Marcos Carranza In the Introduction to torch.export Tutorial , we learned how to use torch.export. This tutorial expands on the previous one and explores the process of exporting popular models with code, as well as addresses common challenges that may arise with torch.export. In this tutorial, you will learn how to export models for these use cases: Video classifier (MViT) Automatic Speech Recognition (OpenAI Whisper-Tiny) Image Captioning (BLIP) Promptable Image Segmentation (SAM2) Each of the four models were chosen to demonstrate unique features of torch.export, as well as some practical considerations and issues faced in the implementation. Prerequisites# PyTorch 2.4 or later Basic understanding of torch.export and PyTorch Eager inference. Key requirement for torch.export: No graph break# torch.compile speeds up PyTorch code by using JIT to compile PyTorch code into optimized kernels. It optimizes the given model using TorchDynamo and creates an optimized graph , which is then lowered into the hardware using the backend specified in the API. When TorchDynamo encounters unsupported Python features, it breaks the computation graph, lets the default Python interpreter handle the unsupported code, and then resumes capturing the graph. This break in the computation graph is called a graph break. One of the key differences between torch.export and torch.compile is that torch.export doesn\u2019t support graph breaks which means that the entire model or part of the model that you are exporting needs to be a single graph. This is because handling graph breaks involves interpreting the unsupported operation with default Python evaluation, which is incompatible with what torch.export is designed for. You can read details about the differences between the various PyTorch frameworks in this link You can identify graph breaks in your program by using the following command: TORCH_LOGS=\"graph_breaks\" python \u003cfile_name\u003e.py You will need to modify your program to get rid of graph breaks. Once resolved, you are ready to export the model. PyTorch runs nightly benchmarks for torch.compile on popular HuggingFace and TIMM models. Most of these models have no graph breaks. The models in this recipe have no graph breaks, but fail with torch.export. Video Classification# MViT is a class of models based on MultiScale Vision Transformers. This model has been trained for video classification using the Kinetics-400 Dataset. This model with a relevant dataset can be used for action recognition in the context of gaming. The code below exports MViT by tracing with batch_size=2 and then checks if the ExportedProgram can run with batch_size=4. import numpy as np import torch from torchvision.models.video import MViT_V1_B_Weights, mvit_v1_b import traceback as tb model = mvit_v1_b(weights=MViT_V1_B_Weights.DEFAULT) # Create a batch of 2 videos, each with 16 frames of shape 224x224x3. input_frames = torch.randn(2,16, 224, 224, 3) # Transpose to get [1, 3, num_clips, height, width]. input_frames = np.transpose(input_frames, (0, 4, 1, 2, 3)) # Export the model. exported_program = torch.export.export( model, (input_frames,), ) # Create a batch of 4 videos, each with 16 frames of shape 224x224x3. input_frames = torch.randn(4,16, 224, 224, 3) input_frames = np.transpose(input_frames, (0, 4, 1, 2, 3)) try: exported_program.module()(input_frames) except Exception: tb.print_exc() Error: Static batch size# raise RuntimeError( RuntimeError: Expected input at *args[0].shape[0] to be equal to 2, but got 4 By default, the exporting flow will trace the program assuming that all input shapes are static, so if you run the program with input shapes that are different than the ones you used while tracing, you will run into an error. Solution# To address the error, we specify the first dimension of the input (batch_size) to be dynamic , specifying the expected range of batch_size. In the corrected example shown below, we specify that the expected batch_size can range from 1 to 16. One detail to notice that min=2 is not a bug and is explained in The 0/1 Specialization Problem. A detailed description of dynamic shapes for torch.export can be found in the export tutorial. The code shown below demonstrates how to export mViT with dynamic batch sizes: import numpy as np import torch from torchvision.models.video import MViT_V1_B_Weights, mvit_v1_b import traceback as tb model = mvit_v1_b(weights=MViT_V1_B_Weights.DEFAULT) # Create a batch of 2 videos, each with 16 frames of shape 224x224x3. input_frames = torch.randn(2,16, 224, 224, 3) # Transpose to get [1, 3, num_clips, height, width]. input_frames = np.transpose(input_frames, (0, 4, 1, 2, 3)) # Export the model. batch_dim = torch.export.Dim(\"batch\", min=2, max=16) exported_program = torch.export.export( model, (input_frames,), # Specify the first dimension of the input x as dynamic dynamic_shapes={\"x\": {0: batch_dim}}, ) # Create a batch of 4 videos, each with 16 frames of shape 224x224x3. input_frames = torch.randn(4,16, 224, 224, 3) input_frames = np.transpose(input_frames, (0, 4, 1, 2, 3)) try: exported_program.module()(input_frames) except Exception: tb.print_exc() Automatic Speech Recognition# Automatic Speech Recognition (ASR) is the use of machine learning to transcribe spoken language into text. Whisper is a Transformer based encoder-decoder model from OpenAI, which was trained on 680k hours of labelled data for ASR and speech translation. The code below tries to export whisper-tiny model for ASR. import torch from transformers import WhisperProcessor, WhisperForConditionalGeneration from datasets import load_dataset # load model model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-tiny\") # dummy inputs for exporting the model input_features = torch.randn(1,80, 3000) attention_mask = torch.ones(1, 3000) decoder_input_ids = torch.tensor([[1, 1, 1 , 1]]) * model.config.decoder_start_token_id model.eval() exported_program: torch.export.ExportedProgram= torch.export.export(model, args=(input_features, attention_mask, decoder_input_ids,)) Error: strict tracing with TorchDynamo# torch._dynamo.exc.InternalTorchDynamoError: AttributeError: \u0027DynamicCache\u0027 object has no attribute \u0027key_cache\u0027 By default torch.export traces your code using TorchDynamo, a byte-code analysis engine, which symbolically analyzes your code and builds a graph. This analysis provides a stronger guarantee about safety but not all Python code is supported. When we export the whisper-tiny model using the default strict mode, it typically returns an error in Dynamo due to an unsupported feature. To understand why this errors in Dynamo, you can refer to this GitHub issue. Solution# To address the above error , torch.export supports the non_strict mode where the program is traced using the Python interpreter, which works similar to PyTorch eager execution. The only difference is that all Tensor objects will be replaced by ProxyTensors, which will record all their operations into a graph. By using strict=False, we are able to export the program. import torch from transformers import WhisperProcessor, WhisperForConditionalGeneration from datasets import load_dataset # load model model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-tiny\") # dummy inputs for exporting the model input_features = torch.randn(1,80, 3000) attention_mask = torch.ones(1, 3000) decoder_input_ids = torch.tensor([[1, 1, 1 , 1]]) * model.config.decoder_start_token_id model.eval() exported_program: torch.export.ExportedProgram= torch.export.export(model, args=(input_features, attention_mask, decoder_input_ids,), strict=False) Image Captioning# Image Captioning is the task of defining the contents of an image in words. In the context of gaming, Image Captioning can be used to enhance the gameplay experience by dynamically generating text description of the various game objects in the scene, thereby providing the gamer with additional details. BLIP is a popular model for Image Captioning released by SalesForce Research. The code below tries to export BLIP with batch_size=1. import torch from models.blip import blip_decoder device = torch.device(\u0027cuda\u0027 if torch.cuda.is_available() else \u0027cpu\u0027) image_size = 384 image = torch.randn(1, 3,384,384).to(device) caption_input = \"\" model_url = \u0027https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_capfilt_large.pth\u0027 model = blip_decoder(pretrained=model_url, image_size=image_size, vit=\u0027base\u0027) model.eval() model = model.to(device) exported_program: torch.export.ExportedProgram= torch.export.export(model, args=(image,caption_input,), strict=False) Error: Cannot mutate tensors with frozen storage# While exporting a model, it might fail because the model implementation might contain certain Python operations which are not yet supported by torch.export. Some of these failures may have a workaround. BLIP is an example where the original model errors, which can be resolved by making a small change in the code. torch.export lists the common cases of supported and unsupported operations in ExportDB and shows how you can modify your code to make it export compatible. File \"/BLIP/models/blip.py\", line 112, in forward text.input_ids[:,0] = self.tokenizer.bos_token_id File \"/anaconda3/envs/export/lib/python3.10/site-packages/torch/_subclasses/functional_tensor.py\", line 545, in __torch_dispatch__ outs_unwrapped = func._op_dk( RuntimeError: cannot mutate tensors with frozen storage Solution# Clone the tensor where export fails. text.input_ids = text.input_ids.clone() # clone the tensor text.input_ids[:,0] = self.tokenizer.bos_token_id \ucc38\uace0 This constraint has been relaxed in PyTorch 2.7 nightlies. This should work out-of-the-box in PyTorch 2.7 Promptable Image Segmentation# Image segmentation is a computer vision technique that divides a digital image into distinct groups of pixels, or segments, based on their characteristics. Segment Anything Model (SAM)) introduced promptable image segmentation, which predicts object masks given prompts that indicate the desired object. SAM 2 is the first unified model for segmenting objects across images and videos. The SAM2ImagePredictor class provides an easy interface to the model for prompting the model. The model can take as input both point and box prompts, as well as masks from the previous iteration of prediction. Since SAM2 provides strong zero-shot performance for object tracking, it can be used for tracking game objects in a scene. The tensor operations in the predict method of SAM2ImagePredictor are happening in the _predict method. So, we try to export like this. ep = torch.export.export( self._predict, args=(unnorm_coords, labels, unnorm_box, mask_input, multimask_output), kwargs={\"return_logits\": return_logits}, strict=False, ) Error: Model is not of type torch.nn.Module# torch.export expects the module to be of type torch.nn.Module. However, the module we are trying to export is a class method. Hence it errors. Traceback (most recent call last): File \"/sam2/image_predict.py\", line 20, in \u003cmodule\u003e masks, scores, _ = predictor.predict( File \"/sam2/sam2/sam2_image_predictor.py\", line 312, in predict ep = torch.export.export( File \"python3.10/site-packages/torch/export/__init__.py\", line 359, in export raise ValueError( ValueError: Expected `mod` to be an instance of `torch.nn.Module`, got \u003cclass \u0027method\u0027\u003e. Solution# We write a helper class, which inherits from torch.nn.Module and call the _predict method in the forward method of the class. The complete code can be found here. class ExportHelper(torch.nn.Module): def __init__(self): super().__init__() def forward(_, *args, **kwargs): return self._predict(*args, **kwargs) model_to_export = ExportHelper() ep = torch.export.export( model_to_export, args=(unnorm_coords, labels, unnorm_box, mask_input, multimask_output), kwargs={\"return_logits\": return_logits}, strict=False, ) Conclusion# In this tutorial, we have learned how to use torch.export to export models for popular use cases by addressing challenges through correct configuration and simple code modifications. Once you are able to export a model, you can lower the ExportedProgram into your hardware using AOTInductor in case of servers and ExecuTorch in case of edge device. To learn more about AOTInductor (AOTI), please refer to the AOTI tutorial. To learn more about ExecuTorch , please refer to the ExecuTorch tutorial.",
       "author": {
         "@type": "Organization",
         "name": "PyTorch Contributors",
         "url": "https://pytorch.org"
       },
       "image": "../_static/img/pytorch_seo.png",
       "mainEntityOfPage": {
         "@type": "WebPage",
         "@id": "/recipes/torch_export_challenges_solutions.html"
       },
       "datePublished": "2023-01-01T00:00:00Z",
       "dateModified": "2023-01-01T00:00:00Z"
     }
 </script>
  <script>
    // Tutorials Call to action event tracking
    $("[data-behavior='call-to-action-event']").on('click', function () {
      fbq('trackCustom', "Download", {
        tutorialTitle: $('h1:first').text(),
        downloadLink: this.href,
        tutorialLink: window.location.href,
        downloadTitle: $(this).attr("data-response")
      });
      if (typeof gtag === 'function') {
        gtag('event', 'click', {
          'event_category': $(this).attr("data-response"),
          'event_label': $("h1").first().text(),
          'tutorial_link': window.location.href
        });
      }
    });
  </script>
  
  </body>
</html>