
<!DOCTYPE html>


<html lang="ko" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <meta property="article:modified_time" content="2022-11-30T07:09:41+00:00" /><meta property="og:title" content="기초부터 시작하는 NLP: 문자-단위 RNN으로 이름 생성하기" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://tutorials.pytorch.kr/intermediate/char_rnn_generation_tutorial.html" />
<meta property="og:site_name" content="PyTorch Tutorials KR" />
<meta property="og:description" content="Author: Sean Robertson, 번역: 황성수,. 이 튜토리얼은 3부로 구성된 시리즈의 일부입니다: 기초부터 시작하는 NLP: 문자-단위 RNN으로 이름 분류하기, 기초부터 시작하는 NLP: 문자-단위 RNN으로 이름 생성하기, 기초부터 시작하는 NLP: Sequence to Sequence 네트워크와 Attention을 이용한 번역. 이 튜토리얼은 3개로 이뤄진 “기초부터 시작하는 NLP”의 2번째 튜토리얼입니다. 첫번째 튜토리얼인 기초부터 시작하는 NLP: 문자-단위 RNN으로 이름 분류하기 에서는 RNN을 사용..." />
<meta property="og:image" content="https://tutorials.pytorch.kr/_static/logos/logo-kr-sm-dark.png" />
<meta property="og:image:alt" content="PyTorch Tutorials KR" />
<meta name="description" content="Author: Sean Robertson, 번역: 황성수,. 이 튜토리얼은 3부로 구성된 시리즈의 일부입니다: 기초부터 시작하는 NLP: 문자-단위 RNN으로 이름 분류하기, 기초부터 시작하는 NLP: 문자-단위 RNN으로 이름 생성하기, 기초부터 시작하는 NLP: Sequence to Sequence 네트워크와 Attention을 이용한 번역. 이 튜토리얼은 3개로 이뤄진 “기초부터 시작하는 NLP”의 2번째 튜토리얼입니다. 첫번째 튜토리얼인 기초부터 시작하는 NLP: 문자-단위 RNN으로 이름 분류하기 에서는 RNN을 사용..." />
<meta property="og:ignore_canonical" content="true" />

    <title>기초부터 시작하는 NLP: 문자-단위 RNN으로 이름 생성하기 &#8212; 파이토치 한국어 튜토리얼 (PyTorch tutorials in Korean)</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=536c50fe" />
    <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=4d2595e5" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/katex-math.css?v=91adb8b6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/pytorch_theme.css?v=c326296f" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css?v=097efa9c" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom2.css?v=b169ea90" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=725a5b95"></script>
    <script src="../_static/doctools.js?v=92e14aea"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/translations.js?v=b5f768d8"></script>
    <script src="../_static/katex.min.js?v=be8ff15f"></script>
    <script src="../_static/auto-render.min.js?v=ad136472"></script>
    <script src="../_static/katex_autorenderer.js?v=bebc588a"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'intermediate/char_rnn_generation_tutorial';</script>
    <link rel="canonical" href="https://tutorials.pytorch.kr/intermediate/char_rnn_generation_tutorial.html" />
    <link rel="icon" href="../_static/favicon.ico"/>
    <link rel="index" title="색인" href="../genindex.html" />
    <link rel="search" title="검색" href="../search.html" />

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="ko"/>
    <meta name="docbuild:last-update" content="2022년 11월 30일"/>
<script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/2.3.1/list.min.js"></script>
<script>
  if (window.location.hostname === 'docs.pytorch.org' || window.location.hostname === 'docs-preview.pytorch.org') {
    const script = document.createElement('script');
    script.src = 'https://cmp.osano.com/16A0DbT9yDNIaQkvZ/31b1b91a-e0b6-47ea-bde2-7f2bd13dbe5c/osano.js?variant=one';
    document.head.appendChild(script);
  }
</script>
<script>
  // Cookie banner for non-LF projects
  document.addEventListener('DOMContentLoaded', function () {
    // Hide cookie banner on local environments and LF owned docs
    if (window.location.hostname === 'localhost' ||
      window.location.hostname === '0.0.0.0' ||
      window.location.hostname === '127.0.0.1' ||
      window.location.hostname === 'docs.pytorch.org' ||
      window.location.hostname === 'docs-preview.pytorch.org' ||
      window.location.hostname.startsWith('192.168.')) {
      const banner = document.querySelector('.cookie-banner-wrapper');
      if (banner) {
        banner.style.display = 'none';
      }
    }
  });
</script>
<!-- Conditional CSS for header and footer height adjustment -->

<link rel="stylesheet" type="text/css" href="../_static/css/theme.css" crossorigin="anonymous">
<script type="text/javascript" src="../_static/js/theme.js"></script>
<script type="text/javascript" src="../_static/js/dropdown-menu.js"></script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Nanum+Gothic:wght@400;700&family=Nanum+Gothic+Coding:wght@400;700&family=Montserrat:wght@300;400&display=swap" rel="stylesheet">
<meta property="og:image" content="../_static/img/pytorch_seo.png" />
<link rel="stylesheet" href="../_static/webfonts/all.min.css" crossorigin="anonymous">
<meta http-equiv="Content-Security-Policy"
  content="default-src * 'unsafe-inline' 'unsafe-eval' data: blob:; style-src * 'unsafe-inline'; script-src * 'unsafe-inline' 'unsafe-eval' blob:;">
<meta name="pytorch_project" content="tutorials">
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=G-LZRD6GXDLF" height="0" width="0"
    style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
<!-- Google Tag Manager -->
<script>(function (w, d, s, l, i) {
    w[l] = w[l] || []; w[l].push({
      'gtm.start':
        new Date().getTime(), event: 'gtm.js'
    }); var f = d.getElementsByTagName(s)[0],
      j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : ''; j.async = true; j.src =
        'https://www.googletagmanager.com/gtm.js?id=' + i + dl; f.parentNode.insertBefore(j, f);
    j.onload = function () {
      window.dispatchEvent(new Event('gtm_loaded'));
      console.log('GTM loaded successfully');
    };
  })(window, document, 'script', 'dataLayer', 'G-LZRD6GXDLF');
</script>
<!-- End Google Tag Manager -->
<!-- Facebook Pixel Code -->
<script>
  !function (f, b, e, v, n, t, s) {
    if (f.fbq) return; n = f.fbq = function () {
      n.callMethod ?
        n.callMethod.apply(n, arguments) : n.queue.push(arguments)
    };
    if (!f._fbq) f._fbq = n; n.push = n; n.loaded = !0; n.version = '2.0';
    n.queue = []; t = b.createElement(e); t.async = !0;
    t.src = v; s = b.getElementsByTagName(e)[0];
    s.parentNode.insertBefore(t, s)
  }(window, document, 'script',
    'https://connect.facebook.net/en_US/fbevents.js');
  fbq('init', '243028289693773');
  fbq('track', 'PageView');
</script>
<script>
  document.documentElement.setAttribute('data-version', 'v2.8.0+cu128');
</script>
<noscript>
  <img height="1" width="1" src="https://www.facebook.com/tr?id=243028289693773&ev=PageView&noscript=1" />
</noscript>
<script>
  function gtag() {
    window.dataLayer.push(arguments);
  }
</script>
<!-- End Facebook Pixel Code -->
<!-- Script to Fix scrolling -->
<script>
  document.addEventListener('DOMContentLoaded', function () {
    // Fix anchor scrolling
    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener('click', function (e) {
        e.preventDefault();
        const targetId = this.getAttribute('href').substring(1);
        const targetElement = document.getElementById(targetId);

        if (targetElement) {
          const headerHeight =
            (document.querySelector('.header-holder') ? document.querySelector('.header-holder').offsetHeight : 0) +
            (document.querySelector('.bd-header') ? document.querySelector('.bd-header').offsetHeight : 0) + 20;

          const targetPosition = targetElement.getBoundingClientRect().top + window.pageYOffset - headerHeight;
          window.scrollTo({
            top: targetPosition,
            behavior: 'smooth'
          });

          // Update URL hash without scrolling
          history.pushState(null, null, '#' + targetId);
        }
      });
    });
  });
</script>

<script async src="https://cse.google.com/cse.js?cx=e65585f8c3ea1440e"></script>


  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="ko"/>
    <meta name="docbuild:last-update" content="2022년 11월 30일"/>

  </head>

<body data-feedback-url="https://github.com/PyTorchKorea/tutorials-kr" class="pytorch-body">
  
    <div class="container-fluid header-holder tutorials-header" id="header-holder">
   <div class="header-container-wrapper">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.kr/" aria-label="PyTorchKR"></a>

      <div class="main-menu">
        <ul>

          <li class="main-menu-item">
          <div id="learnDropdownButton" data-toggle="learn-dropdown" class="learn-dropdown">
              <a class="with-down-arrow">
                <span>배우기</span>
              </a>
              <div class="learn-dropdown-menu dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.kr/get-started/locally/">
                  <span class="dropdown-title">PyTorch 시작하기</span>
                </a>
                <a class="nav-dropdown-item" href="https://tutorials.pytorch.kr/beginner/basics/intro.html">
                  <span class="dropdown-title">기본 익히기</span>
                </a>
                <a class="nav-dropdown-item" href="https://tutorials.pytorch.kr/" target="_self">
                  <span class="dropdown-title">한국어 튜토리얼</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.kr/hub/">
                  <span class="dropdown-title">한국어 모델 허브</span>
                </a>
                <a class="nav-dropdown-item" href="https://docs.pytorch.org/tutorials/" target="_blank">
                  <span class="dropdown-title">Official Tutorials</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <a href="https://pytorch.kr/blog/">
              <span>블로그</span>
            </a>
          </li>

          <li class="main-menu-item">
          <div id="docsDropdownButton" data-toggle="docs-dropdown" class="docs-dropdown">
              <a class="with-down-arrow">
              <span>문서</span>
              </a>
              <div class="docs-dropdown-menu dropdown-menu">
                <a class="nav-dropdown-item" href="https://docs.pytorch.org/docs/" target="_blank">
                  <span class="dropdown-title">PyTorch API</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.kr/domains/">
                  <span class="dropdown-title">Domain API 소개</span>
                </a>
                <a class="nav-dropdown-item" href="https://tutorials.pytorch.kr/" target="_self">
                  <span class="dropdown-title">한국어 튜토리얼</span>
                </a>
                <a class="nav-dropdown-item" href="https://docs.pytorch.org/tutorials/" target="_blank">
                  <span class="dropdown-title">Official Tutorials</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
          <div id="communityDropdownButton" data-toggle="community-dropdown" class="community-dropdown">
              <a class="with-down-arrow">
              <span>커뮤니티</span>
              </a>
              <div class="community-dropdown-menu dropdown-menu">
                <a class="nav-dropdown-item" href="https://discuss.pytorch.kr/" target="_self">
                  <span class="dropdown-title">한국어 커뮤니티</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.kr/resources/">
                  <span class="dropdown-title">개발자 정보</span>
                </a>
                <a class="nav-dropdown-item" href="https://landscape.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Landscape</span>
                </a>
              </div>
            </div>
          </li>

        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu">
        <i class="fa-solid fa-ellipsis"></i>
      </a>
    </div>
  </div>
 </div>

 <!-- Begin Mobile Menu -->

<div class="mobile-main-menu">
  <div class="container-fluid">
    <div class="header-container-wrapper">
      <div class="mobile-main-menu-header-container">
        <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu">
          <i class="fa-solid fa-xmark"></i>
        </a>
      </div>
    </div>
  </div>

  <div class="mobile-main-menu-links-container">
    <div class="main-menu">
      <ul>
         <li class="resources-mobile-menu-title">
           <a>배우기</a>
         </li>
         <ul class="resources-mobile-menu-items">
           <li>
             <a href="https://pytorch.kr/get-started/locally/">PyTorch 시작하기</a>
           </li>
           <li>
             <a href="https://tutorials.pytorch.kr/beginner/basics/intro.html">기본 익히기</a>
           </li>
           <li>
             <a href="https://tutorials.pytorch.kr/">한국어 튜토리얼</a>
           </li>
           <li>
             <a href="https://pytorch.kr/hub/">한국어 모델 허브</a>
           </li>
           <li>
             <a href="https://docs.pytorch.org/tutorials/" target="_blank">Official Tutorials</a>
           </li>
        </ul>
         <li class="resources-mobile-menu-title">
           <a href="https://pytorch.kr/blog/">블로그</a>
         </li>
         <li class="resources-mobile-menu-title">
           <a>문서</a>
         </li>
         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://docs.pytorch.org/docs/" target="_blank">PyTorch API</a>
          </li>
          <li>
            <a href="https://pytorch.kr/domains/">Domain API 소개</a>
          </li>
          <li>
            <a href="https://tutorials.pytorch.kr/">한국어 튜토리얼</a>
          </li>
          <li>
            <a href="https://docs.pytorch.org/tutorials/" target="_blank">Official Tutorials</a>
          </li>
        </ul>
        <li class="resources-mobile-menu-title">
          <a>커뮤니티</a>
        </li>
         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://discuss.pytorch.kr/">한국어 커뮤니티</a>
          </li>
          <li>
            <a href="https://pytorch.kr/resources/">개발자 정보</a>
          </li>
          <li>
            <a href="https://landscape.pytorch.org/" target="_blank">Landscape</a>
          </li>
        </ul>
      </ul>
    </div>
  </div>
</div>

<!-- End Mobile Menu -->
  
  
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">
  <a href="../index.html" class="version">v2.8.0+cu128</a>
</div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../intro.html">
    Intro
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../compilers_index.html">
    Compilers
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../domains.html">
    Domains
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../distributed.html">
    Distributed
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../deep-dive.html">
    Deep Dive
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../extension.html">
    Extension
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../ecosystem.html">
    Ecosystem
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../recipes_index.html">
    Recipes
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
      
        <div class="navbar-item">
<div class="search-container-wrapper">
  <div id="sphinx-search" class="search-container">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </div>

  <div id="google-search" class="search-container" style="display:none;">
    <div class="gcse-search-wrapper">
      <i class="fa-solid fa-magnifying-glass" aria-hidden="true"></i>
      <div class="gcse-search"></div>
    </div>
  </div>

  <div class="search-toggle-container" data-bs-title="Google Search Off" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <div class="search-toggle-inner">
      <label class="switch">
        <input type="checkbox" id="search-toggle">
        <span class="slider round"></span>
      </label>
    </div>
  </div>
</div>

<script>
  document.addEventListener('DOMContentLoaded', function() {
  // Define the search callback
  const myWebSearchStartingCallback = (gname, query) => {
    if (typeof dataLayer !== 'undefined' && query) {
      window.dataLayer = window.dataLayer || [];
      dataLayer.push({
        'event': 'google_search',
        'search_term': query,
        'event_category': 'Search',
        'event_label': 'Google Search'
      });
    }
    return '';
  };

  // Set up the GCSE search callbacks
  window.__gcse || (window.__gcse = {});
  window.__gcse.searchCallbacks = {
    web: { starting: myWebSearchStartingCallback }
  };

  if (window.location.pathname.includes('/search.html')) {
    document.body.classList.add('search-page');
  }

  // Function to reinitialize Google CSE
  function reinitializeGoogleSearch() {
    if (window.__gcse && window.__gcse.initializationCallback) {
      window.__gcse.initializationCallback();
    }
  }

  // Function to handle search toggle
  function handleSearchToggle(toggle, sphinxSearch, googleSearch) {
    if (!toggle || !sphinxSearch || !googleSearch) return;

    // Check if the URL contains /stable/ or /tutorials/
    const currentUrl = window.location.href;
    // TODO: We've had reports that the google programmable search is returning stale documentation,
    //       Simple reproduction is to turn google search on and search for multinomial which will
    //       result in returning 1.8.1 documentation.
    //       We should turn this back on when we resolve that bug.
    const shouldDefaultToGoogle = false;
    const savedPreference = localStorage.getItem('searchPreference');

    // Set initial state
    if (savedPreference === 'google' || (savedPreference === null && shouldDefaultToGoogle)) {
      toggle.checked = true;
      sphinxSearch.style.display = 'none';
      googleSearch.style.display = 'block';
      if (savedPreference === null) {
        localStorage.setItem('searchPreference', 'google');
      }
      reinitializeGoogleSearch();
    } else {
      toggle.checked = false;
      sphinxSearch.style.display = 'block';
      googleSearch.style.display = 'none';
    }

    // Update tooltip
    updateTooltip(toggle.checked);

    // Skip if already initialized
    if (toggle.hasAttribute('data-initialized')) return;
    toggle.setAttribute('data-initialized', 'true');

    toggle.addEventListener('change', function() {
      if (this.checked) {
        sphinxSearch.style.display = 'none';
        googleSearch.style.display = 'block';
        localStorage.setItem('searchPreference', 'google');
        reinitializeGoogleSearch();
        trackSearchEngineSwitch('Google');
      } else {
        sphinxSearch.style.display = 'block';
        googleSearch.style.display = 'none';
        localStorage.setItem('searchPreference', 'sphinx');
        trackSearchEngineSwitch('Sphinx');
      }

      updateTooltip(this.checked);
      updateMobileSearch();
    });
  }

  // Update tooltip based on toggle state
  function updateTooltip(isChecked) {
    const tooltipElement = document.querySelector('.search-toggle-container');
    if (!tooltipElement) return;

    tooltipElement.setAttribute('data-bs-title', isChecked ? 'Google Search On' : 'Google Search Off');

    if (bootstrap && bootstrap.Tooltip) {
      const tooltipInstance = bootstrap.Tooltip.getInstance(tooltipElement);
      if (tooltipInstance) tooltipInstance.dispose();
      new bootstrap.Tooltip(tooltipElement);
    }
  }

  // Track search engine switch
  function trackSearchEngineSwitch(engine) {
    if (typeof dataLayer !== 'undefined') {
      window.dataLayer = window.dataLayer || [];
      dataLayer.push({
        'event': 'search_engine_switch',
        'event_category': 'Search',
        'event_label': engine
      });
    }
  }

  // Function to update mobile search based on current toggle state
  function updateMobileSearch() {
    const toggle = document.getElementById('search-toggle');
    if (!toggle) return;

    const mobileSearchContainer = document.querySelector('.sidebar-header-items__end .navbar-item .search-container-wrapper');
    if (!mobileSearchContainer) return;

    const mobileSphinxSearch = mobileSearchContainer.querySelector('#sphinx-search');
    const mobileGoogleSearch = mobileSearchContainer.querySelector('#google-search');

    if (mobileSphinxSearch && mobileGoogleSearch) {
      mobileSphinxSearch.style.display = toggle.checked ? 'none' : 'block';
      mobileGoogleSearch.style.display = toggle.checked ? 'block' : 'none';

      if (toggle.checked) {
        reinitializeGoogleSearch();
      }
    }
  }

  // Initialize desktop search toggle
  const toggle = document.getElementById('search-toggle');
  const sphinxSearch = document.getElementById('sphinx-search');
  const googleSearch = document.getElementById('google-search');
  handleSearchToggle(toggle, sphinxSearch, googleSearch);

  // Set placeholder text for Google search input
  const observer = new MutationObserver(function() {
    document.querySelectorAll('.gsc-input input').forEach(input => {
      if (input && !input.hasAttribute('data-placeholder-set')) {
        input.setAttribute('placeholder', 'Search the docs ...');
        input.setAttribute('data-placeholder-set', 'true');
      }
    });
  });

  observer.observe(document.body, { childList: true, subtree: true });

  // Fix for scroll jump issue - improved approach
  function setupSearchInputHandlers(input) {
    if (input.hasAttribute('data-scroll-fixed')) return;
    input.setAttribute('data-scroll-fixed', 'true');

    let lastScrollPosition = 0;
    let isTyping = false;
    let scrollTimeout;

    // Save position before typing starts
    input.addEventListener('keydown', () => {
      lastScrollPosition = window.scrollY;
      isTyping = true;

      // Reset typing state after a short delay
      clearTimeout(scrollTimeout);
      scrollTimeout = setTimeout(() => {
        isTyping = false;
      }, 100);
    });

    // Only maintain scroll position during typing
    function maintainScroll() {
      if (document.activeElement === input && isTyping) {
        window.scrollTo(0, lastScrollPosition);
        requestAnimationFrame(maintainScroll);
      }
    }

    input.addEventListener('focus', () => {
      // Just store initial position but don't force it
      lastScrollPosition = window.scrollY;
    });

    input.addEventListener('input', () => {
      isTyping = true;
      window.scrollTo(0, lastScrollPosition);

      // Reset typing state after a short delay
      clearTimeout(scrollTimeout);
      scrollTimeout = setTimeout(() => {
        isTyping = false;
      }, 100);

      requestAnimationFrame(maintainScroll);
    });
  }

  // Apply to all search inputs and observe for new ones
  function applyToSearchInputs() {
    document.querySelectorAll('.search-container input, .gsc-input input').forEach(setupSearchInputHandlers);
  }

  applyToSearchInputs();

  const searchObserver = new MutationObserver(applyToSearchInputs);
  searchObserver.observe(document.body, { childList: true, subtree: true });

  // Watch for mobile menu creation
  const mobileMenuObserver = new MutationObserver(function(mutations) {
    for (const mutation of mutations) {
      if (!mutation.addedNodes.length) continue;

      // Style mobile search inputs
      document.querySelectorAll('.sidebar-header-items__end .navbar-item .search-container-wrapper .gsc-input input').forEach(input => {
        if (input) {
          input.setAttribute('placeholder', 'Search the docs ...');
          input.style.paddingLeft = '36px';
        }
      });

      // Check for mobile search container
      const mobileSearchContainer = document.querySelector('.sidebar-header-items__end .navbar-item .search-container-wrapper');
      if (!mobileSearchContainer) continue;

      const mobileToggle = mobileSearchContainer.querySelector('#search-toggle');
      if (mobileToggle && toggle) {
        // Sync mobile toggle with desktop toggle
        mobileToggle.checked = toggle.checked;
        updateMobileSearch();

        // Add event listener to mobile toggle if not already added
        if (!mobileToggle.hasAttribute('data-initialized')) {
          mobileToggle.setAttribute('data-initialized', 'true');
          mobileToggle.addEventListener('change', function() {
            // Sync desktop toggle with mobile toggle
            toggle.checked = this.checked;
            // Trigger change event on desktop toggle to update both
            toggle.dispatchEvent(new Event('change'));
          });
        }
      }
    }
  });

  mobileMenuObserver.observe(document.body, { childList: true, subtree: true });

  // Ensure Google CSE is properly loaded
  if (window.__gcse) {
    window.__gcse.callback = function() {
      // This will run after Google CSE is fully loaded
      if (toggle && toggle.checked) {
        reinitializeGoogleSearch();
      }
    };
  } else {
    window.__gcse = {
      callback: function() {
        if (toggle && toggle.checked) {
          reinitializeGoogleSearch();
        }
      }
    };
  }
});
</script>
</div>
      
        <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/PyTorchKorea/tutorials-kr" title="한국어 튜토리얼 GitHub 저장소" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">한국어 튜토리얼 GitHub 저장소</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discuss.pytorch.kr/" title="파이토치 한국어 커뮤니티" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">파이토치 한국어 커뮤니티</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <div class="bd-sidebar-primary bd-sidebar hide-on-wide">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../intro.html">
    Intro
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../compilers_index.html">
    Compilers
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../domains.html">
    Domains
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../distributed.html">
    Distributed
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../deep-dive.html">
    Deep Dive
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../extension.html">
    Extension
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../ecosystem.html">
    Ecosystem
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../recipes_index.html">
    Recipes
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
<div class="search-container-wrapper">
  <div id="sphinx-search" class="search-container">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </div>

  <div id="google-search" class="search-container" style="display:none;">
    <div class="gcse-search-wrapper">
      <i class="fa-solid fa-magnifying-glass" aria-hidden="true"></i>
      <div class="gcse-search"></div>
    </div>
  </div>

  <div class="search-toggle-container" data-bs-title="Google Search Off" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <div class="search-toggle-inner">
      <label class="switch">
        <input type="checkbox" id="search-toggle">
        <span class="slider round"></span>
      </label>
    </div>
  </div>
</div>

<script>
  document.addEventListener('DOMContentLoaded', function() {
  // Define the search callback
  const myWebSearchStartingCallback = (gname, query) => {
    if (typeof dataLayer !== 'undefined' && query) {
      window.dataLayer = window.dataLayer || [];
      dataLayer.push({
        'event': 'google_search',
        'search_term': query,
        'event_category': 'Search',
        'event_label': 'Google Search'
      });
    }
    return '';
  };

  // Set up the GCSE search callbacks
  window.__gcse || (window.__gcse = {});
  window.__gcse.searchCallbacks = {
    web: { starting: myWebSearchStartingCallback }
  };

  if (window.location.pathname.includes('/search.html')) {
    document.body.classList.add('search-page');
  }

  // Function to reinitialize Google CSE
  function reinitializeGoogleSearch() {
    if (window.__gcse && window.__gcse.initializationCallback) {
      window.__gcse.initializationCallback();
    }
  }

  // Function to handle search toggle
  function handleSearchToggle(toggle, sphinxSearch, googleSearch) {
    if (!toggle || !sphinxSearch || !googleSearch) return;

    // Check if the URL contains /stable/ or /tutorials/
    const currentUrl = window.location.href;
    // TODO: We've had reports that the google programmable search is returning stale documentation,
    //       Simple reproduction is to turn google search on and search for multinomial which will
    //       result in returning 1.8.1 documentation.
    //       We should turn this back on when we resolve that bug.
    const shouldDefaultToGoogle = false;
    const savedPreference = localStorage.getItem('searchPreference');

    // Set initial state
    if (savedPreference === 'google' || (savedPreference === null && shouldDefaultToGoogle)) {
      toggle.checked = true;
      sphinxSearch.style.display = 'none';
      googleSearch.style.display = 'block';
      if (savedPreference === null) {
        localStorage.setItem('searchPreference', 'google');
      }
      reinitializeGoogleSearch();
    } else {
      toggle.checked = false;
      sphinxSearch.style.display = 'block';
      googleSearch.style.display = 'none';
    }

    // Update tooltip
    updateTooltip(toggle.checked);

    // Skip if already initialized
    if (toggle.hasAttribute('data-initialized')) return;
    toggle.setAttribute('data-initialized', 'true');

    toggle.addEventListener('change', function() {
      if (this.checked) {
        sphinxSearch.style.display = 'none';
        googleSearch.style.display = 'block';
        localStorage.setItem('searchPreference', 'google');
        reinitializeGoogleSearch();
        trackSearchEngineSwitch('Google');
      } else {
        sphinxSearch.style.display = 'block';
        googleSearch.style.display = 'none';
        localStorage.setItem('searchPreference', 'sphinx');
        trackSearchEngineSwitch('Sphinx');
      }

      updateTooltip(this.checked);
      updateMobileSearch();
    });
  }

  // Update tooltip based on toggle state
  function updateTooltip(isChecked) {
    const tooltipElement = document.querySelector('.search-toggle-container');
    if (!tooltipElement) return;

    tooltipElement.setAttribute('data-bs-title', isChecked ? 'Google Search On' : 'Google Search Off');

    if (bootstrap && bootstrap.Tooltip) {
      const tooltipInstance = bootstrap.Tooltip.getInstance(tooltipElement);
      if (tooltipInstance) tooltipInstance.dispose();
      new bootstrap.Tooltip(tooltipElement);
    }
  }

  // Track search engine switch
  function trackSearchEngineSwitch(engine) {
    if (typeof dataLayer !== 'undefined') {
      window.dataLayer = window.dataLayer || [];
      dataLayer.push({
        'event': 'search_engine_switch',
        'event_category': 'Search',
        'event_label': engine
      });
    }
  }

  // Function to update mobile search based on current toggle state
  function updateMobileSearch() {
    const toggle = document.getElementById('search-toggle');
    if (!toggle) return;

    const mobileSearchContainer = document.querySelector('.sidebar-header-items__end .navbar-item .search-container-wrapper');
    if (!mobileSearchContainer) return;

    const mobileSphinxSearch = mobileSearchContainer.querySelector('#sphinx-search');
    const mobileGoogleSearch = mobileSearchContainer.querySelector('#google-search');

    if (mobileSphinxSearch && mobileGoogleSearch) {
      mobileSphinxSearch.style.display = toggle.checked ? 'none' : 'block';
      mobileGoogleSearch.style.display = toggle.checked ? 'block' : 'none';

      if (toggle.checked) {
        reinitializeGoogleSearch();
      }
    }
  }

  // Initialize desktop search toggle
  const toggle = document.getElementById('search-toggle');
  const sphinxSearch = document.getElementById('sphinx-search');
  const googleSearch = document.getElementById('google-search');
  handleSearchToggle(toggle, sphinxSearch, googleSearch);

  // Set placeholder text for Google search input
  const observer = new MutationObserver(function() {
    document.querySelectorAll('.gsc-input input').forEach(input => {
      if (input && !input.hasAttribute('data-placeholder-set')) {
        input.setAttribute('placeholder', 'Search the docs ...');
        input.setAttribute('data-placeholder-set', 'true');
      }
    });
  });

  observer.observe(document.body, { childList: true, subtree: true });

  // Fix for scroll jump issue - improved approach
  function setupSearchInputHandlers(input) {
    if (input.hasAttribute('data-scroll-fixed')) return;
    input.setAttribute('data-scroll-fixed', 'true');

    let lastScrollPosition = 0;
    let isTyping = false;
    let scrollTimeout;

    // Save position before typing starts
    input.addEventListener('keydown', () => {
      lastScrollPosition = window.scrollY;
      isTyping = true;

      // Reset typing state after a short delay
      clearTimeout(scrollTimeout);
      scrollTimeout = setTimeout(() => {
        isTyping = false;
      }, 100);
    });

    // Only maintain scroll position during typing
    function maintainScroll() {
      if (document.activeElement === input && isTyping) {
        window.scrollTo(0, lastScrollPosition);
        requestAnimationFrame(maintainScroll);
      }
    }

    input.addEventListener('focus', () => {
      // Just store initial position but don't force it
      lastScrollPosition = window.scrollY;
    });

    input.addEventListener('input', () => {
      isTyping = true;
      window.scrollTo(0, lastScrollPosition);

      // Reset typing state after a short delay
      clearTimeout(scrollTimeout);
      scrollTimeout = setTimeout(() => {
        isTyping = false;
      }, 100);

      requestAnimationFrame(maintainScroll);
    });
  }

  // Apply to all search inputs and observe for new ones
  function applyToSearchInputs() {
    document.querySelectorAll('.search-container input, .gsc-input input').forEach(setupSearchInputHandlers);
  }

  applyToSearchInputs();

  const searchObserver = new MutationObserver(applyToSearchInputs);
  searchObserver.observe(document.body, { childList: true, subtree: true });

  // Watch for mobile menu creation
  const mobileMenuObserver = new MutationObserver(function(mutations) {
    for (const mutation of mutations) {
      if (!mutation.addedNodes.length) continue;

      // Style mobile search inputs
      document.querySelectorAll('.sidebar-header-items__end .navbar-item .search-container-wrapper .gsc-input input').forEach(input => {
        if (input) {
          input.setAttribute('placeholder', 'Search the docs ...');
          input.style.paddingLeft = '36px';
        }
      });

      // Check for mobile search container
      const mobileSearchContainer = document.querySelector('.sidebar-header-items__end .navbar-item .search-container-wrapper');
      if (!mobileSearchContainer) continue;

      const mobileToggle = mobileSearchContainer.querySelector('#search-toggle');
      if (mobileToggle && toggle) {
        // Sync mobile toggle with desktop toggle
        mobileToggle.checked = toggle.checked;
        updateMobileSearch();

        // Add event listener to mobile toggle if not already added
        if (!mobileToggle.hasAttribute('data-initialized')) {
          mobileToggle.setAttribute('data-initialized', 'true');
          mobileToggle.addEventListener('change', function() {
            // Sync desktop toggle with mobile toggle
            toggle.checked = this.checked;
            // Trigger change event on desktop toggle to update both
            toggle.dispatchEvent(new Event('change'));
          });
        }
      }
    }
  });

  mobileMenuObserver.observe(document.body, { childList: true, subtree: true });

  // Ensure Google CSE is properly loaded
  if (window.__gcse) {
    window.__gcse.callback = function() {
      // This will run after Google CSE is fully loaded
      if (toggle && toggle.checked) {
        reinitializeGoogleSearch();
      }
    };
  } else {
    window.__gcse = {
      callback: function() {
        if (toggle && toggle.checked) {
          reinitializeGoogleSearch();
        }
      }
    };
  }
});
</script>
</div>
        
          <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/PyTorchKorea/tutorials-kr" title="한국어 튜토리얼 GitHub 저장소" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">한국어 튜토리얼 GitHub 저장소</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discuss.pytorch.kr/" title="파이토치 한국어 커뮤니티" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">파이토치 한국어 커뮤니티</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    <li class="breadcrumb-item active" aria-current="page">기초부터 시작하는...</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
        
    </div>
</div>
</div>
      
    </div>
  
</div>
</div>
              
              
  
<div id="searchbox"></div>
  <article class="bd-article" id="pytorch-article">
    <!-- Hidden breadcrumb schema for SEO only -->
    <div style="display:none;" itemscope itemtype="https://schema.org/BreadcrumbList">
      
      <div itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <meta itemprop="name" content="기초부터 시작하는 NLP: 문자-단위 RNN으로 이름 생성하기">
        <meta itemprop="position" content="1">
      </div>
    </div>

    
    <script>
      if ((window.location.href.indexOf("/unstable/") != -1) && (window.location.href.indexOf("/unstable/unstable_index") < 1)) {
        var div = '<div class="prototype-banner"><i class="fa fa-flask" aria-hidden="true"></i> <strong>Unstable feature:</strong> Not typically available in binary distributions like PyPI. Early stage for feedback and testing.</div>'
        document.addEventListener('DOMContentLoaded', function () {
          document.getElementById("pytorch-article").insertAdjacentHTML('afterBegin', div);
        });
      }
    </script>
    
    
    <div class="pytorch-call-to-action-links">
      <div id="tutorial-type">intermediate/char_rnn_generation_tutorial</div>
      <a id="colab-link" data-behavior="call-to-action-event" data-response="Run in Google Colab" target="_blank">
        <div id="google-colab-link">
          <img class="call-to-action-img" src="../_static/img/pytorch-colab.svg" />
          <div class="call-to-action-desktop-view">Run in Google Colab</div>
          <div class="call-to-action-mobile-view">Colab</div>
        </div>
      </a>
      <a id="notebook-link" data-behavior="call-to-action-event" data-response="Download Notebook">
        <div id="download-notebook-link">
          <img class="call-to-action-notebook-img" src="../_static/img/pytorch-download.svg" />
          <div class="call-to-action-desktop-view">Download Notebook</div>
          <div class="call-to-action-mobile-view">Notebook</div>
        </div>
      </a>
      <a id="github-link" data-behavior="call-to-action-event" data-response="View on Github" target="_blank">
        <div id="github-view-link">
          <img class="call-to-action-img" src="../_static/img/pytorch-github.svg" />
          <div class="call-to-action-desktop-view">View on GitHub</div>
          <div class="call-to-action-mobile-view">GitHub</div>
        </div>
      </a>
    </div>
    

    
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">참고</p>
<p><a class="reference internal" href="#sphx-glr-download-intermediate-char-rnn-generation-tutorial-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code.</p>
</div>
<section class="sphx-glr-example-title" id="nlp-rnn">
<span id="sphx-glr-intermediate-char-rnn-generation-tutorial-py"></span><h1>기초부터 시작하는 NLP: 문자-단위 RNN으로 이름 생성하기<a class="headerlink" href="#nlp-rnn" title="Link to this heading">#</a></h1>
<dl class="simple">
<dt><strong>Author</strong>: <a class="reference external" href="https://github.com/spro">Sean Robertson</a></dt><dd><p><strong>번역</strong>: <a class="reference external" href="https://github.com/adonisues">황성수</a></p>
</dd>
</dl>
<p>이 튜토리얼은 3부로 구성된 시리즈의 일부입니다:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://tutorials.pytorch.kr/intermediate/char_rnn_classification_tutorial.html">기초부터 시작하는 NLP: 문자-단위 RNN으로 이름 분류하기</a></p></li>
<li><p><a class="reference external" href="https://tutorials.pytorch.kr/intermediate/char_rnn_generation_tutorial.html">기초부터 시작하는 NLP: 문자-단위 RNN으로 이름 생성하기</a></p></li>
<li><p><a class="reference external" href="https://tutorials.pytorch.kr/intermediate/seq2seq_translation_tutorial.html">기초부터 시작하는 NLP: Sequence to Sequence 네트워크와 Attention을 이용한 번역</a></p></li>
</ul>
<p>이 튜토리얼은 3개로 이뤄진 “기초부터 시작하는 NLP”의 2번째 튜토리얼입니다.
첫번째 튜토리얼인 <a class="reference internal" href="char_rnn_classification_tutorial.html"><span class="doc">기초부터 시작하는 NLP: 문자-단위 RNN으로 이름 분류하기</span></a>
에서는 RNN을 사용하여 주어진 이름이 어떠한 언어인지를 분류했습니다.
이번에는 반대로 언어로부터 이름을 생성할 예정입니다.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>&gt;<span class="w"> </span>python<span class="w"> </span>sample.py<span class="w"> </span>Russian<span class="w"> </span>RUS
Rovakov
Uantov
Shavakov

&gt;<span class="w"> </span>python<span class="w"> </span>sample.py<span class="w"> </span>German<span class="w"> </span>GER
Gerren
Ereng
Rosher

&gt;<span class="w"> </span>python<span class="w"> </span>sample.py<span class="w"> </span>Spanish<span class="w"> </span>SPA
Salla
Parer
Allan

&gt;<span class="w"> </span>python<span class="w"> </span>sample.py<span class="w"> </span>Chinese<span class="w"> </span>CHI
Chan
Hang
Iun
</pre></div>
</div>
<p>우리는 몇 개의 선형 계층으로 작은 RNN을 직접 만들고 있습니다.
이전 튜토리얼인 이름을 읽은 후 그 언어를 예측하는 것과의 큰 차이점은
언어를 입력하고 한 번에 한 글자를 생성하여 출력하는 것입니다.
언어 형성(단어 또는 다른 고차원 구조로도 수행될 수 있음)을 위해
문자를 반복적으로 예측하는 것을 “언어 모델” 이라고 합니다.</p>
<p><strong>추천 자료:</strong></p>
<p>Pytorch를 설치했고, Python을 알고, Tensor를 이해한다고 가정합니다:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://pytorch.org/">https://pytorch.org/</a> 설치 안내</p></li>
<li><p><a class="reference internal" href="../beginner/deep_learning_60min_blitz.html"><span class="doc">PyTorch로 딥러닝하기: 60분만에 끝장내기</span></a> PyTorch 시작하기</p></li>
<li><p><a class="reference internal" href="../beginner/pytorch_with_examples.html"><span class="doc">예제로 배우는 파이토치(PyTorch)</span></a> 넓고 깊은 통찰을 위한 자료</p></li>
<li><p><a class="reference internal" href="../beginner/former_torchies_tutorial.html"><span class="doc">Torch 사용자를 위한 PyTorch</span></a> 이전 Lua Torch 사용자를 위한 자료</p></li>
</ul>
<p>RNN과 작동 방식을 아는 것 또한 유용합니다:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://karpathy.github.io/2015/05/21/rnn-effectiveness/">The Unreasonable Effectiveness of Recurrent Neural
Networks</a>
실생활 예제를 보여 줍니다.</p></li>
<li><p><a class="reference external" href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/">Understanding LSTM
Networks</a>
LSTM에 관한 것이지만 RNN에 관해서도 유익합니다.</p></li>
</ul>
<p>이전 튜토리얼도 추천합니다. <a class="reference internal" href="char_rnn_classification_tutorial.html"><span class="doc">기초부터 시작하는 NLP: 문자-단위 RNN으로 이름 분류하기</span></a></p>
<section id="id2">
<h2>데이터 준비<a class="headerlink" href="#id2" title="Link to this heading">#</a></h2>
<div class="admonition note">
<p class="admonition-title">참고</p>
<p><a class="reference external" href="https://download.pytorch.org/tutorial/data.zip">여기</a>
에서 데이터를 다운 받고, 현재 디렉토리에 압축을 푸십시오.</p>
</div>
<p>이 과정의 더 자세한 사항은 지난 튜토리얼을 보십시오.
요약하면, 줄마다 이름이 적힌 텍스트 파일 <code class="docutils literal notranslate"><span class="pre">data/names/[Language].txt</span></code> 있습니다.
이것을 array로 분리하고, Unicode를 ASCII로 변경하고,
사전 <code class="docutils literal notranslate"><span class="pre">{language:</span> <span class="pre">[names</span> <span class="pre">...]}</span></code> 을 만들어서 마무리합니다.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">__future__</span><span class="w"> </span><span class="kn">import</span> <span class="n">unicode_literals</span><span class="p">,</span> <span class="n">print_function</span><span class="p">,</span> <span class="n">division</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">io</span><span class="w"> </span><span class="kn">import</span> <span class="nb">open</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">glob</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">unicodedata</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">string</span>

<span class="n">all_letters</span> <span class="o">=</span> <span class="n">string</span><span class="o">.</span><span class="n">ascii_letters</span> <span class="o">+</span> <span class="s2">&quot; .,;&#39;-&quot;</span>
<span class="n">n_letters</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_letters</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span> <span class="c1"># EOS(end of sentence) 기호 추가</span>

<span class="k">def</span><span class="w"> </span><span class="nf">findFiles</span><span class="p">(</span><span class="n">path</span><span class="p">):</span> <span class="k">return</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>

<span class="c1"># 유니코드 문자열을 ASCII로 변환, https://stackoverflow.com/a/518232/2809427</span>
<span class="k">def</span><span class="w"> </span><span class="nf">unicodeToAscii</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
    <span class="k">return</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
        <span class="n">c</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">unicodedata</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="s1">&#39;NFD&#39;</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">unicodedata</span><span class="o">.</span><span class="n">category</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="o">!=</span> <span class="s1">&#39;Mn&#39;</span>
        <span class="ow">and</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">all_letters</span>
    <span class="p">)</span>

<span class="c1"># 파일을 읽고 줄 단위로 분리</span>
<span class="k">def</span><span class="w"> </span><span class="nf">readLines</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">some_file</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">unicodeToAscii</span><span class="p">(</span><span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">some_file</span><span class="p">]</span>

<span class="c1"># 각 언어의 이름 목록인 category_lines 사전 생성</span>
<span class="n">category_lines</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">all_categories</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">filename</span> <span class="ow">in</span> <span class="n">findFiles</span><span class="p">(</span><span class="s1">&#39;data/names/*.txt&#39;</span><span class="p">):</span>
    <span class="n">category</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">splitext</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">filename</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">all_categories</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">category</span><span class="p">)</span>
    <span class="n">lines</span> <span class="o">=</span> <span class="n">readLines</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
    <span class="n">category_lines</span><span class="p">[</span><span class="n">category</span><span class="p">]</span> <span class="o">=</span> <span class="n">lines</span>

<span class="n">n_categories</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_categories</span><span class="p">)</span>

<span class="k">if</span> <span class="n">n_categories</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;Data not found. Make sure that you downloaded data &#39;</span>
        <span class="s1">&#39;from https://download.pytorch.org/tutorial/data.zip and extract it to &#39;</span>
        <span class="s1">&#39;the current directory.&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;# categories:&#39;</span><span class="p">,</span> <span class="n">n_categories</span><span class="p">,</span> <span class="n">all_categories</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">unicodeToAscii</span><span class="p">(</span><span class="s2">&quot;O&#39;Néàl&quot;</span><span class="p">))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span># categories: 18 [&#39;English&#39;, &#39;Dutch&#39;, &#39;Spanish&#39;, &#39;Japanese&#39;, &#39;Portuguese&#39;, &#39;Arabic&#39;, &#39;Czech&#39;, &#39;Vietnamese&#39;, &#39;Irish&#39;, &#39;French&#39;, &#39;German&#39;, &#39;Russian&#39;, &#39;Italian&#39;, &#39;Chinese&#39;, &#39;Korean&#39;, &#39;Greek&#39;, &#39;Polish&#39;, &#39;Scottish&#39;]
O&#39;Neal
</pre></div>
</div>
</section>
<section id="id4">
<h2>네트워크 생성<a class="headerlink" href="#id4" title="Link to this heading">#</a></h2>
<p>이 네트워크는 <a class="reference external" href="#Creating-the-Network">지난 튜토리얼의 RNN</a> 이
다른 입력들과 연결되는 category tensor를 추가 인자로 가지게 확장합니다.
category tensor는 문자 입력과 마찬가지로 one-hot 벡터입니다.</p>
<p>역자주: 기존 입력과 category tensor를 결합하여 입력으로 사용하기 때문에
입력의 사이즈가 n_categories 만큼 커집니다.</p>
<p>우리는 출력을 다음 문자의 확률로 해석합니다. 샘플링 할 때,
가장 확률이 높은 문자가 다음 입력 문자로 사용됩니다.</p>
<p>더 나은 동작을 위해 두 번째 선형 레이어
<code class="docutils literal notranslate"><span class="pre">o2o</span></code> (은닉과 출력을 결합한 후) 를 추가했습니다 .
또한 Drop-out 계층이 있습니다. 이 계층은 주어진 확률(여기서는 0.1)로
<a class="reference external" href="https://arxiv.org/abs/1207.0580">무작위로 입력을 0 #</a> 으로 만듭니다.
일반적으로 입력을 흐리게 해서 과적합을 막는 데 사용됩니다.
여기서 우리는 고의로 일부 혼돈을 추가하고 샘플링 다양성을 높이기
위해 네트워크의 마지막에 이것을 사용합니다.</p>
<figure class="align-default">
<img alt="" src="https://i.imgur.com/jzVrf7f.png" />
</figure>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>

<span class="k">class</span><span class="w"> </span><span class="nc">RNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">RNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">i2h</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_categories</span> <span class="o">+</span> <span class="n">input_size</span> <span class="o">+</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">i2o</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_categories</span> <span class="o">+</span> <span class="n">input_size</span> <span class="o">+</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">o2o</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span> <span class="o">+</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LogSoftmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">category</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">hidden</span><span class="p">):</span>
        <span class="n">input_combined</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">category</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">hidden</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">i2h</span><span class="p">(</span><span class="n">input_combined</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">i2o</span><span class="p">(</span><span class="n">input_combined</span><span class="p">)</span>
        <span class="n">output_combined</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">hidden</span><span class="p">,</span> <span class="n">output</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">o2o</span><span class="p">(</span><span class="n">output_combined</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">initHidden</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id5">
<h2>학습<a class="headerlink" href="#id5" title="Link to this heading">#</a></h2>
<section id="id6">
<h3>학습 준비<a class="headerlink" href="#id6" title="Link to this heading">#</a></h3>
<p>제일 먼저 (category, line)의 무작위 쌍을 얻는 함수:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">random</span>

<span class="c1"># 목록에서 무작위 아이템 반환</span>
<span class="k">def</span><span class="w"> </span><span class="nf">randomChoice</span><span class="p">(</span><span class="n">l</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">l</span><span class="p">[</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">l</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)]</span>

<span class="c1"># 임의의 category 및 그 category에서 무작위 줄(이름) 얻기</span>
<span class="k">def</span><span class="w"> </span><span class="nf">randomTrainingPair</span><span class="p">():</span>
    <span class="n">category</span> <span class="o">=</span> <span class="n">randomChoice</span><span class="p">(</span><span class="n">all_categories</span><span class="p">)</span>
    <span class="n">line</span> <span class="o">=</span> <span class="n">randomChoice</span><span class="p">(</span><span class="n">category_lines</span><span class="p">[</span><span class="n">category</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">category</span><span class="p">,</span> <span class="n">line</span>
</pre></div>
</div>
<p>각 시간 단계 마다 (즉, 학습 단어의 각 문자 마다) 네트워크의 입력은
<code class="docutils literal notranslate"><span class="pre">(언어,</span> <span class="pre">현재</span> <span class="pre">문자,</span> <span class="pre">은닉</span> <span class="pre">상태)</span></code> 가 되고, 출력은
<code class="docutils literal notranslate"><span class="pre">(다음</span> <span class="pre">문자,</span> <span class="pre">다음</span> <span class="pre">은닉</span> <span class="pre">상태)</span></code> 가 된다. 따라서 각 학습 세트 마다
언어, 입력 문자의 세트, 출력/목표 문자의 세트가 필요하다.</p>
<p>각 시간 단계마다 현재 문자에서 다음 문자를 예측하기 때문에,
문자 쌍은 한 줄(하나의 이름)에서 연속된 문자 그룹입니다. - 예를 들어 <code class="docutils literal notranslate"><span class="pre">&quot;ABCD&lt;EOS&gt;&quot;</span></code> 는
(“A”, “B”), (“B”, “C”), (“C”, “D”), (“D”, “EOS”) 로 생성합니다.</p>
<figure class="align-default">
<img alt="" src="https://i.imgur.com/JH58tXY.png" />
</figure>
<p>Category(언어) Tensor는 <code class="docutils literal notranslate"><span class="pre">&lt;1</span> <span class="pre">x</span> <span class="pre">n_categories&gt;</span></code> 크기의 <a class="reference external" href="https://en.wikipedia.org/wiki/One-hot">One-hot
Tensor</a> 입니다.
학습시에 모든 시간 단계에서 네트워크에 이것을 전달합니다.
- 이것은 설계 선택사항으로, 초기 은닉 상태 또는
또 다른 전략의 부분으로 포함될 수 있습니다.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Category를 위한 One-hot 벡터</span>
<span class="k">def</span><span class="w"> </span><span class="nf">categoryTensor</span><span class="p">(</span><span class="n">category</span><span class="p">):</span>
    <span class="n">li</span> <span class="o">=</span> <span class="n">all_categories</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">category</span><span class="p">)</span>
    <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_categories</span><span class="p">)</span>
    <span class="n">tensor</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">li</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">tensor</span>

<span class="c1"># 입력을 위한 처음부터 마지막 문자(EOS 제외)까지의  One-hot 행렬</span>
<span class="k">def</span><span class="w"> </span><span class="nf">inputTensor</span><span class="p">(</span><span class="n">line</span><span class="p">):</span>
    <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">line</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_letters</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">li</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">line</span><span class="p">)):</span>
        <span class="n">letter</span> <span class="o">=</span> <span class="n">line</span><span class="p">[</span><span class="n">li</span><span class="p">]</span>
        <span class="n">tensor</span><span class="p">[</span><span class="n">li</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="n">all_letters</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="n">letter</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">tensor</span>

<span class="c1"># 목표를 위한 두번째 문자 부터 마지막(EOS)까지의 ``LongTensor``</span>
<span class="k">def</span><span class="w"> </span><span class="nf">targetTensor</span><span class="p">(</span><span class="n">line</span><span class="p">):</span>
    <span class="n">letter_indexes</span> <span class="o">=</span> <span class="p">[</span><span class="n">all_letters</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="n">line</span><span class="p">[</span><span class="n">li</span><span class="p">])</span> <span class="k">for</span> <span class="n">li</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">line</span><span class="p">))]</span>
    <span class="n">letter_indexes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">n_letters</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># EOS</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">letter_indexes</span><span class="p">)</span>
</pre></div>
</div>
<p>학습 동안 편의를 위해 무작위로 (category[언어], line[이름])을 가져오고
그것을 필요한 형태 (category[언어], input[현재 문자], target[다음 문자]) Tensor로 바꾸는
<code class="docutils literal notranslate"><span class="pre">randomTrainingExample</span></code> 함수를 만들 예정입니다.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 임의의 Category에서 Category, Input, Target Tensor를 만듭니다.</span>
<span class="k">def</span><span class="w"> </span><span class="nf">randomTrainingExample</span><span class="p">():</span>
    <span class="n">category</span><span class="p">,</span> <span class="n">line</span> <span class="o">=</span> <span class="n">randomTrainingPair</span><span class="p">()</span>
    <span class="n">category_tensor</span> <span class="o">=</span> <span class="n">categoryTensor</span><span class="p">(</span><span class="n">category</span><span class="p">)</span>
    <span class="n">input_line_tensor</span> <span class="o">=</span> <span class="n">inputTensor</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
    <span class="n">target_line_tensor</span> <span class="o">=</span> <span class="n">targetTensor</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">category_tensor</span><span class="p">,</span> <span class="n">input_line_tensor</span><span class="p">,</span> <span class="n">target_line_tensor</span>
</pre></div>
</div>
</section>
<section id="id7">
<h3>네트워크 학습<a class="headerlink" href="#id7" title="Link to this heading">#</a></h3>
<p>마지막 출력만 사용하는 분류와 달리, 모든 단계에서 예측을 수행하므로
모든 단계에서 손실을 계산합니다.</p>
<p>Autograd의 마법이 각 단계의 손실들을 간단하게 합하고 마지막에
역전파를 호출하게 해줍니다.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span>

<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.0005</span>

<span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span><span class="n">category_tensor</span><span class="p">,</span> <span class="n">input_line_tensor</span><span class="p">,</span> <span class="n">target_line_tensor</span><span class="p">):</span>
    <span class="n">target_line_tensor</span><span class="o">.</span><span class="n">unsqueeze_</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">hidden</span> <span class="o">=</span> <span class="n">rnn</span><span class="o">.</span><span class="n">initHidden</span><span class="p">()</span>

    <span class="n">rnn</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

    <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">])</span> <span class="c1"># 또는 그냥 ``loss = 0`` 을 사용해도 됩니다.</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">input_line_tensor</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)):</span>
        <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="n">rnn</span><span class="p">(</span><span class="n">category_tensor</span><span class="p">,</span> <span class="n">input_line_tensor</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">hidden</span><span class="p">)</span>
        <span class="n">l</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target_line_tensor</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="n">loss</span> <span class="o">+=</span> <span class="n">l</span>

    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">rnn</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
        <span class="n">p</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">add_</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=-</span><span class="n">learning_rate</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">/</span> <span class="n">input_line_tensor</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<p>학습에 걸리는 시간을 추적하기 위해 사람이 읽을 수 있는 문자열을
반환하는``timeSince (timestamp)`` 함수를 추가합니다:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">math</span>

<span class="k">def</span><span class="w"> </span><span class="nf">timeSince</span><span class="p">(</span><span class="n">since</span><span class="p">):</span>
    <span class="n">now</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">now</span> <span class="o">-</span> <span class="n">since</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">s</span> <span class="o">/</span> <span class="mi">60</span><span class="p">)</span>
    <span class="n">s</span> <span class="o">-=</span> <span class="n">m</span> <span class="o">*</span> <span class="mi">60</span>
    <span class="k">return</span> <span class="s1">&#39;</span><span class="si">%d</span><span class="s1">m </span><span class="si">%d</span><span class="s1">s&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
</pre></div>
</div>
<p>학습은 일상적인 일입니다. - 몇 번 train() 을 호출하고, 몇 분 정도
기다렸다가 <code class="docutils literal notranslate"><span class="pre">print_every</span></code> 마다 현재 시간과 손실을 출력하고,
나중에 도식화를 위해  <code class="docutils literal notranslate"><span class="pre">plot_every</span></code> 마다 <code class="docutils literal notranslate"><span class="pre">all_losses</span></code> 에
평균 손실을 저장합니다.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">rnn</span> <span class="o">=</span> <span class="n">RNN</span><span class="p">(</span><span class="n">n_letters</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">n_letters</span><span class="p">)</span>

<span class="n">n_iters</span> <span class="o">=</span> <span class="mi">100000</span>
<span class="n">print_every</span> <span class="o">=</span> <span class="mi">5000</span>
<span class="n">plot_every</span> <span class="o">=</span> <span class="mi">500</span>
<span class="n">all_losses</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span> <span class="c1"># ``plot_every`` 마다 초기화</span>

<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="k">for</span> <span class="nb">iter</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_iters</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">output</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="o">*</span><span class="n">randomTrainingExample</span><span class="p">())</span>
    <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span>

    <span class="k">if</span> <span class="nb">iter</span> <span class="o">%</span> <span class="n">print_every</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">%s</span><span class="s1"> (</span><span class="si">%d</span><span class="s1"> </span><span class="si">%d%%</span><span class="s1">) </span><span class="si">%.4f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">timeSince</span><span class="p">(</span><span class="n">start</span><span class="p">),</span> <span class="nb">iter</span><span class="p">,</span> <span class="nb">iter</span> <span class="o">/</span> <span class="n">n_iters</span> <span class="o">*</span> <span class="mi">100</span><span class="p">,</span> <span class="n">loss</span><span class="p">))</span>

    <span class="k">if</span> <span class="nb">iter</span> <span class="o">%</span> <span class="n">plot_every</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">all_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">total_loss</span> <span class="o">/</span> <span class="n">plot_every</span><span class="p">)</span>
        <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>0m 15s (5000 5%) 3.0273
0m 26s (10000 10%) 2.8095
0m 38s (15000 15%) 3.2219
0m 49s (20000 20%) 1.5323
1m 1s (25000 25%) 2.5673
1m 12s (30000 30%) 2.1202
1m 23s (35000 35%) 2.5683
1m 35s (40000 40%) 2.3383
1m 46s (45000 45%) 2.3752
1m 57s (50000 50%) 2.7899
2m 8s (55000 55%) 1.7466
2m 19s (60000 60%) 2.2184
2m 31s (65000 65%) 3.2277
2m 42s (70000 70%) 2.4214
2m 53s (75000 75%) 2.9422
3m 4s (80000 80%) 2.3035
3m 15s (85000 85%) 2.5719
3m 26s (90000 90%) 3.0298
3m 38s (95000 95%) 3.1836
3m 49s (100000 100%) 2.6175
</pre></div>
</div>
</section>
<section id="id8">
<h3>손실 도식화<a class="headerlink" href="#id8" title="Link to this heading">#</a></h3>
<p>all_losses를 이용한 손실의 도식화는
네트워크의 학습 상태를 보여줍니다:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">all_losses</span><span class="p">)</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_char_rnn_generation_tutorial_001.png" srcset="../_images/sphx_glr_char_rnn_generation_tutorial_001.png" alt="char rnn generation tutorial" class = "sphx-glr-single-img"/><div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[&lt;matplotlib.lines.Line2D object at 0x7f0dab102bd0&gt;]
</pre></div>
</div>
</section>
</section>
<section id="id9">
<h2>네트워크 샘플링<a class="headerlink" href="#id9" title="Link to this heading">#</a></h2>
<p>샘플링을 위해서, 네트워크에 하나의 글자를 주고 다음 문자를 물어보고
이것을 다음 문자로 전달하는 것을 EOS 토큰까지 반복합니다.</p>
<ul class="simple">
<li><p>입력 카테고리(언어), 시작 문자, 비어 있는 은닉 상태를 위한 Tensor를 생성하십시오</p></li>
<li><p>시작 문자로 <code class="docutils literal notranslate"><span class="pre">output_name</span></code> 문자열을 생성하십시오</p></li>
<li><p>최대 출력 길이까지,</p>
<ul>
<li><p>현재 문자를 네트워크에 전달하십시오.</p></li>
<li><p>가장 높은 출력에서 다음 문자와 다음 은닉 상태를 얻으십시오</p></li>
<li><p>만일 문자가 EOS면, 여기서 멈추십시오</p></li>
<li><p>만일 일반적인 문자라면, <code class="docutils literal notranslate"><span class="pre">output_name</span></code> 에 추가하고 계속하십시오</p></li>
</ul>
</li>
<li><p>마지막 이름을 반환하십시오</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">참고</p>
<p>시작 문자를 주는 것 외에 “문자열 시작” 토큰을 학습에
포함되게 하고 네트워크가 자체적으로 시작 문자를 선택하게 하는
다른 방법도 있습니다.</p>
</div>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">max_length</span> <span class="o">=</span> <span class="mi">20</span>

<span class="c1"># 카테고리와 시작 문자로부터 샘플링 하기</span>
<span class="k">def</span><span class="w"> </span><span class="nf">sample</span><span class="p">(</span><span class="n">category</span><span class="p">,</span> <span class="n">start_letter</span><span class="o">=</span><span class="s1">&#39;A&#39;</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>  <span class="c1"># 샘플링에서 히스토리를 추적할 필요 없음</span>
        <span class="n">category_tensor</span> <span class="o">=</span> <span class="n">categoryTensor</span><span class="p">(</span><span class="n">category</span><span class="p">)</span>
        <span class="nb">input</span> <span class="o">=</span> <span class="n">inputTensor</span><span class="p">(</span><span class="n">start_letter</span><span class="p">)</span>
        <span class="n">hidden</span> <span class="o">=</span> <span class="n">rnn</span><span class="o">.</span><span class="n">initHidden</span><span class="p">()</span>

        <span class="n">output_name</span> <span class="o">=</span> <span class="n">start_letter</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_length</span><span class="p">):</span>
            <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="n">rnn</span><span class="p">(</span><span class="n">category_tensor</span><span class="p">,</span> <span class="nb">input</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">hidden</span><span class="p">)</span>
            <span class="n">topv</span><span class="p">,</span> <span class="n">topi</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">topi</span> <span class="o">=</span> <span class="n">topi</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">topi</span> <span class="o">==</span> <span class="n">n_letters</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">break</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">letter</span> <span class="o">=</span> <span class="n">all_letters</span><span class="p">[</span><span class="n">topi</span><span class="p">]</span>
                <span class="n">output_name</span> <span class="o">+=</span> <span class="n">letter</span>
            <span class="nb">input</span> <span class="o">=</span> <span class="n">inputTensor</span><span class="p">(</span><span class="n">letter</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">output_name</span>

<span class="c1"># 하나의 카테고리와 여러 시작 문자들로 여러 개의 샘플 얻기</span>
<span class="k">def</span><span class="w"> </span><span class="nf">samples</span><span class="p">(</span><span class="n">category</span><span class="p">,</span> <span class="n">start_letters</span><span class="o">=</span><span class="s1">&#39;ABC&#39;</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">start_letter</span> <span class="ow">in</span> <span class="n">start_letters</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">sample</span><span class="p">(</span><span class="n">category</span><span class="p">,</span> <span class="n">start_letter</span><span class="p">))</span>

<span class="n">samples</span><span class="p">(</span><span class="s1">&#39;Russian&#39;</span><span class="p">,</span> <span class="s1">&#39;RUS&#39;</span><span class="p">)</span>

<span class="n">samples</span><span class="p">(</span><span class="s1">&#39;German&#39;</span><span class="p">,</span> <span class="s1">&#39;GER&#39;</span><span class="p">)</span>

<span class="n">samples</span><span class="p">(</span><span class="s1">&#39;Spanish&#39;</span><span class="p">,</span> <span class="s1">&#39;SPA&#39;</span><span class="p">)</span>

<span class="n">samples</span><span class="p">(</span><span class="s1">&#39;Chinese&#39;</span><span class="p">,</span> <span class="s1">&#39;CHI&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Rakovak
Uantovov
Shillov
Gerren
Eren
Rour
Salla
Pares
Allan
Chin
Han
Iun
</pre></div>
</div>
</section>
<section id="exercises">
<h2>Exercises<a class="headerlink" href="#exercises" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Try with a different dataset of category -&gt; line, for example:</p>
<ul>
<li><p>Fictional series -&gt; Character name</p></li>
<li><p>Part of speech -&gt; Word</p></li>
<li><p>Country -&gt; City</p></li>
</ul>
</li>
<li><p>Use a “start of sentence” token so that sampling can be done without
choosing a start letter</p></li>
<li><p>Get better results with a bigger and/or better shaped network</p>
<ul>
<li><p>Try the <code class="docutils literal notranslate"><span class="pre">nn.LSTM</span></code> and <code class="docutils literal notranslate"><span class="pre">nn.GRU</span></code> layers</p></li>
<li><p>상위 수준 네트워크로 여러 개의 이런 RNN을 결합해 보십시오</p></li>
</ul>
</li>
</ul>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (3 minutes 49.522 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-intermediate-char-rnn-generation-tutorial-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/a75cfadf4fa84dd594874d4c53b62820/char_rnn_generation_tutorial.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">char_rnn_generation_tutorial.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/322506af160d5e2056afd75de1fd34ee/char_rnn_generation_tutorial.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">char_rnn_generation_tutorial.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../_downloads/3af0543b3600b020bfdbf10ab130c2f8/char_rnn_generation_tutorial.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">char_rnn_generation_tutorial.zip</span></code></a></p>
</div>
</div>
</section>
</section>


                </article>
              
  </article>
  
              
              
                <footer class="bd-footer-article">
                  <div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item">
<div class="feedback">
  
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
        
    </div>
</div>

  <div class="feedback-send">
    <button class="feedback-btn"
            onclick="openGitHubIssue()"
            data-bs-title="Create a GitHub Issue"
            data-bs-placement="bottom"
            data-bs-toggle="tooltip"
            data-gtm="feedback-btn-click">Send Feedback
    </button>
  </div>
</div>

<div class="prev-next-area">
</div>

<div class="footer-info">
  <p class="copyright">
    
      
        © Copyright 2018-2025, PyTorch &amp; 파이토치 한국 사용자 모임(PyTorchKR).
      
      <br/>
    
  </p>

  <p class="theme-version">
    Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
  </p>
</div>
</div>
  
</div>
                </footer>
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc">
<div class="sidebar-secondary-items sidebar-secondary__inner">
    
       <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">데이터 준비</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">네트워크 생성</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">학습</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">학습 준비</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">네트워크 학습</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">손실 도식화</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">네트워크 샘플링</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">Exercises</a></li>
</ul>
  </nav></div>
    




<div class="sidebar-secondary-item">
  <div class="sidebar-heading">PyTorch Libraries</div>
  <ul style="list-style-type: none; padding: 0; padding-bottom: 80px;">
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/ao" style="color: var(--pst-color-text-muted)">torchao</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchrec" style="color: var(--pst-color-text-muted)">torchrec</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchft" style="color: var(--pst-color-text-muted)">torchft</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchcodec" style="color: var(--pst-color-text-muted)">TorchCodec</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/vision" style="color: var(--pst-color-text-muted)">torchvision</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/executorch" style="color: var(--pst-color-text-muted)">ExecuTorch</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/xla" style="color: var(--pst-color-text-muted)">PyTorch on XLA Devices</a></li>
  
  </ul>
</div>

</div>
</div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <div class="container-fluid docs-tutorials-resources">
  <div class="container">
    <div class="row">
      <div class="col-md-4 text-center">
        <h2>PyTorchKorea @ GitHub</h2>
        <p>파이토치 한국 사용자 모임을 GitHub에서 만나보세요.</p>
        <a class="with-right-arrow" href="https://github.com/PyTorchKorea">GitHub로 이동</a>
      </div>

      <div class="col-md-4 text-center">
        <h2>한국어 튜토리얼</h2>
        <p>한국어로 번역 중인 파이토치 튜토리얼을 만나보세요.</p>
        <a class="with-right-arrow" href="https://tutorials.pytorch.kr/">튜토리얼로 이동</a>
      </div>

      <div class="col-md-4 text-center">
        <h2>한국어 커뮤니티</h2>
        <p>다른 사용자들과 의견을 나누고, 도와주세요!</p>
        <a class="with-right-arrow" href="https://discuss.pytorch.kr/">커뮤니티로 이동</a>
      </div>
    </div>
  </div>
</div>

<footer class="site-footer">
  <div class="container footer-container">
    <div class="footer-logo-wrapper">
      <a href="https://pytorch.kr/" class="footer-logo"></a>
    </div>

    <div class="footer-links-wrapper">
      <div class="footer-links-col">
        <ul>
          <li class="list-title"><a href="https://pytorch.kr/">파이토치 한국 사용자 모임</a></li>
          <li><a href="https://pytorch.kr/about">사용자 모임 소개</a></li>
          <li><a href="https://pytorch.kr/contributors">기여해주신 분들</a></li>
          <li><a href="https://pytorch.kr/resources/">리소스</a></li>
          <li><a href="https://pytorch.kr/coc">행동 강령</a></li>
        </ul>
      </div>
    </div>

    <div class="trademark-disclaimer">
      <ul>
        <li>이 사이트는 독립적인 파이토치 사용자 커뮤니티로, 최신 버전이 아니거나 잘못된 내용이 포함되어 있을 수 있습니다. This site is an independent user community and may be out of date or contain incorrect information.</li>
        <li><a href="https://pytorch.kr/coc">행동 강령</a>을 읽고 지켜주세요. PyTorch 공식 로고 사용 규정은 <a href="https://www.linuxfoundation.org/policies/">Linux Foundation의 정책</a>을 따릅니다. Please read and follow <a href="https://pytorch.kr/coc">our code of conduct</a>. All PyTorch trademark policy applicable to <a href="https://www.linuxfoundation.org/policies/">Linux Foundation's policies</a>.</li>
      </ul>
    </div>
  </div>
</footer>

<div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../_static/img/pytorch-x.svg">
  </div>
</div>
  
  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2018-2025, PyTorch &amp; 파이토치 한국 사용자 모임(PyTorchKR).
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.2.6 버전으로 생성되었습니다.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
</p></div>
      
    </div>
  
</div>

  </footer>
  <script type="application/ld+json">
    {
       "@context": "https://schema.org",
       "@type": "Article",
       "name": "\uae30\ucd08\ubd80\ud130 \uc2dc\uc791\ud558\ub294 NLP: \ubb38\uc790-\ub2e8\uc704 RNN\uc73c\ub85c \uc774\ub984 \uc0dd\uc131\ud558\uae30",
       "headline": "\uae30\ucd08\ubd80\ud130 \uc2dc\uc791\ud558\ub294 NLP: \ubb38\uc790-\ub2e8\uc704 RNN\uc73c\ub85c \uc774\ub984 \uc0dd\uc131\ud558\uae30",
       "description": "PyTorch Documentation. Explore PyTorch, an open-source machine learning library that accelerates the path from research prototyping to production deployment. Discover tutorials, API references, and guides to help you build and deploy deep learning models efficiently.",
       "url": "/intermediate/char_rnn_generation_tutorial.html",
       "articleBody": "\ucc38\uace0 Go to the end to download the full example code. \uae30\ucd08\ubd80\ud130 \uc2dc\uc791\ud558\ub294 NLP: \ubb38\uc790-\ub2e8\uc704 RNN\uc73c\ub85c \uc774\ub984 \uc0dd\uc131\ud558\uae30# Author: Sean Robertson\ubc88\uc5ed: \ud669\uc131\uc218 \uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc740 3\ubd80\ub85c \uad6c\uc131\ub41c \uc2dc\ub9ac\uc988\uc758 \uc77c\ubd80\uc785\ub2c8\ub2e4: \uae30\ucd08\ubd80\ud130 \uc2dc\uc791\ud558\ub294 NLP: \ubb38\uc790-\ub2e8\uc704 RNN\uc73c\ub85c \uc774\ub984 \ubd84\ub958\ud558\uae30 \uae30\ucd08\ubd80\ud130 \uc2dc\uc791\ud558\ub294 NLP: \ubb38\uc790-\ub2e8\uc704 RNN\uc73c\ub85c \uc774\ub984 \uc0dd\uc131\ud558\uae30 \uae30\ucd08\ubd80\ud130 \uc2dc\uc791\ud558\ub294 NLP: Sequence to Sequence \ub124\ud2b8\uc6cc\ud06c\uc640 Attention\uc744 \uc774\uc6a9\ud55c \ubc88\uc5ed \uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc740 3\uac1c\ub85c \uc774\ub904\uc9c4 \u201c\uae30\ucd08\ubd80\ud130 \uc2dc\uc791\ud558\ub294 NLP\u201d\uc758 2\ubc88\uc9f8 \ud29c\ud1a0\ub9ac\uc5bc\uc785\ub2c8\ub2e4. \uccab\ubc88\uc9f8 \ud29c\ud1a0\ub9ac\uc5bc\uc778 \uae30\ucd08\ubd80\ud130 \uc2dc\uc791\ud558\ub294 NLP: \ubb38\uc790-\ub2e8\uc704 RNN\uc73c\ub85c \uc774\ub984 \ubd84\ub958\ud558\uae30 \uc5d0\uc11c\ub294 RNN\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc8fc\uc5b4\uc9c4 \uc774\ub984\uc774 \uc5b4\ub5a0\ud55c \uc5b8\uc5b4\uc778\uc9c0\ub97c \ubd84\ub958\ud588\uc2b5\ub2c8\ub2e4. \uc774\ubc88\uc5d0\ub294 \ubc18\ub300\ub85c \uc5b8\uc5b4\ub85c\ubd80\ud130 \uc774\ub984\uc744 \uc0dd\uc131\ud560 \uc608\uc815\uc785\ub2c8\ub2e4. \u003e python sample.py Russian RUS Rovakov Uantov Shavakov \u003e python sample.py German GER Gerren Ereng Rosher \u003e python sample.py Spanish SPA Salla Parer Allan \u003e python sample.py Chinese CHI Chan Hang Iun \uc6b0\ub9ac\ub294 \uba87 \uac1c\uc758 \uc120\ud615 \uacc4\uce35\uc73c\ub85c \uc791\uc740 RNN\uc744 \uc9c1\uc811 \ub9cc\ub4e4\uace0 \uc788\uc2b5\ub2c8\ub2e4. \uc774\uc804 \ud29c\ud1a0\ub9ac\uc5bc\uc778 \uc774\ub984\uc744 \uc77d\uc740 \ud6c4 \uadf8 \uc5b8\uc5b4\ub97c \uc608\uce21\ud558\ub294 \uac83\uacfc\uc758 \ud070 \ucc28\uc774\uc810\uc740 \uc5b8\uc5b4\ub97c \uc785\ub825\ud558\uace0 \ud55c \ubc88\uc5d0 \ud55c \uae00\uc790\ub97c \uc0dd\uc131\ud558\uc5ec \ucd9c\ub825\ud558\ub294 \uac83\uc785\ub2c8\ub2e4. \uc5b8\uc5b4 \ud615\uc131(\ub2e8\uc5b4 \ub610\ub294 \ub2e4\ub978 \uace0\ucc28\uc6d0 \uad6c\uc870\ub85c\ub3c4 \uc218\ud589\ub420 \uc218 \uc788\uc74c)\uc744 \uc704\ud574 \ubb38\uc790\ub97c \ubc18\ubcf5\uc801\uc73c\ub85c \uc608\uce21\ud558\ub294 \uac83\uc744 \u201c\uc5b8\uc5b4 \ubaa8\ub378\u201d \uc774\ub77c\uace0 \ud569\ub2c8\ub2e4. \ucd94\ucc9c \uc790\ub8cc: Pytorch\ub97c \uc124\uce58\ud588\uace0, Python\uc744 \uc54c\uace0, Tensor\ub97c \uc774\ud574\ud55c\ub2e4\uace0 \uac00\uc815\ud569\ub2c8\ub2e4: https://pytorch.org/ \uc124\uce58 \uc548\ub0b4 PyTorch\ub85c \ub525\ub7ec\ub2dd\ud558\uae30: 60\ubd84\ub9cc\uc5d0 \ub05d\uc7a5\ub0b4\uae30 PyTorch \uc2dc\uc791\ud558\uae30 \uc608\uc81c\ub85c \ubc30\uc6b0\ub294 \ud30c\uc774\ud1a0\uce58(PyTorch) \ub113\uace0 \uae4a\uc740 \ud1b5\ucc30\uc744 \uc704\ud55c \uc790\ub8cc Torch \uc0ac\uc6a9\uc790\ub97c \uc704\ud55c PyTorch \uc774\uc804 Lua Torch \uc0ac\uc6a9\uc790\ub97c \uc704\ud55c \uc790\ub8cc RNN\uacfc \uc791\ub3d9 \ubc29\uc2dd\uc744 \uc544\ub294 \uac83 \ub610\ud55c \uc720\uc6a9\ud569\ub2c8\ub2e4: The Unreasonable Effectiveness of Recurrent Neural Networks \uc2e4\uc0dd\ud65c \uc608\uc81c\ub97c \ubcf4\uc5ec \uc90d\ub2c8\ub2e4. Understanding LSTM Networks LSTM\uc5d0 \uad00\ud55c \uac83\uc774\uc9c0\ub9cc RNN\uc5d0 \uad00\ud574\uc11c\ub3c4 \uc720\uc775\ud569\ub2c8\ub2e4. \uc774\uc804 \ud29c\ud1a0\ub9ac\uc5bc\ub3c4 \ucd94\ucc9c\ud569\ub2c8\ub2e4. \uae30\ucd08\ubd80\ud130 \uc2dc\uc791\ud558\ub294 NLP: \ubb38\uc790-\ub2e8\uc704 RNN\uc73c\ub85c \uc774\ub984 \ubd84\ub958\ud558\uae30 \ub370\uc774\ud130 \uc900\ube44# \ucc38\uace0 \uc5ec\uae30 \uc5d0\uc11c \ub370\uc774\ud130\ub97c \ub2e4\uc6b4 \ubc1b\uace0, \ud604\uc7ac \ub514\ub809\ud1a0\ub9ac\uc5d0 \uc555\ucd95\uc744 \ud478\uc2ed\uc2dc\uc624. \uc774 \uacfc\uc815\uc758 \ub354 \uc790\uc138\ud55c \uc0ac\ud56d\uc740 \uc9c0\ub09c \ud29c\ud1a0\ub9ac\uc5bc\uc744 \ubcf4\uc2ed\uc2dc\uc624. \uc694\uc57d\ud558\uba74, \uc904\ub9c8\ub2e4 \uc774\ub984\uc774 \uc801\ud78c \ud14d\uc2a4\ud2b8 \ud30c\uc77c data/names/[Language].txt \uc788\uc2b5\ub2c8\ub2e4. \uc774\uac83\uc744 array\ub85c \ubd84\ub9ac\ud558\uace0, Unicode\ub97c ASCII\ub85c \ubcc0\uacbd\ud558\uace0, \uc0ac\uc804 {language: [names ...]} \uc744 \ub9cc\ub4e4\uc5b4\uc11c \ub9c8\ubb34\ub9ac\ud569\ub2c8\ub2e4. from __future__ import unicode_literals, print_function, division from io import open import glob import os import unicodedata import string all_letters = string.ascii_letters + \" .,;\u0027-\" n_letters = len(all_letters) + 1 # EOS(end of sentence) \uae30\ud638 \ucd94\uac00 def findFiles(path): return glob.glob(path) # \uc720\ub2c8\ucf54\ub4dc \ubb38\uc790\uc5f4\uc744 ASCII\ub85c \ubcc0\ud658, https://stackoverflow.com/a/518232/2809427 def unicodeToAscii(s): return \u0027\u0027.join( c for c in unicodedata.normalize(\u0027NFD\u0027, s) if unicodedata.category(c) != \u0027Mn\u0027 and c in all_letters ) # \ud30c\uc77c\uc744 \uc77d\uace0 \uc904 \ub2e8\uc704\ub85c \ubd84\ub9ac def readLines(filename): with open(filename, encoding=\u0027utf-8\u0027) as some_file: return [unicodeToAscii(line.strip()) for line in some_file] # \uac01 \uc5b8\uc5b4\uc758 \uc774\ub984 \ubaa9\ub85d\uc778 category_lines \uc0ac\uc804 \uc0dd\uc131 category_lines = {} all_categories = [] for filename in findFiles(\u0027data/names/*.txt\u0027): category = os.path.splitext(os.path.basename(filename))[0] all_categories.append(category) lines = readLines(filename) category_lines[category] = lines n_categories = len(all_categories) if n_categories == 0: raise RuntimeError(\u0027Data not found. Make sure that you downloaded data \u0027 \u0027from https://download.pytorch.org/tutorial/data.zip and extract it to \u0027 \u0027the current directory.\u0027) print(\u0027# categories:\u0027, n_categories, all_categories) print(unicodeToAscii(\"O\u0027N\u00e9\u00e0l\")) # categories: 18 [\u0027English\u0027, \u0027Dutch\u0027, \u0027Spanish\u0027, \u0027Japanese\u0027, \u0027Portuguese\u0027, \u0027Arabic\u0027, \u0027Czech\u0027, \u0027Vietnamese\u0027, \u0027Irish\u0027, \u0027French\u0027, \u0027German\u0027, \u0027Russian\u0027, \u0027Italian\u0027, \u0027Chinese\u0027, \u0027Korean\u0027, \u0027Greek\u0027, \u0027Polish\u0027, \u0027Scottish\u0027] O\u0027Neal \ub124\ud2b8\uc6cc\ud06c \uc0dd\uc131# \uc774 \ub124\ud2b8\uc6cc\ud06c\ub294 \uc9c0\ub09c \ud29c\ud1a0\ub9ac\uc5bc\uc758 RNN \uc774 \ub2e4\ub978 \uc785\ub825\ub4e4\uacfc \uc5f0\uacb0\ub418\ub294 category tensor\ub97c \ucd94\uac00 \uc778\uc790\ub85c \uac00\uc9c0\uac8c \ud655\uc7a5\ud569\ub2c8\ub2e4. category tensor\ub294 \ubb38\uc790 \uc785\ub825\uacfc \ub9c8\ucc2c\uac00\uc9c0\ub85c one-hot \ubca1\ud130\uc785\ub2c8\ub2e4. \uc5ed\uc790\uc8fc: \uae30\uc874 \uc785\ub825\uacfc category tensor\ub97c \uacb0\ud569\ud558\uc5ec \uc785\ub825\uc73c\ub85c \uc0ac\uc6a9\ud558\uae30 \ub54c\ubb38\uc5d0 \uc785\ub825\uc758 \uc0ac\uc774\uc988\uac00 n_categories \ub9cc\ud07c \ucee4\uc9d1\ub2c8\ub2e4. \uc6b0\ub9ac\ub294 \ucd9c\ub825\uc744 \ub2e4\uc74c \ubb38\uc790\uc758 \ud655\ub960\ub85c \ud574\uc11d\ud569\ub2c8\ub2e4. \uc0d8\ud50c\ub9c1 \ud560 \ub54c, \uac00\uc7a5 \ud655\ub960\uc774 \ub192\uc740 \ubb38\uc790\uac00 \ub2e4\uc74c \uc785\ub825 \ubb38\uc790\ub85c \uc0ac\uc6a9\ub429\ub2c8\ub2e4. \ub354 \ub098\uc740 \ub3d9\uc791\uc744 \uc704\ud574 \ub450 \ubc88\uc9f8 \uc120\ud615 \ub808\uc774\uc5b4 o2o (\uc740\ub2c9\uacfc \ucd9c\ub825\uc744 \uacb0\ud569\ud55c \ud6c4) \ub97c \ucd94\uac00\ud588\uc2b5\ub2c8\ub2e4 . \ub610\ud55c Drop-out \uacc4\uce35\uc774 \uc788\uc2b5\ub2c8\ub2e4. \uc774 \uacc4\uce35\uc740 \uc8fc\uc5b4\uc9c4 \ud655\ub960(\uc5ec\uae30\uc11c\ub294 0.1)\ub85c \ubb34\uc791\uc704\ub85c \uc785\ub825\uc744 0 # \uc73c\ub85c \ub9cc\ub4ed\ub2c8\ub2e4. \uc77c\ubc18\uc801\uc73c\ub85c \uc785\ub825\uc744 \ud750\ub9ac\uac8c \ud574\uc11c \uacfc\uc801\ud569\uc744 \ub9c9\ub294 \ub370 \uc0ac\uc6a9\ub429\ub2c8\ub2e4. \uc5ec\uae30\uc11c \uc6b0\ub9ac\ub294 \uace0\uc758\ub85c \uc77c\ubd80 \ud63c\ub3c8\uc744 \ucd94\uac00\ud558\uace0 \uc0d8\ud50c\ub9c1 \ub2e4\uc591\uc131\uc744 \ub192\uc774\uae30 \uc704\ud574 \ub124\ud2b8\uc6cc\ud06c\uc758 \ub9c8\uc9c0\ub9c9\uc5d0 \uc774\uac83\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4. import torch import torch.nn as nn class RNN(nn.Module): def __init__(self, input_size, hidden_size, output_size): super(RNN, self).__init__() self.hidden_size = hidden_size self.i2h = nn.Linear(n_categories + input_size + hidden_size, hidden_size) self.i2o = nn.Linear(n_categories + input_size + hidden_size, output_size) self.o2o = nn.Linear(hidden_size + output_size, output_size) self.dropout = nn.Dropout(0.1) self.softmax = nn.LogSoftmax(dim=1) def forward(self, category, input, hidden): input_combined = torch.cat((category, input, hidden), 1) hidden = self.i2h(input_combined) output = self.i2o(input_combined) output_combined = torch.cat((hidden, output), 1) output = self.o2o(output_combined) output = self.dropout(output) output = self.softmax(output) return output, hidden def initHidden(self): return torch.zeros(1, self.hidden_size) \ud559\uc2b5# \ud559\uc2b5 \uc900\ube44# \uc81c\uc77c \uba3c\uc800 (category, line)\uc758 \ubb34\uc791\uc704 \uc30d\uc744 \uc5bb\ub294 \ud568\uc218: import random # \ubaa9\ub85d\uc5d0\uc11c \ubb34\uc791\uc704 \uc544\uc774\ud15c \ubc18\ud658 def randomChoice(l): return l[random.randint(0, len(l) - 1)] # \uc784\uc758\uc758 category \ubc0f \uadf8 category\uc5d0\uc11c \ubb34\uc791\uc704 \uc904(\uc774\ub984) \uc5bb\uae30 def randomTrainingPair(): category = randomChoice(all_categories) line = randomChoice(category_lines[category]) return category, line \uac01 \uc2dc\uac04 \ub2e8\uacc4 \ub9c8\ub2e4 (\uc989, \ud559\uc2b5 \ub2e8\uc5b4\uc758 \uac01 \ubb38\uc790 \ub9c8\ub2e4) \ub124\ud2b8\uc6cc\ud06c\uc758 \uc785\ub825\uc740 (\uc5b8\uc5b4, \ud604\uc7ac \ubb38\uc790, \uc740\ub2c9 \uc0c1\ud0dc) \uac00 \ub418\uace0, \ucd9c\ub825\uc740 (\ub2e4\uc74c \ubb38\uc790, \ub2e4\uc74c \uc740\ub2c9 \uc0c1\ud0dc) \uac00 \ub41c\ub2e4. \ub530\ub77c\uc11c \uac01 \ud559\uc2b5 \uc138\ud2b8 \ub9c8\ub2e4 \uc5b8\uc5b4, \uc785\ub825 \ubb38\uc790\uc758 \uc138\ud2b8, \ucd9c\ub825/\ubaa9\ud45c \ubb38\uc790\uc758 \uc138\ud2b8\uac00 \ud544\uc694\ud558\ub2e4. \uac01 \uc2dc\uac04 \ub2e8\uacc4\ub9c8\ub2e4 \ud604\uc7ac \ubb38\uc790\uc5d0\uc11c \ub2e4\uc74c \ubb38\uc790\ub97c \uc608\uce21\ud558\uae30 \ub54c\ubb38\uc5d0, \ubb38\uc790 \uc30d\uc740 \ud55c \uc904(\ud558\ub098\uc758 \uc774\ub984)\uc5d0\uc11c \uc5f0\uc18d\ub41c \ubb38\uc790 \uadf8\ub8f9\uc785\ub2c8\ub2e4. - \uc608\ub97c \ub4e4\uc5b4 \"ABCD\u003cEOS\u003e\" \ub294 (\u201cA\u201d, \u201cB\u201d), (\u201cB\u201d, \u201cC\u201d), (\u201cC\u201d, \u201cD\u201d), (\u201cD\u201d, \u201cEOS\u201d) \ub85c \uc0dd\uc131\ud569\ub2c8\ub2e4. Category(\uc5b8\uc5b4) Tensor\ub294 \u003c1 x n_categories\u003e \ud06c\uae30\uc758 One-hot Tensor \uc785\ub2c8\ub2e4. \ud559\uc2b5\uc2dc\uc5d0 \ubaa8\ub4e0 \uc2dc\uac04 \ub2e8\uacc4\uc5d0\uc11c \ub124\ud2b8\uc6cc\ud06c\uc5d0 \uc774\uac83\uc744 \uc804\ub2ec\ud569\ub2c8\ub2e4. - \uc774\uac83\uc740 \uc124\uacc4 \uc120\ud0dd\uc0ac\ud56d\uc73c\ub85c, \ucd08\uae30 \uc740\ub2c9 \uc0c1\ud0dc \ub610\ub294 \ub610 \ub2e4\ub978 \uc804\ub7b5\uc758 \ubd80\ubd84\uc73c\ub85c \ud3ec\ud568\ub420 \uc218 \uc788\uc2b5\ub2c8\ub2e4. # Category\ub97c \uc704\ud55c One-hot \ubca1\ud130 def categoryTensor(category): li = all_categories.index(category) tensor = torch.zeros(1, n_categories) tensor[0][li] = 1 return tensor # \uc785\ub825\uc744 \uc704\ud55c \ucc98\uc74c\ubd80\ud130 \ub9c8\uc9c0\ub9c9 \ubb38\uc790(EOS \uc81c\uc678)\uae4c\uc9c0\uc758 One-hot \ud589\ub82c def inputTensor(line): tensor = torch.zeros(len(line), 1, n_letters) for li in range(len(line)): letter = line[li] tensor[li][0][all_letters.find(letter)] = 1 return tensor # \ubaa9\ud45c\ub97c \uc704\ud55c \ub450\ubc88\uc9f8 \ubb38\uc790 \ubd80\ud130 \ub9c8\uc9c0\ub9c9(EOS)\uae4c\uc9c0\uc758 ``LongTensor`` def targetTensor(line): letter_indexes = [all_letters.find(line[li]) for li in range(1, len(line))] letter_indexes.append(n_letters - 1) # EOS return torch.LongTensor(letter_indexes) \ud559\uc2b5 \ub3d9\uc548 \ud3b8\uc758\ub97c \uc704\ud574 \ubb34\uc791\uc704\ub85c (category[\uc5b8\uc5b4], line[\uc774\ub984])\uc744 \uac00\uc838\uc624\uace0 \uadf8\uac83\uc744 \ud544\uc694\ud55c \ud615\ud0dc (category[\uc5b8\uc5b4], input[\ud604\uc7ac \ubb38\uc790], target[\ub2e4\uc74c \ubb38\uc790]) Tensor\ub85c \ubc14\uafb8\ub294 randomTrainingExample \ud568\uc218\ub97c \ub9cc\ub4e4 \uc608\uc815\uc785\ub2c8\ub2e4. # \uc784\uc758\uc758 Category\uc5d0\uc11c Category, Input, Target Tensor\ub97c \ub9cc\ub4ed\ub2c8\ub2e4. def randomTrainingExample(): category, line = randomTrainingPair() category_tensor = categoryTensor(category) input_line_tensor = inputTensor(line) target_line_tensor = targetTensor(line) return category_tensor, input_line_tensor, target_line_tensor \ub124\ud2b8\uc6cc\ud06c \ud559\uc2b5# \ub9c8\uc9c0\ub9c9 \ucd9c\ub825\ub9cc \uc0ac\uc6a9\ud558\ub294 \ubd84\ub958\uc640 \ub2ec\ub9ac, \ubaa8\ub4e0 \ub2e8\uacc4\uc5d0\uc11c \uc608\uce21\uc744 \uc218\ud589\ud558\ubbc0\ub85c \ubaa8\ub4e0 \ub2e8\uacc4\uc5d0\uc11c \uc190\uc2e4\uc744 \uacc4\uc0b0\ud569\ub2c8\ub2e4. Autograd\uc758 \ub9c8\ubc95\uc774 \uac01 \ub2e8\uacc4\uc758 \uc190\uc2e4\ub4e4\uc744 \uac04\ub2e8\ud558\uac8c \ud569\ud558\uace0 \ub9c8\uc9c0\ub9c9\uc5d0 \uc5ed\uc804\ud30c\ub97c \ud638\ucd9c\ud558\uac8c \ud574\uc90d\ub2c8\ub2e4. criterion = nn.NLLLoss() learning_rate = 0.0005 def train(category_tensor, input_line_tensor, target_line_tensor): target_line_tensor.unsqueeze_(-1) hidden = rnn.initHidden() rnn.zero_grad() loss = torch.Tensor([0]) # \ub610\ub294 \uadf8\ub0e5 ``loss = 0`` \uc744 \uc0ac\uc6a9\ud574\ub3c4 \ub429\ub2c8\ub2e4. for i in range(input_line_tensor.size(0)): output, hidden = rnn(category_tensor, input_line_tensor[i], hidden) l = criterion(output, target_line_tensor[i]) loss += l loss.backward() for p in rnn.parameters(): p.data.add_(p.grad.data, alpha=-learning_rate) return output, loss.item() / input_line_tensor.size(0) \ud559\uc2b5\uc5d0 \uac78\ub9ac\ub294 \uc2dc\uac04\uc744 \ucd94\uc801\ud558\uae30 \uc704\ud574 \uc0ac\ub78c\uc774 \uc77d\uc744 \uc218 \uc788\ub294 \ubb38\uc790\uc5f4\uc744 \ubc18\ud658\ud558\ub294``timeSince (timestamp)`` \ud568\uc218\ub97c \ucd94\uac00\ud569\ub2c8\ub2e4: import time import math def timeSince(since): now = time.time() s = now - since m = math.floor(s / 60) s -= m * 60 return \u0027%dm %ds\u0027 % (m, s) \ud559\uc2b5\uc740 \uc77c\uc0c1\uc801\uc778 \uc77c\uc785\ub2c8\ub2e4. - \uba87 \ubc88 train() \uc744 \ud638\ucd9c\ud558\uace0, \uba87 \ubd84 \uc815\ub3c4 \uae30\ub2e4\ub838\ub2e4\uac00 print_every \ub9c8\ub2e4 \ud604\uc7ac \uc2dc\uac04\uacfc \uc190\uc2e4\uc744 \ucd9c\ub825\ud558\uace0, \ub098\uc911\uc5d0 \ub3c4\uc2dd\ud654\ub97c \uc704\ud574 plot_every \ub9c8\ub2e4 all_losses \uc5d0 \ud3c9\uade0 \uc190\uc2e4\uc744 \uc800\uc7a5\ud569\ub2c8\ub2e4. rnn = RNN(n_letters, 128, n_letters) n_iters = 100000 print_every = 5000 plot_every = 500 all_losses = [] total_loss = 0 # ``plot_every`` \ub9c8\ub2e4 \ucd08\uae30\ud654 start = time.time() for iter in range(1, n_iters + 1): output, loss = train(*randomTrainingExample()) total_loss += loss if iter % print_every == 0: print(\u0027%s (%d %d%%) %.4f\u0027 % (timeSince(start), iter, iter / n_iters * 100, loss)) if iter % plot_every == 0: all_losses.append(total_loss / plot_every) total_loss = 0 0m 15s (5000 5%) 3.0273 0m 26s (10000 10%) 2.8095 0m 38s (15000 15%) 3.2219 0m 49s (20000 20%) 1.5323 1m 1s (25000 25%) 2.5673 1m 12s (30000 30%) 2.1202 1m 23s (35000 35%) 2.5683 1m 35s (40000 40%) 2.3383 1m 46s (45000 45%) 2.3752 1m 57s (50000 50%) 2.7899 2m 8s (55000 55%) 1.7466 2m 19s (60000 60%) 2.2184 2m 31s (65000 65%) 3.2277 2m 42s (70000 70%) 2.4214 2m 53s (75000 75%) 2.9422 3m 4s (80000 80%) 2.3035 3m 15s (85000 85%) 2.5719 3m 26s (90000 90%) 3.0298 3m 38s (95000 95%) 3.1836 3m 49s (100000 100%) 2.6175 \uc190\uc2e4 \ub3c4\uc2dd\ud654# all_losses\ub97c \uc774\uc6a9\ud55c \uc190\uc2e4\uc758 \ub3c4\uc2dd\ud654\ub294 \ub124\ud2b8\uc6cc\ud06c\uc758 \ud559\uc2b5 \uc0c1\ud0dc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4: import matplotlib.pyplot as plt plt.figure() plt.plot(all_losses) [\u003cmatplotlib.lines.Line2D object at 0x7f0dab102bd0\u003e] \ub124\ud2b8\uc6cc\ud06c \uc0d8\ud50c\ub9c1# \uc0d8\ud50c\ub9c1\uc744 \uc704\ud574\uc11c, \ub124\ud2b8\uc6cc\ud06c\uc5d0 \ud558\ub098\uc758 \uae00\uc790\ub97c \uc8fc\uace0 \ub2e4\uc74c \ubb38\uc790\ub97c \ubb3c\uc5b4\ubcf4\uace0 \uc774\uac83\uc744 \ub2e4\uc74c \ubb38\uc790\ub85c \uc804\ub2ec\ud558\ub294 \uac83\uc744 EOS \ud1a0\ud070\uae4c\uc9c0 \ubc18\ubcf5\ud569\ub2c8\ub2e4. \uc785\ub825 \uce74\ud14c\uace0\ub9ac(\uc5b8\uc5b4), \uc2dc\uc791 \ubb38\uc790, \ube44\uc5b4 \uc788\ub294 \uc740\ub2c9 \uc0c1\ud0dc\ub97c \uc704\ud55c Tensor\ub97c \uc0dd\uc131\ud558\uc2ed\uc2dc\uc624 \uc2dc\uc791 \ubb38\uc790\ub85c output_name \ubb38\uc790\uc5f4\uc744 \uc0dd\uc131\ud558\uc2ed\uc2dc\uc624 \ucd5c\ub300 \ucd9c\ub825 \uae38\uc774\uae4c\uc9c0, \ud604\uc7ac \ubb38\uc790\ub97c \ub124\ud2b8\uc6cc\ud06c\uc5d0 \uc804\ub2ec\ud558\uc2ed\uc2dc\uc624. \uac00\uc7a5 \ub192\uc740 \ucd9c\ub825\uc5d0\uc11c \ub2e4\uc74c \ubb38\uc790\uc640 \ub2e4\uc74c \uc740\ub2c9 \uc0c1\ud0dc\ub97c \uc5bb\uc73c\uc2ed\uc2dc\uc624 \ub9cc\uc77c \ubb38\uc790\uac00 EOS\uba74, \uc5ec\uae30\uc11c \uba48\ucd94\uc2ed\uc2dc\uc624 \ub9cc\uc77c \uc77c\ubc18\uc801\uc778 \ubb38\uc790\ub77c\uba74, output_name \uc5d0 \ucd94\uac00\ud558\uace0 \uacc4\uc18d\ud558\uc2ed\uc2dc\uc624 \ub9c8\uc9c0\ub9c9 \uc774\ub984\uc744 \ubc18\ud658\ud558\uc2ed\uc2dc\uc624 \ucc38\uace0 \uc2dc\uc791 \ubb38\uc790\ub97c \uc8fc\ub294 \uac83 \uc678\uc5d0 \u201c\ubb38\uc790\uc5f4 \uc2dc\uc791\u201d \ud1a0\ud070\uc744 \ud559\uc2b5\uc5d0 \ud3ec\ud568\ub418\uac8c \ud558\uace0 \ub124\ud2b8\uc6cc\ud06c\uac00 \uc790\uccb4\uc801\uc73c\ub85c \uc2dc\uc791 \ubb38\uc790\ub97c \uc120\ud0dd\ud558\uac8c \ud558\ub294 \ub2e4\ub978 \ubc29\ubc95\ub3c4 \uc788\uc2b5\ub2c8\ub2e4. max_length = 20 # \uce74\ud14c\uace0\ub9ac\uc640 \uc2dc\uc791 \ubb38\uc790\ub85c\ubd80\ud130 \uc0d8\ud50c\ub9c1 \ud558\uae30 def sample(category, start_letter=\u0027A\u0027): with torch.no_grad(): # \uc0d8\ud50c\ub9c1\uc5d0\uc11c \ud788\uc2a4\ud1a0\ub9ac\ub97c \ucd94\uc801\ud560 \ud544\uc694 \uc5c6\uc74c category_tensor = categoryTensor(category) input = inputTensor(start_letter) hidden = rnn.initHidden() output_name = start_letter for i in range(max_length): output, hidden = rnn(category_tensor, input[0], hidden) topv, topi = output.topk(1) topi = topi[0][0] if topi == n_letters - 1: break else: letter = all_letters[topi] output_name += letter input = inputTensor(letter) return output_name # \ud558\ub098\uc758 \uce74\ud14c\uace0\ub9ac\uc640 \uc5ec\ub7ec \uc2dc\uc791 \ubb38\uc790\ub4e4\ub85c \uc5ec\ub7ec \uac1c\uc758 \uc0d8\ud50c \uc5bb\uae30 def samples(category, start_letters=\u0027ABC\u0027): for start_letter in start_letters: print(sample(category, start_letter)) samples(\u0027Russian\u0027, \u0027RUS\u0027) samples(\u0027German\u0027, \u0027GER\u0027) samples(\u0027Spanish\u0027, \u0027SPA\u0027) samples(\u0027Chinese\u0027, \u0027CHI\u0027) Rakovak Uantovov Shillov Gerren Eren Rour Salla Pares Allan Chin Han Iun Exercises# Try with a different dataset of category -\u003e line, for example: Fictional series -\u003e Character name Part of speech -\u003e Word Country -\u003e City Use a \u201cstart of sentence\u201d token so that sampling can be done without choosing a start letter Get better results with a bigger and/or better shaped network Try the nn.LSTM and nn.GRU layers \uc0c1\uc704 \uc218\uc900 \ub124\ud2b8\uc6cc\ud06c\ub85c \uc5ec\ub7ec \uac1c\uc758 \uc774\ub7f0 RNN\uc744 \uacb0\ud569\ud574 \ubcf4\uc2ed\uc2dc\uc624 Total running time of the script: (3 minutes 49.522 seconds) Download Jupyter notebook: char_rnn_generation_tutorial.ipynb Download Python source code: char_rnn_generation_tutorial.py Download zipped: char_rnn_generation_tutorial.zip",
       "author": {
         "@type": "Organization",
         "name": "PyTorch Contributors",
         "url": "https://pytorch.org"
       },
       "image": "../_static/img/pytorch_seo.png",
       "mainEntityOfPage": {
         "@type": "WebPage",
         "@id": "/intermediate/char_rnn_generation_tutorial.html"
       },
       "datePublished": "2023-01-01T00:00:00Z",
       "dateModified": "2023-01-01T00:00:00Z"
     }
 </script>
  <script>
    // Tutorials Call to action event tracking
    $("[data-behavior='call-to-action-event']").on('click', function () {
      fbq('trackCustom', "Download", {
        tutorialTitle: $('h1:first').text(),
        downloadLink: this.href,
        tutorialLink: window.location.href,
        downloadTitle: $(this).attr("data-response")
      });
      if (typeof gtag === 'function') {
        gtag('event', 'click', {
          'event_category': $(this).attr("data-response"),
          'event_label': $("h1").first().text(),
          'tutorial_link': window.location.href
        });
      }
    });
  </script>
  
  </body>
</html>