
<!DOCTYPE html>


<html lang="ko" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <meta property="article:modified_time" content="2022-11-30T07:09:41+00:00" /><meta property="og:title" content="가지치기 기법(Pruning) 튜토리얼" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://tutorials.pytorch.kr/intermediate/pruning_tutorial.html" />
<meta property="og:site_name" content="PyTorch Tutorials KR" />
<meta property="og:description" content="Author: Michela Paganini, 번역: 안상준,. 최첨단 딥러닝 모델들은 굉장히 많은 수의 파라미터값들로 구성되기 때문에, 쉽게 배포하기가 어렵습니다. 이와 반대로, 생물학적 신경망들은 효율적으로 희소하게 연결된 것으로 알려져 있습니다. 모델의 정확도를 훼손하지 않으면서 모델에 포함된 파라미터 수를 줄여 압축하는 최적의 기법을 파악하는 것은 메모리, 배터리, 하드웨어 소비량을 줄일 수 있기 때문에 중요합니다. 그럼으로서 기기에 경량화된 모델을 배포하여 개개인이 사용하고 있는 기기에서 연산을 수행하여 프라이버시를 ..." />
<meta property="og:image" content="https://tutorials.pytorch.kr/_static/logos/logo-kr-sm-dark.png" />
<meta property="og:image:alt" content="PyTorch Tutorials KR" />
<meta name="description" content="Author: Michela Paganini, 번역: 안상준,. 최첨단 딥러닝 모델들은 굉장히 많은 수의 파라미터값들로 구성되기 때문에, 쉽게 배포하기가 어렵습니다. 이와 반대로, 생물학적 신경망들은 효율적으로 희소하게 연결된 것으로 알려져 있습니다. 모델의 정확도를 훼손하지 않으면서 모델에 포함된 파라미터 수를 줄여 압축하는 최적의 기법을 파악하는 것은 메모리, 배터리, 하드웨어 소비량을 줄일 수 있기 때문에 중요합니다. 그럼으로서 기기에 경량화된 모델을 배포하여 개개인이 사용하고 있는 기기에서 연산을 수행하여 프라이버시를 ..." />
<meta property="og:ignore_canonical" content="true" />

    <title>가지치기 기법(Pruning) 튜토리얼 &#8212; 파이토치 한국어 튜토리얼 (PyTorch tutorials in Korean)</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=536c50fe" />
    <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=4d2595e5" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/katex-math.css?v=91adb8b6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/pytorch_theme.css?v=c326296f" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css?v=097efa9c" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom2.css?v=b169ea90" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=725a5b95"></script>
    <script src="../_static/doctools.js?v=92e14aea"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/translations.js?v=b5f768d8"></script>
    <script src="../_static/katex.min.js?v=be8ff15f"></script>
    <script src="../_static/auto-render.min.js?v=ad136472"></script>
    <script src="../_static/katex_autorenderer.js?v=bebc588a"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'intermediate/pruning_tutorial';</script>
    <link rel="canonical" href="https://tutorials.pytorch.kr/intermediate/pruning_tutorial.html" />
    <link rel="icon" href="../_static/favicon.ico"/>
    <link rel="index" title="색인" href="../genindex.html" />
    <link rel="search" title="검색" href="../search.html" />
    <link rel="next" title="(Beta) Scaled Dot Product Attention (SDPA)로 고성능 트랜스포머(Transformers) 구현하기" href="scaled_dot_product_attention_tutorial.html" />
    <link rel="prev" title="Parametrizations Tutorial" href="parametrizations.html" />

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="ko"/>
    <meta name="docbuild:last-update" content="2022년 11월 30일"/>
<script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/2.3.1/list.min.js"></script>
<script>
  if (window.location.hostname === 'docs.pytorch.org' || window.location.hostname === 'docs-preview.pytorch.org') {
    const script = document.createElement('script');
    script.src = 'https://cmp.osano.com/16A0DbT9yDNIaQkvZ/31b1b91a-e0b6-47ea-bde2-7f2bd13dbe5c/osano.js?variant=one';
    document.head.appendChild(script);
  }
</script>
<script>
  // Cookie banner for non-LF projects
  document.addEventListener('DOMContentLoaded', function () {
    // Hide cookie banner on local environments and LF owned docs
    if (window.location.hostname === 'localhost' ||
      window.location.hostname === '0.0.0.0' ||
      window.location.hostname === '127.0.0.1' ||
      window.location.hostname === 'docs.pytorch.org' ||
      window.location.hostname === 'docs-preview.pytorch.org' ||
      window.location.hostname.startsWith('192.168.')) {
      const banner = document.querySelector('.cookie-banner-wrapper');
      if (banner) {
        banner.style.display = 'none';
      }
    }
  });
</script>
<!-- Conditional CSS for header and footer height adjustment -->

<link rel="stylesheet" type="text/css" href="../_static/css/theme.css" crossorigin="anonymous">
<script type="text/javascript" src="../_static/js/theme.js"></script>
<script type="text/javascript" src="../_static/js/dropdown-menu.js"></script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Nanum+Gothic:wght@400;700&family=Nanum+Gothic+Coding:wght@400;700&family=Montserrat:wght@300;400&display=swap" rel="stylesheet">
<meta property="og:image" content="../_static/img/pytorch_seo.png" />
<link rel="stylesheet" href="../_static/webfonts/all.min.css" crossorigin="anonymous">
<meta http-equiv="Content-Security-Policy"
  content="default-src * 'unsafe-inline' 'unsafe-eval' data: blob:; style-src * 'unsafe-inline'; script-src * 'unsafe-inline' 'unsafe-eval' blob:;">
<meta name="pytorch_project" content="tutorials">
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=G-LZRD6GXDLF" height="0" width="0"
    style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
<!-- Google Tag Manager -->
<script>(function (w, d, s, l, i) {
    w[l] = w[l] || []; w[l].push({
      'gtm.start':
        new Date().getTime(), event: 'gtm.js'
    }); var f = d.getElementsByTagName(s)[0],
      j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : ''; j.async = true; j.src =
        'https://www.googletagmanager.com/gtm.js?id=' + i + dl; f.parentNode.insertBefore(j, f);
    j.onload = function () {
      window.dispatchEvent(new Event('gtm_loaded'));
      console.log('GTM loaded successfully');
    };
  })(window, document, 'script', 'dataLayer', 'G-LZRD6GXDLF');
</script>
<!-- End Google Tag Manager -->
<!-- Facebook Pixel Code -->
<script>
  !function (f, b, e, v, n, t, s) {
    if (f.fbq) return; n = f.fbq = function () {
      n.callMethod ?
        n.callMethod.apply(n, arguments) : n.queue.push(arguments)
    };
    if (!f._fbq) f._fbq = n; n.push = n; n.loaded = !0; n.version = '2.0';
    n.queue = []; t = b.createElement(e); t.async = !0;
    t.src = v; s = b.getElementsByTagName(e)[0];
    s.parentNode.insertBefore(t, s)
  }(window, document, 'script',
    'https://connect.facebook.net/en_US/fbevents.js');
  fbq('init', '243028289693773');
  fbq('track', 'PageView');
</script>
<script>
  document.documentElement.setAttribute('data-version', 'v2.8.0+cu128');
</script>
<noscript>
  <img height="1" width="1" src="https://www.facebook.com/tr?id=243028289693773&ev=PageView&noscript=1" />
</noscript>
<script>
  function gtag() {
    window.dataLayer.push(arguments);
  }
</script>
<!-- End Facebook Pixel Code -->
<!-- Script to Fix scrolling -->
<script>
  document.addEventListener('DOMContentLoaded', function () {
    // Fix anchor scrolling
    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener('click', function (e) {
        e.preventDefault();
        const targetId = this.getAttribute('href').substring(1);
        const targetElement = document.getElementById(targetId);

        if (targetElement) {
          const headerHeight =
            (document.querySelector('.header-holder') ? document.querySelector('.header-holder').offsetHeight : 0) +
            (document.querySelector('.bd-header') ? document.querySelector('.bd-header').offsetHeight : 0) + 20;

          const targetPosition = targetElement.getBoundingClientRect().top + window.pageYOffset - headerHeight;
          window.scrollTo({
            top: targetPosition,
            behavior: 'smooth'
          });

          // Update URL hash without scrolling
          history.pushState(null, null, '#' + targetId);
        }
      });
    });
  });
</script>

<script async src="https://cse.google.com/cse.js?cx=e65585f8c3ea1440e"></script>


  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="ko"/>
    <meta name="docbuild:last-update" content="2022년 11월 30일"/>

  </head>

<body data-feedback-url="https://github.com/PyTorchKorea/tutorials-kr" class="pytorch-body">
  
    <div class="container-fluid header-holder tutorials-header" id="header-holder">
   <div class="header-container-wrapper">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.kr/" aria-label="PyTorchKR"></a>

      <div class="main-menu">
        <ul>

          <li class="main-menu-item">
          <div id="learnDropdownButton" data-toggle="learn-dropdown" class="learn-dropdown">
              <a class="with-down-arrow">
                <span>배우기</span>
              </a>
              <div class="learn-dropdown-menu dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.kr/get-started/locally/">
                  <span class="dropdown-title">PyTorch 시작하기</span>
                </a>
                <a class="nav-dropdown-item" href="https://tutorials.pytorch.kr/beginner/basics/intro.html">
                  <span class="dropdown-title">기본 익히기</span>
                </a>
                <a class="nav-dropdown-item" href="https://tutorials.pytorch.kr/" target="_self">
                  <span class="dropdown-title">한국어 튜토리얼</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.kr/hub/">
                  <span class="dropdown-title">한국어 모델 허브</span>
                </a>
                <a class="nav-dropdown-item" href="https://docs.pytorch.org/tutorials/" target="_blank">
                  <span class="dropdown-title">Official Tutorials</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <a href="https://pytorch.kr/blog/">
              <span>블로그</span>
            </a>
          </li>

          <li class="main-menu-item">
          <div id="docsDropdownButton" data-toggle="docs-dropdown" class="docs-dropdown">
              <a class="with-down-arrow">
              <span>문서</span>
              </a>
              <div class="docs-dropdown-menu dropdown-menu">
                <a class="nav-dropdown-item" href="https://docs.pytorch.org/docs/" target="_blank">
                  <span class="dropdown-title">PyTorch API</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.kr/domains/">
                  <span class="dropdown-title">Domain API 소개</span>
                </a>
                <a class="nav-dropdown-item" href="https://tutorials.pytorch.kr/" target="_self">
                  <span class="dropdown-title">한국어 튜토리얼</span>
                </a>
                <a class="nav-dropdown-item" href="https://docs.pytorch.org/tutorials/" target="_blank">
                  <span class="dropdown-title">Official Tutorials</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
          <div id="communityDropdownButton" data-toggle="community-dropdown" class="community-dropdown">
              <a class="with-down-arrow">
              <span>커뮤니티</span>
              </a>
              <div class="community-dropdown-menu dropdown-menu">
                <a class="nav-dropdown-item" href="https://discuss.pytorch.kr/" target="_self">
                  <span class="dropdown-title">한국어 커뮤니티</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.kr/resources/">
                  <span class="dropdown-title">개발자 정보</span>
                </a>
                <a class="nav-dropdown-item" href="https://landscape.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Landscape</span>
                </a>
              </div>
            </div>
          </li>

        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu">
        <i class="fa-solid fa-ellipsis"></i>
      </a>
    </div>
  </div>
 </div>

 <!-- Begin Mobile Menu -->

<div class="mobile-main-menu">
  <div class="container-fluid">
    <div class="header-container-wrapper">
      <div class="mobile-main-menu-header-container">
        <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu">
          <i class="fa-solid fa-xmark"></i>
        </a>
      </div>
    </div>
  </div>

  <div class="mobile-main-menu-links-container">
    <div class="main-menu">
      <ul>
         <li class="resources-mobile-menu-title">
           <a>배우기</a>
         </li>
         <ul class="resources-mobile-menu-items">
           <li>
             <a href="https://pytorch.kr/get-started/locally/">PyTorch 시작하기</a>
           </li>
           <li>
             <a href="https://tutorials.pytorch.kr/beginner/basics/intro.html">기본 익히기</a>
           </li>
           <li>
             <a href="https://tutorials.pytorch.kr/">한국어 튜토리얼</a>
           </li>
           <li>
             <a href="https://pytorch.kr/hub/">한국어 모델 허브</a>
           </li>
           <li>
             <a href="https://docs.pytorch.org/tutorials/" target="_blank">Official Tutorials</a>
           </li>
        </ul>
         <li class="resources-mobile-menu-title">
           <a href="https://pytorch.kr/blog/">블로그</a>
         </li>
         <li class="resources-mobile-menu-title">
           <a>문서</a>
         </li>
         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://docs.pytorch.org/docs/" target="_blank">PyTorch API</a>
          </li>
          <li>
            <a href="https://pytorch.kr/domains/">Domain API 소개</a>
          </li>
          <li>
            <a href="https://tutorials.pytorch.kr/">한국어 튜토리얼</a>
          </li>
          <li>
            <a href="https://docs.pytorch.org/tutorials/" target="_blank">Official Tutorials</a>
          </li>
        </ul>
        <li class="resources-mobile-menu-title">
          <a>커뮤니티</a>
        </li>
         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://discuss.pytorch.kr/">한국어 커뮤니티</a>
          </li>
          <li>
            <a href="https://pytorch.kr/resources/">개발자 정보</a>
          </li>
          <li>
            <a href="https://landscape.pytorch.org/" target="_blank">Landscape</a>
          </li>
        </ul>
      </ul>
    </div>
  </div>
</div>

<!-- End Mobile Menu -->
  
  
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">
  <a href="../index.html" class="version">v2.8.0+cu128</a>
</div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../intro.html">
    Intro
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../compilers_index.html">
    Compilers
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../domains.html">
    Domains
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../distributed.html">
    Distributed
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../deep-dive.html">
    Deep Dive
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../extension.html">
    Extension
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../ecosystem.html">
    Ecosystem
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../recipes_index.html">
    Recipes
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
      
        <div class="navbar-item">
<div class="search-container-wrapper">
  <div id="sphinx-search" class="search-container">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </div>

  <div id="google-search" class="search-container" style="display:none;">
    <div class="gcse-search-wrapper">
      <i class="fa-solid fa-magnifying-glass" aria-hidden="true"></i>
      <div class="gcse-search"></div>
    </div>
  </div>

  <div class="search-toggle-container" data-bs-title="Google Search Off" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <div class="search-toggle-inner">
      <label class="switch">
        <input type="checkbox" id="search-toggle">
        <span class="slider round"></span>
      </label>
    </div>
  </div>
</div>

<script>
  document.addEventListener('DOMContentLoaded', function() {
  // Define the search callback
  const myWebSearchStartingCallback = (gname, query) => {
    if (typeof dataLayer !== 'undefined' && query) {
      window.dataLayer = window.dataLayer || [];
      dataLayer.push({
        'event': 'google_search',
        'search_term': query,
        'event_category': 'Search',
        'event_label': 'Google Search'
      });
    }
    return '';
  };

  // Set up the GCSE search callbacks
  window.__gcse || (window.__gcse = {});
  window.__gcse.searchCallbacks = {
    web: { starting: myWebSearchStartingCallback }
  };

  if (window.location.pathname.includes('/search.html')) {
    document.body.classList.add('search-page');
  }

  // Function to reinitialize Google CSE
  function reinitializeGoogleSearch() {
    if (window.__gcse && window.__gcse.initializationCallback) {
      window.__gcse.initializationCallback();
    }
  }

  // Function to handle search toggle
  function handleSearchToggle(toggle, sphinxSearch, googleSearch) {
    if (!toggle || !sphinxSearch || !googleSearch) return;

    // Check if the URL contains /stable/ or /tutorials/
    const currentUrl = window.location.href;
    // TODO: We've had reports that the google programmable search is returning stale documentation,
    //       Simple reproduction is to turn google search on and search for multinomial which will
    //       result in returning 1.8.1 documentation.
    //       We should turn this back on when we resolve that bug.
    const shouldDefaultToGoogle = false;
    const savedPreference = localStorage.getItem('searchPreference');

    // Set initial state
    if (savedPreference === 'google' || (savedPreference === null && shouldDefaultToGoogle)) {
      toggle.checked = true;
      sphinxSearch.style.display = 'none';
      googleSearch.style.display = 'block';
      if (savedPreference === null) {
        localStorage.setItem('searchPreference', 'google');
      }
      reinitializeGoogleSearch();
    } else {
      toggle.checked = false;
      sphinxSearch.style.display = 'block';
      googleSearch.style.display = 'none';
    }

    // Update tooltip
    updateTooltip(toggle.checked);

    // Skip if already initialized
    if (toggle.hasAttribute('data-initialized')) return;
    toggle.setAttribute('data-initialized', 'true');

    toggle.addEventListener('change', function() {
      if (this.checked) {
        sphinxSearch.style.display = 'none';
        googleSearch.style.display = 'block';
        localStorage.setItem('searchPreference', 'google');
        reinitializeGoogleSearch();
        trackSearchEngineSwitch('Google');
      } else {
        sphinxSearch.style.display = 'block';
        googleSearch.style.display = 'none';
        localStorage.setItem('searchPreference', 'sphinx');
        trackSearchEngineSwitch('Sphinx');
      }

      updateTooltip(this.checked);
      updateMobileSearch();
    });
  }

  // Update tooltip based on toggle state
  function updateTooltip(isChecked) {
    const tooltipElement = document.querySelector('.search-toggle-container');
    if (!tooltipElement) return;

    tooltipElement.setAttribute('data-bs-title', isChecked ? 'Google Search On' : 'Google Search Off');

    if (bootstrap && bootstrap.Tooltip) {
      const tooltipInstance = bootstrap.Tooltip.getInstance(tooltipElement);
      if (tooltipInstance) tooltipInstance.dispose();
      new bootstrap.Tooltip(tooltipElement);
    }
  }

  // Track search engine switch
  function trackSearchEngineSwitch(engine) {
    if (typeof dataLayer !== 'undefined') {
      window.dataLayer = window.dataLayer || [];
      dataLayer.push({
        'event': 'search_engine_switch',
        'event_category': 'Search',
        'event_label': engine
      });
    }
  }

  // Function to update mobile search based on current toggle state
  function updateMobileSearch() {
    const toggle = document.getElementById('search-toggle');
    if (!toggle) return;

    const mobileSearchContainer = document.querySelector('.sidebar-header-items__end .navbar-item .search-container-wrapper');
    if (!mobileSearchContainer) return;

    const mobileSphinxSearch = mobileSearchContainer.querySelector('#sphinx-search');
    const mobileGoogleSearch = mobileSearchContainer.querySelector('#google-search');

    if (mobileSphinxSearch && mobileGoogleSearch) {
      mobileSphinxSearch.style.display = toggle.checked ? 'none' : 'block';
      mobileGoogleSearch.style.display = toggle.checked ? 'block' : 'none';

      if (toggle.checked) {
        reinitializeGoogleSearch();
      }
    }
  }

  // Initialize desktop search toggle
  const toggle = document.getElementById('search-toggle');
  const sphinxSearch = document.getElementById('sphinx-search');
  const googleSearch = document.getElementById('google-search');
  handleSearchToggle(toggle, sphinxSearch, googleSearch);

  // Set placeholder text for Google search input
  const observer = new MutationObserver(function() {
    document.querySelectorAll('.gsc-input input').forEach(input => {
      if (input && !input.hasAttribute('data-placeholder-set')) {
        input.setAttribute('placeholder', 'Search the docs ...');
        input.setAttribute('data-placeholder-set', 'true');
      }
    });
  });

  observer.observe(document.body, { childList: true, subtree: true });

  // Fix for scroll jump issue - improved approach
  function setupSearchInputHandlers(input) {
    if (input.hasAttribute('data-scroll-fixed')) return;
    input.setAttribute('data-scroll-fixed', 'true');

    let lastScrollPosition = 0;
    let isTyping = false;
    let scrollTimeout;

    // Save position before typing starts
    input.addEventListener('keydown', () => {
      lastScrollPosition = window.scrollY;
      isTyping = true;

      // Reset typing state after a short delay
      clearTimeout(scrollTimeout);
      scrollTimeout = setTimeout(() => {
        isTyping = false;
      }, 100);
    });

    // Only maintain scroll position during typing
    function maintainScroll() {
      if (document.activeElement === input && isTyping) {
        window.scrollTo(0, lastScrollPosition);
        requestAnimationFrame(maintainScroll);
      }
    }

    input.addEventListener('focus', () => {
      // Just store initial position but don't force it
      lastScrollPosition = window.scrollY;
    });

    input.addEventListener('input', () => {
      isTyping = true;
      window.scrollTo(0, lastScrollPosition);

      // Reset typing state after a short delay
      clearTimeout(scrollTimeout);
      scrollTimeout = setTimeout(() => {
        isTyping = false;
      }, 100);

      requestAnimationFrame(maintainScroll);
    });
  }

  // Apply to all search inputs and observe for new ones
  function applyToSearchInputs() {
    document.querySelectorAll('.search-container input, .gsc-input input').forEach(setupSearchInputHandlers);
  }

  applyToSearchInputs();

  const searchObserver = new MutationObserver(applyToSearchInputs);
  searchObserver.observe(document.body, { childList: true, subtree: true });

  // Watch for mobile menu creation
  const mobileMenuObserver = new MutationObserver(function(mutations) {
    for (const mutation of mutations) {
      if (!mutation.addedNodes.length) continue;

      // Style mobile search inputs
      document.querySelectorAll('.sidebar-header-items__end .navbar-item .search-container-wrapper .gsc-input input').forEach(input => {
        if (input) {
          input.setAttribute('placeholder', 'Search the docs ...');
          input.style.paddingLeft = '36px';
        }
      });

      // Check for mobile search container
      const mobileSearchContainer = document.querySelector('.sidebar-header-items__end .navbar-item .search-container-wrapper');
      if (!mobileSearchContainer) continue;

      const mobileToggle = mobileSearchContainer.querySelector('#search-toggle');
      if (mobileToggle && toggle) {
        // Sync mobile toggle with desktop toggle
        mobileToggle.checked = toggle.checked;
        updateMobileSearch();

        // Add event listener to mobile toggle if not already added
        if (!mobileToggle.hasAttribute('data-initialized')) {
          mobileToggle.setAttribute('data-initialized', 'true');
          mobileToggle.addEventListener('change', function() {
            // Sync desktop toggle with mobile toggle
            toggle.checked = this.checked;
            // Trigger change event on desktop toggle to update both
            toggle.dispatchEvent(new Event('change'));
          });
        }
      }
    }
  });

  mobileMenuObserver.observe(document.body, { childList: true, subtree: true });

  // Ensure Google CSE is properly loaded
  if (window.__gcse) {
    window.__gcse.callback = function() {
      // This will run after Google CSE is fully loaded
      if (toggle && toggle.checked) {
        reinitializeGoogleSearch();
      }
    };
  } else {
    window.__gcse = {
      callback: function() {
        if (toggle && toggle.checked) {
          reinitializeGoogleSearch();
        }
      }
    };
  }
});
</script>
</div>
      
        <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/PyTorchKorea/tutorials-kr" title="한국어 튜토리얼 GitHub 저장소" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">한국어 튜토리얼 GitHub 저장소</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discuss.pytorch.kr/" title="파이토치 한국어 커뮤니티" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">파이토치 한국어 커뮤니티</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../intro.html">
    Intro
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../compilers_index.html">
    Compilers
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../domains.html">
    Domains
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../distributed.html">
    Distributed
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../deep-dive.html">
    Deep Dive
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../extension.html">
    Extension
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../ecosystem.html">
    Ecosystem
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../recipes_index.html">
    Recipes
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
<div class="search-container-wrapper">
  <div id="sphinx-search" class="search-container">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </div>

  <div id="google-search" class="search-container" style="display:none;">
    <div class="gcse-search-wrapper">
      <i class="fa-solid fa-magnifying-glass" aria-hidden="true"></i>
      <div class="gcse-search"></div>
    </div>
  </div>

  <div class="search-toggle-container" data-bs-title="Google Search Off" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <div class="search-toggle-inner">
      <label class="switch">
        <input type="checkbox" id="search-toggle">
        <span class="slider round"></span>
      </label>
    </div>
  </div>
</div>

<script>
  document.addEventListener('DOMContentLoaded', function() {
  // Define the search callback
  const myWebSearchStartingCallback = (gname, query) => {
    if (typeof dataLayer !== 'undefined' && query) {
      window.dataLayer = window.dataLayer || [];
      dataLayer.push({
        'event': 'google_search',
        'search_term': query,
        'event_category': 'Search',
        'event_label': 'Google Search'
      });
    }
    return '';
  };

  // Set up the GCSE search callbacks
  window.__gcse || (window.__gcse = {});
  window.__gcse.searchCallbacks = {
    web: { starting: myWebSearchStartingCallback }
  };

  if (window.location.pathname.includes('/search.html')) {
    document.body.classList.add('search-page');
  }

  // Function to reinitialize Google CSE
  function reinitializeGoogleSearch() {
    if (window.__gcse && window.__gcse.initializationCallback) {
      window.__gcse.initializationCallback();
    }
  }

  // Function to handle search toggle
  function handleSearchToggle(toggle, sphinxSearch, googleSearch) {
    if (!toggle || !sphinxSearch || !googleSearch) return;

    // Check if the URL contains /stable/ or /tutorials/
    const currentUrl = window.location.href;
    // TODO: We've had reports that the google programmable search is returning stale documentation,
    //       Simple reproduction is to turn google search on and search for multinomial which will
    //       result in returning 1.8.1 documentation.
    //       We should turn this back on when we resolve that bug.
    const shouldDefaultToGoogle = false;
    const savedPreference = localStorage.getItem('searchPreference');

    // Set initial state
    if (savedPreference === 'google' || (savedPreference === null && shouldDefaultToGoogle)) {
      toggle.checked = true;
      sphinxSearch.style.display = 'none';
      googleSearch.style.display = 'block';
      if (savedPreference === null) {
        localStorage.setItem('searchPreference', 'google');
      }
      reinitializeGoogleSearch();
    } else {
      toggle.checked = false;
      sphinxSearch.style.display = 'block';
      googleSearch.style.display = 'none';
    }

    // Update tooltip
    updateTooltip(toggle.checked);

    // Skip if already initialized
    if (toggle.hasAttribute('data-initialized')) return;
    toggle.setAttribute('data-initialized', 'true');

    toggle.addEventListener('change', function() {
      if (this.checked) {
        sphinxSearch.style.display = 'none';
        googleSearch.style.display = 'block';
        localStorage.setItem('searchPreference', 'google');
        reinitializeGoogleSearch();
        trackSearchEngineSwitch('Google');
      } else {
        sphinxSearch.style.display = 'block';
        googleSearch.style.display = 'none';
        localStorage.setItem('searchPreference', 'sphinx');
        trackSearchEngineSwitch('Sphinx');
      }

      updateTooltip(this.checked);
      updateMobileSearch();
    });
  }

  // Update tooltip based on toggle state
  function updateTooltip(isChecked) {
    const tooltipElement = document.querySelector('.search-toggle-container');
    if (!tooltipElement) return;

    tooltipElement.setAttribute('data-bs-title', isChecked ? 'Google Search On' : 'Google Search Off');

    if (bootstrap && bootstrap.Tooltip) {
      const tooltipInstance = bootstrap.Tooltip.getInstance(tooltipElement);
      if (tooltipInstance) tooltipInstance.dispose();
      new bootstrap.Tooltip(tooltipElement);
    }
  }

  // Track search engine switch
  function trackSearchEngineSwitch(engine) {
    if (typeof dataLayer !== 'undefined') {
      window.dataLayer = window.dataLayer || [];
      dataLayer.push({
        'event': 'search_engine_switch',
        'event_category': 'Search',
        'event_label': engine
      });
    }
  }

  // Function to update mobile search based on current toggle state
  function updateMobileSearch() {
    const toggle = document.getElementById('search-toggle');
    if (!toggle) return;

    const mobileSearchContainer = document.querySelector('.sidebar-header-items__end .navbar-item .search-container-wrapper');
    if (!mobileSearchContainer) return;

    const mobileSphinxSearch = mobileSearchContainer.querySelector('#sphinx-search');
    const mobileGoogleSearch = mobileSearchContainer.querySelector('#google-search');

    if (mobileSphinxSearch && mobileGoogleSearch) {
      mobileSphinxSearch.style.display = toggle.checked ? 'none' : 'block';
      mobileGoogleSearch.style.display = toggle.checked ? 'block' : 'none';

      if (toggle.checked) {
        reinitializeGoogleSearch();
      }
    }
  }

  // Initialize desktop search toggle
  const toggle = document.getElementById('search-toggle');
  const sphinxSearch = document.getElementById('sphinx-search');
  const googleSearch = document.getElementById('google-search');
  handleSearchToggle(toggle, sphinxSearch, googleSearch);

  // Set placeholder text for Google search input
  const observer = new MutationObserver(function() {
    document.querySelectorAll('.gsc-input input').forEach(input => {
      if (input && !input.hasAttribute('data-placeholder-set')) {
        input.setAttribute('placeholder', 'Search the docs ...');
        input.setAttribute('data-placeholder-set', 'true');
      }
    });
  });

  observer.observe(document.body, { childList: true, subtree: true });

  // Fix for scroll jump issue - improved approach
  function setupSearchInputHandlers(input) {
    if (input.hasAttribute('data-scroll-fixed')) return;
    input.setAttribute('data-scroll-fixed', 'true');

    let lastScrollPosition = 0;
    let isTyping = false;
    let scrollTimeout;

    // Save position before typing starts
    input.addEventListener('keydown', () => {
      lastScrollPosition = window.scrollY;
      isTyping = true;

      // Reset typing state after a short delay
      clearTimeout(scrollTimeout);
      scrollTimeout = setTimeout(() => {
        isTyping = false;
      }, 100);
    });

    // Only maintain scroll position during typing
    function maintainScroll() {
      if (document.activeElement === input && isTyping) {
        window.scrollTo(0, lastScrollPosition);
        requestAnimationFrame(maintainScroll);
      }
    }

    input.addEventListener('focus', () => {
      // Just store initial position but don't force it
      lastScrollPosition = window.scrollY;
    });

    input.addEventListener('input', () => {
      isTyping = true;
      window.scrollTo(0, lastScrollPosition);

      // Reset typing state after a short delay
      clearTimeout(scrollTimeout);
      scrollTimeout = setTimeout(() => {
        isTyping = false;
      }, 100);

      requestAnimationFrame(maintainScroll);
    });
  }

  // Apply to all search inputs and observe for new ones
  function applyToSearchInputs() {
    document.querySelectorAll('.search-container input, .gsc-input input').forEach(setupSearchInputHandlers);
  }

  applyToSearchInputs();

  const searchObserver = new MutationObserver(applyToSearchInputs);
  searchObserver.observe(document.body, { childList: true, subtree: true });

  // Watch for mobile menu creation
  const mobileMenuObserver = new MutationObserver(function(mutations) {
    for (const mutation of mutations) {
      if (!mutation.addedNodes.length) continue;

      // Style mobile search inputs
      document.querySelectorAll('.sidebar-header-items__end .navbar-item .search-container-wrapper .gsc-input input').forEach(input => {
        if (input) {
          input.setAttribute('placeholder', 'Search the docs ...');
          input.style.paddingLeft = '36px';
        }
      });

      // Check for mobile search container
      const mobileSearchContainer = document.querySelector('.sidebar-header-items__end .navbar-item .search-container-wrapper');
      if (!mobileSearchContainer) continue;

      const mobileToggle = mobileSearchContainer.querySelector('#search-toggle');
      if (mobileToggle && toggle) {
        // Sync mobile toggle with desktop toggle
        mobileToggle.checked = toggle.checked;
        updateMobileSearch();

        // Add event listener to mobile toggle if not already added
        if (!mobileToggle.hasAttribute('data-initialized')) {
          mobileToggle.setAttribute('data-initialized', 'true');
          mobileToggle.addEventListener('change', function() {
            // Sync desktop toggle with mobile toggle
            toggle.checked = this.checked;
            // Trigger change event on desktop toggle to update both
            toggle.dispatchEvent(new Event('change'));
          });
        }
      }
    }
  });

  mobileMenuObserver.observe(document.body, { childList: true, subtree: true });

  // Ensure Google CSE is properly loaded
  if (window.__gcse) {
    window.__gcse.callback = function() {
      // This will run after Google CSE is fully loaded
      if (toggle && toggle.checked) {
        reinitializeGoogleSearch();
      }
    };
  } else {
    window.__gcse = {
      callback: function() {
        if (toggle && toggle.checked) {
          reinitializeGoogleSearch();
        }
      }
    };
  }
});
</script>
</div>
        
          <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/PyTorchKorea/tutorials-kr" title="한국어 튜토리얼 GitHub 저장소" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">한국어 튜토리얼 GitHub 저장소</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discuss.pytorch.kr/" title="파이토치 한국어 커뮤니티" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">파이토치 한국어 커뮤니티</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../beginner/profiler.html">PyTorch 모듈 프로파일링하기</a></li>
<li class="toctree-l1"><a class="reference internal" href="parametrizations.html">Parametrizations Tutorial</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">가지치기 기법(Pruning) 튜토리얼</a></li>
<li class="toctree-l1"><a class="reference internal" href="inductor_debug_cpu.html">Inductor CPU backend debugging and profiling</a></li>
<li class="toctree-l1"><a class="reference internal" href="scaled_dot_product_attention_tutorial.html">(Beta) Scaled Dot Product Attention (SDPA)로 고성능 트랜스포머(Transformers) 구현하기</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/knowledge_distillation_tutorial.html">Knowledge Distillation Tutorial</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Frontend APIs</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="memory_format_tutorial.html">(베타) PyTorch를 사용한 Channels Last 메모리 형식</a></li>
<li class="toctree-l1"><a class="reference internal" href="forward_ad_usage.html">Forward-mode Automatic Differentiation (Beta)</a></li>
<li class="toctree-l1"><a class="reference internal" href="jacobians_hessians.html">Jacobians, Hessians, hvp, vhp, and more: composing function transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="ensembling.html">모델 앙상블</a></li>
<li class="toctree-l1"><a class="reference internal" href="per_sample_grads.html">Per-sample-gradients</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_frontend.html">PyTorch C++ 프론트엔드 사용하기</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_autograd.html">C++ 프론트엔드의 자동 미분 (autograd)</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../deep-dive.html" class="nav-link">Deep Dive</a></li>
    
    <li class="breadcrumb-item active" aria-current="page">가지치기...</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
        
    </div>
</div>
</div>
      
    </div>
  
</div>
</div>
              
              
  
<div id="searchbox"></div>
  <article class="bd-article" id="pytorch-article">
    <!-- Hidden breadcrumb schema for SEO only -->
    <div style="display:none;" itemscope itemtype="https://schema.org/BreadcrumbList">
      
      <div itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <link itemprop="item" href="../deep-dive.html">
        <meta itemprop="name" content="Deep Dive">
        <meta itemprop="position" content="1">
      </div>
      
      <div itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <meta itemprop="name" content="가지치기 기법(Pruning) 튜토리얼">
        <meta itemprop="position" content="2">
      </div>
    </div>

    
    <script>
      if ((window.location.href.indexOf("/unstable/") != -1) && (window.location.href.indexOf("/unstable/unstable_index") < 1)) {
        var div = '<div class="prototype-banner"><i class="fa fa-flask" aria-hidden="true"></i> <strong>Unstable feature:</strong> Not typically available in binary distributions like PyPI. Early stage for feedback and testing.</div>'
        document.addEventListener('DOMContentLoaded', function () {
          document.getElementById("pytorch-article").insertAdjacentHTML('afterBegin', div);
        });
      }
    </script>
    
    
    <div class="pytorch-call-to-action-links">
      <div id="tutorial-type">intermediate/pruning_tutorial</div>
      <a id="colab-link" data-behavior="call-to-action-event" data-response="Run in Google Colab" target="_blank">
        <div id="google-colab-link">
          <img class="call-to-action-img" src="../_static/img/pytorch-colab.svg" />
          <div class="call-to-action-desktop-view">Run in Google Colab</div>
          <div class="call-to-action-mobile-view">Colab</div>
        </div>
      </a>
      <a id="notebook-link" data-behavior="call-to-action-event" data-response="Download Notebook">
        <div id="download-notebook-link">
          <img class="call-to-action-notebook-img" src="../_static/img/pytorch-download.svg" />
          <div class="call-to-action-desktop-view">Download Notebook</div>
          <div class="call-to-action-mobile-view">Notebook</div>
        </div>
      </a>
      <a id="github-link" data-behavior="call-to-action-event" data-response="View on Github" target="_blank">
        <div id="github-view-link">
          <img class="call-to-action-img" src="../_static/img/pytorch-github.svg" />
          <div class="call-to-action-desktop-view">View on GitHub</div>
          <div class="call-to-action-mobile-view">GitHub</div>
        </div>
      </a>
    </div>
    

    
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">참고</p>
<p><a class="reference internal" href="#sphx-glr-download-intermediate-pruning-tutorial-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code.</p>
</div>
<section class="sphx-glr-example-title" id="pruning">
<span id="sphx-glr-intermediate-pruning-tutorial-py"></span><h1>가지치기 기법(Pruning) 튜토리얼<a class="headerlink" href="#pruning" title="Link to this heading">#</a></h1>
<dl class="simple">
<dt><strong>Author</strong>: <a class="reference external" href="https://github.com/mickypaganini">Michela Paganini</a></dt><dd><p><strong>번역</strong>: <a class="reference external" href="https://github.com/Justin-A">안상준</a></p>
</dd>
</dl>
<p>최첨단 딥러닝 모델들은 굉장히 많은 수의 파라미터값들로 구성되기 때문에, 쉽게 배포하기가 어렵습니다.
이와 반대로, 생물학적 신경망들은 효율적으로 희소하게 연결된 것으로 알려져 있습니다.
모델의 정확도를 훼손하지 않으면서 모델에 포함된 파라미터 수를 줄여 압축하는 최적의 기법을 파악하는 것은
메모리, 배터리, 하드웨어 소비량을 줄일 수 있기 때문에 중요합니다. 그럼으로서 기기에 경량화된 모델을 배포하여
개개인이 사용하고 있는 기기에서 연산을 수행하여 프라이버시를 보장할 수 있기 때문입니다.
연구 측면에서는, 가지치기 기법은 굉장히 많은 수의 파라미터값들로 구성된 모델과
굉장히 적은 수의 파라미터값들로 구성된 모델 간 학습 역학 차이를 조사하는데 주로 이용되기도 하며,
하위 신경망 모델과 파라미터값들의 초기화가 운이 좋게 잘 된 케이스를 바탕으로
(”<a class="reference external" href="https://arxiv.org/abs/1803.03635">lottery tickets</a>”) 신경망 구조를 찾는 기술들에 대해 반대 의견을 제시하기도 합니다.</p>
<p>이번 튜토리얼에서는, <code class="docutils literal notranslate"><span class="pre">torch.nn.utils.prune</span></code> 을 사용하여 여러분이 설계한 딥러닝 모델에 대해 가지치기 기법을 적용해보는 것을 배워보고,
심화적으로 여러분의 맞춤형 가지치기 기법을 구현하는 방법에 대해 배워보도록 하겠습니다.</p>
<section id="id2">
<h2>요구사항<a class="headerlink" href="#id2" title="Link to this heading">#</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">&quot;torch&gt;=1.4&quot;</span></code></p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.utils.prune</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">prune</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>
</pre></div>
</div>
</section>
<section id="id3">
<h2>딥러닝 모델 생성<a class="headerlink" href="#id3" title="Link to this heading">#</a></h2>
<p>이번 튜토리얼에서는, 얀 르쿤 교수님의 연구진들이 1998년도에 발표한 <a class="reference external" href="http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf">LeNet</a> 의 모델 구조를 이용합니다.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>

<span class="k">class</span><span class="w"> </span><span class="nc">LeNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LeNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># 1개 채널 수의 이미지를 입력값으로 이용하여 6개 채널 수의 출력값을 계산하는 방식</span>
        <span class="c1"># Convolution 연산을 진행하는 커널(필터)의 크기는 5x5 을 이용</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">16</span> <span class="o">*</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">120</span><span class="p">)</span>  <span class="c1"># Convolution 연산 결과 5x5 크기의 16 채널 수의 이미지</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">120</span><span class="p">,</span> <span class="mi">84</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">84</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)),</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">nelement</span><span class="p">()</span> <span class="o">/</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">LeNet</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id4">
<h2>모듈 점검<a class="headerlink" href="#id4" title="Link to this heading">#</a></h2>
<p>가지치기 기법이 적용되지 않은 LeNet 모델의 <code class="docutils literal notranslate"><span class="pre">conv1</span></code> 층을 점검해봅시다.
여기에는 2개의 파라미터값들인 <code class="docutils literal notranslate"><span class="pre">가중치</span></code> 값과 <code class="docutils literal notranslate"><span class="pre">편향</span></code> 값이 포함될 것이며, 버퍼는 존재하지 않을 것입니다.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">module</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">conv1</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">()))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[(&#39;weight&#39;, Parameter containing:
tensor([[[[ 0.1232, -0.0642, -0.0623, -0.1485,  0.0055],
          [ 0.0314, -0.1857, -0.0403,  0.1223,  0.1689],
          [-0.0559, -0.1542,  0.0177,  0.0988,  0.0749],
          [ 0.0634, -0.1869,  0.1766,  0.1120,  0.0219],
          [-0.1110, -0.0066, -0.0742,  0.1935, -0.1882]]],


        [[[-0.1891,  0.0554, -0.1982,  0.1154, -0.0523],
          [ 0.0580,  0.1063,  0.1315, -0.1787, -0.0445],
          [-0.1216,  0.1807,  0.1527, -0.1806, -0.0789],
          [-0.0206, -0.1911, -0.0794,  0.1364,  0.0037],
          [ 0.0427, -0.1558, -0.1073, -0.0763,  0.0211]]],


        [[[ 0.0116, -0.1011, -0.1792, -0.0166, -0.1940],
          [-0.1058, -0.0902, -0.0587,  0.0361, -0.0123],
          [-0.1890, -0.0632,  0.0668, -0.0883, -0.1008],
          [-0.0702,  0.1404,  0.0646, -0.1084, -0.0797],
          [-0.0942, -0.0567, -0.1763,  0.0473, -0.1682]]],


        [[[-0.0958,  0.0936,  0.1754, -0.0095,  0.0009],
          [-0.1752, -0.1877,  0.1632, -0.0735,  0.1270],
          [-0.0448, -0.0554,  0.0111,  0.1206,  0.0263],
          [ 0.1758, -0.1420,  0.1933, -0.1722, -0.1062],
          [-0.0772,  0.0547,  0.0716,  0.0628,  0.0945]]],


        [[[ 0.1180, -0.0116,  0.1336, -0.0599, -0.0110],
          [ 0.1084,  0.1545, -0.0840, -0.1709, -0.0822],
          [-0.1528,  0.1098,  0.1429, -0.0835, -0.1162],
          [-0.1901,  0.0091,  0.1081,  0.0753, -0.0684],
          [ 0.0304,  0.0038, -0.0709,  0.0481, -0.0312]]],


        [[[ 0.0692, -0.1867, -0.0930, -0.0373, -0.1380],
          [-0.0196,  0.1388,  0.0801, -0.1948,  0.0013],
          [ 0.0478, -0.1248, -0.0969, -0.1181,  0.1294],
          [ 0.0343, -0.0799, -0.0200, -0.1351, -0.0577],
          [-0.0725,  0.0144, -0.0758,  0.0333,  0.0219]]]], device=&#39;cuda:0&#39;,
       requires_grad=True)), (&#39;bias&#39;, Parameter containing:
tensor([-0.0229, -0.0985, -0.0547, -0.0255, -0.1460, -0.1458], device=&#39;cuda:0&#39;,
       requires_grad=True))]
</pre></div>
</div>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">named_buffers</span><span class="p">()))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[]
</pre></div>
</div>
</section>
<section id="id5">
<h2>모듈 가지치기 기법 적용 예제<a class="headerlink" href="#id5" title="Link to this heading">#</a></h2>
<p>모듈에 대해 가지치기 기법을 적용하기 위해 (이번 예제에서는, LeNet 모델의 <code class="docutils literal notranslate"><span class="pre">conv1</span></code> 층)
첫 번째로는, <code class="docutils literal notranslate"><span class="pre">torch.nn.utils.prune</span></code> (또는 <code class="docutils literal notranslate"><span class="pre">BasePruningMethod</span></code> 의 서브 클래스로 직접
<a class="reference external" href="torch-nn-utils-prune">구현</a> )
내 존재하는 가지치기 기법을 선택합니다.
그 후, 해당 모듈 내에서 가지치기 기법을 적용하고자 하는 모듈과 파라미터를 지정합니다.
마지막으로, 가지치기 기법에 적당한 키워드 인자값을 이용하여 가지치기 매개변수를 지정합니다.
이번 예제에서는, <code class="docutils literal notranslate"><span class="pre">conv1</span></code> 층의 가중치의 30%값들을 랜덤으로 가지치기 기법을 적용해보겠습니다.
모듈은 함수에 대한 첫 번째 인자값으로 전달되며, <code class="docutils literal notranslate"><span class="pre">name</span></code> 은 문자열 식별자를 이용하여 해당 모듈 내 매개변수를 구분합니다.
그리고, <code class="docutils literal notranslate"><span class="pre">amount</span></code> 는 가지치기 기법을 적용하기 위한 대상 가중치값들의 백분율 (0과 1사이의 실수값),
혹은 가중치값의 연결의 개수 (음수가 아닌 정수) 를 지정합니다.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">prune</span><span class="o">.</span><span class="n">random_unstructured</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;weight&quot;</span><span class="p">,</span> <span class="n">amount</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))
</pre></div>
</div>
<p>가지치기 기법은 가중치값들을 파라미터값들로부터 제거하고 <code class="docutils literal notranslate"><span class="pre">weight_orig</span></code> (즉, 초기 가중치 이름에 “_orig”을 붙인) 이라는
새로운 파라미터값으로 대체하는 것으로 실행됩니다.
<code class="docutils literal notranslate"><span class="pre">weight_orig</span></code> 은 텐서값에 가지치기 기법이 적용되지 않은 상태를 저장합니다.
<code class="docutils literal notranslate"><span class="pre">bias</span></code> 은 가지치기 기법이 적용되지 않았기 때문에 그대로 남아 있습니다.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">()))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[(&#39;bias&#39;, Parameter containing:
tensor([-0.0229, -0.0985, -0.0547, -0.0255, -0.1460, -0.1458], device=&#39;cuda:0&#39;,
       requires_grad=True)), (&#39;weight_orig&#39;, Parameter containing:
tensor([[[[ 0.1232, -0.0642, -0.0623, -0.1485,  0.0055],
          [ 0.0314, -0.1857, -0.0403,  0.1223,  0.1689],
          [-0.0559, -0.1542,  0.0177,  0.0988,  0.0749],
          [ 0.0634, -0.1869,  0.1766,  0.1120,  0.0219],
          [-0.1110, -0.0066, -0.0742,  0.1935, -0.1882]]],


        [[[-0.1891,  0.0554, -0.1982,  0.1154, -0.0523],
          [ 0.0580,  0.1063,  0.1315, -0.1787, -0.0445],
          [-0.1216,  0.1807,  0.1527, -0.1806, -0.0789],
          [-0.0206, -0.1911, -0.0794,  0.1364,  0.0037],
          [ 0.0427, -0.1558, -0.1073, -0.0763,  0.0211]]],


        [[[ 0.0116, -0.1011, -0.1792, -0.0166, -0.1940],
          [-0.1058, -0.0902, -0.0587,  0.0361, -0.0123],
          [-0.1890, -0.0632,  0.0668, -0.0883, -0.1008],
          [-0.0702,  0.1404,  0.0646, -0.1084, -0.0797],
          [-0.0942, -0.0567, -0.1763,  0.0473, -0.1682]]],


        [[[-0.0958,  0.0936,  0.1754, -0.0095,  0.0009],
          [-0.1752, -0.1877,  0.1632, -0.0735,  0.1270],
          [-0.0448, -0.0554,  0.0111,  0.1206,  0.0263],
          [ 0.1758, -0.1420,  0.1933, -0.1722, -0.1062],
          [-0.0772,  0.0547,  0.0716,  0.0628,  0.0945]]],


        [[[ 0.1180, -0.0116,  0.1336, -0.0599, -0.0110],
          [ 0.1084,  0.1545, -0.0840, -0.1709, -0.0822],
          [-0.1528,  0.1098,  0.1429, -0.0835, -0.1162],
          [-0.1901,  0.0091,  0.1081,  0.0753, -0.0684],
          [ 0.0304,  0.0038, -0.0709,  0.0481, -0.0312]]],


        [[[ 0.0692, -0.1867, -0.0930, -0.0373, -0.1380],
          [-0.0196,  0.1388,  0.0801, -0.1948,  0.0013],
          [ 0.0478, -0.1248, -0.0969, -0.1181,  0.1294],
          [ 0.0343, -0.0799, -0.0200, -0.1351, -0.0577],
          [-0.0725,  0.0144, -0.0758,  0.0333,  0.0219]]]], device=&#39;cuda:0&#39;,
       requires_grad=True))]
</pre></div>
</div>
<p>위에서 선택한 가지치기 기법에 의해 생성되는 가지치기 마스크는 초기 파라미터  <code class="docutils literal notranslate"><span class="pre">name</span></code> 에 <code class="docutils literal notranslate"><span class="pre">weight_mask</span></code>
(즉, 초기 가중치 이름에 “_mask”를 붙인) 이름의 모듈 버퍼로 저장됩니다.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">named_buffers</span><span class="p">()))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[(&#39;weight_mask&#39;, tensor([[[[0., 0., 1., 0., 1.],
          [1., 1., 0., 1., 1.],
          [0., 0., 1., 1., 1.],
          [1., 0., 1., 0., 1.],
          [0., 0., 1., 1., 1.]]],


        [[[1., 1., 0., 1., 0.],
          [1., 1., 1., 1., 0.],
          [1., 1., 1., 1., 1.],
          [0., 1., 1., 0., 0.],
          [1., 1., 1., 0., 1.]]],


        [[[1., 1., 1., 1., 0.],
          [1., 1., 1., 1., 0.],
          [1., 1., 1., 0., 1.],
          [1., 1., 0., 0., 0.],
          [1., 0., 1., 0., 0.]]],


        [[[1., 1., 1., 0., 1.],
          [1., 1., 1., 1., 1.],
          [1., 0., 1., 1., 0.],
          [0., 1., 1., 1., 1.],
          [1., 1., 0., 1., 0.]]],


        [[[1., 0., 1., 1., 0.],
          [1., 1., 1., 1., 0.],
          [0., 1., 1., 1., 1.],
          [1., 1., 0., 1., 1.],
          [1., 0., 1., 1., 0.]]],


        [[[0., 1., 1., 1., 1.],
          [1., 1., 0., 1., 1.],
          [1., 0., 1., 1., 1.],
          [1., 1., 0., 0., 0.],
          [1., 1., 1., 1., 1.]]]], device=&#39;cuda:0&#39;))]
</pre></div>
</div>
<p>수정이 되지 않은 상태에서 순전파를 진행하기 위해서는 <code class="docutils literal notranslate"><span class="pre">가중치</span></code> 값 속성이 존재해야 합니다.
<code class="docutils literal notranslate"><span class="pre">torch.nn.utils.prune</span></code> 내 구현된 가지치기 기법은 가지치기 기법이 적용된 가중치값들을 이용하여
(기존의 가중치값에 가지치기 기법이 적용된) 순전파를 진행하고, <code class="docutils literal notranslate"><span class="pre">weight</span></code> 속성값에 가지치기 기법이 적용된 가중치값들을 저장합니다.
이제 가중치값들은 <code class="docutils literal notranslate"><span class="pre">module</span></code> 의 매개변수가 아니라 하나의 속성값으로 취급되는 점을 주의하세요.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>tensor([[[[ 0.0000, -0.0000, -0.0623, -0.0000,  0.0055],
          [ 0.0314, -0.1857, -0.0000,  0.1223,  0.1689],
          [-0.0000, -0.0000,  0.0177,  0.0988,  0.0749],
          [ 0.0634, -0.0000,  0.1766,  0.0000,  0.0219],
          [-0.0000, -0.0000, -0.0742,  0.1935, -0.1882]]],


        [[[-0.1891,  0.0554, -0.0000,  0.1154, -0.0000],
          [ 0.0580,  0.1063,  0.1315, -0.1787, -0.0000],
          [-0.1216,  0.1807,  0.1527, -0.1806, -0.0789],
          [-0.0000, -0.1911, -0.0794,  0.0000,  0.0000],
          [ 0.0427, -0.1558, -0.1073, -0.0000,  0.0211]]],


        [[[ 0.0116, -0.1011, -0.1792, -0.0166, -0.0000],
          [-0.1058, -0.0902, -0.0587,  0.0361, -0.0000],
          [-0.1890, -0.0632,  0.0668, -0.0000, -0.1008],
          [-0.0702,  0.1404,  0.0000, -0.0000, -0.0000],
          [-0.0942, -0.0000, -0.1763,  0.0000, -0.0000]]],


        [[[-0.0958,  0.0936,  0.1754, -0.0000,  0.0009],
          [-0.1752, -0.1877,  0.1632, -0.0735,  0.1270],
          [-0.0448, -0.0000,  0.0111,  0.1206,  0.0000],
          [ 0.0000, -0.1420,  0.1933, -0.1722, -0.1062],
          [-0.0772,  0.0547,  0.0000,  0.0628,  0.0000]]],


        [[[ 0.1180, -0.0000,  0.1336, -0.0599, -0.0000],
          [ 0.1084,  0.1545, -0.0840, -0.1709, -0.0000],
          [-0.0000,  0.1098,  0.1429, -0.0835, -0.1162],
          [-0.1901,  0.0091,  0.0000,  0.0753, -0.0684],
          [ 0.0304,  0.0000, -0.0709,  0.0481, -0.0000]]],


        [[[ 0.0000, -0.1867, -0.0930, -0.0373, -0.1380],
          [-0.0196,  0.1388,  0.0000, -0.1948,  0.0013],
          [ 0.0478, -0.0000, -0.0969, -0.1181,  0.1294],
          [ 0.0343, -0.0799, -0.0000, -0.0000, -0.0000],
          [-0.0725,  0.0144, -0.0758,  0.0333,  0.0219]]]], device=&#39;cuda:0&#39;,
       grad_fn=&lt;MulBackward0&gt;)
</pre></div>
</div>
<p>최종적으로, 가지치기 기법은 파이토치의 <code class="docutils literal notranslate"><span class="pre">forward_pre_hooks</span></code> 를 이용하여 각 순전파가 진행되기 전에 가지치기 기법이 적용됩니다.
구체적으로, 지금까지 진행한 것 처럼, 모듈이 가지치기 기법이 적용되었을 때,
가지치기 기법이 적용된 각 파라미터값들이 <code class="docutils literal notranslate"><span class="pre">forward_pre_hook</span></code> 를 얻게됩니다.
이러한 경우, <code class="docutils literal notranslate"><span class="pre">weight</span></code> 이름인 기존 파라미터값에 대해서만 가지치기 기법을 적용하였기 때문에,
훅은 오직 1개만 존재할 것입니다.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">_forward_pre_hooks</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>OrderedDict([(0, &lt;torch.nn.utils.prune.RandomUnstructured object at 0x7f0dab246050&gt;)])
</pre></div>
</div>
<p>완결성을 위해, 편향값에 대해서도 가지치기 기법을 적용할 수 있으며,
모듈의 파라미터, 버퍼, 훅, 속성값들이 어떻게 변경되는지 확인할 수 있습니다.
또 다른 가지치기 기법을 적용해보기 위해, <code class="docutils literal notranslate"><span class="pre">l1_unstructured</span></code> 가지치기 함수에서 구현된 내용과 같이,
L1 Norm 값이 가장 작은 편향값 3개를 가지치기를 시도해봅시다.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">prune</span><span class="o">.</span><span class="n">l1_unstructured</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;bias&quot;</span><span class="p">,</span> <span class="n">amount</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))
</pre></div>
</div>
<p>이전에서 실습한 내용을 토대로, 명명된 파라미터값들이 <code class="docutils literal notranslate"><span class="pre">weight_orig</span></code>, <code class="docutils literal notranslate"><span class="pre">bias_orig</span></code> 2개를 모두 포함할 것이라 예상할 수 있습니다.
버퍼들은 <code class="docutils literal notranslate"><span class="pre">weight_mask</span></code>, <code class="docutils literal notranslate"><span class="pre">bias_mask</span></code> 2개를 포함할 것입니다.
가지치기 기법이 적용된 2개의 텐서값들은 모듈의 속성값으로 존재할 것이며, 모듈은 2개의 <code class="docutils literal notranslate"><span class="pre">forward_pre_hooks</span></code> 을 갖게 될 것입니다.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">()))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[(&#39;weight_orig&#39;, Parameter containing:
tensor([[[[ 0.1232, -0.0642, -0.0623, -0.1485,  0.0055],
          [ 0.0314, -0.1857, -0.0403,  0.1223,  0.1689],
          [-0.0559, -0.1542,  0.0177,  0.0988,  0.0749],
          [ 0.0634, -0.1869,  0.1766,  0.1120,  0.0219],
          [-0.1110, -0.0066, -0.0742,  0.1935, -0.1882]]],


        [[[-0.1891,  0.0554, -0.1982,  0.1154, -0.0523],
          [ 0.0580,  0.1063,  0.1315, -0.1787, -0.0445],
          [-0.1216,  0.1807,  0.1527, -0.1806, -0.0789],
          [-0.0206, -0.1911, -0.0794,  0.1364,  0.0037],
          [ 0.0427, -0.1558, -0.1073, -0.0763,  0.0211]]],


        [[[ 0.0116, -0.1011, -0.1792, -0.0166, -0.1940],
          [-0.1058, -0.0902, -0.0587,  0.0361, -0.0123],
          [-0.1890, -0.0632,  0.0668, -0.0883, -0.1008],
          [-0.0702,  0.1404,  0.0646, -0.1084, -0.0797],
          [-0.0942, -0.0567, -0.1763,  0.0473, -0.1682]]],


        [[[-0.0958,  0.0936,  0.1754, -0.0095,  0.0009],
          [-0.1752, -0.1877,  0.1632, -0.0735,  0.1270],
          [-0.0448, -0.0554,  0.0111,  0.1206,  0.0263],
          [ 0.1758, -0.1420,  0.1933, -0.1722, -0.1062],
          [-0.0772,  0.0547,  0.0716,  0.0628,  0.0945]]],


        [[[ 0.1180, -0.0116,  0.1336, -0.0599, -0.0110],
          [ 0.1084,  0.1545, -0.0840, -0.1709, -0.0822],
          [-0.1528,  0.1098,  0.1429, -0.0835, -0.1162],
          [-0.1901,  0.0091,  0.1081,  0.0753, -0.0684],
          [ 0.0304,  0.0038, -0.0709,  0.0481, -0.0312]]],


        [[[ 0.0692, -0.1867, -0.0930, -0.0373, -0.1380],
          [-0.0196,  0.1388,  0.0801, -0.1948,  0.0013],
          [ 0.0478, -0.1248, -0.0969, -0.1181,  0.1294],
          [ 0.0343, -0.0799, -0.0200, -0.1351, -0.0577],
          [-0.0725,  0.0144, -0.0758,  0.0333,  0.0219]]]], device=&#39;cuda:0&#39;,
       requires_grad=True)), (&#39;bias_orig&#39;, Parameter containing:
tensor([-0.0229, -0.0985, -0.0547, -0.0255, -0.1460, -0.1458], device=&#39;cuda:0&#39;,
       requires_grad=True))]
</pre></div>
</div>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">named_buffers</span><span class="p">()))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[(&#39;weight_mask&#39;, tensor([[[[0., 0., 1., 0., 1.],
          [1., 1., 0., 1., 1.],
          [0., 0., 1., 1., 1.],
          [1., 0., 1., 0., 1.],
          [0., 0., 1., 1., 1.]]],


        [[[1., 1., 0., 1., 0.],
          [1., 1., 1., 1., 0.],
          [1., 1., 1., 1., 1.],
          [0., 1., 1., 0., 0.],
          [1., 1., 1., 0., 1.]]],


        [[[1., 1., 1., 1., 0.],
          [1., 1., 1., 1., 0.],
          [1., 1., 1., 0., 1.],
          [1., 1., 0., 0., 0.],
          [1., 0., 1., 0., 0.]]],


        [[[1., 1., 1., 0., 1.],
          [1., 1., 1., 1., 1.],
          [1., 0., 1., 1., 0.],
          [0., 1., 1., 1., 1.],
          [1., 1., 0., 1., 0.]]],


        [[[1., 0., 1., 1., 0.],
          [1., 1., 1., 1., 0.],
          [0., 1., 1., 1., 1.],
          [1., 1., 0., 1., 1.],
          [1., 0., 1., 1., 0.]]],


        [[[0., 1., 1., 1., 1.],
          [1., 1., 0., 1., 1.],
          [1., 0., 1., 1., 1.],
          [1., 1., 0., 0., 0.],
          [1., 1., 1., 1., 1.]]]], device=&#39;cuda:0&#39;)), (&#39;bias_mask&#39;, tensor([0., 1., 0., 0., 1., 1.], device=&#39;cuda:0&#39;))]
</pre></div>
</div>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>tensor([-0.0000, -0.0985, -0.0000, -0.0000, -0.1460, -0.1458], device=&#39;cuda:0&#39;,
       grad_fn=&lt;MulBackward0&gt;)
</pre></div>
</div>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">_forward_pre_hooks</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>OrderedDict([(0, &lt;torch.nn.utils.prune.RandomUnstructured object at 0x7f0dab246050&gt;), (1, &lt;torch.nn.utils.prune.L1Unstructured object at 0x7f0dab183890&gt;)])
</pre></div>
</div>
</section>
<section id="id7">
<h2>가지치기 기법 반복 적용<a class="headerlink" href="#id7" title="Link to this heading">#</a></h2>
<p>모듈 내 같은 파라미터값에 대해 가지치기 기법이 여러번 적용될 수 있으며, 다양한 가지치기 기법의 조합이 적용된 것과 동일하게 적용될 수 있습니다.
새로운 마스크와 이전의 마스크의 결합은 <code class="docutils literal notranslate"><span class="pre">PruningContainer</span></code> 의 <code class="docutils literal notranslate"><span class="pre">compute_mask</span></code> 메소드를 통해 처리할 수 있습니다.</p>
<p>예를 들어, 만약 <code class="docutils literal notranslate"><span class="pre">module.weight</span></code> 값에 가지치기 기법을 적용하고 싶을 때, 텐서의 0번째 축의 L2 norm값을 기준으로 구조화된 가지치기 기법을 적용합니다.
(여기서 0번째 축이란, 합성곱 연산을 통해 계산된 출력값에 대해 각 채널별로 적용된다는 것을 의미합니다.)
이 방식은 <code class="docutils literal notranslate"><span class="pre">ln_structured</span></code> 함수와 <code class="docutils literal notranslate"><span class="pre">n=2</span></code> 와 <code class="docutils literal notranslate"><span class="pre">dim=0</span></code> 의 인자값을 바탕으로 구현될 수 있습니다.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">prune</span><span class="o">.</span><span class="n">ln_structured</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;weight&quot;</span><span class="p">,</span> <span class="n">amount</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))
</pre></div>
</div>
<p>우리가 확인할 수 있듯이, 이전 마스크의 작용을 유지하면서 채널의 50% (6개 중 3개) 에 해당되는 모든 연결을 0으로 변경합니다.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>tensor([[[[ 0.0000, -0.0000, -0.0000, -0.0000,  0.0000],
          [ 0.0000, -0.0000, -0.0000,  0.0000,  0.0000],
          [-0.0000, -0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000, -0.0000,  0.0000,  0.0000,  0.0000],
          [-0.0000, -0.0000, -0.0000,  0.0000, -0.0000]]],


        [[[-0.1891,  0.0554, -0.0000,  0.1154, -0.0000],
          [ 0.0580,  0.1063,  0.1315, -0.1787, -0.0000],
          [-0.1216,  0.1807,  0.1527, -0.1806, -0.0789],
          [-0.0000, -0.1911, -0.0794,  0.0000,  0.0000],
          [ 0.0427, -0.1558, -0.1073, -0.0000,  0.0211]]],


        [[[ 0.0000, -0.0000, -0.0000, -0.0000, -0.0000],
          [-0.0000, -0.0000, -0.0000,  0.0000, -0.0000],
          [-0.0000, -0.0000,  0.0000, -0.0000, -0.0000],
          [-0.0000,  0.0000,  0.0000, -0.0000, -0.0000],
          [-0.0000, -0.0000, -0.0000,  0.0000, -0.0000]]],


        [[[-0.0958,  0.0936,  0.1754, -0.0000,  0.0009],
          [-0.1752, -0.1877,  0.1632, -0.0735,  0.1270],
          [-0.0448, -0.0000,  0.0111,  0.1206,  0.0000],
          [ 0.0000, -0.1420,  0.1933, -0.1722, -0.1062],
          [-0.0772,  0.0547,  0.0000,  0.0628,  0.0000]]],


        [[[ 0.1180, -0.0000,  0.1336, -0.0599, -0.0000],
          [ 0.1084,  0.1545, -0.0840, -0.1709, -0.0000],
          [-0.0000,  0.1098,  0.1429, -0.0835, -0.1162],
          [-0.1901,  0.0091,  0.0000,  0.0753, -0.0684],
          [ 0.0304,  0.0000, -0.0709,  0.0481, -0.0000]]],


        [[[ 0.0000, -0.0000, -0.0000, -0.0000, -0.0000],
          [-0.0000,  0.0000,  0.0000, -0.0000,  0.0000],
          [ 0.0000, -0.0000, -0.0000, -0.0000,  0.0000],
          [ 0.0000, -0.0000, -0.0000, -0.0000, -0.0000],
          [-0.0000,  0.0000, -0.0000,  0.0000,  0.0000]]]], device=&#39;cuda:0&#39;,
       grad_fn=&lt;MulBackward0&gt;)
</pre></div>
</div>
<p>이에 해당하는 훅은 <code class="docutils literal notranslate"><span class="pre">torch.nn.utils.prune.PruningContainer</span></code> 형태로 존재하며, 가중치에 적용된 가지치기 기법의 이력을 저장합니다.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">hook</span> <span class="ow">in</span> <span class="n">module</span><span class="o">.</span><span class="n">_forward_pre_hooks</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">hook</span><span class="o">.</span><span class="n">_tensor_name</span> <span class="o">==</span> <span class="s2">&quot;weight&quot;</span><span class="p">:</span>  <span class="c1"># 가중치에 해당하는 훅을 선택</span>
        <span class="k">break</span>

<span class="nb">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">hook</span><span class="p">))</span>  <span class="c1"># 컨테이너 내 가지치기 기법의 이력</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[&lt;torch.nn.utils.prune.RandomUnstructured object at 0x7f0dab246050&gt;, &lt;torch.nn.utils.prune.LnStructured object at 0x7f0dab0edd10&gt;]
</pre></div>
</div>
</section>
<section id="id8">
<h2>가지치기 기법이 적용된 모델의 직렬화<a class="headerlink" href="#id8" title="Link to this heading">#</a></h2>
<p>마스크 버퍼들과 가지치기 기법이 적용된 텐서 계산에 사용된 기존의 파라미터를 포함하여 관련된 모든 텐서값들은
필요한 경우 모델의 <code class="docutils literal notranslate"><span class="pre">state_dict</span></code> 에 저장되기 때문에, 쉽게 직렬화하여 저장할 수 있습니다.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>odict_keys([&#39;conv1.weight_orig&#39;, &#39;conv1.bias_orig&#39;, &#39;conv1.weight_mask&#39;, &#39;conv1.bias_mask&#39;, &#39;conv2.weight&#39;, &#39;conv2.bias&#39;, &#39;fc1.weight&#39;, &#39;fc1.bias&#39;, &#39;fc2.weight&#39;, &#39;fc2.bias&#39;, &#39;fc3.weight&#39;, &#39;fc3.bias&#39;])
</pre></div>
</div>
</section>
<section id="id9">
<h2>가지치기 기법의 재-파라미터화 제거<a class="headerlink" href="#id9" title="Link to this heading">#</a></h2>
<p>가지치기 기법이 적용된 것을 영구적으로 만들기 위해서, 재-파라미터화 관점의
<code class="docutils literal notranslate"><span class="pre">weight_orig</span></code> 와 <code class="docutils literal notranslate"><span class="pre">weight_mask</span></code> 값을 제거하고, <code class="docutils literal notranslate"><span class="pre">forward_pre_hook</span></code> 값을 제거합니다.
제거하기 위해 <code class="docutils literal notranslate"><span class="pre">torch.nn.utils.prune</span></code> 내 <code class="docutils literal notranslate"><span class="pre">remove</span></code> 함수를 이용할 수 있습니다.
가지치기 기법이 적용되지 않은 것처럼 실행되는 것이 아닌 점을 주의하세요.
이는 단지 가지치기 기법이 적용된 상태에서 가중치 파라미터값을 모델 파라미터값으로 재할당하는 것을 통해 영구적으로 만드는 것일 뿐입니다.</p>
<p>재-파라미터화를 제거하기 전 상태</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">()))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[(&#39;weight_orig&#39;, Parameter containing:
tensor([[[[ 0.1232, -0.0642, -0.0623, -0.1485,  0.0055],
          [ 0.0314, -0.1857, -0.0403,  0.1223,  0.1689],
          [-0.0559, -0.1542,  0.0177,  0.0988,  0.0749],
          [ 0.0634, -0.1869,  0.1766,  0.1120,  0.0219],
          [-0.1110, -0.0066, -0.0742,  0.1935, -0.1882]]],


        [[[-0.1891,  0.0554, -0.1982,  0.1154, -0.0523],
          [ 0.0580,  0.1063,  0.1315, -0.1787, -0.0445],
          [-0.1216,  0.1807,  0.1527, -0.1806, -0.0789],
          [-0.0206, -0.1911, -0.0794,  0.1364,  0.0037],
          [ 0.0427, -0.1558, -0.1073, -0.0763,  0.0211]]],


        [[[ 0.0116, -0.1011, -0.1792, -0.0166, -0.1940],
          [-0.1058, -0.0902, -0.0587,  0.0361, -0.0123],
          [-0.1890, -0.0632,  0.0668, -0.0883, -0.1008],
          [-0.0702,  0.1404,  0.0646, -0.1084, -0.0797],
          [-0.0942, -0.0567, -0.1763,  0.0473, -0.1682]]],


        [[[-0.0958,  0.0936,  0.1754, -0.0095,  0.0009],
          [-0.1752, -0.1877,  0.1632, -0.0735,  0.1270],
          [-0.0448, -0.0554,  0.0111,  0.1206,  0.0263],
          [ 0.1758, -0.1420,  0.1933, -0.1722, -0.1062],
          [-0.0772,  0.0547,  0.0716,  0.0628,  0.0945]]],


        [[[ 0.1180, -0.0116,  0.1336, -0.0599, -0.0110],
          [ 0.1084,  0.1545, -0.0840, -0.1709, -0.0822],
          [-0.1528,  0.1098,  0.1429, -0.0835, -0.1162],
          [-0.1901,  0.0091,  0.1081,  0.0753, -0.0684],
          [ 0.0304,  0.0038, -0.0709,  0.0481, -0.0312]]],


        [[[ 0.0692, -0.1867, -0.0930, -0.0373, -0.1380],
          [-0.0196,  0.1388,  0.0801, -0.1948,  0.0013],
          [ 0.0478, -0.1248, -0.0969, -0.1181,  0.1294],
          [ 0.0343, -0.0799, -0.0200, -0.1351, -0.0577],
          [-0.0725,  0.0144, -0.0758,  0.0333,  0.0219]]]], device=&#39;cuda:0&#39;,
       requires_grad=True)), (&#39;bias_orig&#39;, Parameter containing:
tensor([-0.0229, -0.0985, -0.0547, -0.0255, -0.1460, -0.1458], device=&#39;cuda:0&#39;,
       requires_grad=True))]
</pre></div>
</div>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">named_buffers</span><span class="p">()))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[(&#39;weight_mask&#39;, tensor([[[[0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.]]],


        [[[1., 1., 0., 1., 0.],
          [1., 1., 1., 1., 0.],
          [1., 1., 1., 1., 1.],
          [0., 1., 1., 0., 0.],
          [1., 1., 1., 0., 1.]]],


        [[[0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.]]],


        [[[1., 1., 1., 0., 1.],
          [1., 1., 1., 1., 1.],
          [1., 0., 1., 1., 0.],
          [0., 1., 1., 1., 1.],
          [1., 1., 0., 1., 0.]]],


        [[[1., 0., 1., 1., 0.],
          [1., 1., 1., 1., 0.],
          [0., 1., 1., 1., 1.],
          [1., 1., 0., 1., 1.],
          [1., 0., 1., 1., 0.]]],


        [[[0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.]]]], device=&#39;cuda:0&#39;)), (&#39;bias_mask&#39;, tensor([0., 1., 0., 0., 1., 1.], device=&#39;cuda:0&#39;))]
</pre></div>
</div>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>tensor([[[[ 0.0000, -0.0000, -0.0000, -0.0000,  0.0000],
          [ 0.0000, -0.0000, -0.0000,  0.0000,  0.0000],
          [-0.0000, -0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000, -0.0000,  0.0000,  0.0000,  0.0000],
          [-0.0000, -0.0000, -0.0000,  0.0000, -0.0000]]],


        [[[-0.1891,  0.0554, -0.0000,  0.1154, -0.0000],
          [ 0.0580,  0.1063,  0.1315, -0.1787, -0.0000],
          [-0.1216,  0.1807,  0.1527, -0.1806, -0.0789],
          [-0.0000, -0.1911, -0.0794,  0.0000,  0.0000],
          [ 0.0427, -0.1558, -0.1073, -0.0000,  0.0211]]],


        [[[ 0.0000, -0.0000, -0.0000, -0.0000, -0.0000],
          [-0.0000, -0.0000, -0.0000,  0.0000, -0.0000],
          [-0.0000, -0.0000,  0.0000, -0.0000, -0.0000],
          [-0.0000,  0.0000,  0.0000, -0.0000, -0.0000],
          [-0.0000, -0.0000, -0.0000,  0.0000, -0.0000]]],


        [[[-0.0958,  0.0936,  0.1754, -0.0000,  0.0009],
          [-0.1752, -0.1877,  0.1632, -0.0735,  0.1270],
          [-0.0448, -0.0000,  0.0111,  0.1206,  0.0000],
          [ 0.0000, -0.1420,  0.1933, -0.1722, -0.1062],
          [-0.0772,  0.0547,  0.0000,  0.0628,  0.0000]]],


        [[[ 0.1180, -0.0000,  0.1336, -0.0599, -0.0000],
          [ 0.1084,  0.1545, -0.0840, -0.1709, -0.0000],
          [-0.0000,  0.1098,  0.1429, -0.0835, -0.1162],
          [-0.1901,  0.0091,  0.0000,  0.0753, -0.0684],
          [ 0.0304,  0.0000, -0.0709,  0.0481, -0.0000]]],


        [[[ 0.0000, -0.0000, -0.0000, -0.0000, -0.0000],
          [-0.0000,  0.0000,  0.0000, -0.0000,  0.0000],
          [ 0.0000, -0.0000, -0.0000, -0.0000,  0.0000],
          [ 0.0000, -0.0000, -0.0000, -0.0000, -0.0000],
          [-0.0000,  0.0000, -0.0000,  0.0000,  0.0000]]]], device=&#39;cuda:0&#39;,
       grad_fn=&lt;MulBackward0&gt;)
</pre></div>
</div>
<p>재-파라미터를 제거한 후 상태</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">prune</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">()))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[(&#39;bias_orig&#39;, Parameter containing:
tensor([-0.0229, -0.0985, -0.0547, -0.0255, -0.1460, -0.1458], device=&#39;cuda:0&#39;,
       requires_grad=True)), (&#39;weight&#39;, Parameter containing:
tensor([[[[ 0.0000, -0.0000, -0.0000, -0.0000,  0.0000],
          [ 0.0000, -0.0000, -0.0000,  0.0000,  0.0000],
          [-0.0000, -0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000, -0.0000,  0.0000,  0.0000,  0.0000],
          [-0.0000, -0.0000, -0.0000,  0.0000, -0.0000]]],


        [[[-0.1891,  0.0554, -0.0000,  0.1154, -0.0000],
          [ 0.0580,  0.1063,  0.1315, -0.1787, -0.0000],
          [-0.1216,  0.1807,  0.1527, -0.1806, -0.0789],
          [-0.0000, -0.1911, -0.0794,  0.0000,  0.0000],
          [ 0.0427, -0.1558, -0.1073, -0.0000,  0.0211]]],


        [[[ 0.0000, -0.0000, -0.0000, -0.0000, -0.0000],
          [-0.0000, -0.0000, -0.0000,  0.0000, -0.0000],
          [-0.0000, -0.0000,  0.0000, -0.0000, -0.0000],
          [-0.0000,  0.0000,  0.0000, -0.0000, -0.0000],
          [-0.0000, -0.0000, -0.0000,  0.0000, -0.0000]]],


        [[[-0.0958,  0.0936,  0.1754, -0.0000,  0.0009],
          [-0.1752, -0.1877,  0.1632, -0.0735,  0.1270],
          [-0.0448, -0.0000,  0.0111,  0.1206,  0.0000],
          [ 0.0000, -0.1420,  0.1933, -0.1722, -0.1062],
          [-0.0772,  0.0547,  0.0000,  0.0628,  0.0000]]],


        [[[ 0.1180, -0.0000,  0.1336, -0.0599, -0.0000],
          [ 0.1084,  0.1545, -0.0840, -0.1709, -0.0000],
          [-0.0000,  0.1098,  0.1429, -0.0835, -0.1162],
          [-0.1901,  0.0091,  0.0000,  0.0753, -0.0684],
          [ 0.0304,  0.0000, -0.0709,  0.0481, -0.0000]]],


        [[[ 0.0000, -0.0000, -0.0000, -0.0000, -0.0000],
          [-0.0000,  0.0000,  0.0000, -0.0000,  0.0000],
          [ 0.0000, -0.0000, -0.0000, -0.0000,  0.0000],
          [ 0.0000, -0.0000, -0.0000, -0.0000, -0.0000],
          [-0.0000,  0.0000, -0.0000,  0.0000,  0.0000]]]], device=&#39;cuda:0&#39;,
       requires_grad=True))]
</pre></div>
</div>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">named_buffers</span><span class="p">()))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[(&#39;bias_mask&#39;, tensor([0., 1., 0., 0., 1., 1.], device=&#39;cuda:0&#39;))]
</pre></div>
</div>
</section>
<section id="id10">
<h2>모델 내 여러 파라미터값들에 대하여 가지치기 기법 적용<a class="headerlink" href="#id10" title="Link to this heading">#</a></h2>
<p>가지치기 기법을 적용하고 싶은 파라미터값들을 지정함으로써, 이번 예제에서 볼 수 있는 것 처럼,
신경망 모델 내 여러 텐서값들에 대해서 쉽게 가지치기 기법을 적용할 수 있습니다.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">new_model</span> <span class="o">=</span> <span class="n">LeNet</span><span class="p">()</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">new_model</span><span class="o">.</span><span class="n">named_modules</span><span class="p">():</span>
    <span class="c1"># 모든 2D-conv 층의 20% 연결에 대해 가지치기 기법을 적용</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">):</span>
        <span class="n">prune</span><span class="o">.</span><span class="n">l1_unstructured</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;weight&#39;</span><span class="p">,</span> <span class="n">amount</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
    <span class="c1"># 모든 선형 층의 40% 연결에 대해 가지치기 기법을 적용</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">):</span>
        <span class="n">prune</span><span class="o">.</span><span class="n">l1_unstructured</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;weight&#39;</span><span class="p">,</span> <span class="n">amount</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">new_model</span><span class="o">.</span><span class="n">named_buffers</span><span class="p">())</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>  <span class="c1"># 존재하는 모든 마스크들을 확인</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>dict_keys([&#39;conv1.weight_mask&#39;, &#39;conv2.weight_mask&#39;, &#39;fc1.weight_mask&#39;, &#39;fc2.weight_mask&#39;, &#39;fc3.weight_mask&#39;])
</pre></div>
</div>
</section>
<section id="id11">
<h2>전역 범위에 대한 가지치기 기법 적용<a class="headerlink" href="#id11" title="Link to this heading">#</a></h2>
<p>지금까지, “지역 변수” 에 대해서만 가지치기 기법을 적용하는 방법을 살펴보았습니다.
(즉, 가중치 규모, 활성화 정도, 경사값 등의 각 항목의 통계량을 바탕으로 모델 내 텐서값 하나씩 가지치기 기법을 적용하는 방식)
그러나, 범용적이고 아마 더 강력한 방법은 각 층에서 가장 낮은 20%의 연결을 제거하는 것 대신에, 전체 모델에 대해서 가장 낮은 20% 연결을 한번에 제거하는 것입니다.
이것은 각 층에 대해서 가지치기 기법을 적용하는 연결의 백분율값을 다르게 만들 가능성이 있습니다.
<code class="docutils literal notranslate"><span class="pre">torch.nn.utils.prune</span></code> 내 <code class="docutils literal notranslate"><span class="pre">global_unstructured</span></code> 을 이용하여 어떻게 전역 범위에 대한 가지치기 기법을 적용하는지 살펴봅시다.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">LeNet</span><span class="p">()</span>

<span class="n">parameters_to_prune</span> <span class="o">=</span> <span class="p">(</span>
    <span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">conv1</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">),</span>
    <span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">conv2</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">),</span>
    <span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">fc1</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">),</span>
    <span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">fc2</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">),</span>
    <span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">fc3</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">),</span>
<span class="p">)</span>

<span class="n">prune</span><span class="o">.</span><span class="n">global_unstructured</span><span class="p">(</span>
    <span class="n">parameters_to_prune</span><span class="p">,</span>
    <span class="n">pruning_method</span><span class="o">=</span><span class="n">prune</span><span class="o">.</span><span class="n">L1Unstructured</span><span class="p">,</span>
    <span class="n">amount</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>이제 각 층에 존재하는 연결들에 가지치기 기법이 적용된 정도가 20%가 아닌 것을 확인할 수 있습니다.
그러나, 전체 가지치기 적용 범위는 약 20%가 될 것입니다.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Sparsity in conv1.weight: </span><span class="si">{:.2f}</span><span class="s2">%&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="mf">100.</span> <span class="o">*</span> <span class="nb">float</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">conv1</span><span class="o">.</span><span class="n">weight</span> <span class="o">==</span> <span class="mi">0</span><span class="p">))</span>
        <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">conv1</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">nelement</span><span class="p">())</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Sparsity in conv2.weight: </span><span class="si">{:.2f}</span><span class="s2">%&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="mf">100.</span> <span class="o">*</span> <span class="nb">float</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">conv2</span><span class="o">.</span><span class="n">weight</span> <span class="o">==</span> <span class="mi">0</span><span class="p">))</span>
        <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">conv2</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">nelement</span><span class="p">())</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Sparsity in fc1.weight: </span><span class="si">{:.2f}</span><span class="s2">%&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="mf">100.</span> <span class="o">*</span> <span class="nb">float</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">fc1</span><span class="o">.</span><span class="n">weight</span> <span class="o">==</span> <span class="mi">0</span><span class="p">))</span>
        <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">fc1</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">nelement</span><span class="p">())</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Sparsity in fc2.weight: </span><span class="si">{:.2f}</span><span class="s2">%&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="mf">100.</span> <span class="o">*</span> <span class="nb">float</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">fc2</span><span class="o">.</span><span class="n">weight</span> <span class="o">==</span> <span class="mi">0</span><span class="p">))</span>
        <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">fc2</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">nelement</span><span class="p">())</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Sparsity in fc3.weight: </span><span class="si">{:.2f}</span><span class="s2">%&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="mf">100.</span> <span class="o">*</span> <span class="nb">float</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">fc3</span><span class="o">.</span><span class="n">weight</span> <span class="o">==</span> <span class="mi">0</span><span class="p">))</span>
        <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">fc3</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">nelement</span><span class="p">())</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Global sparsity: </span><span class="si">{:.2f}</span><span class="s2">%&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="mf">100.</span> <span class="o">*</span> <span class="nb">float</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">conv1</span><span class="o">.</span><span class="n">weight</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
            <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">conv2</span><span class="o">.</span><span class="n">weight</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
            <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">fc1</span><span class="o">.</span><span class="n">weight</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
            <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">fc2</span><span class="o">.</span><span class="n">weight</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
            <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">fc3</span><span class="o">.</span><span class="n">weight</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="o">/</span> <span class="nb">float</span><span class="p">(</span>
            <span class="n">model</span><span class="o">.</span><span class="n">conv1</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">nelement</span><span class="p">()</span>
            <span class="o">+</span> <span class="n">model</span><span class="o">.</span><span class="n">conv2</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">nelement</span><span class="p">()</span>
            <span class="o">+</span> <span class="n">model</span><span class="o">.</span><span class="n">fc1</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">nelement</span><span class="p">()</span>
            <span class="o">+</span> <span class="n">model</span><span class="o">.</span><span class="n">fc2</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">nelement</span><span class="p">()</span>
            <span class="o">+</span> <span class="n">model</span><span class="o">.</span><span class="n">fc3</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">nelement</span><span class="p">()</span>
        <span class="p">)</span>
    <span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Sparsity in conv1.weight: 4.67%
Sparsity in conv2.weight: 13.12%
Sparsity in fc1.weight: 22.33%
Sparsity in fc2.weight: 11.69%
Sparsity in fc3.weight: 9.17%
Global sparsity: 20.00%
</pre></div>
</div>
</section>
<section id="torch-nn-utils-prune">
<h2><code class="docutils literal notranslate"><span class="pre">torch.nn.utils.prune</span></code> 에서 확장된 맞춤형 가지치기 기법<a class="headerlink" href="#torch-nn-utils-prune" title="Link to this heading">#</a></h2>
<p>맞춤형 가지치기 기법은, 다른 가지치기 기법을 적용하는 것과 같은 방식으로,
<code class="docutils literal notranslate"><span class="pre">BasePruningMethod</span></code> 의 기본 클래스인 <code class="docutils literal notranslate"><span class="pre">nn.utils.prune</span></code> 모듈을 활용하여 구현할 수 있습니다.
기본 클래스는 <code class="docutils literal notranslate"><span class="pre">__call__</span></code>, <code class="docutils literal notranslate"><span class="pre">apply_mask</span></code>, <code class="docutils literal notranslate"><span class="pre">apply</span></code>, <code class="docutils literal notranslate"><span class="pre">prune</span></code>, <code class="docutils literal notranslate"><span class="pre">remove</span></code> 메소드들을 내포하고 있습니다.
특별한 케이스가 아닌 경우, 기본적으로 구성된 메소드들을 재구성할 필요가 없습니다.
그러나, <code class="docutils literal notranslate"><span class="pre">__init__</span></code> (구성요소), <code class="docutils literal notranslate"><span class="pre">compute_mask</span></code>
(가지치기 기법의 논리에 따라 주어진 텐서값에 마스크를 적용하는 방법) 을 고려하여 구성해야 합니다.
게다가, 가지치기 기법을 어떠한 방식으로 적용하는지 명확하게 구성해야 합니다.
(지원되는 옵션은 <code class="docutils literal notranslate"><span class="pre">global</span></code>, <code class="docutils literal notranslate"><span class="pre">structured</span></code>, <code class="docutils literal notranslate"><span class="pre">unstructured</span></code> 입니다.)
이러한 방식은, 가지치기 기법을 반복적으로 적용해야 하는 경우 마스크를 결합하는 방법을 결정하기 위해 필요합니다.
즉, 이미 가지치기 기법이 적용된 모델에 대해서 가지치기 기법을 적용할 때,
기존의 가지치기 기법이 적용되지 않은 파라미터 값에 대해 가지치기 기법이 영향을 미칠 것으로 예상됩니다.
<code class="docutils literal notranslate"><span class="pre">PRUNING_TYPE</span></code> 을 지정한다면, 가지치기 기법을 적용하기 위해 파라미터 값을 올바르게 제거하는
<code class="docutils literal notranslate"><span class="pre">PruningContainer</span></code> (마스크 가지치기 기법을 반복적으로 적용하는 것을 처리하는)를 가능하게 합니다.
예를 들어, 다른 모든 항목이 존재하는 텐서를 가지치기 기법을 구현하고 싶을 때,
(또는, 텐서가 이전에 가지치기 기법에 의해 제거되었거나 남아있는 텐서에 대해)
한 층의 개별 연결에 작용하며 전체 유닛/채널 (<code class="docutils literal notranslate"><span class="pre">'structured'</span></code>), 또는 다른 파라미터 간
(<code class="docutils literal notranslate"><span class="pre">'global'</span></code>) 연결에는 작용하지 않기 때문에 <code class="docutils literal notranslate"><span class="pre">PRUNING_TYPE='unstructured'</span></code> 방식으로 진행됩니다.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">FooBarPruningMethod</span><span class="p">(</span><span class="n">prune</span><span class="o">.</span><span class="n">BasePruningMethod</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    텐서 내 다른 항목들에 대해 가지치기 기법을 적용</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">PRUNING_TYPE</span> <span class="o">=</span> <span class="s1">&#39;unstructured&#39;</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">compute_mask</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">default_mask</span><span class="p">):</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">default_mask</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="n">mask</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)[::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="n">mask</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> 의 매개변수에 적용하기 위해 인스턴스화하고 적용하는 간단한 기능을 구현해봅니다.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">foobar_unstructured</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    텐서 내 다른 모든 항목들을 제거하여 `module` 에서 `name` 이라는 파라미터에 대해 가자치기 기법을 적용</span>
<span class="sd">    다음 내용에 따라 모듈을 수정 (또는 수정된 모듈을 반환):</span>
<span class="sd">        1) 가지치기 기법에 의해 매개변수 `name` 에 적용된 이진 마스크에 해당하는 명명된 버퍼 `name+&#39;_mask&#39;` 를 추가합니다.</span>
<span class="sd">        `name` 파라미터는 가지치기 기법이 적용된 것으로 대체되며, 가지치기 기법이 적용되지 않은</span>
<span class="sd">        기존의 파라미터는 `name+&#39;_orig&#39;` 라는 이름의 새로운 매개변수에 저장됩니다.</span>

<span class="sd">    인자값:</span>
<span class="sd">        module (nn.Module): 가지치기 기법을 적용해야 하는 텐서를 포함하는 모듈</span>
<span class="sd">        name (string): 모듈 내 가지치기 기법이 적용될 파라미터의 이름</span>

<span class="sd">    반환값:</span>
<span class="sd">        module (nn.Module): 입력 모듈에 대해서 가지치기 기법이 적용된 모듈</span>

<span class="sd">    예시:</span>
<span class="sd">        &gt;&gt;&gt; m = nn.Linear(3, 4)</span>
<span class="sd">        &gt;&gt;&gt; foobar_unstructured(m, name=&#39;bias&#39;)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">FooBarPruningMethod</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">module</span>
</pre></div>
</div>
<p>한번 해봅시다!</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">LeNet</span><span class="p">()</span>
<span class="n">foobar_unstructured</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">fc3</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;bias&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">fc3</span><span class="o">.</span><span class="n">bias_mask</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>tensor([0., 1., 0., 1., 0., 1., 0., 1., 0., 1.])
</pre></div>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (0 minutes 4.590 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-intermediate-pruning-tutorial-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/7126bf7beed4c4c3a05bcc2dac8baa3c/pruning_tutorial.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">pruning_tutorial.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/ef3541eb2ef78e22efa65b3d6f4ba737/pruning_tutorial.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">pruning_tutorial.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../_downloads/1e036e7987dc88cd2a4a764e3ca458a4/pruning_tutorial.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">pruning_tutorial.zip</span></code></a></p>
</div>
</div>
</section>
</section>


                </article>
              
  </article>
  
              
              
                <footer class="bd-footer-article">
                  <div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item">
<div class="feedback">
  
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
        
    </div>
</div>

  <div class="feedback-send">
    <button class="feedback-btn"
            onclick="openGitHubIssue()"
            data-bs-title="Create a GitHub Issue"
            data-bs-placement="bottom"
            data-bs-toggle="tooltip"
            data-gtm="feedback-btn-click">Send Feedback
    </button>
  </div>
</div>

<div class="prev-next-area">
    <a class="left-prev"
       href="parametrizations.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">이전</p>
        <p class="prev-next-title">Parametrizations Tutorial</p>
      </div>
    </a>
    <a class="right-next"
       href="scaled_dot_product_attention_tutorial.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">다음</p>
        <p class="prev-next-title">(Beta) Scaled Dot Product Attention (SDPA)로 고성능 트랜스포머(Transformers) 구현하기</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>

<div class="footer-info">
  <p class="copyright">
    
      
        © Copyright 2018-2025, PyTorch &amp; 파이토치 한국 사용자 모임(PyTorchKR).
      
      <br/>
    
  </p>

  <p class="theme-version">
    Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
  </p>
</div>
</div>
  
</div>
                </footer>
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="parametrizations.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">이전</p>
        <p class="prev-next-title">Parametrizations Tutorial</p>
      </div>
    </a>
    <a class="right-next"
       href="scaled_dot_product_attention_tutorial.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">다음</p>
        <p class="prev-next-title">(Beta) Scaled Dot Product Attention (SDPA)로 고성능 트랜스포머(Transformers) 구현하기</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc">
<div class="sidebar-secondary-items sidebar-secondary__inner">
    
       <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">요구사항</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">딥러닝 모델 생성</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">모듈 점검</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">모듈 가지치기 기법 적용 예제</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">가지치기 기법 반복 적용</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">가지치기 기법이 적용된 모델의 직렬화</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">가지치기 기법의 재-파라미터화 제거</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">모델 내 여러 파라미터값들에 대하여 가지치기 기법 적용</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id11">전역 범위에 대한 가지치기 기법 적용</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#torch-nn-utils-prune"><code class="docutils literal notranslate"><span class="pre">torch.nn.utils.prune</span></code> 에서 확장된 맞춤형 가지치기 기법</a></li>
</ul>
  </nav></div>
    




<div class="sidebar-secondary-item">
  <div class="sidebar-heading">PyTorch Libraries</div>
  <ul style="list-style-type: none; padding: 0; padding-bottom: 80px;">
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/ao" style="color: var(--pst-color-text-muted)">torchao</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchrec" style="color: var(--pst-color-text-muted)">torchrec</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchft" style="color: var(--pst-color-text-muted)">torchft</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchcodec" style="color: var(--pst-color-text-muted)">TorchCodec</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/vision" style="color: var(--pst-color-text-muted)">torchvision</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/executorch" style="color: var(--pst-color-text-muted)">ExecuTorch</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/xla" style="color: var(--pst-color-text-muted)">PyTorch on XLA Devices</a></li>
  
  </ul>
</div>

</div>
</div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <div class="container-fluid docs-tutorials-resources">
  <div class="container">
    <div class="row">
      <div class="col-md-4 text-center">
        <h2>PyTorchKorea @ GitHub</h2>
        <p>파이토치 한국 사용자 모임을 GitHub에서 만나보세요.</p>
        <a class="with-right-arrow" href="https://github.com/PyTorchKorea">GitHub로 이동</a>
      </div>

      <div class="col-md-4 text-center">
        <h2>한국어 튜토리얼</h2>
        <p>한국어로 번역 중인 파이토치 튜토리얼을 만나보세요.</p>
        <a class="with-right-arrow" href="https://tutorials.pytorch.kr/">튜토리얼로 이동</a>
      </div>

      <div class="col-md-4 text-center">
        <h2>한국어 커뮤니티</h2>
        <p>다른 사용자들과 의견을 나누고, 도와주세요!</p>
        <a class="with-right-arrow" href="https://discuss.pytorch.kr/">커뮤니티로 이동</a>
      </div>
    </div>
  </div>
</div>

<footer class="site-footer">
  <div class="container footer-container">
    <div class="footer-logo-wrapper">
      <a href="https://pytorch.kr/" class="footer-logo"></a>
    </div>

    <div class="footer-links-wrapper">
      <div class="footer-links-col">
        <ul>
          <li class="list-title"><a href="https://pytorch.kr/">파이토치 한국 사용자 모임</a></li>
          <li><a href="https://pytorch.kr/about">사용자 모임 소개</a></li>
          <li><a href="https://pytorch.kr/contributors">기여해주신 분들</a></li>
          <li><a href="https://pytorch.kr/resources/">리소스</a></li>
          <li><a href="https://pytorch.kr/coc">행동 강령</a></li>
        </ul>
      </div>
    </div>

    <div class="trademark-disclaimer">
      <ul>
        <li>이 사이트는 독립적인 파이토치 사용자 커뮤니티로, 최신 버전이 아니거나 잘못된 내용이 포함되어 있을 수 있습니다. This site is an independent user community and may be out of date or contain incorrect information.</li>
        <li><a href="https://pytorch.kr/coc">행동 강령</a>을 읽고 지켜주세요. PyTorch 공식 로고 사용 규정은 <a href="https://www.linuxfoundation.org/policies/">Linux Foundation의 정책</a>을 따릅니다. Please read and follow <a href="https://pytorch.kr/coc">our code of conduct</a>. All PyTorch trademark policy applicable to <a href="https://www.linuxfoundation.org/policies/">Linux Foundation's policies</a>.</li>
      </ul>
    </div>
  </div>
</footer>

<div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../_static/img/pytorch-x.svg">
  </div>
</div>
  
  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2018-2025, PyTorch &amp; 파이토치 한국 사용자 모임(PyTorchKR).
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.2.6 버전으로 생성되었습니다.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
</p></div>
      
    </div>
  
</div>

  </footer>
  <script type="application/ld+json">
    {
       "@context": "https://schema.org",
       "@type": "Article",
       "name": "\uac00\uc9c0\uce58\uae30 \uae30\ubc95(Pruning) \ud29c\ud1a0\ub9ac\uc5bc",
       "headline": "\uac00\uc9c0\uce58\uae30 \uae30\ubc95(Pruning) \ud29c\ud1a0\ub9ac\uc5bc",
       "description": "PyTorch Documentation. Explore PyTorch, an open-source machine learning library that accelerates the path from research prototyping to production deployment. Discover tutorials, API references, and guides to help you build and deploy deep learning models efficiently.",
       "url": "/intermediate/pruning_tutorial.html",
       "articleBody": "\ucc38\uace0 Go to the end to download the full example code. \uac00\uc9c0\uce58\uae30 \uae30\ubc95(Pruning) \ud29c\ud1a0\ub9ac\uc5bc# Author: Michela Paganini\ubc88\uc5ed: \uc548\uc0c1\uc900 \ucd5c\ucca8\ub2e8 \ub525\ub7ec\ub2dd \ubaa8\ub378\ub4e4\uc740 \uad49\uc7a5\ud788 \ub9ce\uc740 \uc218\uc758 \ud30c\ub77c\ubbf8\ud130\uac12\ub4e4\ub85c \uad6c\uc131\ub418\uae30 \ub54c\ubb38\uc5d0, \uc27d\uac8c \ubc30\ud3ec\ud558\uae30\uac00 \uc5b4\ub835\uc2b5\ub2c8\ub2e4. \uc774\uc640 \ubc18\ub300\ub85c, \uc0dd\ubb3c\ud559\uc801 \uc2e0\uacbd\ub9dd\ub4e4\uc740 \ud6a8\uc728\uc801\uc73c\ub85c \ud76c\uc18c\ud558\uac8c \uc5f0\uacb0\ub41c \uac83\uc73c\ub85c \uc54c\ub824\uc838 \uc788\uc2b5\ub2c8\ub2e4. \ubaa8\ub378\uc758 \uc815\ud655\ub3c4\ub97c \ud6fc\uc190\ud558\uc9c0 \uc54a\uc73c\uba74\uc11c \ubaa8\ub378\uc5d0 \ud3ec\ud568\ub41c \ud30c\ub77c\ubbf8\ud130 \uc218\ub97c \uc904\uc5ec \uc555\ucd95\ud558\ub294 \ucd5c\uc801\uc758 \uae30\ubc95\uc744 \ud30c\uc545\ud558\ub294 \uac83\uc740 \uba54\ubaa8\ub9ac, \ubc30\ud130\ub9ac, \ud558\ub4dc\uc6e8\uc5b4 \uc18c\ube44\ub7c9\uc744 \uc904\uc77c \uc218 \uc788\uae30 \ub54c\ubb38\uc5d0 \uc911\uc694\ud569\ub2c8\ub2e4. \uadf8\ub7fc\uc73c\ub85c\uc11c \uae30\uae30\uc5d0 \uacbd\ub7c9\ud654\ub41c \ubaa8\ub378\uc744 \ubc30\ud3ec\ud558\uc5ec \uac1c\uac1c\uc778\uc774 \uc0ac\uc6a9\ud558\uace0 \uc788\ub294 \uae30\uae30\uc5d0\uc11c \uc5f0\uc0b0\uc744 \uc218\ud589\ud558\uc5ec \ud504\ub77c\uc774\ubc84\uc2dc\ub97c \ubcf4\uc7a5\ud560 \uc218 \uc788\uae30 \ub54c\ubb38\uc785\ub2c8\ub2e4. \uc5f0\uad6c \uce21\uba74\uc5d0\uc11c\ub294, \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc740 \uad49\uc7a5\ud788 \ub9ce\uc740 \uc218\uc758 \ud30c\ub77c\ubbf8\ud130\uac12\ub4e4\ub85c \uad6c\uc131\ub41c \ubaa8\ub378\uacfc \uad49\uc7a5\ud788 \uc801\uc740 \uc218\uc758 \ud30c\ub77c\ubbf8\ud130\uac12\ub4e4\ub85c \uad6c\uc131\ub41c \ubaa8\ub378 \uac04 \ud559\uc2b5 \uc5ed\ud559 \ucc28\uc774\ub97c \uc870\uc0ac\ud558\ub294\ub370 \uc8fc\ub85c \uc774\uc6a9\ub418\uae30\ub3c4 \ud558\uba70, \ud558\uc704 \uc2e0\uacbd\ub9dd \ubaa8\ub378\uacfc \ud30c\ub77c\ubbf8\ud130\uac12\ub4e4\uc758 \ucd08\uae30\ud654\uac00 \uc6b4\uc774 \uc88b\uac8c \uc798 \ub41c \ucf00\uc774\uc2a4\ub97c \ubc14\ud0d5\uc73c\ub85c (\u201dlottery tickets\u201d) \uc2e0\uacbd\ub9dd \uad6c\uc870\ub97c \ucc3e\ub294 \uae30\uc220\ub4e4\uc5d0 \ub300\ud574 \ubc18\ub300 \uc758\uacac\uc744 \uc81c\uc2dc\ud558\uae30\ub3c4 \ud569\ub2c8\ub2e4. \uc774\ubc88 \ud29c\ud1a0\ub9ac\uc5bc\uc5d0\uc11c\ub294, torch.nn.utils.prune \uc744 \uc0ac\uc6a9\ud558\uc5ec \uc5ec\ub7ec\ubd84\uc774 \uc124\uacc4\ud55c \ub525\ub7ec\ub2dd \ubaa8\ub378\uc5d0 \ub300\ud574 \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc744 \uc801\uc6a9\ud574\ubcf4\ub294 \uac83\uc744 \ubc30\uc6cc\ubcf4\uace0, \uc2ec\ud654\uc801\uc73c\ub85c \uc5ec\ub7ec\ubd84\uc758 \ub9de\ucda4\ud615 \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc744 \uad6c\ud604\ud558\ub294 \ubc29\ubc95\uc5d0 \ub300\ud574 \ubc30\uc6cc\ubcf4\ub3c4\ub85d \ud558\uaca0\uc2b5\ub2c8\ub2e4. \uc694\uad6c\uc0ac\ud56d# \"torch\u003e=1.4\" import torch from torch import nn import torch.nn.utils.prune as prune import torch.nn.functional as F \ub525\ub7ec\ub2dd \ubaa8\ub378 \uc0dd\uc131# \uc774\ubc88 \ud29c\ud1a0\ub9ac\uc5bc\uc5d0\uc11c\ub294, \uc580 \ub974\ucfe4 \uad50\uc218\ub2d8\uc758 \uc5f0\uad6c\uc9c4\ub4e4\uc774 1998\ub144\ub3c4\uc5d0 \ubc1c\ud45c\ud55c LeNet \uc758 \ubaa8\ub378 \uad6c\uc870\ub97c \uc774\uc6a9\ud569\ub2c8\ub2e4. device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") class LeNet(nn.Module): def __init__(self): super(LeNet, self).__init__() # 1\uac1c \ucc44\ub110 \uc218\uc758 \uc774\ubbf8\uc9c0\ub97c \uc785\ub825\uac12\uc73c\ub85c \uc774\uc6a9\ud558\uc5ec 6\uac1c \ucc44\ub110 \uc218\uc758 \ucd9c\ub825\uac12\uc744 \uacc4\uc0b0\ud558\ub294 \ubc29\uc2dd # Convolution \uc5f0\uc0b0\uc744 \uc9c4\ud589\ud558\ub294 \ucee4\ub110(\ud544\ud130)\uc758 \ud06c\uae30\ub294 5x5 \uc744 \uc774\uc6a9 self.conv1 = nn.Conv2d(1, 6, 5) self.conv2 = nn.Conv2d(6, 16, 5) self.fc1 = nn.Linear(16 * 5 * 5, 120) # Convolution \uc5f0\uc0b0 \uacb0\uacfc 5x5 \ud06c\uae30\uc758 16 \ucc44\ub110 \uc218\uc758 \uc774\ubbf8\uc9c0 self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def forward(self, x): x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) x = F.max_pool2d(F.relu(self.conv2(x)), 2) x = x.view(-1, int(x.nelement() / x.shape[0])) x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return x model = LeNet().to(device=device) \ubaa8\ub4c8 \uc810\uac80# \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc774 \uc801\uc6a9\ub418\uc9c0 \uc54a\uc740 LeNet \ubaa8\ub378\uc758 conv1 \uce35\uc744 \uc810\uac80\ud574\ubd05\uc2dc\ub2e4. \uc5ec\uae30\uc5d0\ub294 2\uac1c\uc758 \ud30c\ub77c\ubbf8\ud130\uac12\ub4e4\uc778 \uac00\uc911\uce58 \uac12\uacfc \ud3b8\ud5a5 \uac12\uc774 \ud3ec\ud568\ub420 \uac83\uc774\uba70, \ubc84\ud37c\ub294 \uc874\uc7ac\ud558\uc9c0 \uc54a\uc744 \uac83\uc785\ub2c8\ub2e4. module = model.conv1 print(list(module.named_parameters())) [(\u0027weight\u0027, Parameter containing: tensor([[[[ 0.1232, -0.0642, -0.0623, -0.1485, 0.0055], [ 0.0314, -0.1857, -0.0403, 0.1223, 0.1689], [-0.0559, -0.1542, 0.0177, 0.0988, 0.0749], [ 0.0634, -0.1869, 0.1766, 0.1120, 0.0219], [-0.1110, -0.0066, -0.0742, 0.1935, -0.1882]]], [[[-0.1891, 0.0554, -0.1982, 0.1154, -0.0523], [ 0.0580, 0.1063, 0.1315, -0.1787, -0.0445], [-0.1216, 0.1807, 0.1527, -0.1806, -0.0789], [-0.0206, -0.1911, -0.0794, 0.1364, 0.0037], [ 0.0427, -0.1558, -0.1073, -0.0763, 0.0211]]], [[[ 0.0116, -0.1011, -0.1792, -0.0166, -0.1940], [-0.1058, -0.0902, -0.0587, 0.0361, -0.0123], [-0.1890, -0.0632, 0.0668, -0.0883, -0.1008], [-0.0702, 0.1404, 0.0646, -0.1084, -0.0797], [-0.0942, -0.0567, -0.1763, 0.0473, -0.1682]]], [[[-0.0958, 0.0936, 0.1754, -0.0095, 0.0009], [-0.1752, -0.1877, 0.1632, -0.0735, 0.1270], [-0.0448, -0.0554, 0.0111, 0.1206, 0.0263], [ 0.1758, -0.1420, 0.1933, -0.1722, -0.1062], [-0.0772, 0.0547, 0.0716, 0.0628, 0.0945]]], [[[ 0.1180, -0.0116, 0.1336, -0.0599, -0.0110], [ 0.1084, 0.1545, -0.0840, -0.1709, -0.0822], [-0.1528, 0.1098, 0.1429, -0.0835, -0.1162], [-0.1901, 0.0091, 0.1081, 0.0753, -0.0684], [ 0.0304, 0.0038, -0.0709, 0.0481, -0.0312]]], [[[ 0.0692, -0.1867, -0.0930, -0.0373, -0.1380], [-0.0196, 0.1388, 0.0801, -0.1948, 0.0013], [ 0.0478, -0.1248, -0.0969, -0.1181, 0.1294], [ 0.0343, -0.0799, -0.0200, -0.1351, -0.0577], [-0.0725, 0.0144, -0.0758, 0.0333, 0.0219]]]], device=\u0027cuda:0\u0027, requires_grad=True)), (\u0027bias\u0027, Parameter containing: tensor([-0.0229, -0.0985, -0.0547, -0.0255, -0.1460, -0.1458], device=\u0027cuda:0\u0027, requires_grad=True))] print(list(module.named_buffers())) [] \ubaa8\ub4c8 \uac00\uc9c0\uce58\uae30 \uae30\ubc95 \uc801\uc6a9 \uc608\uc81c# \ubaa8\ub4c8\uc5d0 \ub300\ud574 \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc744 \uc801\uc6a9\ud558\uae30 \uc704\ud574 (\uc774\ubc88 \uc608\uc81c\uc5d0\uc11c\ub294, LeNet \ubaa8\ub378\uc758 conv1 \uce35) \uccab \ubc88\uc9f8\ub85c\ub294, torch.nn.utils.prune (\ub610\ub294 BasePruningMethod \uc758 \uc11c\ube0c \ud074\ub798\uc2a4\ub85c \uc9c1\uc811 \uad6c\ud604 ) \ub0b4 \uc874\uc7ac\ud558\ub294 \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc744 \uc120\ud0dd\ud569\ub2c8\ub2e4. \uadf8 \ud6c4, \ud574\ub2f9 \ubaa8\ub4c8 \ub0b4\uc5d0\uc11c \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc744 \uc801\uc6a9\ud558\uace0\uc790 \ud558\ub294 \ubaa8\ub4c8\uacfc \ud30c\ub77c\ubbf8\ud130\ub97c \uc9c0\uc815\ud569\ub2c8\ub2e4. \ub9c8\uc9c0\ub9c9\uc73c\ub85c, \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc5d0 \uc801\ub2f9\ud55c \ud0a4\uc6cc\ub4dc \uc778\uc790\uac12\uc744 \uc774\uc6a9\ud558\uc5ec \uac00\uc9c0\uce58\uae30 \ub9e4\uac1c\ubcc0\uc218\ub97c \uc9c0\uc815\ud569\ub2c8\ub2e4. \uc774\ubc88 \uc608\uc81c\uc5d0\uc11c\ub294, conv1 \uce35\uc758 \uac00\uc911\uce58\uc758 30%\uac12\ub4e4\uc744 \ub79c\ub364\uc73c\ub85c \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc744 \uc801\uc6a9\ud574\ubcf4\uaca0\uc2b5\ub2c8\ub2e4. \ubaa8\ub4c8\uc740 \ud568\uc218\uc5d0 \ub300\ud55c \uccab \ubc88\uc9f8 \uc778\uc790\uac12\uc73c\ub85c \uc804\ub2ec\ub418\uba70, name \uc740 \ubb38\uc790\uc5f4 \uc2dd\ubcc4\uc790\ub97c \uc774\uc6a9\ud558\uc5ec \ud574\ub2f9 \ubaa8\ub4c8 \ub0b4 \ub9e4\uac1c\ubcc0\uc218\ub97c \uad6c\ubd84\ud569\ub2c8\ub2e4. \uadf8\ub9ac\uace0, amount \ub294 \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc744 \uc801\uc6a9\ud558\uae30 \uc704\ud55c \ub300\uc0c1 \uac00\uc911\uce58\uac12\ub4e4\uc758 \ubc31\ubd84\uc728 (0\uacfc 1\uc0ac\uc774\uc758 \uc2e4\uc218\uac12), \ud639\uc740 \uac00\uc911\uce58\uac12\uc758 \uc5f0\uacb0\uc758 \uac1c\uc218 (\uc74c\uc218\uac00 \uc544\ub2cc \uc815\uc218) \ub97c \uc9c0\uc815\ud569\ub2c8\ub2e4. prune.random_unstructured(module, name=\"weight\", amount=0.3) Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1)) \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc740 \uac00\uc911\uce58\uac12\ub4e4\uc744 \ud30c\ub77c\ubbf8\ud130\uac12\ub4e4\ub85c\ubd80\ud130 \uc81c\uac70\ud558\uace0 weight_orig (\uc989, \ucd08\uae30 \uac00\uc911\uce58 \uc774\ub984\uc5d0 \u201c_orig\u201d\uc744 \ubd99\uc778) \uc774\ub77c\ub294 \uc0c8\ub85c\uc6b4 \ud30c\ub77c\ubbf8\ud130\uac12\uc73c\ub85c \ub300\uccb4\ud558\ub294 \uac83\uc73c\ub85c \uc2e4\ud589\ub429\ub2c8\ub2e4. weight_orig \uc740 \ud150\uc11c\uac12\uc5d0 \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc774 \uc801\uc6a9\ub418\uc9c0 \uc54a\uc740 \uc0c1\ud0dc\ub97c \uc800\uc7a5\ud569\ub2c8\ub2e4. bias \uc740 \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc774 \uc801\uc6a9\ub418\uc9c0 \uc54a\uc558\uae30 \ub54c\ubb38\uc5d0 \uadf8\ub300\ub85c \ub0a8\uc544 \uc788\uc2b5\ub2c8\ub2e4. print(list(module.named_parameters())) [(\u0027bias\u0027, Parameter containing: tensor([-0.0229, -0.0985, -0.0547, -0.0255, -0.1460, -0.1458], device=\u0027cuda:0\u0027, requires_grad=True)), (\u0027weight_orig\u0027, Parameter containing: tensor([[[[ 0.1232, -0.0642, -0.0623, -0.1485, 0.0055], [ 0.0314, -0.1857, -0.0403, 0.1223, 0.1689], [-0.0559, -0.1542, 0.0177, 0.0988, 0.0749], [ 0.0634, -0.1869, 0.1766, 0.1120, 0.0219], [-0.1110, -0.0066, -0.0742, 0.1935, -0.1882]]], [[[-0.1891, 0.0554, -0.1982, 0.1154, -0.0523], [ 0.0580, 0.1063, 0.1315, -0.1787, -0.0445], [-0.1216, 0.1807, 0.1527, -0.1806, -0.0789], [-0.0206, -0.1911, -0.0794, 0.1364, 0.0037], [ 0.0427, -0.1558, -0.1073, -0.0763, 0.0211]]], [[[ 0.0116, -0.1011, -0.1792, -0.0166, -0.1940], [-0.1058, -0.0902, -0.0587, 0.0361, -0.0123], [-0.1890, -0.0632, 0.0668, -0.0883, -0.1008], [-0.0702, 0.1404, 0.0646, -0.1084, -0.0797], [-0.0942, -0.0567, -0.1763, 0.0473, -0.1682]]], [[[-0.0958, 0.0936, 0.1754, -0.0095, 0.0009], [-0.1752, -0.1877, 0.1632, -0.0735, 0.1270], [-0.0448, -0.0554, 0.0111, 0.1206, 0.0263], [ 0.1758, -0.1420, 0.1933, -0.1722, -0.1062], [-0.0772, 0.0547, 0.0716, 0.0628, 0.0945]]], [[[ 0.1180, -0.0116, 0.1336, -0.0599, -0.0110], [ 0.1084, 0.1545, -0.0840, -0.1709, -0.0822], [-0.1528, 0.1098, 0.1429, -0.0835, -0.1162], [-0.1901, 0.0091, 0.1081, 0.0753, -0.0684], [ 0.0304, 0.0038, -0.0709, 0.0481, -0.0312]]], [[[ 0.0692, -0.1867, -0.0930, -0.0373, -0.1380], [-0.0196, 0.1388, 0.0801, -0.1948, 0.0013], [ 0.0478, -0.1248, -0.0969, -0.1181, 0.1294], [ 0.0343, -0.0799, -0.0200, -0.1351, -0.0577], [-0.0725, 0.0144, -0.0758, 0.0333, 0.0219]]]], device=\u0027cuda:0\u0027, requires_grad=True))] \uc704\uc5d0\uc11c \uc120\ud0dd\ud55c \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc5d0 \uc758\ud574 \uc0dd\uc131\ub418\ub294 \uac00\uc9c0\uce58\uae30 \ub9c8\uc2a4\ud06c\ub294 \ucd08\uae30 \ud30c\ub77c\ubbf8\ud130 name \uc5d0 weight_mask (\uc989, \ucd08\uae30 \uac00\uc911\uce58 \uc774\ub984\uc5d0 \u201c_mask\u201d\ub97c \ubd99\uc778) \uc774\ub984\uc758 \ubaa8\ub4c8 \ubc84\ud37c\ub85c \uc800\uc7a5\ub429\ub2c8\ub2e4. print(list(module.named_buffers())) [(\u0027weight_mask\u0027, tensor([[[[0., 0., 1., 0., 1.], [1., 1., 0., 1., 1.], [0., 0., 1., 1., 1.], [1., 0., 1., 0., 1.], [0., 0., 1., 1., 1.]]], [[[1., 1., 0., 1., 0.], [1., 1., 1., 1., 0.], [1., 1., 1., 1., 1.], [0., 1., 1., 0., 0.], [1., 1., 1., 0., 1.]]], [[[1., 1., 1., 1., 0.], [1., 1., 1., 1., 0.], [1., 1., 1., 0., 1.], [1., 1., 0., 0., 0.], [1., 0., 1., 0., 0.]]], [[[1., 1., 1., 0., 1.], [1., 1., 1., 1., 1.], [1., 0., 1., 1., 0.], [0., 1., 1., 1., 1.], [1., 1., 0., 1., 0.]]], [[[1., 0., 1., 1., 0.], [1., 1., 1., 1., 0.], [0., 1., 1., 1., 1.], [1., 1., 0., 1., 1.], [1., 0., 1., 1., 0.]]], [[[0., 1., 1., 1., 1.], [1., 1., 0., 1., 1.], [1., 0., 1., 1., 1.], [1., 1., 0., 0., 0.], [1., 1., 1., 1., 1.]]]], device=\u0027cuda:0\u0027))] \uc218\uc815\uc774 \ub418\uc9c0 \uc54a\uc740 \uc0c1\ud0dc\uc5d0\uc11c \uc21c\uc804\ud30c\ub97c \uc9c4\ud589\ud558\uae30 \uc704\ud574\uc11c\ub294 \uac00\uc911\uce58 \uac12 \uc18d\uc131\uc774 \uc874\uc7ac\ud574\uc57c \ud569\ub2c8\ub2e4. torch.nn.utils.prune \ub0b4 \uad6c\ud604\ub41c \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc740 \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc774 \uc801\uc6a9\ub41c \uac00\uc911\uce58\uac12\ub4e4\uc744 \uc774\uc6a9\ud558\uc5ec (\uae30\uc874\uc758 \uac00\uc911\uce58\uac12\uc5d0 \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc774 \uc801\uc6a9\ub41c) \uc21c\uc804\ud30c\ub97c \uc9c4\ud589\ud558\uace0, weight \uc18d\uc131\uac12\uc5d0 \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc774 \uc801\uc6a9\ub41c \uac00\uc911\uce58\uac12\ub4e4\uc744 \uc800\uc7a5\ud569\ub2c8\ub2e4. \uc774\uc81c \uac00\uc911\uce58\uac12\ub4e4\uc740 module \uc758 \ub9e4\uac1c\ubcc0\uc218\uac00 \uc544\ub2c8\ub77c \ud558\ub098\uc758 \uc18d\uc131\uac12\uc73c\ub85c \ucde8\uae09\ub418\ub294 \uc810\uc744 \uc8fc\uc758\ud558\uc138\uc694. print(module.weight) tensor([[[[ 0.0000, -0.0000, -0.0623, -0.0000, 0.0055], [ 0.0314, -0.1857, -0.0000, 0.1223, 0.1689], [-0.0000, -0.0000, 0.0177, 0.0988, 0.0749], [ 0.0634, -0.0000, 0.1766, 0.0000, 0.0219], [-0.0000, -0.0000, -0.0742, 0.1935, -0.1882]]], [[[-0.1891, 0.0554, -0.0000, 0.1154, -0.0000], [ 0.0580, 0.1063, 0.1315, -0.1787, -0.0000], [-0.1216, 0.1807, 0.1527, -0.1806, -0.0789], [-0.0000, -0.1911, -0.0794, 0.0000, 0.0000], [ 0.0427, -0.1558, -0.1073, -0.0000, 0.0211]]], [[[ 0.0116, -0.1011, -0.1792, -0.0166, -0.0000], [-0.1058, -0.0902, -0.0587, 0.0361, -0.0000], [-0.1890, -0.0632, 0.0668, -0.0000, -0.1008], [-0.0702, 0.1404, 0.0000, -0.0000, -0.0000], [-0.0942, -0.0000, -0.1763, 0.0000, -0.0000]]], [[[-0.0958, 0.0936, 0.1754, -0.0000, 0.0009], [-0.1752, -0.1877, 0.1632, -0.0735, 0.1270], [-0.0448, -0.0000, 0.0111, 0.1206, 0.0000], [ 0.0000, -0.1420, 0.1933, -0.1722, -0.1062], [-0.0772, 0.0547, 0.0000, 0.0628, 0.0000]]], [[[ 0.1180, -0.0000, 0.1336, -0.0599, -0.0000], [ 0.1084, 0.1545, -0.0840, -0.1709, -0.0000], [-0.0000, 0.1098, 0.1429, -0.0835, -0.1162], [-0.1901, 0.0091, 0.0000, 0.0753, -0.0684], [ 0.0304, 0.0000, -0.0709, 0.0481, -0.0000]]], [[[ 0.0000, -0.1867, -0.0930, -0.0373, -0.1380], [-0.0196, 0.1388, 0.0000, -0.1948, 0.0013], [ 0.0478, -0.0000, -0.0969, -0.1181, 0.1294], [ 0.0343, -0.0799, -0.0000, -0.0000, -0.0000], [-0.0725, 0.0144, -0.0758, 0.0333, 0.0219]]]], device=\u0027cuda:0\u0027, grad_fn=\u003cMulBackward0\u003e) \ucd5c\uc885\uc801\uc73c\ub85c, \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc740 \ud30c\uc774\ud1a0\uce58\uc758 forward_pre_hooks \ub97c \uc774\uc6a9\ud558\uc5ec \uac01 \uc21c\uc804\ud30c\uac00 \uc9c4\ud589\ub418\uae30 \uc804\uc5d0 \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc774 \uc801\uc6a9\ub429\ub2c8\ub2e4. \uad6c\uccb4\uc801\uc73c\ub85c, \uc9c0\uae08\uae4c\uc9c0 \uc9c4\ud589\ud55c \uac83 \ucc98\ub7fc, \ubaa8\ub4c8\uc774 \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc774 \uc801\uc6a9\ub418\uc5c8\uc744 \ub54c, \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc774 \uc801\uc6a9\ub41c \uac01 \ud30c\ub77c\ubbf8\ud130\uac12\ub4e4\uc774 forward_pre_hook \ub97c \uc5bb\uac8c\ub429\ub2c8\ub2e4. \uc774\ub7ec\ud55c \uacbd\uc6b0, weight \uc774\ub984\uc778 \uae30\uc874 \ud30c\ub77c\ubbf8\ud130\uac12\uc5d0 \ub300\ud574\uc11c\ub9cc \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc744 \uc801\uc6a9\ud558\uc600\uae30 \ub54c\ubb38\uc5d0, \ud6c5\uc740 \uc624\uc9c1 1\uac1c\ub9cc \uc874\uc7ac\ud560 \uac83\uc785\ub2c8\ub2e4. print(module._forward_pre_hooks) OrderedDict([(0, \u003ctorch.nn.utils.prune.RandomUnstructured object at 0x7f0dab246050\u003e)]) \uc644\uacb0\uc131\uc744 \uc704\ud574, \ud3b8\ud5a5\uac12\uc5d0 \ub300\ud574\uc11c\ub3c4 \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc744 \uc801\uc6a9\ud560 \uc218 \uc788\uc73c\uba70, \ubaa8\ub4c8\uc758 \ud30c\ub77c\ubbf8\ud130, \ubc84\ud37c, \ud6c5, \uc18d\uc131\uac12\ub4e4\uc774 \uc5b4\ub5bb\uac8c \ubcc0\uacbd\ub418\ub294\uc9c0 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ub610 \ub2e4\ub978 \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc744 \uc801\uc6a9\ud574\ubcf4\uae30 \uc704\ud574, l1_unstructured \uac00\uc9c0\uce58\uae30 \ud568\uc218\uc5d0\uc11c \uad6c\ud604\ub41c \ub0b4\uc6a9\uacfc \uac19\uc774, L1 Norm \uac12\uc774 \uac00\uc7a5 \uc791\uc740 \ud3b8\ud5a5\uac12 3\uac1c\ub97c \uac00\uc9c0\uce58\uae30\ub97c \uc2dc\ub3c4\ud574\ubd05\uc2dc\ub2e4. prune.l1_unstructured(module, name=\"bias\", amount=3) Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1)) \uc774\uc804\uc5d0\uc11c \uc2e4\uc2b5\ud55c \ub0b4\uc6a9\uc744 \ud1a0\ub300\ub85c, \uba85\uba85\ub41c \ud30c\ub77c\ubbf8\ud130\uac12\ub4e4\uc774 weight_orig, bias_orig 2\uac1c\ub97c \ubaa8\ub450 \ud3ec\ud568\ud560 \uac83\uc774\ub77c \uc608\uc0c1\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ubc84\ud37c\ub4e4\uc740 weight_mask, bias_mask 2\uac1c\ub97c \ud3ec\ud568\ud560 \uac83\uc785\ub2c8\ub2e4. \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc774 \uc801\uc6a9\ub41c 2\uac1c\uc758 \ud150\uc11c\uac12\ub4e4\uc740 \ubaa8\ub4c8\uc758 \uc18d\uc131\uac12\uc73c\ub85c \uc874\uc7ac\ud560 \uac83\uc774\uba70, \ubaa8\ub4c8\uc740 2\uac1c\uc758 forward_pre_hooks \uc744 \uac16\uac8c \ub420 \uac83\uc785\ub2c8\ub2e4. print(list(module.named_parameters())) [(\u0027weight_orig\u0027, Parameter containing: tensor([[[[ 0.1232, -0.0642, -0.0623, -0.1485, 0.0055], [ 0.0314, -0.1857, -0.0403, 0.1223, 0.1689], [-0.0559, -0.1542, 0.0177, 0.0988, 0.0749], [ 0.0634, -0.1869, 0.1766, 0.1120, 0.0219], [-0.1110, -0.0066, -0.0742, 0.1935, -0.1882]]], [[[-0.1891, 0.0554, -0.1982, 0.1154, -0.0523], [ 0.0580, 0.1063, 0.1315, -0.1787, -0.0445], [-0.1216, 0.1807, 0.1527, -0.1806, -0.0789], [-0.0206, -0.1911, -0.0794, 0.1364, 0.0037], [ 0.0427, -0.1558, -0.1073, -0.0763, 0.0211]]], [[[ 0.0116, -0.1011, -0.1792, -0.0166, -0.1940], [-0.1058, -0.0902, -0.0587, 0.0361, -0.0123], [-0.1890, -0.0632, 0.0668, -0.0883, -0.1008], [-0.0702, 0.1404, 0.0646, -0.1084, -0.0797], [-0.0942, -0.0567, -0.1763, 0.0473, -0.1682]]], [[[-0.0958, 0.0936, 0.1754, -0.0095, 0.0009], [-0.1752, -0.1877, 0.1632, -0.0735, 0.1270], [-0.0448, -0.0554, 0.0111, 0.1206, 0.0263], [ 0.1758, -0.1420, 0.1933, -0.1722, -0.1062], [-0.0772, 0.0547, 0.0716, 0.0628, 0.0945]]], [[[ 0.1180, -0.0116, 0.1336, -0.0599, -0.0110], [ 0.1084, 0.1545, -0.0840, -0.1709, -0.0822], [-0.1528, 0.1098, 0.1429, -0.0835, -0.1162], [-0.1901, 0.0091, 0.1081, 0.0753, -0.0684], [ 0.0304, 0.0038, -0.0709, 0.0481, -0.0312]]], [[[ 0.0692, -0.1867, -0.0930, -0.0373, -0.1380], [-0.0196, 0.1388, 0.0801, -0.1948, 0.0013], [ 0.0478, -0.1248, -0.0969, -0.1181, 0.1294], [ 0.0343, -0.0799, -0.0200, -0.1351, -0.0577], [-0.0725, 0.0144, -0.0758, 0.0333, 0.0219]]]], device=\u0027cuda:0\u0027, requires_grad=True)), (\u0027bias_orig\u0027, Parameter containing: tensor([-0.0229, -0.0985, -0.0547, -0.0255, -0.1460, -0.1458], device=\u0027cuda:0\u0027, requires_grad=True))] print(list(module.named_buffers())) [(\u0027weight_mask\u0027, tensor([[[[0., 0., 1., 0., 1.], [1., 1., 0., 1., 1.], [0., 0., 1., 1., 1.], [1., 0., 1., 0., 1.], [0., 0., 1., 1., 1.]]], [[[1., 1., 0., 1., 0.], [1., 1., 1., 1., 0.], [1., 1., 1., 1., 1.], [0., 1., 1., 0., 0.], [1., 1., 1., 0., 1.]]], [[[1., 1., 1., 1., 0.], [1., 1., 1., 1., 0.], [1., 1., 1., 0., 1.], [1., 1., 0., 0., 0.], [1., 0., 1., 0., 0.]]], [[[1., 1., 1., 0., 1.], [1., 1., 1., 1., 1.], [1., 0., 1., 1., 0.], [0., 1., 1., 1., 1.], [1., 1., 0., 1., 0.]]], [[[1., 0., 1., 1., 0.], [1., 1., 1., 1., 0.], [0., 1., 1., 1., 1.], [1., 1., 0., 1., 1.], [1., 0., 1., 1., 0.]]], [[[0., 1., 1., 1., 1.], [1., 1., 0., 1., 1.], [1., 0., 1., 1., 1.], [1., 1., 0., 0., 0.], [1., 1., 1., 1., 1.]]]], device=\u0027cuda:0\u0027)), (\u0027bias_mask\u0027, tensor([0., 1., 0., 0., 1., 1.], device=\u0027cuda:0\u0027))] print(module.bias) tensor([-0.0000, -0.0985, -0.0000, -0.0000, -0.1460, -0.1458], device=\u0027cuda:0\u0027, grad_fn=\u003cMulBackward0\u003e) print(module._forward_pre_hooks) OrderedDict([(0, \u003ctorch.nn.utils.prune.RandomUnstructured object at 0x7f0dab246050\u003e), (1, \u003ctorch.nn.utils.prune.L1Unstructured object at 0x7f0dab183890\u003e)]) \uac00\uc9c0\uce58\uae30 \uae30\ubc95 \ubc18\ubcf5 \uc801\uc6a9# \ubaa8\ub4c8 \ub0b4 \uac19\uc740 \ud30c\ub77c\ubbf8\ud130\uac12\uc5d0 \ub300\ud574 \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc774 \uc5ec\ub7ec\ubc88 \uc801\uc6a9\ub420 \uc218 \uc788\uc73c\uba70, \ub2e4\uc591\ud55c \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc758 \uc870\ud569\uc774 \uc801\uc6a9\ub41c \uac83\uacfc \ub3d9\uc77c\ud558\uac8c \uc801\uc6a9\ub420 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc0c8\ub85c\uc6b4 \ub9c8\uc2a4\ud06c\uc640 \uc774\uc804\uc758 \ub9c8\uc2a4\ud06c\uc758 \uacb0\ud569\uc740 PruningContainer \uc758 compute_mask \uba54\uc18c\ub4dc\ub97c \ud1b5\ud574 \ucc98\ub9ac\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc608\ub97c \ub4e4\uc5b4, \ub9cc\uc57d module.weight \uac12\uc5d0 \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc744 \uc801\uc6a9\ud558\uace0 \uc2f6\uc744 \ub54c, \ud150\uc11c\uc758 0\ubc88\uc9f8 \ucd95\uc758 L2 norm\uac12\uc744 \uae30\uc900\uc73c\ub85c \uad6c\uc870\ud654\ub41c \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc744 \uc801\uc6a9\ud569\ub2c8\ub2e4. (\uc5ec\uae30\uc11c 0\ubc88\uc9f8 \ucd95\uc774\ub780, \ud569\uc131\uacf1 \uc5f0\uc0b0\uc744 \ud1b5\ud574 \uacc4\uc0b0\ub41c \ucd9c\ub825\uac12\uc5d0 \ub300\ud574 \uac01 \ucc44\ub110\ubcc4\ub85c \uc801\uc6a9\ub41c\ub2e4\ub294 \uac83\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4.) \uc774 \ubc29\uc2dd\uc740 ln_structured \ud568\uc218\uc640 n=2 \uc640 dim=0 \uc758 \uc778\uc790\uac12\uc744 \ubc14\ud0d5\uc73c\ub85c \uad6c\ud604\ub420 \uc218 \uc788\uc2b5\ub2c8\ub2e4. prune.ln_structured(module, name=\"weight\", amount=0.5, n=2, dim=0) Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1)) \uc6b0\ub9ac\uac00 \ud655\uc778\ud560 \uc218 \uc788\ub4ef\uc774, \uc774\uc804 \ub9c8\uc2a4\ud06c\uc758 \uc791\uc6a9\uc744 \uc720\uc9c0\ud558\uba74\uc11c \ucc44\ub110\uc758 50% (6\uac1c \uc911 3\uac1c) \uc5d0 \ud574\ub2f9\ub418\ub294 \ubaa8\ub4e0 \uc5f0\uacb0\uc744 0\uc73c\ub85c \ubcc0\uacbd\ud569\ub2c8\ub2e4. print(module.weight) tensor([[[[ 0.0000, -0.0000, -0.0000, -0.0000, 0.0000], [ 0.0000, -0.0000, -0.0000, 0.0000, 0.0000], [-0.0000, -0.0000, 0.0000, 0.0000, 0.0000], [ 0.0000, -0.0000, 0.0000, 0.0000, 0.0000], [-0.0000, -0.0000, -0.0000, 0.0000, -0.0000]]], [[[-0.1891, 0.0554, -0.0000, 0.1154, -0.0000], [ 0.0580, 0.1063, 0.1315, -0.1787, -0.0000], [-0.1216, 0.1807, 0.1527, -0.1806, -0.0789], [-0.0000, -0.1911, -0.0794, 0.0000, 0.0000], [ 0.0427, -0.1558, -0.1073, -0.0000, 0.0211]]], [[[ 0.0000, -0.0000, -0.0000, -0.0000, -0.0000], [-0.0000, -0.0000, -0.0000, 0.0000, -0.0000], [-0.0000, -0.0000, 0.0000, -0.0000, -0.0000], [-0.0000, 0.0000, 0.0000, -0.0000, -0.0000], [-0.0000, -0.0000, -0.0000, 0.0000, -0.0000]]], [[[-0.0958, 0.0936, 0.1754, -0.0000, 0.0009], [-0.1752, -0.1877, 0.1632, -0.0735, 0.1270], [-0.0448, -0.0000, 0.0111, 0.1206, 0.0000], [ 0.0000, -0.1420, 0.1933, -0.1722, -0.1062], [-0.0772, 0.0547, 0.0000, 0.0628, 0.0000]]], [[[ 0.1180, -0.0000, 0.1336, -0.0599, -0.0000], [ 0.1084, 0.1545, -0.0840, -0.1709, -0.0000], [-0.0000, 0.1098, 0.1429, -0.0835, -0.1162], [-0.1901, 0.0091, 0.0000, 0.0753, -0.0684], [ 0.0304, 0.0000, -0.0709, 0.0481, -0.0000]]], [[[ 0.0000, -0.0000, -0.0000, -0.0000, -0.0000], [-0.0000, 0.0000, 0.0000, -0.0000, 0.0000], [ 0.0000, -0.0000, -0.0000, -0.0000, 0.0000], [ 0.0000, -0.0000, -0.0000, -0.0000, -0.0000], [-0.0000, 0.0000, -0.0000, 0.0000, 0.0000]]]], device=\u0027cuda:0\u0027, grad_fn=\u003cMulBackward0\u003e) \uc774\uc5d0 \ud574\ub2f9\ud558\ub294 \ud6c5\uc740 torch.nn.utils.prune.PruningContainer \ud615\ud0dc\ub85c \uc874\uc7ac\ud558\uba70, \uac00\uc911\uce58\uc5d0 \uc801\uc6a9\ub41c \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc758 \uc774\ub825\uc744 \uc800\uc7a5\ud569\ub2c8\ub2e4. for hook in module._forward_pre_hooks.values(): if hook._tensor_name == \"weight\": # \uac00\uc911\uce58\uc5d0 \ud574\ub2f9\ud558\ub294 \ud6c5\uc744 \uc120\ud0dd break print(list(hook)) # \ucee8\ud14c\uc774\ub108 \ub0b4 \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc758 \uc774\ub825 [\u003ctorch.nn.utils.prune.RandomUnstructured object at 0x7f0dab246050\u003e, \u003ctorch.nn.utils.prune.LnStructured object at 0x7f0dab0edd10\u003e] \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc774 \uc801\uc6a9\ub41c \ubaa8\ub378\uc758 \uc9c1\ub82c\ud654# \ub9c8\uc2a4\ud06c \ubc84\ud37c\ub4e4\uacfc \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc774 \uc801\uc6a9\ub41c \ud150\uc11c \uacc4\uc0b0\uc5d0 \uc0ac\uc6a9\ub41c \uae30\uc874\uc758 \ud30c\ub77c\ubbf8\ud130\ub97c \ud3ec\ud568\ud558\uc5ec \uad00\ub828\ub41c \ubaa8\ub4e0 \ud150\uc11c\uac12\ub4e4\uc740 \ud544\uc694\ud55c \uacbd\uc6b0 \ubaa8\ub378\uc758 state_dict \uc5d0 \uc800\uc7a5\ub418\uae30 \ub54c\ubb38\uc5d0, \uc27d\uac8c \uc9c1\ub82c\ud654\ud558\uc5ec \uc800\uc7a5\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. print(model.state_dict().keys()) odict_keys([\u0027conv1.weight_orig\u0027, \u0027conv1.bias_orig\u0027, \u0027conv1.weight_mask\u0027, \u0027conv1.bias_mask\u0027, \u0027conv2.weight\u0027, \u0027conv2.bias\u0027, \u0027fc1.weight\u0027, \u0027fc1.bias\u0027, \u0027fc2.weight\u0027, \u0027fc2.bias\u0027, \u0027fc3.weight\u0027, \u0027fc3.bias\u0027]) \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc758 \uc7ac-\ud30c\ub77c\ubbf8\ud130\ud654 \uc81c\uac70# \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc774 \uc801\uc6a9\ub41c \uac83\uc744 \uc601\uad6c\uc801\uc73c\ub85c \ub9cc\ub4e4\uae30 \uc704\ud574\uc11c, \uc7ac-\ud30c\ub77c\ubbf8\ud130\ud654 \uad00\uc810\uc758 weight_orig \uc640 weight_mask \uac12\uc744 \uc81c\uac70\ud558\uace0, forward_pre_hook \uac12\uc744 \uc81c\uac70\ud569\ub2c8\ub2e4. \uc81c\uac70\ud558\uae30 \uc704\ud574 torch.nn.utils.prune \ub0b4 remove \ud568\uc218\ub97c \uc774\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc774 \uc801\uc6a9\ub418\uc9c0 \uc54a\uc740 \uac83\ucc98\ub7fc \uc2e4\ud589\ub418\ub294 \uac83\uc774 \uc544\ub2cc \uc810\uc744 \uc8fc\uc758\ud558\uc138\uc694. \uc774\ub294 \ub2e8\uc9c0 \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc774 \uc801\uc6a9\ub41c \uc0c1\ud0dc\uc5d0\uc11c \uac00\uc911\uce58 \ud30c\ub77c\ubbf8\ud130\uac12\uc744 \ubaa8\ub378 \ud30c\ub77c\ubbf8\ud130\uac12\uc73c\ub85c \uc7ac\ud560\ub2f9\ud558\ub294 \uac83\uc744 \ud1b5\ud574 \uc601\uad6c\uc801\uc73c\ub85c \ub9cc\ub4dc\ub294 \uac83\uc77c \ubfd0\uc785\ub2c8\ub2e4. \uc7ac-\ud30c\ub77c\ubbf8\ud130\ud654\ub97c \uc81c\uac70\ud558\uae30 \uc804 \uc0c1\ud0dc print(list(module.named_parameters())) [(\u0027weight_orig\u0027, Parameter containing: tensor([[[[ 0.1232, -0.0642, -0.0623, -0.1485, 0.0055], [ 0.0314, -0.1857, -0.0403, 0.1223, 0.1689], [-0.0559, -0.1542, 0.0177, 0.0988, 0.0749], [ 0.0634, -0.1869, 0.1766, 0.1120, 0.0219], [-0.1110, -0.0066, -0.0742, 0.1935, -0.1882]]], [[[-0.1891, 0.0554, -0.1982, 0.1154, -0.0523], [ 0.0580, 0.1063, 0.1315, -0.1787, -0.0445], [-0.1216, 0.1807, 0.1527, -0.1806, -0.0789], [-0.0206, -0.1911, -0.0794, 0.1364, 0.0037], [ 0.0427, -0.1558, -0.1073, -0.0763, 0.0211]]], [[[ 0.0116, -0.1011, -0.1792, -0.0166, -0.1940], [-0.1058, -0.0902, -0.0587, 0.0361, -0.0123], [-0.1890, -0.0632, 0.0668, -0.0883, -0.1008], [-0.0702, 0.1404, 0.0646, -0.1084, -0.0797], [-0.0942, -0.0567, -0.1763, 0.0473, -0.1682]]], [[[-0.0958, 0.0936, 0.1754, -0.0095, 0.0009], [-0.1752, -0.1877, 0.1632, -0.0735, 0.1270], [-0.0448, -0.0554, 0.0111, 0.1206, 0.0263], [ 0.1758, -0.1420, 0.1933, -0.1722, -0.1062], [-0.0772, 0.0547, 0.0716, 0.0628, 0.0945]]], [[[ 0.1180, -0.0116, 0.1336, -0.0599, -0.0110], [ 0.1084, 0.1545, -0.0840, -0.1709, -0.0822], [-0.1528, 0.1098, 0.1429, -0.0835, -0.1162], [-0.1901, 0.0091, 0.1081, 0.0753, -0.0684], [ 0.0304, 0.0038, -0.0709, 0.0481, -0.0312]]], [[[ 0.0692, -0.1867, -0.0930, -0.0373, -0.1380], [-0.0196, 0.1388, 0.0801, -0.1948, 0.0013], [ 0.0478, -0.1248, -0.0969, -0.1181, 0.1294], [ 0.0343, -0.0799, -0.0200, -0.1351, -0.0577], [-0.0725, 0.0144, -0.0758, 0.0333, 0.0219]]]], device=\u0027cuda:0\u0027, requires_grad=True)), (\u0027bias_orig\u0027, Parameter containing: tensor([-0.0229, -0.0985, -0.0547, -0.0255, -0.1460, -0.1458], device=\u0027cuda:0\u0027, requires_grad=True))] print(list(module.named_buffers())) [(\u0027weight_mask\u0027, tensor([[[[0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.]]], [[[1., 1., 0., 1., 0.], [1., 1., 1., 1., 0.], [1., 1., 1., 1., 1.], [0., 1., 1., 0., 0.], [1., 1., 1., 0., 1.]]], [[[0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.]]], [[[1., 1., 1., 0., 1.], [1., 1., 1., 1., 1.], [1., 0., 1., 1., 0.], [0., 1., 1., 1., 1.], [1., 1., 0., 1., 0.]]], [[[1., 0., 1., 1., 0.], [1., 1., 1., 1., 0.], [0., 1., 1., 1., 1.], [1., 1., 0., 1., 1.], [1., 0., 1., 1., 0.]]], [[[0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.]]]], device=\u0027cuda:0\u0027)), (\u0027bias_mask\u0027, tensor([0., 1., 0., 0., 1., 1.], device=\u0027cuda:0\u0027))] print(module.weight) tensor([[[[ 0.0000, -0.0000, -0.0000, -0.0000, 0.0000], [ 0.0000, -0.0000, -0.0000, 0.0000, 0.0000], [-0.0000, -0.0000, 0.0000, 0.0000, 0.0000], [ 0.0000, -0.0000, 0.0000, 0.0000, 0.0000], [-0.0000, -0.0000, -0.0000, 0.0000, -0.0000]]], [[[-0.1891, 0.0554, -0.0000, 0.1154, -0.0000], [ 0.0580, 0.1063, 0.1315, -0.1787, -0.0000], [-0.1216, 0.1807, 0.1527, -0.1806, -0.0789], [-0.0000, -0.1911, -0.0794, 0.0000, 0.0000], [ 0.0427, -0.1558, -0.1073, -0.0000, 0.0211]]], [[[ 0.0000, -0.0000, -0.0000, -0.0000, -0.0000], [-0.0000, -0.0000, -0.0000, 0.0000, -0.0000], [-0.0000, -0.0000, 0.0000, -0.0000, -0.0000], [-0.0000, 0.0000, 0.0000, -0.0000, -0.0000], [-0.0000, -0.0000, -0.0000, 0.0000, -0.0000]]], [[[-0.0958, 0.0936, 0.1754, -0.0000, 0.0009], [-0.1752, -0.1877, 0.1632, -0.0735, 0.1270], [-0.0448, -0.0000, 0.0111, 0.1206, 0.0000], [ 0.0000, -0.1420, 0.1933, -0.1722, -0.1062], [-0.0772, 0.0547, 0.0000, 0.0628, 0.0000]]], [[[ 0.1180, -0.0000, 0.1336, -0.0599, -0.0000], [ 0.1084, 0.1545, -0.0840, -0.1709, -0.0000], [-0.0000, 0.1098, 0.1429, -0.0835, -0.1162], [-0.1901, 0.0091, 0.0000, 0.0753, -0.0684], [ 0.0304, 0.0000, -0.0709, 0.0481, -0.0000]]], [[[ 0.0000, -0.0000, -0.0000, -0.0000, -0.0000], [-0.0000, 0.0000, 0.0000, -0.0000, 0.0000], [ 0.0000, -0.0000, -0.0000, -0.0000, 0.0000], [ 0.0000, -0.0000, -0.0000, -0.0000, -0.0000], [-0.0000, 0.0000, -0.0000, 0.0000, 0.0000]]]], device=\u0027cuda:0\u0027, grad_fn=\u003cMulBackward0\u003e) \uc7ac-\ud30c\ub77c\ubbf8\ud130\ub97c \uc81c\uac70\ud55c \ud6c4 \uc0c1\ud0dc prune.remove(module, \u0027weight\u0027) print(list(module.named_parameters())) [(\u0027bias_orig\u0027, Parameter containing: tensor([-0.0229, -0.0985, -0.0547, -0.0255, -0.1460, -0.1458], device=\u0027cuda:0\u0027, requires_grad=True)), (\u0027weight\u0027, Parameter containing: tensor([[[[ 0.0000, -0.0000, -0.0000, -0.0000, 0.0000], [ 0.0000, -0.0000, -0.0000, 0.0000, 0.0000], [-0.0000, -0.0000, 0.0000, 0.0000, 0.0000], [ 0.0000, -0.0000, 0.0000, 0.0000, 0.0000], [-0.0000, -0.0000, -0.0000, 0.0000, -0.0000]]], [[[-0.1891, 0.0554, -0.0000, 0.1154, -0.0000], [ 0.0580, 0.1063, 0.1315, -0.1787, -0.0000], [-0.1216, 0.1807, 0.1527, -0.1806, -0.0789], [-0.0000, -0.1911, -0.0794, 0.0000, 0.0000], [ 0.0427, -0.1558, -0.1073, -0.0000, 0.0211]]], [[[ 0.0000, -0.0000, -0.0000, -0.0000, -0.0000], [-0.0000, -0.0000, -0.0000, 0.0000, -0.0000], [-0.0000, -0.0000, 0.0000, -0.0000, -0.0000], [-0.0000, 0.0000, 0.0000, -0.0000, -0.0000], [-0.0000, -0.0000, -0.0000, 0.0000, -0.0000]]], [[[-0.0958, 0.0936, 0.1754, -0.0000, 0.0009], [-0.1752, -0.1877, 0.1632, -0.0735, 0.1270], [-0.0448, -0.0000, 0.0111, 0.1206, 0.0000], [ 0.0000, -0.1420, 0.1933, -0.1722, -0.1062], [-0.0772, 0.0547, 0.0000, 0.0628, 0.0000]]], [[[ 0.1180, -0.0000, 0.1336, -0.0599, -0.0000], [ 0.1084, 0.1545, -0.0840, -0.1709, -0.0000], [-0.0000, 0.1098, 0.1429, -0.0835, -0.1162], [-0.1901, 0.0091, 0.0000, 0.0753, -0.0684], [ 0.0304, 0.0000, -0.0709, 0.0481, -0.0000]]], [[[ 0.0000, -0.0000, -0.0000, -0.0000, -0.0000], [-0.0000, 0.0000, 0.0000, -0.0000, 0.0000], [ 0.0000, -0.0000, -0.0000, -0.0000, 0.0000], [ 0.0000, -0.0000, -0.0000, -0.0000, -0.0000], [-0.0000, 0.0000, -0.0000, 0.0000, 0.0000]]]], device=\u0027cuda:0\u0027, requires_grad=True))] print(list(module.named_buffers())) [(\u0027bias_mask\u0027, tensor([0., 1., 0., 0., 1., 1.], device=\u0027cuda:0\u0027))] \ubaa8\ub378 \ub0b4 \uc5ec\ub7ec \ud30c\ub77c\ubbf8\ud130\uac12\ub4e4\uc5d0 \ub300\ud558\uc5ec \uac00\uc9c0\uce58\uae30 \uae30\ubc95 \uc801\uc6a9# \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc744 \uc801\uc6a9\ud558\uace0 \uc2f6\uc740 \ud30c\ub77c\ubbf8\ud130\uac12\ub4e4\uc744 \uc9c0\uc815\ud568\uc73c\ub85c\uc368, \uc774\ubc88 \uc608\uc81c\uc5d0\uc11c \ubcfc \uc218 \uc788\ub294 \uac83 \ucc98\ub7fc, \uc2e0\uacbd\ub9dd \ubaa8\ub378 \ub0b4 \uc5ec\ub7ec \ud150\uc11c\uac12\ub4e4\uc5d0 \ub300\ud574\uc11c \uc27d\uac8c \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc744 \uc801\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. new_model = LeNet() for name, module in new_model.named_modules(): # \ubaa8\ub4e0 2D-conv \uce35\uc758 20% \uc5f0\uacb0\uc5d0 \ub300\ud574 \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc744 \uc801\uc6a9 if isinstance(module, torch.nn.Conv2d): prune.l1_unstructured(module, name=\u0027weight\u0027, amount=0.2) # \ubaa8\ub4e0 \uc120\ud615 \uce35\uc758 40% \uc5f0\uacb0\uc5d0 \ub300\ud574 \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc744 \uc801\uc6a9 elif isinstance(module, torch.nn.Linear): prune.l1_unstructured(module, name=\u0027weight\u0027, amount=0.4) print(dict(new_model.named_buffers()).keys()) # \uc874\uc7ac\ud558\ub294 \ubaa8\ub4e0 \ub9c8\uc2a4\ud06c\ub4e4\uc744 \ud655\uc778 dict_keys([\u0027conv1.weight_mask\u0027, \u0027conv2.weight_mask\u0027, \u0027fc1.weight_mask\u0027, \u0027fc2.weight_mask\u0027, \u0027fc3.weight_mask\u0027]) \uc804\uc5ed \ubc94\uc704\uc5d0 \ub300\ud55c \uac00\uc9c0\uce58\uae30 \uae30\ubc95 \uc801\uc6a9# \uc9c0\uae08\uae4c\uc9c0, \u201c\uc9c0\uc5ed \ubcc0\uc218\u201d \uc5d0 \ub300\ud574\uc11c\ub9cc \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc744 \uc801\uc6a9\ud558\ub294 \ubc29\ubc95\uc744 \uc0b4\ud3b4\ubcf4\uc558\uc2b5\ub2c8\ub2e4. (\uc989, \uac00\uc911\uce58 \uaddc\ubaa8, \ud65c\uc131\ud654 \uc815\ub3c4, \uacbd\uc0ac\uac12 \ub4f1\uc758 \uac01 \ud56d\ubaa9\uc758 \ud1b5\uacc4\ub7c9\uc744 \ubc14\ud0d5\uc73c\ub85c \ubaa8\ub378 \ub0b4 \ud150\uc11c\uac12 \ud558\ub098\uc529 \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc744 \uc801\uc6a9\ud558\ub294 \ubc29\uc2dd) \uadf8\ub7ec\ub098, \ubc94\uc6a9\uc801\uc774\uace0 \uc544\ub9c8 \ub354 \uac15\ub825\ud55c \ubc29\ubc95\uc740 \uac01 \uce35\uc5d0\uc11c \uac00\uc7a5 \ub0ae\uc740 20%\uc758 \uc5f0\uacb0\uc744 \uc81c\uac70\ud558\ub294 \uac83 \ub300\uc2e0\uc5d0, \uc804\uccb4 \ubaa8\ub378\uc5d0 \ub300\ud574\uc11c \uac00\uc7a5 \ub0ae\uc740 20% \uc5f0\uacb0\uc744 \ud55c\ubc88\uc5d0 \uc81c\uac70\ud558\ub294 \uac83\uc785\ub2c8\ub2e4. \uc774\uac83\uc740 \uac01 \uce35\uc5d0 \ub300\ud574\uc11c \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc744 \uc801\uc6a9\ud558\ub294 \uc5f0\uacb0\uc758 \ubc31\ubd84\uc728\uac12\uc744 \ub2e4\ub974\uac8c \ub9cc\ub4e4 \uac00\ub2a5\uc131\uc774 \uc788\uc2b5\ub2c8\ub2e4. torch.nn.utils.prune \ub0b4 global_unstructured \uc744 \uc774\uc6a9\ud558\uc5ec \uc5b4\ub5bb\uac8c \uc804\uc5ed \ubc94\uc704\uc5d0 \ub300\ud55c \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc744 \uc801\uc6a9\ud558\ub294\uc9c0 \uc0b4\ud3b4\ubd05\uc2dc\ub2e4. model = LeNet() parameters_to_prune = ( (model.conv1, \u0027weight\u0027), (model.conv2, \u0027weight\u0027), (model.fc1, \u0027weight\u0027), (model.fc2, \u0027weight\u0027), (model.fc3, \u0027weight\u0027), ) prune.global_unstructured( parameters_to_prune, pruning_method=prune.L1Unstructured, amount=0.2, ) \uc774\uc81c \uac01 \uce35\uc5d0 \uc874\uc7ac\ud558\ub294 \uc5f0\uacb0\ub4e4\uc5d0 \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc774 \uc801\uc6a9\ub41c \uc815\ub3c4\uac00 20%\uac00 \uc544\ub2cc \uac83\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uadf8\ub7ec\ub098, \uc804\uccb4 \uac00\uc9c0\uce58\uae30 \uc801\uc6a9 \ubc94\uc704\ub294 \uc57d 20%\uac00 \ub420 \uac83\uc785\ub2c8\ub2e4. print( \"Sparsity in conv1.weight: {:.2f}%\".format( 100. * float(torch.sum(model.conv1.weight == 0)) / float(model.conv1.weight.nelement()) ) ) print( \"Sparsity in conv2.weight: {:.2f}%\".format( 100. * float(torch.sum(model.conv2.weight == 0)) / float(model.conv2.weight.nelement()) ) ) print( \"Sparsity in fc1.weight: {:.2f}%\".format( 100. * float(torch.sum(model.fc1.weight == 0)) / float(model.fc1.weight.nelement()) ) ) print( \"Sparsity in fc2.weight: {:.2f}%\".format( 100. * float(torch.sum(model.fc2.weight == 0)) / float(model.fc2.weight.nelement()) ) ) print( \"Sparsity in fc3.weight: {:.2f}%\".format( 100. * float(torch.sum(model.fc3.weight == 0)) / float(model.fc3.weight.nelement()) ) ) print( \"Global sparsity: {:.2f}%\".format( 100. * float( torch.sum(model.conv1.weight == 0) + torch.sum(model.conv2.weight == 0) + torch.sum(model.fc1.weight == 0) + torch.sum(model.fc2.weight == 0) + torch.sum(model.fc3.weight == 0) ) / float( model.conv1.weight.nelement() + model.conv2.weight.nelement() + model.fc1.weight.nelement() + model.fc2.weight.nelement() + model.fc3.weight.nelement() ) ) ) Sparsity in conv1.weight: 4.67% Sparsity in conv2.weight: 13.12% Sparsity in fc1.weight: 22.33% Sparsity in fc2.weight: 11.69% Sparsity in fc3.weight: 9.17% Global sparsity: 20.00% torch.nn.utils.prune \uc5d0\uc11c \ud655\uc7a5\ub41c \ub9de\ucda4\ud615 \uac00\uc9c0\uce58\uae30 \uae30\ubc95# \ub9de\ucda4\ud615 \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc740, \ub2e4\ub978 \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc744 \uc801\uc6a9\ud558\ub294 \uac83\uacfc \uac19\uc740 \ubc29\uc2dd\uc73c\ub85c, BasePruningMethod \uc758 \uae30\ubcf8 \ud074\ub798\uc2a4\uc778 nn.utils.prune \ubaa8\ub4c8\uc744 \ud65c\uc6a9\ud558\uc5ec \uad6c\ud604\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uae30\ubcf8 \ud074\ub798\uc2a4\ub294 __call__, apply_mask, apply, prune, remove \uba54\uc18c\ub4dc\ub4e4\uc744 \ub0b4\ud3ec\ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4. \ud2b9\ubcc4\ud55c \ucf00\uc774\uc2a4\uac00 \uc544\ub2cc \uacbd\uc6b0, \uae30\ubcf8\uc801\uc73c\ub85c \uad6c\uc131\ub41c \uba54\uc18c\ub4dc\ub4e4\uc744 \uc7ac\uad6c\uc131\ud560 \ud544\uc694\uac00 \uc5c6\uc2b5\ub2c8\ub2e4. \uadf8\ub7ec\ub098, __init__ (\uad6c\uc131\uc694\uc18c), compute_mask (\uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc758 \ub17c\ub9ac\uc5d0 \ub530\ub77c \uc8fc\uc5b4\uc9c4 \ud150\uc11c\uac12\uc5d0 \ub9c8\uc2a4\ud06c\ub97c \uc801\uc6a9\ud558\ub294 \ubc29\ubc95) \uc744 \uace0\ub824\ud558\uc5ec \uad6c\uc131\ud574\uc57c \ud569\ub2c8\ub2e4. \uac8c\ub2e4\uac00, \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc744 \uc5b4\ub5a0\ud55c \ubc29\uc2dd\uc73c\ub85c \uc801\uc6a9\ud558\ub294\uc9c0 \uba85\ud655\ud558\uac8c \uad6c\uc131\ud574\uc57c \ud569\ub2c8\ub2e4. (\uc9c0\uc6d0\ub418\ub294 \uc635\uc158\uc740 global, structured, unstructured \uc785\ub2c8\ub2e4.) \uc774\ub7ec\ud55c \ubc29\uc2dd\uc740, \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc744 \ubc18\ubcf5\uc801\uc73c\ub85c \uc801\uc6a9\ud574\uc57c \ud558\ub294 \uacbd\uc6b0 \ub9c8\uc2a4\ud06c\ub97c \uacb0\ud569\ud558\ub294 \ubc29\ubc95\uc744 \uacb0\uc815\ud558\uae30 \uc704\ud574 \ud544\uc694\ud569\ub2c8\ub2e4. \uc989, \uc774\ubbf8 \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc774 \uc801\uc6a9\ub41c \ubaa8\ub378\uc5d0 \ub300\ud574\uc11c \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc744 \uc801\uc6a9\ud560 \ub54c, \uae30\uc874\uc758 \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc774 \uc801\uc6a9\ub418\uc9c0 \uc54a\uc740 \ud30c\ub77c\ubbf8\ud130 \uac12\uc5d0 \ub300\ud574 \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc774 \uc601\ud5a5\uc744 \ubbf8\uce60 \uac83\uc73c\ub85c \uc608\uc0c1\ub429\ub2c8\ub2e4. PRUNING_TYPE \uc744 \uc9c0\uc815\ud55c\ub2e4\uba74, \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc744 \uc801\uc6a9\ud558\uae30 \uc704\ud574 \ud30c\ub77c\ubbf8\ud130 \uac12\uc744 \uc62c\ubc14\ub974\uac8c \uc81c\uac70\ud558\ub294 PruningContainer (\ub9c8\uc2a4\ud06c \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc744 \ubc18\ubcf5\uc801\uc73c\ub85c \uc801\uc6a9\ud558\ub294 \uac83\uc744 \ucc98\ub9ac\ud558\ub294)\ub97c \uac00\ub2a5\ud558\uac8c \ud569\ub2c8\ub2e4. \uc608\ub97c \ub4e4\uc5b4, \ub2e4\ub978 \ubaa8\ub4e0 \ud56d\ubaa9\uc774 \uc874\uc7ac\ud558\ub294 \ud150\uc11c\ub97c \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc744 \uad6c\ud604\ud558\uace0 \uc2f6\uc744 \ub54c, (\ub610\ub294, \ud150\uc11c\uac00 \uc774\uc804\uc5d0 \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc5d0 \uc758\ud574 \uc81c\uac70\ub418\uc5c8\uac70\ub098 \ub0a8\uc544\uc788\ub294 \ud150\uc11c\uc5d0 \ub300\ud574) \ud55c \uce35\uc758 \uac1c\ubcc4 \uc5f0\uacb0\uc5d0 \uc791\uc6a9\ud558\uba70 \uc804\uccb4 \uc720\ub2db/\ucc44\ub110 (\u0027structured\u0027), \ub610\ub294 \ub2e4\ub978 \ud30c\ub77c\ubbf8\ud130 \uac04 (\u0027global\u0027) \uc5f0\uacb0\uc5d0\ub294 \uc791\uc6a9\ud558\uc9c0 \uc54a\uae30 \ub54c\ubb38\uc5d0 PRUNING_TYPE=\u0027unstructured\u0027 \ubc29\uc2dd\uc73c\ub85c \uc9c4\ud589\ub429\ub2c8\ub2e4. class FooBarPruningMethod(prune.BasePruningMethod): \"\"\" \ud150\uc11c \ub0b4 \ub2e4\ub978 \ud56d\ubaa9\ub4e4\uc5d0 \ub300\ud574 \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc744 \uc801\uc6a9 \"\"\" PRUNING_TYPE = \u0027unstructured\u0027 def compute_mask(self, t, default_mask): mask = default_mask.clone() mask.view(-1)[::2] = 0 return mask nn.Module \uc758 \ub9e4\uac1c\ubcc0\uc218\uc5d0 \uc801\uc6a9\ud558\uae30 \uc704\ud574 \uc778\uc2a4\ud134\uc2a4\ud654\ud558\uace0 \uc801\uc6a9\ud558\ub294 \uac04\ub2e8\ud55c \uae30\ub2a5\uc744 \uad6c\ud604\ud574\ubd05\ub2c8\ub2e4. def foobar_unstructured(module, name): \"\"\" \ud150\uc11c \ub0b4 \ub2e4\ub978 \ubaa8\ub4e0 \ud56d\ubaa9\ub4e4\uc744 \uc81c\uac70\ud558\uc5ec `module` \uc5d0\uc11c `name` \uc774\ub77c\ub294 \ud30c\ub77c\ubbf8\ud130\uc5d0 \ub300\ud574 \uac00\uc790\uce58\uae30 \uae30\ubc95\uc744 \uc801\uc6a9 \ub2e4\uc74c \ub0b4\uc6a9\uc5d0 \ub530\ub77c \ubaa8\ub4c8\uc744 \uc218\uc815 (\ub610\ub294 \uc218\uc815\ub41c \ubaa8\ub4c8\uc744 \ubc18\ud658): 1) \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc5d0 \uc758\ud574 \ub9e4\uac1c\ubcc0\uc218 `name` \uc5d0 \uc801\uc6a9\ub41c \uc774\uc9c4 \ub9c8\uc2a4\ud06c\uc5d0 \ud574\ub2f9\ud558\ub294 \uba85\uba85\ub41c \ubc84\ud37c `name+\u0027_mask\u0027` \ub97c \ucd94\uac00\ud569\ub2c8\ub2e4. `name` \ud30c\ub77c\ubbf8\ud130\ub294 \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc774 \uc801\uc6a9\ub41c \uac83\uc73c\ub85c \ub300\uccb4\ub418\uba70, \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc774 \uc801\uc6a9\ub418\uc9c0 \uc54a\uc740 \uae30\uc874\uc758 \ud30c\ub77c\ubbf8\ud130\ub294 `name+\u0027_orig\u0027` \ub77c\ub294 \uc774\ub984\uc758 \uc0c8\ub85c\uc6b4 \ub9e4\uac1c\ubcc0\uc218\uc5d0 \uc800\uc7a5\ub429\ub2c8\ub2e4. \uc778\uc790\uac12: module (nn.Module): \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc744 \uc801\uc6a9\ud574\uc57c \ud558\ub294 \ud150\uc11c\ub97c \ud3ec\ud568\ud558\ub294 \ubaa8\ub4c8 name (string): \ubaa8\ub4c8 \ub0b4 \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc774 \uc801\uc6a9\ub420 \ud30c\ub77c\ubbf8\ud130\uc758 \uc774\ub984 \ubc18\ud658\uac12: module (nn.Module): \uc785\ub825 \ubaa8\ub4c8\uc5d0 \ub300\ud574\uc11c \uac00\uc9c0\uce58\uae30 \uae30\ubc95\uc774 \uc801\uc6a9\ub41c \ubaa8\ub4c8 \uc608\uc2dc: \u003e\u003e\u003e m = nn.Linear(3, 4) \u003e\u003e\u003e foobar_unstructured(m, name=\u0027bias\u0027) \"\"\" FooBarPruningMethod.apply(module, name) return module \ud55c\ubc88 \ud574\ubd05\uc2dc\ub2e4! model = LeNet() foobar_unstructured(model.fc3, name=\u0027bias\u0027) print(model.fc3.bias_mask) tensor([0., 1., 0., 1., 0., 1., 0., 1., 0., 1.]) Total running time of the script: (0 minutes 4.590 seconds) Download Jupyter notebook: pruning_tutorial.ipynb Download Python source code: pruning_tutorial.py Download zipped: pruning_tutorial.zip",
       "author": {
         "@type": "Organization",
         "name": "PyTorch Contributors",
         "url": "https://pytorch.org"
       },
       "image": "../_static/img/pytorch_seo.png",
       "mainEntityOfPage": {
         "@type": "WebPage",
         "@id": "/intermediate/pruning_tutorial.html"
       },
       "datePublished": "2023-01-01T00:00:00Z",
       "dateModified": "2023-01-01T00:00:00Z"
     }
 </script>
  <script>
    // Tutorials Call to action event tracking
    $("[data-behavior='call-to-action-event']").on('click', function () {
      fbq('trackCustom', "Download", {
        tutorialTitle: $('h1:first').text(),
        downloadLink: this.href,
        tutorialLink: window.location.href,
        downloadTitle: $(this).attr("data-response")
      });
      if (typeof gtag === 'function') {
        gtag('event', 'click', {
          'event_category': $(this).attr("data-response"),
          'event_label': $("h1").first().text(),
          'tutorial_link': window.location.href
        });
      }
    });
  </script>
  
  </body>
</html>