
<!DOCTYPE html>


<html lang="ko" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <meta property="article:modified_time" content="2024-06-09T15:35:40+00:00" /><meta property="og:title" content="기초부터 시작하는 NLP: Sequence to Sequence 네트워크와 Attention을 이용한 번역" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://tutorials.pytorch.kr/intermediate/seq2seq_translation_tutorial.html" />
<meta property="og:site_name" content="PyTorch Tutorials KR" />
<meta property="og:description" content="Author: Sean Robertson, 번역: 황성수,. 이 튜토리얼은 3부로 구성된 시리즈의 일부입니다: 기초부터 시작하는 NLP: 문자-단위 RNN으로 이름 분류하기, 기초부터 시작하는 NLP: 문자-단위 RNN으로 이름 생성하기, 기초부터 시작하는 NLP: Sequence to Sequence 네트워크와 Attention을 이용한 번역. 이 튜토리얼은 “기초부터 시작하는 NLP”의 세번째이자 마지막 편으로, NLP 모델링 작업을 위한 데이터 전처리에 사용할 자체 클래스와 함수들을 작성해보겠습니다. 이 프로젝트에서는 신..." />
<meta property="og:image" content="https://tutorials.pytorch.kr/_static/logos/logo-kr-sm-dark.png" />
<meta property="og:image:alt" content="PyTorch Tutorials KR" />
<meta name="description" content="Author: Sean Robertson, 번역: 황성수,. 이 튜토리얼은 3부로 구성된 시리즈의 일부입니다: 기초부터 시작하는 NLP: 문자-단위 RNN으로 이름 분류하기, 기초부터 시작하는 NLP: 문자-단위 RNN으로 이름 생성하기, 기초부터 시작하는 NLP: Sequence to Sequence 네트워크와 Attention을 이용한 번역. 이 튜토리얼은 “기초부터 시작하는 NLP”의 세번째이자 마지막 편으로, NLP 모델링 작업을 위한 데이터 전처리에 사용할 자체 클래스와 함수들을 작성해보겠습니다. 이 프로젝트에서는 신..." />
<meta property="og:ignore_canonical" content="true" />

    <title>기초부터 시작하는 NLP: Sequence to Sequence 네트워크와 Attention을 이용한 번역 &#8212; 파이토치 한국어 튜토리얼 (PyTorch tutorials in Korean)</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=536c50fe" />
    <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=4d2595e5" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/katex-math.css?v=91adb8b6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/pytorch_theme.css?v=c326296f" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css?v=097efa9c" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom2.css?v=b169ea90" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=725a5b95"></script>
    <script src="../_static/doctools.js?v=92e14aea"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/translations.js?v=b5f768d8"></script>
    <script src="../_static/katex.min.js?v=be8ff15f"></script>
    <script src="../_static/auto-render.min.js?v=ad136472"></script>
    <script src="../_static/katex_autorenderer.js?v=bebc588a"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'intermediate/seq2seq_translation_tutorial';</script>
    <link rel="canonical" href="https://tutorials.pytorch.kr/intermediate/seq2seq_translation_tutorial.html" />
    <link rel="icon" href="../_static/favicon.ico"/>
    <link rel="index" title="색인" href="../genindex.html" />
    <link rel="search" title="검색" href="../search.html" />

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="ko"/>
    <meta name="docbuild:last-update" content="2024년 06월 09일"/>
<script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/2.3.1/list.min.js"></script>
<script>
  if (window.location.hostname === 'docs.pytorch.org' || window.location.hostname === 'docs-preview.pytorch.org') {
    const script = document.createElement('script');
    script.src = 'https://cmp.osano.com/16A0DbT9yDNIaQkvZ/31b1b91a-e0b6-47ea-bde2-7f2bd13dbe5c/osano.js?variant=one';
    document.head.appendChild(script);
  }
</script>
<script>
  // Cookie banner for non-LF projects
  document.addEventListener('DOMContentLoaded', function () {
    // Hide cookie banner on local environments and LF owned docs
    if (window.location.hostname === 'localhost' ||
      window.location.hostname === '0.0.0.0' ||
      window.location.hostname === '127.0.0.1' ||
      window.location.hostname === 'docs.pytorch.org' ||
      window.location.hostname === 'docs-preview.pytorch.org' ||
      window.location.hostname.startsWith('192.168.')) {
      const banner = document.querySelector('.cookie-banner-wrapper');
      if (banner) {
        banner.style.display = 'none';
      }
    }
  });
</script>
<!-- Conditional CSS for header and footer height adjustment -->

<link rel="stylesheet" type="text/css" href="../_static/css/theme.css" crossorigin="anonymous">
<script type="text/javascript" src="../_static/js/theme.js"></script>
<script type="text/javascript" src="../_static/js/dropdown-menu.js"></script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Nanum+Gothic:wght@400;700&family=Nanum+Gothic+Coding:wght@400;700&family=Montserrat:wght@300;400&display=swap" rel="stylesheet">
<meta property="og:image" content="../_static/img/pytorch_seo.png" />
<link rel="stylesheet" href="../_static/webfonts/all.min.css" crossorigin="anonymous">
<meta http-equiv="Content-Security-Policy"
  content="default-src * 'unsafe-inline' 'unsafe-eval' data: blob:; style-src * 'unsafe-inline'; script-src * 'unsafe-inline' 'unsafe-eval' blob:;">
<meta name="pytorch_project" content="tutorials">
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=G-LZRD6GXDLF" height="0" width="0"
    style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
<!-- Google Tag Manager -->
<script>(function (w, d, s, l, i) {
    w[l] = w[l] || []; w[l].push({
      'gtm.start':
        new Date().getTime(), event: 'gtm.js'
    }); var f = d.getElementsByTagName(s)[0],
      j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : ''; j.async = true; j.src =
        'https://www.googletagmanager.com/gtm.js?id=' + i + dl; f.parentNode.insertBefore(j, f);
    j.onload = function () {
      window.dispatchEvent(new Event('gtm_loaded'));
      console.log('GTM loaded successfully');
    };
  })(window, document, 'script', 'dataLayer', 'G-LZRD6GXDLF');
</script>
<!-- End Google Tag Manager -->
<!-- Facebook Pixel Code -->
<script>
  !function (f, b, e, v, n, t, s) {
    if (f.fbq) return; n = f.fbq = function () {
      n.callMethod ?
        n.callMethod.apply(n, arguments) : n.queue.push(arguments)
    };
    if (!f._fbq) f._fbq = n; n.push = n; n.loaded = !0; n.version = '2.0';
    n.queue = []; t = b.createElement(e); t.async = !0;
    t.src = v; s = b.getElementsByTagName(e)[0];
    s.parentNode.insertBefore(t, s)
  }(window, document, 'script',
    'https://connect.facebook.net/en_US/fbevents.js');
  fbq('init', '243028289693773');
  fbq('track', 'PageView');
</script>
<script>
  document.documentElement.setAttribute('data-version', 'v2.8.0+cu128');
</script>
<noscript>
  <img height="1" width="1" src="https://www.facebook.com/tr?id=243028289693773&ev=PageView&noscript=1" />
</noscript>
<script>
  function gtag() {
    window.dataLayer.push(arguments);
  }
</script>
<!-- End Facebook Pixel Code -->
<!-- Script to Fix scrolling -->
<script>
  document.addEventListener('DOMContentLoaded', function () {
    // Fix anchor scrolling
    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener('click', function (e) {
        e.preventDefault();
        const targetId = this.getAttribute('href').substring(1);
        const targetElement = document.getElementById(targetId);

        if (targetElement) {
          const headerHeight =
            (document.querySelector('.header-holder') ? document.querySelector('.header-holder').offsetHeight : 0) +
            (document.querySelector('.bd-header') ? document.querySelector('.bd-header').offsetHeight : 0) + 20;

          const targetPosition = targetElement.getBoundingClientRect().top + window.pageYOffset - headerHeight;
          window.scrollTo({
            top: targetPosition,
            behavior: 'smooth'
          });

          // Update URL hash without scrolling
          history.pushState(null, null, '#' + targetId);
        }
      });
    });
  });
</script>

<script async src="https://cse.google.com/cse.js?cx=e65585f8c3ea1440e"></script>


  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="ko"/>
    <meta name="docbuild:last-update" content="2024년 06월 09일"/>

  </head>

<body data-feedback-url="https://github.com/PyTorchKorea/tutorials-kr" class="pytorch-body">
  
    <div class="container-fluid header-holder tutorials-header" id="header-holder">
   <div class="header-container-wrapper">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.kr/" aria-label="PyTorchKR"></a>

      <div class="main-menu">
        <ul>

          <li class="main-menu-item">
          <div id="learnDropdownButton" data-toggle="learn-dropdown" class="learn-dropdown">
              <a class="with-down-arrow">
                <span>배우기</span>
              </a>
              <div class="learn-dropdown-menu dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.kr/get-started/locally/">
                  <span class="dropdown-title">PyTorch 시작하기</span>
                </a>
                <a class="nav-dropdown-item" href="https://tutorials.pytorch.kr/beginner/basics/intro.html">
                  <span class="dropdown-title">기본 익히기</span>
                </a>
                <a class="nav-dropdown-item" href="https://tutorials.pytorch.kr/" target="_self">
                  <span class="dropdown-title">한국어 튜토리얼</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.kr/hub/">
                  <span class="dropdown-title">한국어 모델 허브</span>
                </a>
                <a class="nav-dropdown-item" href="https://docs.pytorch.org/tutorials/" target="_blank">
                  <span class="dropdown-title">Official Tutorials</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <a href="https://pytorch.kr/blog/">
              <span>블로그</span>
            </a>
          </li>

          <li class="main-menu-item">
          <div id="docsDropdownButton" data-toggle="docs-dropdown" class="docs-dropdown">
              <a class="with-down-arrow">
              <span>문서</span>
              </a>
              <div class="docs-dropdown-menu dropdown-menu">
                <a class="nav-dropdown-item" href="https://docs.pytorch.org/docs/" target="_blank">
                  <span class="dropdown-title">PyTorch API</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.kr/domains/">
                  <span class="dropdown-title">Domain API 소개</span>
                </a>
                <a class="nav-dropdown-item" href="https://tutorials.pytorch.kr/" target="_self">
                  <span class="dropdown-title">한국어 튜토리얼</span>
                </a>
                <a class="nav-dropdown-item" href="https://docs.pytorch.org/tutorials/" target="_blank">
                  <span class="dropdown-title">Official Tutorials</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
          <div id="communityDropdownButton" data-toggle="community-dropdown" class="community-dropdown">
              <a class="with-down-arrow">
              <span>커뮤니티</span>
              </a>
              <div class="community-dropdown-menu dropdown-menu">
                <a class="nav-dropdown-item" href="https://discuss.pytorch.kr/" target="_self">
                  <span class="dropdown-title">한국어 커뮤니티</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.kr/resources/">
                  <span class="dropdown-title">개발자 정보</span>
                </a>
                <a class="nav-dropdown-item" href="https://landscape.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Landscape</span>
                </a>
              </div>
            </div>
          </li>

        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu">
        <i class="fa-solid fa-ellipsis"></i>
      </a>
    </div>
  </div>
 </div>

 <!-- Begin Mobile Menu -->

<div class="mobile-main-menu">
  <div class="container-fluid">
    <div class="header-container-wrapper">
      <div class="mobile-main-menu-header-container">
        <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu">
          <i class="fa-solid fa-xmark"></i>
        </a>
      </div>
    </div>
  </div>

  <div class="mobile-main-menu-links-container">
    <div class="main-menu">
      <ul>
         <li class="resources-mobile-menu-title">
           <a>배우기</a>
         </li>
         <ul class="resources-mobile-menu-items">
           <li>
             <a href="https://pytorch.kr/get-started/locally/">PyTorch 시작하기</a>
           </li>
           <li>
             <a href="https://tutorials.pytorch.kr/beginner/basics/intro.html">기본 익히기</a>
           </li>
           <li>
             <a href="https://tutorials.pytorch.kr/">한국어 튜토리얼</a>
           </li>
           <li>
             <a href="https://pytorch.kr/hub/">한국어 모델 허브</a>
           </li>
           <li>
             <a href="https://docs.pytorch.org/tutorials/" target="_blank">Official Tutorials</a>
           </li>
        </ul>
         <li class="resources-mobile-menu-title">
           <a href="https://pytorch.kr/blog/">블로그</a>
         </li>
         <li class="resources-mobile-menu-title">
           <a>문서</a>
         </li>
         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://docs.pytorch.org/docs/" target="_blank">PyTorch API</a>
          </li>
          <li>
            <a href="https://pytorch.kr/domains/">Domain API 소개</a>
          </li>
          <li>
            <a href="https://tutorials.pytorch.kr/">한국어 튜토리얼</a>
          </li>
          <li>
            <a href="https://docs.pytorch.org/tutorials/" target="_blank">Official Tutorials</a>
          </li>
        </ul>
        <li class="resources-mobile-menu-title">
          <a>커뮤니티</a>
        </li>
         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://discuss.pytorch.kr/">한국어 커뮤니티</a>
          </li>
          <li>
            <a href="https://pytorch.kr/resources/">개발자 정보</a>
          </li>
          <li>
            <a href="https://landscape.pytorch.org/" target="_blank">Landscape</a>
          </li>
        </ul>
      </ul>
    </div>
  </div>
</div>

<!-- End Mobile Menu -->
  
  
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">
  <a href="../index.html" class="version">v2.8.0+cu128</a>
</div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../intro.html">
    Intro
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../compilers_index.html">
    Compilers
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../domains.html">
    Domains
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../distributed.html">
    Distributed
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../deep-dive.html">
    Deep Dive
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../extension.html">
    Extension
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../ecosystem.html">
    Ecosystem
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../recipes_index.html">
    Recipes
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
      
        <div class="navbar-item">
<div class="search-container-wrapper">
  <div id="sphinx-search" class="search-container">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </div>

  <div id="google-search" class="search-container" style="display:none;">
    <div class="gcse-search-wrapper">
      <i class="fa-solid fa-magnifying-glass" aria-hidden="true"></i>
      <div class="gcse-search"></div>
    </div>
  </div>

  <div class="search-toggle-container" data-bs-title="Google Search Off" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <div class="search-toggle-inner">
      <label class="switch">
        <input type="checkbox" id="search-toggle">
        <span class="slider round"></span>
      </label>
    </div>
  </div>
</div>

<script>
  document.addEventListener('DOMContentLoaded', function() {
  // Define the search callback
  const myWebSearchStartingCallback = (gname, query) => {
    if (typeof dataLayer !== 'undefined' && query) {
      window.dataLayer = window.dataLayer || [];
      dataLayer.push({
        'event': 'google_search',
        'search_term': query,
        'event_category': 'Search',
        'event_label': 'Google Search'
      });
    }
    return '';
  };

  // Set up the GCSE search callbacks
  window.__gcse || (window.__gcse = {});
  window.__gcse.searchCallbacks = {
    web: { starting: myWebSearchStartingCallback }
  };

  if (window.location.pathname.includes('/search.html')) {
    document.body.classList.add('search-page');
  }

  // Function to reinitialize Google CSE
  function reinitializeGoogleSearch() {
    if (window.__gcse && window.__gcse.initializationCallback) {
      window.__gcse.initializationCallback();
    }
  }

  // Function to handle search toggle
  function handleSearchToggle(toggle, sphinxSearch, googleSearch) {
    if (!toggle || !sphinxSearch || !googleSearch) return;

    // Check if the URL contains /stable/ or /tutorials/
    const currentUrl = window.location.href;
    // TODO: We've had reports that the google programmable search is returning stale documentation,
    //       Simple reproduction is to turn google search on and search for multinomial which will
    //       result in returning 1.8.1 documentation.
    //       We should turn this back on when we resolve that bug.
    const shouldDefaultToGoogle = false;
    const savedPreference = localStorage.getItem('searchPreference');

    // Set initial state
    if (savedPreference === 'google' || (savedPreference === null && shouldDefaultToGoogle)) {
      toggle.checked = true;
      sphinxSearch.style.display = 'none';
      googleSearch.style.display = 'block';
      if (savedPreference === null) {
        localStorage.setItem('searchPreference', 'google');
      }
      reinitializeGoogleSearch();
    } else {
      toggle.checked = false;
      sphinxSearch.style.display = 'block';
      googleSearch.style.display = 'none';
    }

    // Update tooltip
    updateTooltip(toggle.checked);

    // Skip if already initialized
    if (toggle.hasAttribute('data-initialized')) return;
    toggle.setAttribute('data-initialized', 'true');

    toggle.addEventListener('change', function() {
      if (this.checked) {
        sphinxSearch.style.display = 'none';
        googleSearch.style.display = 'block';
        localStorage.setItem('searchPreference', 'google');
        reinitializeGoogleSearch();
        trackSearchEngineSwitch('Google');
      } else {
        sphinxSearch.style.display = 'block';
        googleSearch.style.display = 'none';
        localStorage.setItem('searchPreference', 'sphinx');
        trackSearchEngineSwitch('Sphinx');
      }

      updateTooltip(this.checked);
      updateMobileSearch();
    });
  }

  // Update tooltip based on toggle state
  function updateTooltip(isChecked) {
    const tooltipElement = document.querySelector('.search-toggle-container');
    if (!tooltipElement) return;

    tooltipElement.setAttribute('data-bs-title', isChecked ? 'Google Search On' : 'Google Search Off');

    if (bootstrap && bootstrap.Tooltip) {
      const tooltipInstance = bootstrap.Tooltip.getInstance(tooltipElement);
      if (tooltipInstance) tooltipInstance.dispose();
      new bootstrap.Tooltip(tooltipElement);
    }
  }

  // Track search engine switch
  function trackSearchEngineSwitch(engine) {
    if (typeof dataLayer !== 'undefined') {
      window.dataLayer = window.dataLayer || [];
      dataLayer.push({
        'event': 'search_engine_switch',
        'event_category': 'Search',
        'event_label': engine
      });
    }
  }

  // Function to update mobile search based on current toggle state
  function updateMobileSearch() {
    const toggle = document.getElementById('search-toggle');
    if (!toggle) return;

    const mobileSearchContainer = document.querySelector('.sidebar-header-items__end .navbar-item .search-container-wrapper');
    if (!mobileSearchContainer) return;

    const mobileSphinxSearch = mobileSearchContainer.querySelector('#sphinx-search');
    const mobileGoogleSearch = mobileSearchContainer.querySelector('#google-search');

    if (mobileSphinxSearch && mobileGoogleSearch) {
      mobileSphinxSearch.style.display = toggle.checked ? 'none' : 'block';
      mobileGoogleSearch.style.display = toggle.checked ? 'block' : 'none';

      if (toggle.checked) {
        reinitializeGoogleSearch();
      }
    }
  }

  // Initialize desktop search toggle
  const toggle = document.getElementById('search-toggle');
  const sphinxSearch = document.getElementById('sphinx-search');
  const googleSearch = document.getElementById('google-search');
  handleSearchToggle(toggle, sphinxSearch, googleSearch);

  // Set placeholder text for Google search input
  const observer = new MutationObserver(function() {
    document.querySelectorAll('.gsc-input input').forEach(input => {
      if (input && !input.hasAttribute('data-placeholder-set')) {
        input.setAttribute('placeholder', 'Search the docs ...');
        input.setAttribute('data-placeholder-set', 'true');
      }
    });
  });

  observer.observe(document.body, { childList: true, subtree: true });

  // Fix for scroll jump issue - improved approach
  function setupSearchInputHandlers(input) {
    if (input.hasAttribute('data-scroll-fixed')) return;
    input.setAttribute('data-scroll-fixed', 'true');

    let lastScrollPosition = 0;
    let isTyping = false;
    let scrollTimeout;

    // Save position before typing starts
    input.addEventListener('keydown', () => {
      lastScrollPosition = window.scrollY;
      isTyping = true;

      // Reset typing state after a short delay
      clearTimeout(scrollTimeout);
      scrollTimeout = setTimeout(() => {
        isTyping = false;
      }, 100);
    });

    // Only maintain scroll position during typing
    function maintainScroll() {
      if (document.activeElement === input && isTyping) {
        window.scrollTo(0, lastScrollPosition);
        requestAnimationFrame(maintainScroll);
      }
    }

    input.addEventListener('focus', () => {
      // Just store initial position but don't force it
      lastScrollPosition = window.scrollY;
    });

    input.addEventListener('input', () => {
      isTyping = true;
      window.scrollTo(0, lastScrollPosition);

      // Reset typing state after a short delay
      clearTimeout(scrollTimeout);
      scrollTimeout = setTimeout(() => {
        isTyping = false;
      }, 100);

      requestAnimationFrame(maintainScroll);
    });
  }

  // Apply to all search inputs and observe for new ones
  function applyToSearchInputs() {
    document.querySelectorAll('.search-container input, .gsc-input input').forEach(setupSearchInputHandlers);
  }

  applyToSearchInputs();

  const searchObserver = new MutationObserver(applyToSearchInputs);
  searchObserver.observe(document.body, { childList: true, subtree: true });

  // Watch for mobile menu creation
  const mobileMenuObserver = new MutationObserver(function(mutations) {
    for (const mutation of mutations) {
      if (!mutation.addedNodes.length) continue;

      // Style mobile search inputs
      document.querySelectorAll('.sidebar-header-items__end .navbar-item .search-container-wrapper .gsc-input input').forEach(input => {
        if (input) {
          input.setAttribute('placeholder', 'Search the docs ...');
          input.style.paddingLeft = '36px';
        }
      });

      // Check for mobile search container
      const mobileSearchContainer = document.querySelector('.sidebar-header-items__end .navbar-item .search-container-wrapper');
      if (!mobileSearchContainer) continue;

      const mobileToggle = mobileSearchContainer.querySelector('#search-toggle');
      if (mobileToggle && toggle) {
        // Sync mobile toggle with desktop toggle
        mobileToggle.checked = toggle.checked;
        updateMobileSearch();

        // Add event listener to mobile toggle if not already added
        if (!mobileToggle.hasAttribute('data-initialized')) {
          mobileToggle.setAttribute('data-initialized', 'true');
          mobileToggle.addEventListener('change', function() {
            // Sync desktop toggle with mobile toggle
            toggle.checked = this.checked;
            // Trigger change event on desktop toggle to update both
            toggle.dispatchEvent(new Event('change'));
          });
        }
      }
    }
  });

  mobileMenuObserver.observe(document.body, { childList: true, subtree: true });

  // Ensure Google CSE is properly loaded
  if (window.__gcse) {
    window.__gcse.callback = function() {
      // This will run after Google CSE is fully loaded
      if (toggle && toggle.checked) {
        reinitializeGoogleSearch();
      }
    };
  } else {
    window.__gcse = {
      callback: function() {
        if (toggle && toggle.checked) {
          reinitializeGoogleSearch();
        }
      }
    };
  }
});
</script>
</div>
      
        <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/PyTorchKorea/tutorials-kr" title="한국어 튜토리얼 GitHub 저장소" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">한국어 튜토리얼 GitHub 저장소</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discuss.pytorch.kr/" title="파이토치 한국어 커뮤니티" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">파이토치 한국어 커뮤니티</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <div class="bd-sidebar-primary bd-sidebar hide-on-wide">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../intro.html">
    Intro
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../compilers_index.html">
    Compilers
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../domains.html">
    Domains
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../distributed.html">
    Distributed
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../deep-dive.html">
    Deep Dive
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../extension.html">
    Extension
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../ecosystem.html">
    Ecosystem
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../recipes_index.html">
    Recipes
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
<div class="search-container-wrapper">
  <div id="sphinx-search" class="search-container">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </div>

  <div id="google-search" class="search-container" style="display:none;">
    <div class="gcse-search-wrapper">
      <i class="fa-solid fa-magnifying-glass" aria-hidden="true"></i>
      <div class="gcse-search"></div>
    </div>
  </div>

  <div class="search-toggle-container" data-bs-title="Google Search Off" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <div class="search-toggle-inner">
      <label class="switch">
        <input type="checkbox" id="search-toggle">
        <span class="slider round"></span>
      </label>
    </div>
  </div>
</div>

<script>
  document.addEventListener('DOMContentLoaded', function() {
  // Define the search callback
  const myWebSearchStartingCallback = (gname, query) => {
    if (typeof dataLayer !== 'undefined' && query) {
      window.dataLayer = window.dataLayer || [];
      dataLayer.push({
        'event': 'google_search',
        'search_term': query,
        'event_category': 'Search',
        'event_label': 'Google Search'
      });
    }
    return '';
  };

  // Set up the GCSE search callbacks
  window.__gcse || (window.__gcse = {});
  window.__gcse.searchCallbacks = {
    web: { starting: myWebSearchStartingCallback }
  };

  if (window.location.pathname.includes('/search.html')) {
    document.body.classList.add('search-page');
  }

  // Function to reinitialize Google CSE
  function reinitializeGoogleSearch() {
    if (window.__gcse && window.__gcse.initializationCallback) {
      window.__gcse.initializationCallback();
    }
  }

  // Function to handle search toggle
  function handleSearchToggle(toggle, sphinxSearch, googleSearch) {
    if (!toggle || !sphinxSearch || !googleSearch) return;

    // Check if the URL contains /stable/ or /tutorials/
    const currentUrl = window.location.href;
    // TODO: We've had reports that the google programmable search is returning stale documentation,
    //       Simple reproduction is to turn google search on and search for multinomial which will
    //       result in returning 1.8.1 documentation.
    //       We should turn this back on when we resolve that bug.
    const shouldDefaultToGoogle = false;
    const savedPreference = localStorage.getItem('searchPreference');

    // Set initial state
    if (savedPreference === 'google' || (savedPreference === null && shouldDefaultToGoogle)) {
      toggle.checked = true;
      sphinxSearch.style.display = 'none';
      googleSearch.style.display = 'block';
      if (savedPreference === null) {
        localStorage.setItem('searchPreference', 'google');
      }
      reinitializeGoogleSearch();
    } else {
      toggle.checked = false;
      sphinxSearch.style.display = 'block';
      googleSearch.style.display = 'none';
    }

    // Update tooltip
    updateTooltip(toggle.checked);

    // Skip if already initialized
    if (toggle.hasAttribute('data-initialized')) return;
    toggle.setAttribute('data-initialized', 'true');

    toggle.addEventListener('change', function() {
      if (this.checked) {
        sphinxSearch.style.display = 'none';
        googleSearch.style.display = 'block';
        localStorage.setItem('searchPreference', 'google');
        reinitializeGoogleSearch();
        trackSearchEngineSwitch('Google');
      } else {
        sphinxSearch.style.display = 'block';
        googleSearch.style.display = 'none';
        localStorage.setItem('searchPreference', 'sphinx');
        trackSearchEngineSwitch('Sphinx');
      }

      updateTooltip(this.checked);
      updateMobileSearch();
    });
  }

  // Update tooltip based on toggle state
  function updateTooltip(isChecked) {
    const tooltipElement = document.querySelector('.search-toggle-container');
    if (!tooltipElement) return;

    tooltipElement.setAttribute('data-bs-title', isChecked ? 'Google Search On' : 'Google Search Off');

    if (bootstrap && bootstrap.Tooltip) {
      const tooltipInstance = bootstrap.Tooltip.getInstance(tooltipElement);
      if (tooltipInstance) tooltipInstance.dispose();
      new bootstrap.Tooltip(tooltipElement);
    }
  }

  // Track search engine switch
  function trackSearchEngineSwitch(engine) {
    if (typeof dataLayer !== 'undefined') {
      window.dataLayer = window.dataLayer || [];
      dataLayer.push({
        'event': 'search_engine_switch',
        'event_category': 'Search',
        'event_label': engine
      });
    }
  }

  // Function to update mobile search based on current toggle state
  function updateMobileSearch() {
    const toggle = document.getElementById('search-toggle');
    if (!toggle) return;

    const mobileSearchContainer = document.querySelector('.sidebar-header-items__end .navbar-item .search-container-wrapper');
    if (!mobileSearchContainer) return;

    const mobileSphinxSearch = mobileSearchContainer.querySelector('#sphinx-search');
    const mobileGoogleSearch = mobileSearchContainer.querySelector('#google-search');

    if (mobileSphinxSearch && mobileGoogleSearch) {
      mobileSphinxSearch.style.display = toggle.checked ? 'none' : 'block';
      mobileGoogleSearch.style.display = toggle.checked ? 'block' : 'none';

      if (toggle.checked) {
        reinitializeGoogleSearch();
      }
    }
  }

  // Initialize desktop search toggle
  const toggle = document.getElementById('search-toggle');
  const sphinxSearch = document.getElementById('sphinx-search');
  const googleSearch = document.getElementById('google-search');
  handleSearchToggle(toggle, sphinxSearch, googleSearch);

  // Set placeholder text for Google search input
  const observer = new MutationObserver(function() {
    document.querySelectorAll('.gsc-input input').forEach(input => {
      if (input && !input.hasAttribute('data-placeholder-set')) {
        input.setAttribute('placeholder', 'Search the docs ...');
        input.setAttribute('data-placeholder-set', 'true');
      }
    });
  });

  observer.observe(document.body, { childList: true, subtree: true });

  // Fix for scroll jump issue - improved approach
  function setupSearchInputHandlers(input) {
    if (input.hasAttribute('data-scroll-fixed')) return;
    input.setAttribute('data-scroll-fixed', 'true');

    let lastScrollPosition = 0;
    let isTyping = false;
    let scrollTimeout;

    // Save position before typing starts
    input.addEventListener('keydown', () => {
      lastScrollPosition = window.scrollY;
      isTyping = true;

      // Reset typing state after a short delay
      clearTimeout(scrollTimeout);
      scrollTimeout = setTimeout(() => {
        isTyping = false;
      }, 100);
    });

    // Only maintain scroll position during typing
    function maintainScroll() {
      if (document.activeElement === input && isTyping) {
        window.scrollTo(0, lastScrollPosition);
        requestAnimationFrame(maintainScroll);
      }
    }

    input.addEventListener('focus', () => {
      // Just store initial position but don't force it
      lastScrollPosition = window.scrollY;
    });

    input.addEventListener('input', () => {
      isTyping = true;
      window.scrollTo(0, lastScrollPosition);

      // Reset typing state after a short delay
      clearTimeout(scrollTimeout);
      scrollTimeout = setTimeout(() => {
        isTyping = false;
      }, 100);

      requestAnimationFrame(maintainScroll);
    });
  }

  // Apply to all search inputs and observe for new ones
  function applyToSearchInputs() {
    document.querySelectorAll('.search-container input, .gsc-input input').forEach(setupSearchInputHandlers);
  }

  applyToSearchInputs();

  const searchObserver = new MutationObserver(applyToSearchInputs);
  searchObserver.observe(document.body, { childList: true, subtree: true });

  // Watch for mobile menu creation
  const mobileMenuObserver = new MutationObserver(function(mutations) {
    for (const mutation of mutations) {
      if (!mutation.addedNodes.length) continue;

      // Style mobile search inputs
      document.querySelectorAll('.sidebar-header-items__end .navbar-item .search-container-wrapper .gsc-input input').forEach(input => {
        if (input) {
          input.setAttribute('placeholder', 'Search the docs ...');
          input.style.paddingLeft = '36px';
        }
      });

      // Check for mobile search container
      const mobileSearchContainer = document.querySelector('.sidebar-header-items__end .navbar-item .search-container-wrapper');
      if (!mobileSearchContainer) continue;

      const mobileToggle = mobileSearchContainer.querySelector('#search-toggle');
      if (mobileToggle && toggle) {
        // Sync mobile toggle with desktop toggle
        mobileToggle.checked = toggle.checked;
        updateMobileSearch();

        // Add event listener to mobile toggle if not already added
        if (!mobileToggle.hasAttribute('data-initialized')) {
          mobileToggle.setAttribute('data-initialized', 'true');
          mobileToggle.addEventListener('change', function() {
            // Sync desktop toggle with mobile toggle
            toggle.checked = this.checked;
            // Trigger change event on desktop toggle to update both
            toggle.dispatchEvent(new Event('change'));
          });
        }
      }
    }
  });

  mobileMenuObserver.observe(document.body, { childList: true, subtree: true });

  // Ensure Google CSE is properly loaded
  if (window.__gcse) {
    window.__gcse.callback = function() {
      // This will run after Google CSE is fully loaded
      if (toggle && toggle.checked) {
        reinitializeGoogleSearch();
      }
    };
  } else {
    window.__gcse = {
      callback: function() {
        if (toggle && toggle.checked) {
          reinitializeGoogleSearch();
        }
      }
    };
  }
});
</script>
</div>
        
          <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/PyTorchKorea/tutorials-kr" title="한국어 튜토리얼 GitHub 저장소" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">한국어 튜토리얼 GitHub 저장소</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discuss.pytorch.kr/" title="파이토치 한국어 커뮤니티" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">파이토치 한국어 커뮤니티</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    <li class="breadcrumb-item active" aria-current="page">기초부터 시작하는...</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
        
    </div>
</div>
</div>
      
    </div>
  
</div>
</div>
              
              
  
<div id="searchbox"></div>
  <article class="bd-article" id="pytorch-article">
    <!-- Hidden breadcrumb schema for SEO only -->
    <div style="display:none;" itemscope itemtype="https://schema.org/BreadcrumbList">
      
      <div itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <meta itemprop="name" content="기초부터 시작하는 NLP: Sequence to Sequence 네트워크와 Attention을 이용한 번역">
        <meta itemprop="position" content="1">
      </div>
    </div>

    
    <script>
      if ((window.location.href.indexOf("/unstable/") != -1) && (window.location.href.indexOf("/unstable/unstable_index") < 1)) {
        var div = '<div class="prototype-banner"><i class="fa fa-flask" aria-hidden="true"></i> <strong>Unstable feature:</strong> Not typically available in binary distributions like PyPI. Early stage for feedback and testing.</div>'
        document.addEventListener('DOMContentLoaded', function () {
          document.getElementById("pytorch-article").insertAdjacentHTML('afterBegin', div);
        });
      }
    </script>
    
    
    <div class="pytorch-call-to-action-links">
      <div id="tutorial-type">intermediate/seq2seq_translation_tutorial</div>
      <a id="colab-link" data-behavior="call-to-action-event" data-response="Run in Google Colab" target="_blank">
        <div id="google-colab-link">
          <img class="call-to-action-img" src="../_static/img/pytorch-colab.svg" />
          <div class="call-to-action-desktop-view">Run in Google Colab</div>
          <div class="call-to-action-mobile-view">Colab</div>
        </div>
      </a>
      <a id="notebook-link" data-behavior="call-to-action-event" data-response="Download Notebook">
        <div id="download-notebook-link">
          <img class="call-to-action-notebook-img" src="../_static/img/pytorch-download.svg" />
          <div class="call-to-action-desktop-view">Download Notebook</div>
          <div class="call-to-action-mobile-view">Notebook</div>
        </div>
      </a>
      <a id="github-link" data-behavior="call-to-action-event" data-response="View on Github" target="_blank">
        <div id="github-view-link">
          <img class="call-to-action-img" src="../_static/img/pytorch-github.svg" />
          <div class="call-to-action-desktop-view">View on GitHub</div>
          <div class="call-to-action-mobile-view">GitHub</div>
        </div>
      </a>
    </div>
    

    
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">참고</p>
<p><a class="reference internal" href="#sphx-glr-download-intermediate-seq2seq-translation-tutorial-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code.</p>
</div>
<section class="sphx-glr-example-title" id="nlp-sequence-to-sequence-attention">
<span id="sphx-glr-intermediate-seq2seq-translation-tutorial-py"></span><h1>기초부터 시작하는 NLP: Sequence to Sequence 네트워크와 Attention을 이용한 번역<a class="headerlink" href="#nlp-sequence-to-sequence-attention" title="Link to this heading">#</a></h1>
<dl class="simple">
<dt><strong>Author</strong>: <a class="reference external" href="https://github.com/spro">Sean Robertson</a></dt><dd><p><strong>번역</strong>: <a class="reference external" href="https://github.com/adonisues">황성수</a></p>
</dd>
</dl>
<p>이 튜토리얼은 3부로 구성된 시리즈의 일부입니다:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://tutorials.pytorch.kr/intermediate/char_rnn_classification_tutorial.html">기초부터 시작하는 NLP: 문자-단위 RNN으로 이름 분류하기</a></p></li>
<li><p><a class="reference external" href="https://tutorials.pytorch.kr/intermediate/char_rnn_generation_tutorial.html">기초부터 시작하는 NLP: 문자-단위 RNN으로 이름 생성하기</a></p></li>
<li><p><a class="reference external" href="https://tutorials.pytorch.kr/intermediate/seq2seq_translation_tutorial.html">기초부터 시작하는 NLP: Sequence to Sequence 네트워크와 Attention을 이용한 번역</a></p></li>
</ul>
<p>이 튜토리얼은 “기초부터 시작하는 NLP”의 세번째이자 마지막 편으로, NLP 모델링 작업을
위한 데이터 전처리에 사용할 자체 클래스와 함수들을 작성해보겠습니다.</p>
<p>이 프로젝트에서는 신경망이 불어를 영어로 번역하도록 가르칠 예정입니다.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="o">[</span>KEY:<span class="w"> </span>&gt;<span class="w"> </span>input,<span class="w"> </span><span class="o">=</span><span class="w"> </span>target,<span class="w"> </span>&lt;<span class="w"> </span>output<span class="o">]</span>

&gt;<span class="w"> </span>il<span class="w"> </span>est<span class="w"> </span>en<span class="w"> </span>train<span class="w"> </span>de<span class="w"> </span>peindre<span class="w"> </span>un<span class="w"> </span>tableau<span class="w"> </span>.
<span class="o">=</span><span class="w"> </span>he<span class="w"> </span>is<span class="w"> </span>painting<span class="w"> </span>a<span class="w"> </span>picture<span class="w"> </span>.
&lt;<span class="w"> </span>he<span class="w"> </span>is<span class="w"> </span>painting<span class="w"> </span>a<span class="w"> </span>picture<span class="w"> </span>.

&gt;<span class="w"> </span>pourquoi<span class="w"> </span>ne<span class="w"> </span>pas<span class="w"> </span>essayer<span class="w"> </span>ce<span class="w"> </span>vin<span class="w"> </span>delicieux<span class="w"> </span>?
<span class="o">=</span><span class="w"> </span>why<span class="w"> </span>not<span class="w"> </span>try<span class="w"> </span>that<span class="w"> </span>delicious<span class="w"> </span>wine<span class="w"> </span>?
&lt;<span class="w"> </span>why<span class="w"> </span>not<span class="w"> </span>try<span class="w"> </span>that<span class="w"> </span>delicious<span class="w"> </span>wine<span class="w"> </span>?

&gt;<span class="w"> </span>elle<span class="w"> </span>n<span class="w"> </span>est<span class="w"> </span>pas<span class="w"> </span>poete<span class="w"> </span>mais<span class="w"> </span>romanciere<span class="w"> </span>.
<span class="o">=</span><span class="w"> </span>she<span class="w"> </span>is<span class="w"> </span>not<span class="w"> </span>a<span class="w"> </span>poet<span class="w"> </span>but<span class="w"> </span>a<span class="w"> </span>novelist<span class="w"> </span>.
&lt;<span class="w"> </span>she<span class="w"> </span>not<span class="w"> </span>not<span class="w"> </span>a<span class="w"> </span>poet<span class="w"> </span>but<span class="w"> </span>a<span class="w"> </span>novelist<span class="w"> </span>.

&gt;<span class="w"> </span>vous<span class="w"> </span>etes<span class="w"> </span>trop<span class="w"> </span>maigre<span class="w"> </span>.
<span class="o">=</span><span class="w"> </span>you<span class="w"> </span>re<span class="w"> </span>too<span class="w"> </span>skinny<span class="w"> </span>.
&lt;<span class="w"> </span>you<span class="w"> </span>re<span class="w"> </span>all<span class="w"> </span>alone<span class="w"> </span>.
</pre></div>
</div>
<p>… 성공율은 달라질 수 있습니다.</p>
<p>하나의 시퀀스를 다른 시퀀스로 바꾸는 두 개의 RNN이 함께 동작하는
<a class="reference external" href="https://arxiv.org/abs/1409.3215">sequence to sequence network</a> 의 간단하지만 강력한 아이디어가
이것(번역)을 가능하게 합니다. 인코더 네트워크는 입력 시퀀스를 벡터로 압축하고,
디코더 네트워크는 해당 벡터를 새로운 시퀀스로 펼칩니다.</p>
<figure class="align-default">
<img alt="" src="../_images/seq2seq.png" />
</figure>
<p>이 모델을 개선하기 위해 <a class="reference external" href="https://arxiv.org/abs/1409.0473">Attention Mechanism</a> 을
사용하면 디코더가 입력 시퀀스의 특정 범위에 집중할 수 있도록 합니다.</p>
<p><strong>추천 자료:</strong></p>
<p>최소한 Pytorch를 설치했고, Python을 알고, Tensor를 이해한다고 가정합니다.:</p>
<ul class="simple">
<li><p><a class="reference external" href="http://pytorch.org/">http://pytorch.org/</a> 설치 안내를 위한 자료</p></li>
<li><p><a class="reference internal" href="../beginner/deep_learning_60min_blitz.html"><span class="doc">PyTorch로 딥러닝하기: 60분만에 끝장내기</span></a> 일반적인 PyTorch 시작을 위한 자료</p></li>
<li><p><a class="reference internal" href="../beginner/pytorch_with_examples.html"><span class="doc">예제로 배우는 파이토치(PyTorch)</span></a> 넓고 깊은 통찰을 위한 자료</p></li>
<li><p><a class="reference internal" href="../beginner/former_torchies_tutorial.html"><span class="doc">Torch 사용자를 위한 PyTorch</span></a> 이전 Lua Torch 사용자를 위한 자료</p></li>
</ul>
<p>Sequence to Sequence 네트워크와 동작 방법에 관해서 아는 것은 유용합니다:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://arxiv.org/abs/1406.1078">Learning Phrase Representations using RNN Encoder-Decoder for
Statistical Machine Translation</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1409.3215">Sequence to Sequence Learning with Neural
Networks</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1409.0473">Neural Machine Translation by Jointly Learning to Align and
Translate</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1506.05869">A Neural Conversational Model</a></p></li>
</ul>
<p>이전 튜토리얼에 있는
<a class="reference internal" href="char_rnn_classification_tutorial.html"><span class="doc">기초부터 시작하는 NLP: 문자-단위 RNN으로 이름 분류하기</span></a>
와 <a class="reference internal" href="char_rnn_generation_tutorial.html"><span class="doc">기초부터 시작하는 NLP: 문자-단위 RNN으로 이름 생성하기</span></a> 는
각각 인코더, 디코더 모델과 비슷한 컨센을 가지기 때문에 도움이 됩니다.</p>
<p><strong>요구 사항</strong></p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">__future__</span><span class="w"> </span><span class="kn">import</span> <span class="n">unicode_literals</span><span class="p">,</span> <span class="n">print_function</span><span class="p">,</span> <span class="n">division</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">io</span><span class="w"> </span><span class="kn">import</span> <span class="nb">open</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">unicodedata</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">re</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">random</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">optim</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">TensorDataset</span><span class="p">,</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">RandomSampler</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
</pre></div>
</div>
<section id="id2">
<h2>데이터 파일 불러오기<a class="headerlink" href="#id2" title="Link to this heading">#</a></h2>
<p>이 프로젝트의 데이터는 수천 개의 영어-프랑스어 번역 쌍입니다.</p>
<p><a class="reference external" href="https://opendata.stackexchange.com/questions/3888/dataset-of-sentences-translated-into-many-languages">Open Data Stack Exchange</a>
에 관한 이 질문은 <a class="reference external" href="https://tatoeba.org/eng/downloads">https://tatoeba.org/eng/downloads</a> 에서 다운 로드가 가능한
공개 번역 사이트 <a class="reference external" href="https://tatoeba.org/">https://tatoeba.org/</a> 를 알려 주었습니다. 더 나은 방법으로
언어 쌍을 개별 텍스트 파일로 분할하는 추가 작업을 수행한
<a class="reference external" href="https://www.manythings.org/anki/">https://www.manythings.org/anki/</a> 가 있습니다:</p>
<p>영어-프랑스어 쌍이 너무 커서 저장소에 포함 할 수 없기 때문에
계속하기 전에 <code class="docutils literal notranslate"><span class="pre">data/eng-fra.txt</span></code> 로 다운로드하십시오.
이 파일은 탭으로 구분된 번역 쌍 목록입니다:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>I<span class="w"> </span>am<span class="w"> </span>cold.<span class="w">    </span>J<span class="err">&#39;</span>ai<span class="w"> </span>froid.
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">참고</p>
<p><a class="reference external" href="https://download.pytorch.org/tutorial/data.zip">여기</a>
에서 데이터를 다운 받고 현재 디렉토리에 압축을 푸십시오.</p>
</div>
<p>문자 단위 RNN 튜토리얼에서 사용된 문자 인코딩과 유사하게, 언어의 각
단어들을 One-Hot 벡터 또는 그 단어의 주소에만 단 하나의 1을 제외하고
모두 0인 큰 벡터로 표현합니다. 한 가지 언어에 있는 수십 개의 문자와
달리 번역에는 아주 많은 단어들이 있기 때문에 인코딩 벡터는 매우 더 큽니다.
그러나 우리는 약간의 트릭를 써서 언어 당 수천 단어 만
사용하도록 데이터를 다듬을 것입니다.</p>
<figure class="align-default">
<img alt="" src="../_images/word-encoding.png" />
</figure>
<p>나중에 네트워크의 입력 및 목표로 사용하려면 단어 당 고유 번호가
필요합니다. 이 모든 것을 추적하기 위해 우리는
단어→색인(<code class="docutils literal notranslate"><span class="pre">word2index</span></code>)과 색인→단어(<code class="docutils literal notranslate"><span class="pre">index2word</span></code>) 사전,
그리고 나중에 희귀 단어를 대체하는데 사용할 각 단어의 빈도
<code class="docutils literal notranslate"><span class="pre">word2count</span></code> 를 가진 <code class="docutils literal notranslate"><span class="pre">Lang</span></code> 이라는 헬퍼 클래스를 사용합니다.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">SOS_token</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">EOS_token</span> <span class="o">=</span> <span class="mi">1</span>


<span class="k">class</span><span class="w"> </span><span class="nc">Lang</span><span class="p">:</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">word2index</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">word2count</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">index2word</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="s2">&quot;SOS&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span> <span class="s2">&quot;EOS&quot;</span><span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_words</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># SOS 와 EOS 포함</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">addSentence</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sentence</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">addWord</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">addWord</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">word</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">word2index</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">word2index</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_words</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">word2count</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">index2word</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">n_words</span><span class="p">]</span> <span class="o">=</span> <span class="n">word</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_words</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">word2count</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
</pre></div>
</div>
<p>파일은 모두 유니 코드로 되어있어 간단하게 하기 위해 유니 코드 문자를
ASCII로 변환하고, 모든 문자를 소문자로 만들고, 대부분의 구두점을
지워줍니다.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 유니 코드 문자열을 일반 ASCII로 변환하십시오.</span>
<span class="c1"># https://stackoverflow.com/a/518232/2809427</span>
<span class="k">def</span><span class="w"> </span><span class="nf">unicodeToAscii</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
    <span class="k">return</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
        <span class="n">c</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">unicodedata</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="s1">&#39;NFD&#39;</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">unicodedata</span><span class="o">.</span><span class="n">category</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="o">!=</span> <span class="s1">&#39;Mn&#39;</span>
    <span class="p">)</span>

<span class="c1"># 소문자, 다듬기, 그리고 문자가 아닌 문자 제거</span>
<span class="k">def</span><span class="w"> </span><span class="nf">normalizeString</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">unicodeToAscii</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;([.!?])&quot;</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot; \1&quot;</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;[^a-zA-Z!?]+&quot;</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">s</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
</pre></div>
</div>
<p>To read the data file we will split the file into lines, and then split
lines into pairs. The files are all English → Other Language, so if we
want to translate from Other Language → English I added the <code class="docutils literal notranslate"><span class="pre">reverse</span></code>
flag to reverse the pairs.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">readLangs</span><span class="p">(</span><span class="n">lang1</span><span class="p">,</span> <span class="n">lang2</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Reading lines...&quot;</span><span class="p">)</span>

    <span class="c1"># 파일을 읽고 줄로 분리</span>
    <span class="n">lines</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;data/</span><span class="si">%s</span><span class="s1">-</span><span class="si">%s</span><span class="s1">.txt&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">lang1</span><span class="p">,</span> <span class="n">lang2</span><span class="p">),</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span><span class="o">.</span>\
        <span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="c1"># 모든 줄을 쌍으로 분리하고 정규화</span>
    <span class="n">pairs</span> <span class="o">=</span> <span class="p">[[</span><span class="n">normalizeString</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">l</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">)]</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">]</span>

    <span class="c1"># 쌍을 뒤집고, Lang 인스턴스 생성</span>
    <span class="k">if</span> <span class="n">reverse</span><span class="p">:</span>
        <span class="n">pairs</span> <span class="o">=</span> <span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="nb">reversed</span><span class="p">(</span><span class="n">p</span><span class="p">))</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">pairs</span><span class="p">]</span>
        <span class="n">input_lang</span> <span class="o">=</span> <span class="n">Lang</span><span class="p">(</span><span class="n">lang2</span><span class="p">)</span>
        <span class="n">output_lang</span> <span class="o">=</span> <span class="n">Lang</span><span class="p">(</span><span class="n">lang1</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">input_lang</span> <span class="o">=</span> <span class="n">Lang</span><span class="p">(</span><span class="n">lang1</span><span class="p">)</span>
        <span class="n">output_lang</span> <span class="o">=</span> <span class="n">Lang</span><span class="p">(</span><span class="n">lang2</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">,</span> <span class="n">pairs</span>
</pre></div>
</div>
<p><em>많은</em> 예제 문장이 있고 신속하게 학습하기를 원하기 때문에
비교적 짧고 간단한 문장으로만 데이터 셋을 정리할 것입니다. 여기서
최대 길이는 10 단어 (종료 문장 부호 포함)이며 “I am” 또는
“He is” 등의 형태로 번역되는 문장으로 필터링됩니다.(이전에
아포스트로피는 대체 됨)</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">MAX_LENGTH</span> <span class="o">=</span> <span class="mi">10</span>

<span class="n">eng_prefixes</span> <span class="o">=</span> <span class="p">(</span>
    <span class="s2">&quot;i am &quot;</span><span class="p">,</span> <span class="s2">&quot;i m &quot;</span><span class="p">,</span>
    <span class="s2">&quot;he is&quot;</span><span class="p">,</span> <span class="s2">&quot;he s &quot;</span><span class="p">,</span>
    <span class="s2">&quot;she is&quot;</span><span class="p">,</span> <span class="s2">&quot;she s &quot;</span><span class="p">,</span>
    <span class="s2">&quot;you are&quot;</span><span class="p">,</span> <span class="s2">&quot;you re &quot;</span><span class="p">,</span>
    <span class="s2">&quot;we are&quot;</span><span class="p">,</span> <span class="s2">&quot;we re &quot;</span><span class="p">,</span>
    <span class="s2">&quot;they are&quot;</span><span class="p">,</span> <span class="s2">&quot;they re &quot;</span>
<span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">filterPair</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">))</span> <span class="o">&lt;</span> <span class="n">MAX_LENGTH</span> <span class="ow">and</span> \
        <span class="nb">len</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">))</span> <span class="o">&lt;</span> <span class="n">MAX_LENGTH</span> <span class="ow">and</span> \
        <span class="n">p</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">eng_prefixes</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">filterPairs</span><span class="p">(</span><span class="n">pairs</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">pair</span> <span class="k">for</span> <span class="n">pair</span> <span class="ow">in</span> <span class="n">pairs</span> <span class="k">if</span> <span class="n">filterPair</span><span class="p">(</span><span class="n">pair</span><span class="p">)]</span>
</pre></div>
</div>
<p>데이터 준비를 위한 전체 과정:</p>
<ul class="simple">
<li><p>텍스트 파일을 읽고 줄로 분리하고, 줄을 쌍으로 분리합니다.</p></li>
<li><p>텍스트를 정규화 하고 길이와 내용으로 필터링 합니다.</p></li>
<li><p>쌍을 이룬 문장들로 단어 리스트를 생성합니다.</p></li>
</ul>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">prepareData</span><span class="p">(</span><span class="n">lang1</span><span class="p">,</span> <span class="n">lang2</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">,</span> <span class="n">pairs</span> <span class="o">=</span> <span class="n">readLangs</span><span class="p">(</span><span class="n">lang1</span><span class="p">,</span> <span class="n">lang2</span><span class="p">,</span> <span class="n">reverse</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Read </span><span class="si">%s</span><span class="s2"> sentence pairs&quot;</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">pairs</span><span class="p">))</span>
    <span class="n">pairs</span> <span class="o">=</span> <span class="n">filterPairs</span><span class="p">(</span><span class="n">pairs</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Trimmed to </span><span class="si">%s</span><span class="s2"> sentence pairs&quot;</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">pairs</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Counting words...&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">pair</span> <span class="ow">in</span> <span class="n">pairs</span><span class="p">:</span>
        <span class="n">input_lang</span><span class="o">.</span><span class="n">addSentence</span><span class="p">(</span><span class="n">pair</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">output_lang</span><span class="o">.</span><span class="n">addSentence</span><span class="p">(</span><span class="n">pair</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Counted words:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">input_lang</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">input_lang</span><span class="o">.</span><span class="n">n_words</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">output_lang</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">output_lang</span><span class="o">.</span><span class="n">n_words</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">,</span> <span class="n">pairs</span>


<span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">,</span> <span class="n">pairs</span> <span class="o">=</span> <span class="n">prepareData</span><span class="p">(</span><span class="s1">&#39;eng&#39;</span><span class="p">,</span> <span class="s1">&#39;fra&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">pairs</span><span class="p">))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Reading lines...
Read 135842 sentence pairs
Trimmed to 11445 sentence pairs
Counting words...
Counted words:
fra 4601
eng 2991
[&#39;elle vient de france&#39;, &#39;she is from france&#39;]
</pre></div>
</div>
</section>
<section id="seq2seq">
<h2>Seq2Seq 모델<a class="headerlink" href="#seq2seq" title="Link to this heading">#</a></h2>
<p>Recurrent Neural Network(RNN)는 시퀀스에서 작동하고 다음 단계의
입력으로 자신의 출력을 사용하는 네트워크입니다.</p>
<p><a class="reference external" href="https://arxiv.org/abs/1409.3215">Sequence to Sequence network</a>, 또는
Seq2Seq 네트워크, 또는 <a class="reference external" href="https://arxiv.org/pdf/1406.1078v3.pdf">Encoder Decoder
network</a> 는 인코더 및
디코더라고 하는 두 개의 RNN으로 구성된 모델입니다.
인코더는 입력 시퀀스를 읽고 단일 벡터를 출력하고,
디코더는 해당 벡터를 읽어 출력 시퀀스를 생성합니다.</p>
<figure class="align-default">
<img alt="" src="../_images/seq2seq.png" />
</figure>
<p>모든 입력에 해당하는 출력이 있는 단일 RNN의 시퀀스 예측과 달리
Seq2Seq 모델은 시퀀스 길이와 순서를 자유롭게하기 때문에
두 언어 사이의 번역에 이상적입니다.</p>
<p>다음 문장 <code class="docutils literal notranslate"><span class="pre">Je</span> <span class="pre">ne</span> <span class="pre">suis</span> <span class="pre">pas</span> <span class="pre">le</span> <span class="pre">chat</span> <span class="pre">noir</span></code> → <code class="docutils literal notranslate"><span class="pre">I</span> <span class="pre">am</span> <span class="pre">not</span> <span class="pre">the</span> <span class="pre">black</span> <span class="pre">cat</span></code>
를 살펴 봅시다. 입력 문장의 단어 대부분은 출력 문장에서
직역(<code class="docutils literal notranslate"><span class="pre">chat</span> <span class="pre">noir</span></code> 와 <code class="docutils literal notranslate"><span class="pre">black</span> <span class="pre">cat</span></code>)되지만 약간 다른 순서도 있습니다.
<code class="docutils literal notranslate"><span class="pre">ne/pas</span></code> 구조로 인해 입력 문장에 단어가 하나 더 있습니다.
입력 단어의 시퀀스를 직역해서 정확한 번역을 만드는
것은 어려울 것입니다.</p>
<p>Seq2Seq 모델을 사용하면 인코더는 하나의 벡터를 생성합니다.
이상적인 경우에 입력 시퀀스의 “의미”를 문장의 N 차원 공간에 있는
단일 지점인 단일 벡터으로 인코딩합니다.</p>
<section id="id4">
<h3>인코더<a class="headerlink" href="#id4" title="Link to this heading">#</a></h3>
<p>Seq2Seq 네트워크의 인코더는 입력 문장의 모든 단어에 대해 어떤 값을
출력하는 RNN입니다. 모든 입력 단어에 대해 인코더는 벡터와
은닉 상태를 출력하고 다음 입력 단어를 위해 그 은닉 상태를 사용합니다.</p>
<figure class="align-default">
<img alt="" src="../_images/encoder-network.png" />
</figure>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">EncoderRNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">dropout_p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">EncoderRNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gru</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_p</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
        <span class="n">embedded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="nb">input</span><span class="p">))</span>
        <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gru</span><span class="p">(</span><span class="n">embedded</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span>
</pre></div>
</div>
</section>
<section id="id5">
<h3>디코더<a class="headerlink" href="#id5" title="Link to this heading">#</a></h3>
<p>디코더는 인코더 출력 벡터를 받아서 번역을 생성하기 위한 단어 시퀀스를
출력합니다.</p>
<section id="id6">
<h4>간단한 디코더<a class="headerlink" href="#id6" title="Link to this heading">#</a></h4>
<p>가장 간단한 Seq2Seq 디코더는 인코더의 마지막 출력만을 이용합니다.
이 마지막 출력은 전체 시퀀스에서 문맥을 인코드하기 때문에
<em>문맥 벡터(context vector)</em> 로 불립니다. 이 문맥 벡터는 디코더의 초기 은닉 상태로
사용 됩니다.</p>
<p>디코딩의 매 단계에서 디코더에게 입력 토큰과 은닉 상태가 주어집니다.
초기 입력 토큰은 문자열-시작 (start-of-string) <code class="docutils literal notranslate"><span class="pre">&lt;SOS&gt;</span></code> 토큰이고,
첫 은닉 상태는 문맥 벡터(인코더의 마지막 은닉 상태) 입니다.</p>
<figure class="align-default">
<img alt="" src="../_images/decoder-network.png" />
</figure>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">DecoderRNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DecoderRNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">output_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gru</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">encoder_hidden</span><span class="p">,</span> <span class="n">target_tensor</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">encoder_outputs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">decoder_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="n">SOS_token</span><span class="p">)</span>
        <span class="n">decoder_hidden</span> <span class="o">=</span> <span class="n">encoder_hidden</span>
        <span class="n">decoder_outputs</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">MAX_LENGTH</span><span class="p">):</span>
            <span class="n">decoder_output</span><span class="p">,</span> <span class="n">decoder_hidden</span>  <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward_step</span><span class="p">(</span><span class="n">decoder_input</span><span class="p">,</span> <span class="n">decoder_hidden</span><span class="p">)</span>
            <span class="n">decoder_outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">decoder_output</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">target_tensor</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># Teacher forcing 포함: 목표를 다음 입력으로 전달</span>
                <span class="n">decoder_input</span> <span class="o">=</span> <span class="n">target_tensor</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># Teacher forcing</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Teacher forcing 미포함: 자신의 예측을 다음 입력으로 사용</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">topi</span> <span class="o">=</span> <span class="n">decoder_output</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">decoder_input</span> <span class="o">=</span> <span class="n">topi</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>  <span class="c1"># 입력으로 사용할 부분을 히스토리에서 분리</span>

        <span class="n">decoder_outputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">decoder_outputs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">decoder_outputs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">decoder_outputs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">decoder_outputs</span><span class="p">,</span> <span class="n">decoder_hidden</span><span class="p">,</span> <span class="kc">None</span>   <span class="c1"># 학습 루프의 일관성 유지를 위해 `None` 을 추가로 반환</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">hidden</span><span class="p">):</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gru</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span>
</pre></div>
</div>
<p>이 모델의 결과를 학습하고 관찰하는 것을 권장하지만,
공간을 절약하기 위해 최종 목적지로 바로 이동해서
Attention 메커니즘을 소개 할 것입니다.</p>
</section>
<section id="attention">
<h4>Attention 디코더<a class="headerlink" href="#attention" title="Link to this heading">#</a></h4>
<p>문맥 벡터만 인코더와 디코더 사이로 전달 된다면, 단일 벡터가 전체 문장을
인코딩 해야하는 부담을 가지게 됩니다.</p>
<p>Attention은 디코더 네트워크가 자기 출력의 모든 단계에서 인코더 출력의
다른 부분에 “집중” 할 수 있게 합니다. 첫째 <em>Attention 가중치</em> 의 세트를
계산합니다. 이것은 가중치 조합을 만들기 위해서 인코더 출력 벡터와
곱해집니다. 그 결과(코드에서 <code class="docutils literal notranslate"><span class="pre">attn_applied</span></code>)는 입력 시퀀스의
특정 부분에 관한 정보를 포함해야하고 따라서 디코더가 알맞은 출력
단어를 선택하는 것을 도와줍니다.</p>
<figure class="align-default">
<img alt="" src="https://i.imgur.com/1152PYf.png" />
</figure>
<p>어텐션 가중치 계산은 디코더의 입력 및 은닉 상태를 입력으로
사용하는 다른 feed-forwad 계층인 <code class="docutils literal notranslate"><span class="pre">attn</span></code> 으로 수행됩니다.
학습 데이터에는 모든 크기의 문장이 있기 때문에 이 계층을 실제로
만들고 학습시키려면 적용 할 수 있는 최대 문장 길이 (인코더 출력을 위한 입력 길이)를
선택해야 합니다. 최대 길이의 문장은 모든 Attention 가중치를 사용하지만
더 짧은 문장은 처음 몇 개만 사용합니다.</p>
<figure class="align-default">
<img alt="" src="../_images/attention-decoder-network.png" />
</figure>
<p>부가적 어텐션(Additive Attention)이라고도 알려진 바다나우 어텐션(Bahdanau
Attention)은 기계 번역 작업과 같은 시퀀스-투-시퀀스 모델에서 일반적으로
사용하는 어텐션 기법(mechanism)입니다. 이 어텐션 기법은 Bahdanau et al.의 논문인
<a class="reference external" href="https://arxiv.org/pdf/1409.0473.pdf">Neural Machine Translation by Jointly Learning to Align and Translate</a>
에서 소개되었습니다. 이 어텐션 기법은 학습된 정렬 모델(learned alignment model)을
사용하여 인코더와 디코더의 은닉 상태(hidden state) 간의 어텐션 점수를 계산합니다.
이는 정렬된 어텐션 점수를 계산하기 위해 feed-forward 신경망을 사용합니다.</p>
<p>또는, 디코더의 은닉 상태와 인코더의 은닉 상태 사이의 어텐션 점수를 Dot-Product로
계산하는 루옹 어텐션(Luong Attention)과 같은 다른 어텐션 기법들을 사용할 수도 있습니다.
이는 바다나우 어텐션(Bahdanau Attention)에서 사용하는 비선형 변환(non-linear transformation)을
사용하지는 않습니다.</p>
<p>이 튜토리얼에서는 바다나우 어텐션(Bahdanau Attention)을 사용할 것입니다. 하지만 이를
루옹 어텐션(Luong Attention) 기법으로 변경해보는 것도 좋은 연습이 될 것입니다.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">BahdanauAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">BahdanauAttention</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Wa</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Ua</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Va</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query</span><span class="p">,</span> <span class="n">keys</span><span class="p">):</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Va</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Wa</span><span class="p">(</span><span class="n">query</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">Ua</span><span class="p">(</span><span class="n">keys</span><span class="p">)))</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="n">scores</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">weights</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">context</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">keys</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">context</span><span class="p">,</span> <span class="n">weights</span>

<span class="k">class</span><span class="w"> </span><span class="nc">AttnDecoderRNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">dropout_p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">AttnDecoderRNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">output_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <span class="n">BahdanauAttention</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gru</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_p</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">encoder_hidden</span><span class="p">,</span> <span class="n">target_tensor</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">encoder_outputs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">decoder_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="n">SOS_token</span><span class="p">)</span>
        <span class="n">decoder_hidden</span> <span class="o">=</span> <span class="n">encoder_hidden</span>
        <span class="n">decoder_outputs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">attentions</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">MAX_LENGTH</span><span class="p">):</span>
            <span class="n">decoder_output</span><span class="p">,</span> <span class="n">decoder_hidden</span><span class="p">,</span> <span class="n">attn_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward_step</span><span class="p">(</span>
                <span class="n">decoder_input</span><span class="p">,</span> <span class="n">decoder_hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span>
            <span class="p">)</span>
            <span class="n">decoder_outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">decoder_output</span><span class="p">)</span>
            <span class="n">attentions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">attn_weights</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">target_tensor</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># Teacher forcing 포함: 목표를 다음 입력으로 전달</span>
                <span class="n">decoder_input</span> <span class="o">=</span> <span class="n">target_tensor</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># Teacher forcing</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Teacher forcing 미포함: 자신의 예측을 다음 입력으로 사용</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">topi</span> <span class="o">=</span> <span class="n">decoder_output</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">decoder_input</span> <span class="o">=</span> <span class="n">topi</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>  <span class="c1"># 입력으로 사용할 부분을 히스토리에서 분리</span>

        <span class="n">decoder_outputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">decoder_outputs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">decoder_outputs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">decoder_outputs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">attentions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">attentions</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">decoder_outputs</span><span class="p">,</span> <span class="n">decoder_hidden</span><span class="p">,</span> <span class="n">attentions</span>


    <span class="k">def</span><span class="w"> </span><span class="nf">forward_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">):</span>
        <span class="n">embedded</span> <span class="o">=</span>  <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="nb">input</span><span class="p">))</span>

        <span class="n">query</span> <span class="o">=</span> <span class="n">hidden</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">context</span><span class="p">,</span> <span class="n">attn_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">)</span>
        <span class="n">input_gru</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">embedded</span><span class="p">,</span> <span class="n">context</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

        <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gru</span><span class="p">(</span><span class="n">input_gru</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">attn_weights</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">참고</p>
<p>길이 제한을 해결하기 위해 상대적 위치 접근(relative position approach)
방식을 사용하는 다른 형태의 어텐션 방식들도 있습니다.
<a class="reference external" href="https://arxiv.org/abs/1508.04025">Effective Approaches to Attention-based Neural Machine Translation</a>
에서 “local attention” 에 대해 읽어보세요.</p>
</div>
</section>
</section>
</section>
<section id="id7">
<h2>학습<a class="headerlink" href="#id7" title="Link to this heading">#</a></h2>
<section id="id8">
<h3>학습 데이터 준비<a class="headerlink" href="#id8" title="Link to this heading">#</a></h3>
<p>학습을 위해서, 각 쌍마다 입력 Tensor(입력 문장의 단어 주소)와
목표 Tensor(목표 문장의 단어 주소)가 필요합니다. 이 벡터들을
생성하는 동안 두 시퀀스에 EOS 토큰을 추가 합니다.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">indexesFromSentence</span><span class="p">(</span><span class="n">lang</span><span class="p">,</span> <span class="n">sentence</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">lang</span><span class="o">.</span><span class="n">word2index</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">)]</span>

<span class="k">def</span><span class="w"> </span><span class="nf">tensorFromSentence</span><span class="p">(</span><span class="n">lang</span><span class="p">,</span> <span class="n">sentence</span><span class="p">):</span>
    <span class="n">indexes</span> <span class="o">=</span> <span class="n">indexesFromSentence</span><span class="p">(</span><span class="n">lang</span><span class="p">,</span> <span class="n">sentence</span><span class="p">)</span>
    <span class="n">indexes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">EOS_token</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">indexes</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">tensorsFromPair</span><span class="p">(</span><span class="n">pair</span><span class="p">):</span>
    <span class="n">input_tensor</span> <span class="o">=</span> <span class="n">tensorFromSentence</span><span class="p">(</span><span class="n">input_lang</span><span class="p">,</span> <span class="n">pair</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">target_tensor</span> <span class="o">=</span> <span class="n">tensorFromSentence</span><span class="p">(</span><span class="n">output_lang</span><span class="p">,</span> <span class="n">pair</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">target_tensor</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">get_dataloader</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
    <span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">,</span> <span class="n">pairs</span> <span class="o">=</span> <span class="n">prepareData</span><span class="p">(</span><span class="s1">&#39;eng&#39;</span><span class="p">,</span> <span class="s1">&#39;fra&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>

    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">pairs</span><span class="p">)</span>
    <span class="n">input_ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="n">MAX_LENGTH</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">target_ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="n">MAX_LENGTH</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">tgt</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">pairs</span><span class="p">):</span>
        <span class="n">inp_ids</span> <span class="o">=</span> <span class="n">indexesFromSentence</span><span class="p">(</span><span class="n">input_lang</span><span class="p">,</span> <span class="n">inp</span><span class="p">)</span>
        <span class="n">tgt_ids</span> <span class="o">=</span> <span class="n">indexesFromSentence</span><span class="p">(</span><span class="n">output_lang</span><span class="p">,</span> <span class="n">tgt</span><span class="p">)</span>
        <span class="n">inp_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">EOS_token</span><span class="p">)</span>
        <span class="n">tgt_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">EOS_token</span><span class="p">)</span>
        <span class="n">input_ids</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:</span><span class="nb">len</span><span class="p">(</span><span class="n">inp_ids</span><span class="p">)]</span> <span class="o">=</span> <span class="n">inp_ids</span>
        <span class="n">target_ids</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:</span><span class="nb">len</span><span class="p">(</span><span class="n">tgt_ids</span><span class="p">)]</span> <span class="o">=</span> <span class="n">tgt_ids</span>

    <span class="n">train_data</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span>
                               <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">target_ids</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>

    <span class="n">train_sampler</span> <span class="o">=</span> <span class="n">RandomSampler</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span>
    <span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="n">train_sampler</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">,</span> <span class="n">train_dataloader</span>
</pre></div>
</div>
</section>
<section id="id9">
<h3>모델 학습<a class="headerlink" href="#id9" title="Link to this heading">#</a></h3>
<p>학습을 위해서 인코더에 입력 문장을 넣고 모든 출력과 최신 은닉 상태를
추적합니다. 그런 다음 디코더에 첫 번째 입력으로 <code class="docutils literal notranslate"><span class="pre">&lt;SOS&gt;</span></code> 토큰과
인코더의 마지막 은닉 상태가 첫 번째 은닉 상태로 제공됩니다.</p>
<p>“Teacher forcing”은 다음 입력으로 디코더의 예측을 사용하는 대신
실제 목표 출력을 다음 입력으로 사용하는 컨셉입니다.
“Teacher forcing”을 사용하면 수렴이 빨리되지만 <a class="reference external" href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.378.4095&amp;rep=rep1&amp;type=pdf">학습된 네트워크가
잘못 사용될 때 불안정성을 보입니다.</a>.</p>
<p>Teacher-forced 네트워크의 출력이 일관된 문법으로 읽지만 정확한
번역과는 거리가 멀다는 것을 볼 수 있습니다. 직관적으로 출력 문법을
표현하는 법을 배우고 교사가 처음 몇 단어를 말하면 의미를 “선택” 할 수 있지만,
번역에서 처음으로 문장을 만드는 법은 잘 배우지 못합니다.</p>
<p>PyTorch의 autograd 가 제공하는 자유 덕분에 간단한 If 문으로
Teacher Forcing을 사용할지 아니면 사용하지 않을지를 선택할 수 있습니다.
더 많이 사용하려면 <code class="docutils literal notranslate"><span class="pre">teacher_forcing_ratio</span></code> 를 확인하십시오.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">train_epoch</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">encoder_optimizer</span><span class="p">,</span>
          <span class="n">decoder_optimizer</span><span class="p">,</span> <span class="n">criterion</span><span class="p">):</span>

    <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">dataloader</span><span class="p">:</span>
        <span class="n">input_tensor</span><span class="p">,</span> <span class="n">target_tensor</span> <span class="o">=</span> <span class="n">data</span>

        <span class="n">encoder_optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">decoder_optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">encoder_hidden</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span>
        <span class="n">decoder_outputs</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">decoder</span><span class="p">(</span><span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">encoder_hidden</span><span class="p">,</span> <span class="n">target_tensor</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span>
            <span class="n">decoder_outputs</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">decoder_outputs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)),</span>
            <span class="n">target_tensor</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

        <span class="n">encoder_optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">decoder_optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span>
</pre></div>
</div>
<p>이것은 현재 시간과 진행률%을 고려해 경과된 시간과 남은 예상
시간을 출력하는 헬퍼 함수입니다.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">math</span>

<span class="k">def</span><span class="w"> </span><span class="nf">asMinutes</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">s</span> <span class="o">/</span> <span class="mi">60</span><span class="p">)</span>
    <span class="n">s</span> <span class="o">-=</span> <span class="n">m</span> <span class="o">*</span> <span class="mi">60</span>
    <span class="k">return</span> <span class="s1">&#39;</span><span class="si">%d</span><span class="s1">m </span><span class="si">%d</span><span class="s1">s&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">timeSince</span><span class="p">(</span><span class="n">since</span><span class="p">,</span> <span class="n">percent</span><span class="p">):</span>
    <span class="n">now</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">now</span> <span class="o">-</span> <span class="n">since</span>
    <span class="n">es</span> <span class="o">=</span> <span class="n">s</span> <span class="o">/</span> <span class="p">(</span><span class="n">percent</span><span class="p">)</span>
    <span class="n">rs</span> <span class="o">=</span> <span class="n">es</span> <span class="o">-</span> <span class="n">s</span>
    <span class="k">return</span> <span class="s1">&#39;</span><span class="si">%s</span><span class="s1"> (- </span><span class="si">%s</span><span class="s1">)&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">asMinutes</span><span class="p">(</span><span class="n">s</span><span class="p">),</span> <span class="n">asMinutes</span><span class="p">(</span><span class="n">rs</span><span class="p">))</span>
</pre></div>
</div>
<p>전체 학습 과정은 다음과 같습니다:</p>
<ul class="simple">
<li><p>타이머 시작</p></li>
<li><p>optimizers와 criterion 초기화</p></li>
<li><p>학습 쌍의 세트 생성</p></li>
<li><p>도식화를 위한 빈 손실 배열 시작</p></li>
</ul>
<p>그런 다음 우리는 여러 번 <code class="docutils literal notranslate"><span class="pre">train</span></code> 을 호출하며 때로는 진행률
(예제의 %, 현재까지의 예상 시간)과 평균 손실을 출력합니다.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">n_epochs</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
               <span class="n">print_every</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">plot_every</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">plot_losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">print_loss_total</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># Reset every print_every</span>
    <span class="n">plot_loss_total</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># Reset every plot_every</span>

    <span class="n">encoder_optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
    <span class="n">decoder_optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">decoder</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">train_epoch</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">encoder_optimizer</span><span class="p">,</span> <span class="n">decoder_optimizer</span><span class="p">,</span> <span class="n">criterion</span><span class="p">)</span>
        <span class="n">print_loss_total</span> <span class="o">+=</span> <span class="n">loss</span>
        <span class="n">plot_loss_total</span> <span class="o">+=</span> <span class="n">loss</span>

        <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="n">print_every</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">print_loss_avg</span> <span class="o">=</span> <span class="n">print_loss_total</span> <span class="o">/</span> <span class="n">print_every</span>
            <span class="n">print_loss_total</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">%s</span><span class="s1"> (</span><span class="si">%d</span><span class="s1"> </span><span class="si">%d%%</span><span class="s1">) </span><span class="si">%.4f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">timeSince</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">epoch</span> <span class="o">/</span> <span class="n">n_epochs</span><span class="p">),</span>
                                        <span class="n">epoch</span><span class="p">,</span> <span class="n">epoch</span> <span class="o">/</span> <span class="n">n_epochs</span> <span class="o">*</span> <span class="mi">100</span><span class="p">,</span> <span class="n">print_loss_avg</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="n">plot_every</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">plot_loss_avg</span> <span class="o">=</span> <span class="n">plot_loss_total</span> <span class="o">/</span> <span class="n">plot_every</span>
            <span class="n">plot_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">plot_loss_avg</span><span class="p">)</span>
            <span class="n">plot_loss_total</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="n">showPlot</span><span class="p">(</span><span class="n">plot_losses</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id10">
<h3>결과 도식화<a class="headerlink" href="#id10" title="Link to this heading">#</a></h3>
<p>matplotlib로 학습 중에 저장된 손실 값 <code class="docutils literal notranslate"><span class="pre">plot_losses</span></code> 의 배열을
사용하여 도식화합니다.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="n">plt</span><span class="o">.</span><span class="n">switch_backend</span><span class="p">(</span><span class="s1">&#39;agg&#39;</span><span class="p">)</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.ticker</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">ticker</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="k">def</span><span class="w"> </span><span class="nf">showPlot</span><span class="p">(</span><span class="n">points</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
    <span class="c1"># 주기적인 간격으로 이 locator가 tick을 설정</span>
    <span class="n">loc</span> <span class="o">=</span> <span class="n">ticker</span><span class="o">.</span><span class="n">MultipleLocator</span><span class="p">(</span><span class="n">base</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_locator</span><span class="p">(</span><span class="n">loc</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">points</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="id11">
<h2>평가<a class="headerlink" href="#id11" title="Link to this heading">#</a></h2>
<p>평가는 대부분 학습과 동일하지만 목표가 없으므로 각 단계마다 디코더의
예측을 되돌려 전달합니다.
단어를 예측할 때마다 그 단어를 출력 문자열에 추가합니다.
만약 EOS 토큰을 예측하면 거기에서 멈춥니다.
나중에 도식화를 위해서 디코더의 Attention 출력을 저장합니다.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">sentence</span><span class="p">,</span> <span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">input_tensor</span> <span class="o">=</span> <span class="n">tensorFromSentence</span><span class="p">(</span><span class="n">input_lang</span><span class="p">,</span> <span class="n">sentence</span><span class="p">)</span>

        <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">encoder_hidden</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span>
        <span class="n">decoder_outputs</span><span class="p">,</span> <span class="n">decoder_hidden</span><span class="p">,</span> <span class="n">decoder_attn</span> <span class="o">=</span> <span class="n">decoder</span><span class="p">(</span><span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">encoder_hidden</span><span class="p">)</span>

        <span class="n">_</span><span class="p">,</span> <span class="n">topi</span> <span class="o">=</span> <span class="n">decoder_outputs</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">decoded_ids</span> <span class="o">=</span> <span class="n">topi</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>

        <span class="n">decoded_words</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">decoded_ids</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">idx</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">==</span> <span class="n">EOS_token</span><span class="p">:</span>
                <span class="n">decoded_words</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;&lt;EOS&gt;&#39;</span><span class="p">)</span>
                <span class="k">break</span>
            <span class="n">decoded_words</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output_lang</span><span class="o">.</span><span class="n">index2word</span><span class="p">[</span><span class="n">idx</span><span class="o">.</span><span class="n">item</span><span class="p">()])</span>
    <span class="k">return</span> <span class="n">decoded_words</span><span class="p">,</span> <span class="n">decoder_attn</span>
</pre></div>
</div>
<p>학습 세트에 있는 임의의 문장으로 평가한 다음, 입력(input), 목표(target)
및 출력(output) 값들을 표시하여 주관적으로 품질에 대해 판단해볼 수 있습니다:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">evaluateRandomly</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">pair</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">pairs</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&gt;&#39;</span><span class="p">,</span> <span class="n">pair</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;=&#39;</span><span class="p">,</span> <span class="n">pair</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">output_words</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">pair</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">)</span>
        <span class="n">output_sentence</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_words</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&lt;&#39;</span><span class="p">,</span> <span class="n">output_sentence</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id12">
<h2>학습과 평가<a class="headerlink" href="#id12" title="Link to this heading">#</a></h2>
<p>이러한 모든 헬퍼 함수를 이용해서 (추가 작업처럼 보이지만 여러 실험을
더 쉽게 수행 할 수 있음) 실제로 네트워크를 초기화하고 학습을
시작할 수 있습니다.</p>
<p>입력 문장이 많이 필터링되었음을 기억하십시오. 이 작은 데이터 세트의
경우 256 크기의 은닉 노드(hidden node)와 단일 GRU 계층 같은 상대적으로 작은
네트워크를 사용할 수 있습니다. MacBook CPU에서 약 40분 후에
합리적인 결과를 얻을 것입니다.</p>
<div class="admonition note">
<p class="admonition-title">참고</p>
<p>이 노트북을 실행하면 학습, 커널 중단, 평가를 할 수 있고 나중에
이어서 학습을 할 수 있습니다. 인코더와 디코더가 초기화 된 행을
주석 처리하고 <code class="docutils literal notranslate"><span class="pre">trainIters</span></code> 를 다시 실행하십시오.</p>
</div>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>

<span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">,</span> <span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">get_dataloader</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>

<span class="n">encoder</span> <span class="o">=</span> <span class="n">EncoderRNN</span><span class="p">(</span><span class="n">input_lang</span><span class="o">.</span><span class="n">n_words</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">decoder</span> <span class="o">=</span> <span class="n">AttnDecoderRNN</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_lang</span><span class="o">.</span><span class="n">n_words</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="n">train</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="mi">80</span><span class="p">,</span> <span class="n">print_every</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">plot_every</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
<ul class="sphx-glr-horizontal">
<li><img src="../_images/sphx_glr_seq2seq_translation_tutorial_001.png" srcset="../_images/sphx_glr_seq2seq_translation_tutorial_001.png" alt="seq2seq translation tutorial" class = "sphx-glr-multi-img"/></li>
<li><img src="../_images/sphx_glr_seq2seq_translation_tutorial_002.png" srcset="../_images/sphx_glr_seq2seq_translation_tutorial_002.png" alt="seq2seq translation tutorial" class = "sphx-glr-multi-img"/></li>
</ul>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Reading lines...
Read 135842 sentence pairs
Trimmed to 11445 sentence pairs
Counting words...
Counted words:
fra 4601
eng 2991
0m 34s (- 8m 42s) (5 6%) 1.5170
1m 23s (- 9m 44s) (10 12%) 0.6699
2m 10s (- 9m 25s) (15 18%) 0.3511
2m 57s (- 8m 51s) (20 25%) 0.1969
3m 46s (- 8m 17s) (25 31%) 0.1227
4m 35s (- 7m 39s) (30 37%) 0.0856
6m 2s (- 7m 45s) (35 43%) 0.0657
6m 36s (- 6m 36s) (40 50%) 0.0525
7m 9s (- 5m 34s) (45 56%) 0.0459
7m 45s (- 4m 39s) (50 62%) 0.0409
8m 28s (- 3m 51s) (55 68%) 0.0372
9m 17s (- 3m 5s) (60 75%) 0.0347
10m 7s (- 2m 20s) (65 81%) 0.0329
10m 54s (- 1m 33s) (70 87%) 0.0314
11m 43s (- 0m 46s) (75 93%) 0.0306
12m 32s (- 0m 0s) (80 100%) 0.0287
</pre></div>
</div>
<p>드롭아웃(dropout) 레이어들을 평가 (<code class="docutils literal notranslate"><span class="pre">eval</span></code>) 모드로 설정합니다.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">encoder</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">decoder</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">evaluateRandomly</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&gt; il est a la maison aujourd hui
= he is at home today
&lt; he is at home today &lt;EOS&gt;

&gt; ce sont celles qui veulent y aller
= they are the ones who want to go
&lt; they are the ones who want to go &lt;EOS&gt;

&gt; desole si je vous ai fait peur
= i m sorry if i scared you
&lt; i m sorry if i scared you &lt;EOS&gt;

&gt; je suis heureux de te voir ici
= i m happy to see you here
&lt; i m glad to see you here &lt;EOS&gt;

&gt; je prends mon apres midi demain
= i m taking tomorrow afternoon off
&lt; i m taking tomorrow afternoon off &lt;EOS&gt;

&gt; tu es tres intelligente
= you re very smart
&lt; you re very intelligent &lt;EOS&gt;

&gt; tu es malin
= you re clever
&lt; you re clever &lt;EOS&gt;

&gt; je ne vais pas abandonner maintenant
= i m not quitting now
&lt; i m not quitting now &lt;EOS&gt;

&gt; nous sommes sans emploi
= we re unemployed
&lt; we re unemployed &lt;EOS&gt;

&gt; il est canadien
= he is canadian
&lt; he is canadian &lt;EOS&gt;
</pre></div>
</div>
<section id="id13">
<h3>Attention 시각화<a class="headerlink" href="#id13" title="Link to this heading">#</a></h3>
<p>Attention 메커니즘의 유용한 속성은 하나는 해석 가능성이 높은 출력입니다.
입력 시퀀스의 특정 인코더 출력에 가중치를 부여하는 데 사용되므로
각 시간 단계에서 네트워크가 가장 집중되는 위치를 파악할 수 있습니다.</p>
<p>Attention 출력을 행렬로 표시하기 위해서는 <code class="docutils literal notranslate"><span class="pre">plt.matshow(attentions)</span></code> 을
그냥 실행해도 됩니다. 하지만 좀 더 나은 시각화를 위해 축(axis)과 라벨(label)을
추가하는 약간의 작업을 더 해보겠습니다:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">showAttention</span><span class="p">(</span><span class="n">input_sentence</span><span class="p">,</span> <span class="n">output_words</span><span class="p">,</span> <span class="n">attentions</span><span class="p">):</span>
    <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
    <span class="n">cax</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">matshow</span><span class="p">(</span><span class="n">attentions</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;bone&#39;</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">cax</span><span class="p">)</span>

    <span class="c1"># 축 설정</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">([</span><span class="s1">&#39;&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">input_sentence</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">)</span> <span class="o">+</span>
                       <span class="p">[</span><span class="s1">&#39;&lt;EOS&gt;&#39;</span><span class="p">],</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">([</span><span class="s1">&#39;&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">output_words</span><span class="p">)</span>

    <span class="c1"># 매 틱마다 라벨 보여주기</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_major_locator</span><span class="p">(</span><span class="n">ticker</span><span class="o">.</span><span class="n">MultipleLocator</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_locator</span><span class="p">(</span><span class="n">ticker</span><span class="o">.</span><span class="n">MultipleLocator</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="k">def</span><span class="w"> </span><span class="nf">evaluateAndShowAttention</span><span class="p">(</span><span class="n">input_sentence</span><span class="p">):</span>
    <span class="n">output_words</span><span class="p">,</span> <span class="n">attentions</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">input_sentence</span><span class="p">,</span> <span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;input =&#39;</span><span class="p">,</span> <span class="n">input_sentence</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;output =&#39;</span><span class="p">,</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_words</span><span class="p">))</span>
    <span class="n">showAttention</span><span class="p">(</span><span class="n">input_sentence</span><span class="p">,</span> <span class="n">output_words</span><span class="p">,</span> <span class="n">attentions</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:</span><span class="nb">len</span><span class="p">(</span><span class="n">output_words</span><span class="p">),</span> <span class="p">:])</span>


<span class="n">evaluateAndShowAttention</span><span class="p">(</span><span class="s1">&#39;il n est pas aussi grand que son pere&#39;</span><span class="p">)</span>

<span class="n">evaluateAndShowAttention</span><span class="p">(</span><span class="s1">&#39;je suis trop fatigue pour conduire&#39;</span><span class="p">)</span>

<span class="n">evaluateAndShowAttention</span><span class="p">(</span><span class="s1">&#39;je suis desole si c est une question idiote&#39;</span><span class="p">)</span>

<span class="n">evaluateAndShowAttention</span><span class="p">(</span><span class="s1">&#39;je suis reellement fiere de vous&#39;</span><span class="p">)</span>
</pre></div>
</div>
<ul class="sphx-glr-horizontal">
<li><img src="../_images/sphx_glr_seq2seq_translation_tutorial_003.png" srcset="../_images/sphx_glr_seq2seq_translation_tutorial_003.png" alt="seq2seq translation tutorial" class = "sphx-glr-multi-img"/></li>
<li><img src="../_images/sphx_glr_seq2seq_translation_tutorial_004.png" srcset="../_images/sphx_glr_seq2seq_translation_tutorial_004.png" alt="seq2seq translation tutorial" class = "sphx-glr-multi-img"/></li>
<li><img src="../_images/sphx_glr_seq2seq_translation_tutorial_005.png" srcset="../_images/sphx_glr_seq2seq_translation_tutorial_005.png" alt="seq2seq translation tutorial" class = "sphx-glr-multi-img"/></li>
<li><img src="../_images/sphx_glr_seq2seq_translation_tutorial_006.png" srcset="../_images/sphx_glr_seq2seq_translation_tutorial_006.png" alt="seq2seq translation tutorial" class = "sphx-glr-multi-img"/></li>
</ul>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>input = il n est pas aussi grand que son pere
output = he is not as tall as his father &lt;EOS&gt;
/workspace/tutorials-kr/intermediate_source/seq2seq_translation_tutorial.py:822: UserWarning:

set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.

/workspace/tutorials-kr/intermediate_source/seq2seq_translation_tutorial.py:824: UserWarning:

set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.

input = je suis trop fatigue pour conduire
output = i am too tired to drive away &lt;EOS&gt;
/workspace/tutorials-kr/intermediate_source/seq2seq_translation_tutorial.py:822: UserWarning:

set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.

/workspace/tutorials-kr/intermediate_source/seq2seq_translation_tutorial.py:824: UserWarning:

set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.

input = je suis desole si c est une question idiote
output = i m sorry if this is a stupid question &lt;EOS&gt;
/workspace/tutorials-kr/intermediate_source/seq2seq_translation_tutorial.py:822: UserWarning:

set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.

/workspace/tutorials-kr/intermediate_source/seq2seq_translation_tutorial.py:824: UserWarning:

set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.

input = je suis reellement fiere de vous
output = i m really proud of you &lt;EOS&gt;
/workspace/tutorials-kr/intermediate_source/seq2seq_translation_tutorial.py:822: UserWarning:

set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.

/workspace/tutorials-kr/intermediate_source/seq2seq_translation_tutorial.py:824: UserWarning:

set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.
</pre></div>
</div>
</section>
</section>
<section id="id14">
<h2>연습<a class="headerlink" href="#id14" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>다른 데이터 셋을 시도해 보십시오</p>
<ul>
<li><p>다른 언어쌍</p></li>
<li><p>사람 → 기계 (e.g. IOT 명령어)</p></li>
<li><p>채팅 → 응답</p></li>
<li><p>질문 → 답변</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">word2vec</span></code> 또는 <code class="docutils literal notranslate"><span class="pre">GloVe</span></code> 같은 미리 학습된 word embedding 으로
embedding 을 교체하십시오</p></li>
<li><p>더 많은 레이어, 은닉 유닛, 더 많은 문장을 사용하십시오.
학습 시간과 결과를 비교해 보십시오</p></li>
<li><p>만약 같은 구문 두개의 쌍으로 된 번역 파일을 이용한다면,
(<code class="docutils literal notranslate"><span class="pre">I</span> <span class="pre">am</span> <span class="pre">test</span> <span class="pre">\t</span> <span class="pre">I</span> <span class="pre">am</span> <span class="pre">test</span></code>), 이것을 오토인코더로
사용할 수 있습니다.
이것을 시도해 보십시오:</p>
<ul>
<li><p>오토인코더 학습</p></li>
<li><p>인코더 네트워크 저장하기</p></li>
<li><p>그 상태에서 번역을 위한 새로운 디코더 학습</p></li>
</ul>
</li>
</ul>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (12 minutes 42.958 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-intermediate-seq2seq-translation-tutorial-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/032d653a4f5a9c1ec32b9fc7c989ffe1/seq2seq_translation_tutorial.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">seq2seq_translation_tutorial.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/3baf9960a4be104931872ff3ffda07b7/seq2seq_translation_tutorial.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">seq2seq_translation_tutorial.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../_downloads/aa412a8699f8766ba0890a542ef0d9c8/seq2seq_translation_tutorial.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">seq2seq_translation_tutorial.zip</span></code></a></p>
</div>
</div>
</section>
</section>


                </article>
              
  </article>
  
              
              
                <footer class="bd-footer-article">
                  <div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item">
<div class="feedback">
  
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
        
    </div>
</div>

  <div class="feedback-send">
    <button class="feedback-btn"
            onclick="openGitHubIssue()"
            data-bs-title="Create a GitHub Issue"
            data-bs-placement="bottom"
            data-bs-toggle="tooltip"
            data-gtm="feedback-btn-click">Send Feedback
    </button>
  </div>
</div>

<div class="prev-next-area">
</div>

<div class="footer-info">
  <p class="copyright">
    
      
        © Copyright 2018-2025, PyTorch &amp; 파이토치 한국 사용자 모임(PyTorchKR).
      
      <br/>
    
  </p>

  <p class="theme-version">
    Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
  </p>
</div>
</div>
  
</div>
                </footer>
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc">
<div class="sidebar-secondary-items sidebar-secondary__inner">
    
       <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">데이터 파일 불러오기</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#seq2seq">Seq2Seq 모델</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">인코더</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">디코더</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">간단한 디코더</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#attention">Attention 디코더</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">학습</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">학습 데이터 준비</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">모델 학습</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">결과 도식화</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id11">평가</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id12">학습과 평가</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id13">Attention 시각화</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id14">연습</a></li>
</ul>
  </nav></div>
    




<div class="sidebar-secondary-item">
  <div class="sidebar-heading">PyTorch Libraries</div>
  <ul style="list-style-type: none; padding: 0; padding-bottom: 80px;">
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/ao" style="color: var(--pst-color-text-muted)">torchao</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchrec" style="color: var(--pst-color-text-muted)">torchrec</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchft" style="color: var(--pst-color-text-muted)">torchft</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchcodec" style="color: var(--pst-color-text-muted)">TorchCodec</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/vision" style="color: var(--pst-color-text-muted)">torchvision</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/executorch" style="color: var(--pst-color-text-muted)">ExecuTorch</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/xla" style="color: var(--pst-color-text-muted)">PyTorch on XLA Devices</a></li>
  
  </ul>
</div>

</div>
</div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <div class="container-fluid docs-tutorials-resources">
  <div class="container">
    <div class="row">
      <div class="col-md-4 text-center">
        <h2>PyTorchKorea @ GitHub</h2>
        <p>파이토치 한국 사용자 모임을 GitHub에서 만나보세요.</p>
        <a class="with-right-arrow" href="https://github.com/PyTorchKorea">GitHub로 이동</a>
      </div>

      <div class="col-md-4 text-center">
        <h2>한국어 튜토리얼</h2>
        <p>한국어로 번역 중인 파이토치 튜토리얼을 만나보세요.</p>
        <a class="with-right-arrow" href="https://tutorials.pytorch.kr/">튜토리얼로 이동</a>
      </div>

      <div class="col-md-4 text-center">
        <h2>한국어 커뮤니티</h2>
        <p>다른 사용자들과 의견을 나누고, 도와주세요!</p>
        <a class="with-right-arrow" href="https://discuss.pytorch.kr/">커뮤니티로 이동</a>
      </div>
    </div>
  </div>
</div>

<footer class="site-footer">
  <div class="container footer-container">
    <div class="footer-logo-wrapper">
      <a href="https://pytorch.kr/" class="footer-logo"></a>
    </div>

    <div class="footer-links-wrapper">
      <div class="footer-links-col">
        <ul>
          <li class="list-title"><a href="https://pytorch.kr/">파이토치 한국 사용자 모임</a></li>
          <li><a href="https://pytorch.kr/about">사용자 모임 소개</a></li>
          <li><a href="https://pytorch.kr/contributors">기여해주신 분들</a></li>
          <li><a href="https://pytorch.kr/resources/">리소스</a></li>
          <li><a href="https://pytorch.kr/coc">행동 강령</a></li>
        </ul>
      </div>
    </div>

    <div class="trademark-disclaimer">
      <ul>
        <li>이 사이트는 독립적인 파이토치 사용자 커뮤니티로, 최신 버전이 아니거나 잘못된 내용이 포함되어 있을 수 있습니다. This site is an independent user community and may be out of date or contain incorrect information.</li>
        <li><a href="https://pytorch.kr/coc">행동 강령</a>을 읽고 지켜주세요. PyTorch 공식 로고 사용 규정은 <a href="https://www.linuxfoundation.org/policies/">Linux Foundation의 정책</a>을 따릅니다. Please read and follow <a href="https://pytorch.kr/coc">our code of conduct</a>. All PyTorch trademark policy applicable to <a href="https://www.linuxfoundation.org/policies/">Linux Foundation's policies</a>.</li>
      </ul>
    </div>
  </div>
</footer>

<div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../_static/img/pytorch-x.svg">
  </div>
</div>
  
  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2018-2025, PyTorch &amp; 파이토치 한국 사용자 모임(PyTorchKR).
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.2.6 버전으로 생성되었습니다.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
</p></div>
      
    </div>
  
</div>

  </footer>
  <script type="application/ld+json">
    {
       "@context": "https://schema.org",
       "@type": "Article",
       "name": "\uae30\ucd08\ubd80\ud130 \uc2dc\uc791\ud558\ub294 NLP: Sequence to Sequence \ub124\ud2b8\uc6cc\ud06c\uc640 Attention\uc744 \uc774\uc6a9\ud55c \ubc88\uc5ed",
       "headline": "\uae30\ucd08\ubd80\ud130 \uc2dc\uc791\ud558\ub294 NLP: Sequence to Sequence \ub124\ud2b8\uc6cc\ud06c\uc640 Attention\uc744 \uc774\uc6a9\ud55c \ubc88\uc5ed",
       "description": "PyTorch Documentation. Explore PyTorch, an open-source machine learning library that accelerates the path from research prototyping to production deployment. Discover tutorials, API references, and guides to help you build and deploy deep learning models efficiently.",
       "url": "/intermediate/seq2seq_translation_tutorial.html",
       "articleBody": "\ucc38\uace0 Go to the end to download the full example code. \uae30\ucd08\ubd80\ud130 \uc2dc\uc791\ud558\ub294 NLP: Sequence to Sequence \ub124\ud2b8\uc6cc\ud06c\uc640 Attention\uc744 \uc774\uc6a9\ud55c \ubc88\uc5ed# Author: Sean Robertson\ubc88\uc5ed: \ud669\uc131\uc218 \uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc740 3\ubd80\ub85c \uad6c\uc131\ub41c \uc2dc\ub9ac\uc988\uc758 \uc77c\ubd80\uc785\ub2c8\ub2e4: \uae30\ucd08\ubd80\ud130 \uc2dc\uc791\ud558\ub294 NLP: \ubb38\uc790-\ub2e8\uc704 RNN\uc73c\ub85c \uc774\ub984 \ubd84\ub958\ud558\uae30 \uae30\ucd08\ubd80\ud130 \uc2dc\uc791\ud558\ub294 NLP: \ubb38\uc790-\ub2e8\uc704 RNN\uc73c\ub85c \uc774\ub984 \uc0dd\uc131\ud558\uae30 \uae30\ucd08\ubd80\ud130 \uc2dc\uc791\ud558\ub294 NLP: Sequence to Sequence \ub124\ud2b8\uc6cc\ud06c\uc640 Attention\uc744 \uc774\uc6a9\ud55c \ubc88\uc5ed \uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc740 \u201c\uae30\ucd08\ubd80\ud130 \uc2dc\uc791\ud558\ub294 NLP\u201d\uc758 \uc138\ubc88\uc9f8\uc774\uc790 \ub9c8\uc9c0\ub9c9 \ud3b8\uc73c\ub85c, NLP \ubaa8\ub378\ub9c1 \uc791\uc5c5\uc744 \uc704\ud55c \ub370\uc774\ud130 \uc804\ucc98\ub9ac\uc5d0 \uc0ac\uc6a9\ud560 \uc790\uccb4 \ud074\ub798\uc2a4\uc640 \ud568\uc218\ub4e4\uc744 \uc791\uc131\ud574\ubcf4\uaca0\uc2b5\ub2c8\ub2e4. \uc774 \ud504\ub85c\uc81d\ud2b8\uc5d0\uc11c\ub294 \uc2e0\uacbd\ub9dd\uc774 \ubd88\uc5b4\ub97c \uc601\uc5b4\ub85c \ubc88\uc5ed\ud558\ub3c4\ub85d \uac00\ub974\uce60 \uc608\uc815\uc785\ub2c8\ub2e4. [KEY: \u003e input, = target, \u003c output] \u003e il est en train de peindre un tableau . = he is painting a picture . \u003c he is painting a picture . \u003e pourquoi ne pas essayer ce vin delicieux ? = why not try that delicious wine ? \u003c why not try that delicious wine ? \u003e elle n est pas poete mais romanciere . = she is not a poet but a novelist . \u003c she not not a poet but a novelist . \u003e vous etes trop maigre . = you re too skinny . \u003c you re all alone . \u2026 \uc131\uacf5\uc728\uc740 \ub2ec\ub77c\uc9c8 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ud558\ub098\uc758 \uc2dc\ud000\uc2a4\ub97c \ub2e4\ub978 \uc2dc\ud000\uc2a4\ub85c \ubc14\uafb8\ub294 \ub450 \uac1c\uc758 RNN\uc774 \ud568\uaed8 \ub3d9\uc791\ud558\ub294 sequence to sequence network \uc758 \uac04\ub2e8\ud558\uc9c0\ub9cc \uac15\ub825\ud55c \uc544\uc774\ub514\uc5b4\uac00 \uc774\uac83(\ubc88\uc5ed)\uc744 \uac00\ub2a5\ud558\uac8c \ud569\ub2c8\ub2e4. \uc778\ucf54\ub354 \ub124\ud2b8\uc6cc\ud06c\ub294 \uc785\ub825 \uc2dc\ud000\uc2a4\ub97c \ubca1\ud130\ub85c \uc555\ucd95\ud558\uace0, \ub514\ucf54\ub354 \ub124\ud2b8\uc6cc\ud06c\ub294 \ud574\ub2f9 \ubca1\ud130\ub97c \uc0c8\ub85c\uc6b4 \uc2dc\ud000\uc2a4\ub85c \ud3bc\uce69\ub2c8\ub2e4. \uc774 \ubaa8\ub378\uc744 \uac1c\uc120\ud558\uae30 \uc704\ud574 Attention Mechanism \uc744 \uc0ac\uc6a9\ud558\uba74 \ub514\ucf54\ub354\uac00 \uc785\ub825 \uc2dc\ud000\uc2a4\uc758 \ud2b9\uc815 \ubc94\uc704\uc5d0 \uc9d1\uc911\ud560 \uc218 \uc788\ub3c4\ub85d \ud569\ub2c8\ub2e4. \ucd94\ucc9c \uc790\ub8cc: \ucd5c\uc18c\ud55c Pytorch\ub97c \uc124\uce58\ud588\uace0, Python\uc744 \uc54c\uace0, Tensor\ub97c \uc774\ud574\ud55c\ub2e4\uace0 \uac00\uc815\ud569\ub2c8\ub2e4.: http://pytorch.org/ \uc124\uce58 \uc548\ub0b4\ub97c \uc704\ud55c \uc790\ub8cc PyTorch\ub85c \ub525\ub7ec\ub2dd\ud558\uae30: 60\ubd84\ub9cc\uc5d0 \ub05d\uc7a5\ub0b4\uae30 \uc77c\ubc18\uc801\uc778 PyTorch \uc2dc\uc791\uc744 \uc704\ud55c \uc790\ub8cc \uc608\uc81c\ub85c \ubc30\uc6b0\ub294 \ud30c\uc774\ud1a0\uce58(PyTorch) \ub113\uace0 \uae4a\uc740 \ud1b5\ucc30\uc744 \uc704\ud55c \uc790\ub8cc Torch \uc0ac\uc6a9\uc790\ub97c \uc704\ud55c PyTorch \uc774\uc804 Lua Torch \uc0ac\uc6a9\uc790\ub97c \uc704\ud55c \uc790\ub8cc Sequence to Sequence \ub124\ud2b8\uc6cc\ud06c\uc640 \ub3d9\uc791 \ubc29\ubc95\uc5d0 \uad00\ud574\uc11c \uc544\ub294 \uac83\uc740 \uc720\uc6a9\ud569\ub2c8\ub2e4: Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation Sequence to Sequence Learning with Neural Networks Neural Machine Translation by Jointly Learning to Align and Translate A Neural Conversational Model \uc774\uc804 \ud29c\ud1a0\ub9ac\uc5bc\uc5d0 \uc788\ub294 \uae30\ucd08\ubd80\ud130 \uc2dc\uc791\ud558\ub294 NLP: \ubb38\uc790-\ub2e8\uc704 RNN\uc73c\ub85c \uc774\ub984 \ubd84\ub958\ud558\uae30 \uc640 \uae30\ucd08\ubd80\ud130 \uc2dc\uc791\ud558\ub294 NLP: \ubb38\uc790-\ub2e8\uc704 RNN\uc73c\ub85c \uc774\ub984 \uc0dd\uc131\ud558\uae30 \ub294 \uac01\uac01 \uc778\ucf54\ub354, \ub514\ucf54\ub354 \ubaa8\ub378\uacfc \ube44\uc2b7\ud55c \ucee8\uc13c\uc744 \uac00\uc9c0\uae30 \ub54c\ubb38\uc5d0 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4. \uc694\uad6c \uc0ac\ud56d from __future__ import unicode_literals, print_function, division from io import open import unicodedata import re import random import torch import torch.nn as nn from torch import optim import torch.nn.functional as F import numpy as np from torch.utils.data import TensorDataset, DataLoader, RandomSampler device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \ub370\uc774\ud130 \ud30c\uc77c \ubd88\ub7ec\uc624\uae30# \uc774 \ud504\ub85c\uc81d\ud2b8\uc758 \ub370\uc774\ud130\ub294 \uc218\ucc9c \uac1c\uc758 \uc601\uc5b4-\ud504\ub791\uc2a4\uc5b4 \ubc88\uc5ed \uc30d\uc785\ub2c8\ub2e4. Open Data Stack Exchange \uc5d0 \uad00\ud55c \uc774 \uc9c8\ubb38\uc740 https://tatoeba.org/eng/downloads \uc5d0\uc11c \ub2e4\uc6b4 \ub85c\ub4dc\uac00 \uac00\ub2a5\ud55c \uacf5\uac1c \ubc88\uc5ed \uc0ac\uc774\ud2b8 https://tatoeba.org/ \ub97c \uc54c\ub824 \uc8fc\uc5c8\uc2b5\ub2c8\ub2e4. \ub354 \ub098\uc740 \ubc29\ubc95\uc73c\ub85c \uc5b8\uc5b4 \uc30d\uc744 \uac1c\ubcc4 \ud14d\uc2a4\ud2b8 \ud30c\uc77c\ub85c \ubd84\ud560\ud558\ub294 \ucd94\uac00 \uc791\uc5c5\uc744 \uc218\ud589\ud55c https://www.manythings.org/anki/ \uac00 \uc788\uc2b5\ub2c8\ub2e4: \uc601\uc5b4-\ud504\ub791\uc2a4\uc5b4 \uc30d\uc774 \ub108\ubb34 \ucee4\uc11c \uc800\uc7a5\uc18c\uc5d0 \ud3ec\ud568 \ud560 \uc218 \uc5c6\uae30 \ub54c\ubb38\uc5d0 \uacc4\uc18d\ud558\uae30 \uc804\uc5d0 data/eng-fra.txt \ub85c \ub2e4\uc6b4\ub85c\ub4dc\ud558\uc2ed\uc2dc\uc624. \uc774 \ud30c\uc77c\uc740 \ud0ed\uc73c\ub85c \uad6c\ubd84\ub41c \ubc88\uc5ed \uc30d \ubaa9\ub85d\uc785\ub2c8\ub2e4: I am cold. J\u0027ai froid. \ucc38\uace0 \uc5ec\uae30 \uc5d0\uc11c \ub370\uc774\ud130\ub97c \ub2e4\uc6b4 \ubc1b\uace0 \ud604\uc7ac \ub514\ub809\ud1a0\ub9ac\uc5d0 \uc555\ucd95\uc744 \ud478\uc2ed\uc2dc\uc624. \ubb38\uc790 \ub2e8\uc704 RNN \ud29c\ud1a0\ub9ac\uc5bc\uc5d0\uc11c \uc0ac\uc6a9\ub41c \ubb38\uc790 \uc778\ucf54\ub529\uacfc \uc720\uc0ac\ud558\uac8c, \uc5b8\uc5b4\uc758 \uac01 \ub2e8\uc5b4\ub4e4\uc744 One-Hot \ubca1\ud130 \ub610\ub294 \uadf8 \ub2e8\uc5b4\uc758 \uc8fc\uc18c\uc5d0\ub9cc \ub2e8 \ud558\ub098\uc758 1\uc744 \uc81c\uc678\ud558\uace0 \ubaa8\ub450 0\uc778 \ud070 \ubca1\ud130\ub85c \ud45c\ud604\ud569\ub2c8\ub2e4. \ud55c \uac00\uc9c0 \uc5b8\uc5b4\uc5d0 \uc788\ub294 \uc218\uc2ed \uac1c\uc758 \ubb38\uc790\uc640 \ub2ec\ub9ac \ubc88\uc5ed\uc5d0\ub294 \uc544\uc8fc \ub9ce\uc740 \ub2e8\uc5b4\ub4e4\uc774 \uc788\uae30 \ub54c\ubb38\uc5d0 \uc778\ucf54\ub529 \ubca1\ud130\ub294 \ub9e4\uc6b0 \ub354 \ud07d\ub2c8\ub2e4. \uadf8\ub7ec\ub098 \uc6b0\ub9ac\ub294 \uc57d\uac04\uc758 \ud2b8\ub9ad\ub97c \uc368\uc11c \uc5b8\uc5b4 \ub2f9 \uc218\ucc9c \ub2e8\uc5b4 \ub9cc \uc0ac\uc6a9\ud558\ub3c4\ub85d \ub370\uc774\ud130\ub97c \ub2e4\ub4ec\uc744 \uac83\uc785\ub2c8\ub2e4. \ub098\uc911\uc5d0 \ub124\ud2b8\uc6cc\ud06c\uc758 \uc785\ub825 \ubc0f \ubaa9\ud45c\ub85c \uc0ac\uc6a9\ud558\ub824\uba74 \ub2e8\uc5b4 \ub2f9 \uace0\uc720 \ubc88\ud638\uac00 \ud544\uc694\ud569\ub2c8\ub2e4. \uc774 \ubaa8\ub4e0 \uac83\uc744 \ucd94\uc801\ud558\uae30 \uc704\ud574 \uc6b0\ub9ac\ub294 \ub2e8\uc5b4\u2192\uc0c9\uc778(word2index)\uacfc \uc0c9\uc778\u2192\ub2e8\uc5b4(index2word) \uc0ac\uc804, \uadf8\ub9ac\uace0 \ub098\uc911\uc5d0 \ud76c\uadc0 \ub2e8\uc5b4\ub97c \ub300\uccb4\ud558\ub294\ub370 \uc0ac\uc6a9\ud560 \uac01 \ub2e8\uc5b4\uc758 \ube48\ub3c4 word2count \ub97c \uac00\uc9c4 Lang \uc774\ub77c\ub294 \ud5ec\ud37c \ud074\ub798\uc2a4\ub97c \uc0ac\uc6a9\ud569\ub2c8\ub2e4. SOS_token = 0 EOS_token = 1 class Lang: def __init__(self, name): self.name = name self.word2index = {} self.word2count = {} self.index2word = {0: \"SOS\", 1: \"EOS\"} self.n_words = 2 # SOS \uc640 EOS \ud3ec\ud568 def addSentence(self, sentence): for word in sentence.split(\u0027 \u0027): self.addWord(word) def addWord(self, word): if word not in self.word2index: self.word2index[word] = self.n_words self.word2count[word] = 1 self.index2word[self.n_words] = word self.n_words += 1 else: self.word2count[word] += 1 \ud30c\uc77c\uc740 \ubaa8\ub450 \uc720\ub2c8 \ucf54\ub4dc\ub85c \ub418\uc5b4\uc788\uc5b4 \uac04\ub2e8\ud558\uac8c \ud558\uae30 \uc704\ud574 \uc720\ub2c8 \ucf54\ub4dc \ubb38\uc790\ub97c ASCII\ub85c \ubcc0\ud658\ud558\uace0, \ubaa8\ub4e0 \ubb38\uc790\ub97c \uc18c\ubb38\uc790\ub85c \ub9cc\ub4e4\uace0, \ub300\ubd80\ubd84\uc758 \uad6c\ub450\uc810\uc744 \uc9c0\uc6cc\uc90d\ub2c8\ub2e4. # \uc720\ub2c8 \ucf54\ub4dc \ubb38\uc790\uc5f4\uc744 \uc77c\ubc18 ASCII\ub85c \ubcc0\ud658\ud558\uc2ed\uc2dc\uc624. # https://stackoverflow.com/a/518232/2809427 def unicodeToAscii(s): return \u0027\u0027.join( c for c in unicodedata.normalize(\u0027NFD\u0027, s) if unicodedata.category(c) != \u0027Mn\u0027 ) # \uc18c\ubb38\uc790, \ub2e4\ub4ec\uae30, \uadf8\ub9ac\uace0 \ubb38\uc790\uac00 \uc544\ub2cc \ubb38\uc790 \uc81c\uac70 def normalizeString(s): s = unicodeToAscii(s.lower().strip()) s = re.sub(r\"([.!?])\", r\" \\1\", s) s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s) return s.strip() To read the data file we will split the file into lines, and then split lines into pairs. The files are all English \u2192 Other Language, so if we want to translate from Other Language \u2192 English I added the reverse flag to reverse the pairs. def readLangs(lang1, lang2, reverse=False): print(\"Reading lines...\") # \ud30c\uc77c\uc744 \uc77d\uace0 \uc904\ub85c \ubd84\ub9ac lines = open(\u0027data/%s-%s.txt\u0027 % (lang1, lang2), encoding=\u0027utf-8\u0027).\\ read().strip().split(\u0027\\n\u0027) # \ubaa8\ub4e0 \uc904\uc744 \uc30d\uc73c\ub85c \ubd84\ub9ac\ud558\uace0 \uc815\uaddc\ud654 pairs = [[normalizeString(s) for s in l.split(\u0027\\t\u0027)] for l in lines] # \uc30d\uc744 \ub4a4\uc9d1\uace0, Lang \uc778\uc2a4\ud134\uc2a4 \uc0dd\uc131 if reverse: pairs = [list(reversed(p)) for p in pairs] input_lang = Lang(lang2) output_lang = Lang(lang1) else: input_lang = Lang(lang1) output_lang = Lang(lang2) return input_lang, output_lang, pairs \ub9ce\uc740 \uc608\uc81c \ubb38\uc7a5\uc774 \uc788\uace0 \uc2e0\uc18d\ud558\uac8c \ud559\uc2b5\ud558\uae30\ub97c \uc6d0\ud558\uae30 \ub54c\ubb38\uc5d0 \ube44\uad50\uc801 \uc9e7\uace0 \uac04\ub2e8\ud55c \ubb38\uc7a5\uc73c\ub85c\ub9cc \ub370\uc774\ud130 \uc14b\uc744 \uc815\ub9ac\ud560 \uac83\uc785\ub2c8\ub2e4. \uc5ec\uae30\uc11c \ucd5c\ub300 \uae38\uc774\ub294 10 \ub2e8\uc5b4 (\uc885\ub8cc \ubb38\uc7a5 \ubd80\ud638 \ud3ec\ud568)\uc774\uba70 \u201cI am\u201d \ub610\ub294 \u201cHe is\u201d \ub4f1\uc758 \ud615\ud0dc\ub85c \ubc88\uc5ed\ub418\ub294 \ubb38\uc7a5\uc73c\ub85c \ud544\ud130\ub9c1\ub429\ub2c8\ub2e4.(\uc774\uc804\uc5d0 \uc544\ud3ec\uc2a4\ud2b8\ub85c\ud53c\ub294 \ub300\uccb4 \ub428) MAX_LENGTH = 10 eng_prefixes = ( \"i am \", \"i m \", \"he is\", \"he s \", \"she is\", \"she s \", \"you are\", \"you re \", \"we are\", \"we re \", \"they are\", \"they re \" ) def filterPair(p): return len(p[0].split(\u0027 \u0027)) \u003c MAX_LENGTH and \\ len(p[1].split(\u0027 \u0027)) \u003c MAX_LENGTH and \\ p[1].startswith(eng_prefixes) def filterPairs(pairs): return [pair for pair in pairs if filterPair(pair)] \ub370\uc774\ud130 \uc900\ube44\ub97c \uc704\ud55c \uc804\uccb4 \uacfc\uc815: \ud14d\uc2a4\ud2b8 \ud30c\uc77c\uc744 \uc77d\uace0 \uc904\ub85c \ubd84\ub9ac\ud558\uace0, \uc904\uc744 \uc30d\uc73c\ub85c \ubd84\ub9ac\ud569\ub2c8\ub2e4. \ud14d\uc2a4\ud2b8\ub97c \uc815\uaddc\ud654 \ud558\uace0 \uae38\uc774\uc640 \ub0b4\uc6a9\uc73c\ub85c \ud544\ud130\ub9c1 \ud569\ub2c8\ub2e4. \uc30d\uc744 \uc774\ub8ec \ubb38\uc7a5\ub4e4\ub85c \ub2e8\uc5b4 \ub9ac\uc2a4\ud2b8\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4. def prepareData(lang1, lang2, reverse=False): input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse) print(\"Read %s sentence pairs\" % len(pairs)) pairs = filterPairs(pairs) print(\"Trimmed to %s sentence pairs\" % len(pairs)) print(\"Counting words...\") for pair in pairs: input_lang.addSentence(pair[0]) output_lang.addSentence(pair[1]) print(\"Counted words:\") print(input_lang.name, input_lang.n_words) print(output_lang.name, output_lang.n_words) return input_lang, output_lang, pairs input_lang, output_lang, pairs = prepareData(\u0027eng\u0027, \u0027fra\u0027, True) print(random.choice(pairs)) Reading lines... Read 135842 sentence pairs Trimmed to 11445 sentence pairs Counting words... Counted words: fra 4601 eng 2991 [\u0027elle vient de france\u0027, \u0027she is from france\u0027] Seq2Seq \ubaa8\ub378# Recurrent Neural Network(RNN)\ub294 \uc2dc\ud000\uc2a4\uc5d0\uc11c \uc791\ub3d9\ud558\uace0 \ub2e4\uc74c \ub2e8\uacc4\uc758 \uc785\ub825\uc73c\ub85c \uc790\uc2e0\uc758 \ucd9c\ub825\uc744 \uc0ac\uc6a9\ud558\ub294 \ub124\ud2b8\uc6cc\ud06c\uc785\ub2c8\ub2e4. Sequence to Sequence network, \ub610\ub294 Seq2Seq \ub124\ud2b8\uc6cc\ud06c, \ub610\ub294 Encoder Decoder network \ub294 \uc778\ucf54\ub354 \ubc0f \ub514\ucf54\ub354\ub77c\uace0 \ud558\ub294 \ub450 \uac1c\uc758 RNN\uc73c\ub85c \uad6c\uc131\ub41c \ubaa8\ub378\uc785\ub2c8\ub2e4. \uc778\ucf54\ub354\ub294 \uc785\ub825 \uc2dc\ud000\uc2a4\ub97c \uc77d\uace0 \ub2e8\uc77c \ubca1\ud130\ub97c \ucd9c\ub825\ud558\uace0, \ub514\ucf54\ub354\ub294 \ud574\ub2f9 \ubca1\ud130\ub97c \uc77d\uc5b4 \ucd9c\ub825 \uc2dc\ud000\uc2a4\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4. \ubaa8\ub4e0 \uc785\ub825\uc5d0 \ud574\ub2f9\ud558\ub294 \ucd9c\ub825\uc774 \uc788\ub294 \ub2e8\uc77c RNN\uc758 \uc2dc\ud000\uc2a4 \uc608\uce21\uacfc \ub2ec\ub9ac Seq2Seq \ubaa8\ub378\uc740 \uc2dc\ud000\uc2a4 \uae38\uc774\uc640 \uc21c\uc11c\ub97c \uc790\uc720\ub86d\uac8c\ud558\uae30 \ub54c\ubb38\uc5d0 \ub450 \uc5b8\uc5b4 \uc0ac\uc774\uc758 \ubc88\uc5ed\uc5d0 \uc774\uc0c1\uc801\uc785\ub2c8\ub2e4. \ub2e4\uc74c \ubb38\uc7a5 Je ne suis pas le chat noir \u2192 I am not the black cat \ub97c \uc0b4\ud3b4 \ubd05\uc2dc\ub2e4. \uc785\ub825 \ubb38\uc7a5\uc758 \ub2e8\uc5b4 \ub300\ubd80\ubd84\uc740 \ucd9c\ub825 \ubb38\uc7a5\uc5d0\uc11c \uc9c1\uc5ed(chat noir \uc640 black cat)\ub418\uc9c0\ub9cc \uc57d\uac04 \ub2e4\ub978 \uc21c\uc11c\ub3c4 \uc788\uc2b5\ub2c8\ub2e4. ne/pas \uad6c\uc870\ub85c \uc778\ud574 \uc785\ub825 \ubb38\uc7a5\uc5d0 \ub2e8\uc5b4\uac00 \ud558\ub098 \ub354 \uc788\uc2b5\ub2c8\ub2e4. \uc785\ub825 \ub2e8\uc5b4\uc758 \uc2dc\ud000\uc2a4\ub97c \uc9c1\uc5ed\ud574\uc11c \uc815\ud655\ud55c \ubc88\uc5ed\uc744 \ub9cc\ub4dc\ub294 \uac83\uc740 \uc5b4\ub824\uc6b8 \uac83\uc785\ub2c8\ub2e4. Seq2Seq \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\uba74 \uc778\ucf54\ub354\ub294 \ud558\ub098\uc758 \ubca1\ud130\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4. \uc774\uc0c1\uc801\uc778 \uacbd\uc6b0\uc5d0 \uc785\ub825 \uc2dc\ud000\uc2a4\uc758 \u201c\uc758\ubbf8\u201d\ub97c \ubb38\uc7a5\uc758 N \ucc28\uc6d0 \uacf5\uac04\uc5d0 \uc788\ub294 \ub2e8\uc77c \uc9c0\uc810\uc778 \ub2e8\uc77c \ubca1\ud130\uc73c\ub85c \uc778\ucf54\ub529\ud569\ub2c8\ub2e4. \uc778\ucf54\ub354# Seq2Seq \ub124\ud2b8\uc6cc\ud06c\uc758 \uc778\ucf54\ub354\ub294 \uc785\ub825 \ubb38\uc7a5\uc758 \ubaa8\ub4e0 \ub2e8\uc5b4\uc5d0 \ub300\ud574 \uc5b4\ub5a4 \uac12\uc744 \ucd9c\ub825\ud558\ub294 RNN\uc785\ub2c8\ub2e4. \ubaa8\ub4e0 \uc785\ub825 \ub2e8\uc5b4\uc5d0 \ub300\ud574 \uc778\ucf54\ub354\ub294 \ubca1\ud130\uc640 \uc740\ub2c9 \uc0c1\ud0dc\ub97c \ucd9c\ub825\ud558\uace0 \ub2e4\uc74c \uc785\ub825 \ub2e8\uc5b4\ub97c \uc704\ud574 \uadf8 \uc740\ub2c9 \uc0c1\ud0dc\ub97c \uc0ac\uc6a9\ud569\ub2c8\ub2e4. class EncoderRNN(nn.Module): def __init__(self, input_size, hidden_size, dropout_p=0.1): super(EncoderRNN, self).__init__() self.hidden_size = hidden_size self.embedding = nn.Embedding(input_size, hidden_size) self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True) self.dropout = nn.Dropout(dropout_p) def forward(self, input): embedded = self.dropout(self.embedding(input)) output, hidden = self.gru(embedded) return output, hidden \ub514\ucf54\ub354# \ub514\ucf54\ub354\ub294 \uc778\ucf54\ub354 \ucd9c\ub825 \ubca1\ud130\ub97c \ubc1b\uc544\uc11c \ubc88\uc5ed\uc744 \uc0dd\uc131\ud558\uae30 \uc704\ud55c \ub2e8\uc5b4 \uc2dc\ud000\uc2a4\ub97c \ucd9c\ub825\ud569\ub2c8\ub2e4. \uac04\ub2e8\ud55c \ub514\ucf54\ub354# \uac00\uc7a5 \uac04\ub2e8\ud55c Seq2Seq \ub514\ucf54\ub354\ub294 \uc778\ucf54\ub354\uc758 \ub9c8\uc9c0\ub9c9 \ucd9c\ub825\ub9cc\uc744 \uc774\uc6a9\ud569\ub2c8\ub2e4. \uc774 \ub9c8\uc9c0\ub9c9 \ucd9c\ub825\uc740 \uc804\uccb4 \uc2dc\ud000\uc2a4\uc5d0\uc11c \ubb38\ub9e5\uc744 \uc778\ucf54\ub4dc\ud558\uae30 \ub54c\ubb38\uc5d0 \ubb38\ub9e5 \ubca1\ud130(context vector) \ub85c \ubd88\ub9bd\ub2c8\ub2e4. \uc774 \ubb38\ub9e5 \ubca1\ud130\ub294 \ub514\ucf54\ub354\uc758 \ucd08\uae30 \uc740\ub2c9 \uc0c1\ud0dc\ub85c \uc0ac\uc6a9 \ub429\ub2c8\ub2e4. \ub514\ucf54\ub529\uc758 \ub9e4 \ub2e8\uacc4\uc5d0\uc11c \ub514\ucf54\ub354\uc5d0\uac8c \uc785\ub825 \ud1a0\ud070\uacfc \uc740\ub2c9 \uc0c1\ud0dc\uac00 \uc8fc\uc5b4\uc9d1\ub2c8\ub2e4. \ucd08\uae30 \uc785\ub825 \ud1a0\ud070\uc740 \ubb38\uc790\uc5f4-\uc2dc\uc791 (start-of-string) \u003cSOS\u003e \ud1a0\ud070\uc774\uace0, \uccab \uc740\ub2c9 \uc0c1\ud0dc\ub294 \ubb38\ub9e5 \ubca1\ud130(\uc778\ucf54\ub354\uc758 \ub9c8\uc9c0\ub9c9 \uc740\ub2c9 \uc0c1\ud0dc) \uc785\ub2c8\ub2e4. class DecoderRNN(nn.Module): def __init__(self, hidden_size, output_size): super(DecoderRNN, self).__init__() self.embedding = nn.Embedding(output_size, hidden_size) self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True) self.out = nn.Linear(hidden_size, output_size) def forward(self, encoder_outputs, encoder_hidden, target_tensor=None): batch_size = encoder_outputs.size(0) decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token) decoder_hidden = encoder_hidden decoder_outputs = [] for i in range(MAX_LENGTH): decoder_output, decoder_hidden = self.forward_step(decoder_input, decoder_hidden) decoder_outputs.append(decoder_output) if target_tensor is not None: # Teacher forcing \ud3ec\ud568: \ubaa9\ud45c\ub97c \ub2e4\uc74c \uc785\ub825\uc73c\ub85c \uc804\ub2ec decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing else: # Teacher forcing \ubbf8\ud3ec\ud568: \uc790\uc2e0\uc758 \uc608\uce21\uc744 \ub2e4\uc74c \uc785\ub825\uc73c\ub85c \uc0ac\uc6a9 _, topi = decoder_output.topk(1) decoder_input = topi.squeeze(-1).detach() # \uc785\ub825\uc73c\ub85c \uc0ac\uc6a9\ud560 \ubd80\ubd84\uc744 \ud788\uc2a4\ud1a0\ub9ac\uc5d0\uc11c \ubd84\ub9ac decoder_outputs = torch.cat(decoder_outputs, dim=1) decoder_outputs = F.log_softmax(decoder_outputs, dim=-1) return decoder_outputs, decoder_hidden, None # \ud559\uc2b5 \ub8e8\ud504\uc758 \uc77c\uad00\uc131 \uc720\uc9c0\ub97c \uc704\ud574 `None` \uc744 \ucd94\uac00\ub85c \ubc18\ud658 def forward_step(self, input, hidden): output = self.embedding(input) output = F.relu(output) output, hidden = self.gru(output, hidden) output = self.out(output) return output, hidden \uc774 \ubaa8\ub378\uc758 \uacb0\uacfc\ub97c \ud559\uc2b5\ud558\uace0 \uad00\ucc30\ud558\ub294 \uac83\uc744 \uad8c\uc7a5\ud558\uc9c0\ub9cc, \uacf5\uac04\uc744 \uc808\uc57d\ud558\uae30 \uc704\ud574 \ucd5c\uc885 \ubaa9\uc801\uc9c0\ub85c \ubc14\ub85c \uc774\ub3d9\ud574\uc11c Attention \uba54\ucee4\ub2c8\uc998\uc744 \uc18c\uac1c \ud560 \uac83\uc785\ub2c8\ub2e4. Attention \ub514\ucf54\ub354# \ubb38\ub9e5 \ubca1\ud130\ub9cc \uc778\ucf54\ub354\uc640 \ub514\ucf54\ub354 \uc0ac\uc774\ub85c \uc804\ub2ec \ub41c\ub2e4\uba74, \ub2e8\uc77c \ubca1\ud130\uac00 \uc804\uccb4 \ubb38\uc7a5\uc744 \uc778\ucf54\ub529 \ud574\uc57c\ud558\ub294 \ubd80\ub2f4\uc744 \uac00\uc9c0\uac8c \ub429\ub2c8\ub2e4. Attention\uc740 \ub514\ucf54\ub354 \ub124\ud2b8\uc6cc\ud06c\uac00 \uc790\uae30 \ucd9c\ub825\uc758 \ubaa8\ub4e0 \ub2e8\uacc4\uc5d0\uc11c \uc778\ucf54\ub354 \ucd9c\ub825\uc758 \ub2e4\ub978 \ubd80\ubd84\uc5d0 \u201c\uc9d1\uc911\u201d \ud560 \uc218 \uc788\uac8c \ud569\ub2c8\ub2e4. \uccab\uc9f8 Attention \uac00\uc911\uce58 \uc758 \uc138\ud2b8\ub97c \uacc4\uc0b0\ud569\ub2c8\ub2e4. \uc774\uac83\uc740 \uac00\uc911\uce58 \uc870\ud569\uc744 \ub9cc\ub4e4\uae30 \uc704\ud574\uc11c \uc778\ucf54\ub354 \ucd9c\ub825 \ubca1\ud130\uc640 \uacf1\ud574\uc9d1\ub2c8\ub2e4. \uadf8 \uacb0\uacfc(\ucf54\ub4dc\uc5d0\uc11c attn_applied)\ub294 \uc785\ub825 \uc2dc\ud000\uc2a4\uc758 \ud2b9\uc815 \ubd80\ubd84\uc5d0 \uad00\ud55c \uc815\ubcf4\ub97c \ud3ec\ud568\ud574\uc57c\ud558\uace0 \ub530\ub77c\uc11c \ub514\ucf54\ub354\uac00 \uc54c\ub9de\uc740 \ucd9c\ub825 \ub2e8\uc5b4\ub97c \uc120\ud0dd\ud558\ub294 \uac83\uc744 \ub3c4\uc640\uc90d\ub2c8\ub2e4. \uc5b4\ud150\uc158 \uac00\uc911\uce58 \uacc4\uc0b0\uc740 \ub514\ucf54\ub354\uc758 \uc785\ub825 \ubc0f \uc740\ub2c9 \uc0c1\ud0dc\ub97c \uc785\ub825\uc73c\ub85c \uc0ac\uc6a9\ud558\ub294 \ub2e4\ub978 feed-forwad \uacc4\uce35\uc778 attn \uc73c\ub85c \uc218\ud589\ub429\ub2c8\ub2e4. \ud559\uc2b5 \ub370\uc774\ud130\uc5d0\ub294 \ubaa8\ub4e0 \ud06c\uae30\uc758 \ubb38\uc7a5\uc774 \uc788\uae30 \ub54c\ubb38\uc5d0 \uc774 \uacc4\uce35\uc744 \uc2e4\uc81c\ub85c \ub9cc\ub4e4\uace0 \ud559\uc2b5\uc2dc\ud0a4\ub824\uba74 \uc801\uc6a9 \ud560 \uc218 \uc788\ub294 \ucd5c\ub300 \ubb38\uc7a5 \uae38\uc774 (\uc778\ucf54\ub354 \ucd9c\ub825\uc744 \uc704\ud55c \uc785\ub825 \uae38\uc774)\ub97c \uc120\ud0dd\ud574\uc57c \ud569\ub2c8\ub2e4. \ucd5c\ub300 \uae38\uc774\uc758 \ubb38\uc7a5\uc740 \ubaa8\ub4e0 Attention \uac00\uc911\uce58\ub97c \uc0ac\uc6a9\ud558\uc9c0\ub9cc \ub354 \uc9e7\uc740 \ubb38\uc7a5\uc740 \ucc98\uc74c \uba87 \uac1c\ub9cc \uc0ac\uc6a9\ud569\ub2c8\ub2e4. \ubd80\uac00\uc801 \uc5b4\ud150\uc158(Additive Attention)\uc774\ub77c\uace0\ub3c4 \uc54c\ub824\uc9c4 \ubc14\ub2e4\ub098\uc6b0 \uc5b4\ud150\uc158(Bahdanau Attention)\uc740 \uae30\uacc4 \ubc88\uc5ed \uc791\uc5c5\uacfc \uac19\uc740 \uc2dc\ud000\uc2a4-\ud22c-\uc2dc\ud000\uc2a4 \ubaa8\ub378\uc5d0\uc11c \uc77c\ubc18\uc801\uc73c\ub85c \uc0ac\uc6a9\ud558\ub294 \uc5b4\ud150\uc158 \uae30\ubc95(mechanism)\uc785\ub2c8\ub2e4. \uc774 \uc5b4\ud150\uc158 \uae30\ubc95\uc740 Bahdanau et al.\uc758 \ub17c\ubb38\uc778 Neural Machine Translation by Jointly Learning to Align and Translate \uc5d0\uc11c \uc18c\uac1c\ub418\uc5c8\uc2b5\ub2c8\ub2e4. \uc774 \uc5b4\ud150\uc158 \uae30\ubc95\uc740 \ud559\uc2b5\ub41c \uc815\ub82c \ubaa8\ub378(learned alignment model)\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc778\ucf54\ub354\uc640 \ub514\ucf54\ub354\uc758 \uc740\ub2c9 \uc0c1\ud0dc(hidden state) \uac04\uc758 \uc5b4\ud150\uc158 \uc810\uc218\ub97c \uacc4\uc0b0\ud569\ub2c8\ub2e4. \uc774\ub294 \uc815\ub82c\ub41c \uc5b4\ud150\uc158 \uc810\uc218\ub97c \uacc4\uc0b0\ud558\uae30 \uc704\ud574 feed-forward \uc2e0\uacbd\ub9dd\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4. \ub610\ub294, \ub514\ucf54\ub354\uc758 \uc740\ub2c9 \uc0c1\ud0dc\uc640 \uc778\ucf54\ub354\uc758 \uc740\ub2c9 \uc0c1\ud0dc \uc0ac\uc774\uc758 \uc5b4\ud150\uc158 \uc810\uc218\ub97c Dot-Product\ub85c \uacc4\uc0b0\ud558\ub294 \ub8e8\uc639 \uc5b4\ud150\uc158(Luong Attention)\uacfc \uac19\uc740 \ub2e4\ub978 \uc5b4\ud150\uc158 \uae30\ubc95\ub4e4\uc744 \uc0ac\uc6a9\ud560 \uc218\ub3c4 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub294 \ubc14\ub2e4\ub098\uc6b0 \uc5b4\ud150\uc158(Bahdanau Attention)\uc5d0\uc11c \uc0ac\uc6a9\ud558\ub294 \ube44\uc120\ud615 \ubcc0\ud658(non-linear transformation)\uc744 \uc0ac\uc6a9\ud558\uc9c0\ub294 \uc54a\uc2b5\ub2c8\ub2e4. \uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc5d0\uc11c\ub294 \ubc14\ub2e4\ub098\uc6b0 \uc5b4\ud150\uc158(Bahdanau Attention)\uc744 \uc0ac\uc6a9\ud560 \uac83\uc785\ub2c8\ub2e4. \ud558\uc9c0\ub9cc \uc774\ub97c \ub8e8\uc639 \uc5b4\ud150\uc158(Luong Attention) \uae30\ubc95\uc73c\ub85c \ubcc0\uacbd\ud574\ubcf4\ub294 \uac83\ub3c4 \uc88b\uc740 \uc5f0\uc2b5\uc774 \ub420 \uac83\uc785\ub2c8\ub2e4. class BahdanauAttention(nn.Module): def __init__(self, hidden_size): super(BahdanauAttention, self).__init__() self.Wa = nn.Linear(hidden_size, hidden_size) self.Ua = nn.Linear(hidden_size, hidden_size) self.Va = nn.Linear(hidden_size, 1) def forward(self, query, keys): scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys))) scores = scores.squeeze(2).unsqueeze(1) weights = F.softmax(scores, dim=-1) context = torch.bmm(weights, keys) return context, weights class AttnDecoderRNN(nn.Module): def __init__(self, hidden_size, output_size, dropout_p=0.1): super(AttnDecoderRNN, self).__init__() self.embedding = nn.Embedding(output_size, hidden_size) self.attention = BahdanauAttention(hidden_size) self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True) self.out = nn.Linear(hidden_size, output_size) self.dropout = nn.Dropout(dropout_p) def forward(self, encoder_outputs, encoder_hidden, target_tensor=None): batch_size = encoder_outputs.size(0) decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token) decoder_hidden = encoder_hidden decoder_outputs = [] attentions = [] for i in range(MAX_LENGTH): decoder_output, decoder_hidden, attn_weights = self.forward_step( decoder_input, decoder_hidden, encoder_outputs ) decoder_outputs.append(decoder_output) attentions.append(attn_weights) if target_tensor is not None: # Teacher forcing \ud3ec\ud568: \ubaa9\ud45c\ub97c \ub2e4\uc74c \uc785\ub825\uc73c\ub85c \uc804\ub2ec decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing else: # Teacher forcing \ubbf8\ud3ec\ud568: \uc790\uc2e0\uc758 \uc608\uce21\uc744 \ub2e4\uc74c \uc785\ub825\uc73c\ub85c \uc0ac\uc6a9 _, topi = decoder_output.topk(1) decoder_input = topi.squeeze(-1).detach() # \uc785\ub825\uc73c\ub85c \uc0ac\uc6a9\ud560 \ubd80\ubd84\uc744 \ud788\uc2a4\ud1a0\ub9ac\uc5d0\uc11c \ubd84\ub9ac decoder_outputs = torch.cat(decoder_outputs, dim=1) decoder_outputs = F.log_softmax(decoder_outputs, dim=-1) attentions = torch.cat(attentions, dim=1) return decoder_outputs, decoder_hidden, attentions def forward_step(self, input, hidden, encoder_outputs): embedded = self.dropout(self.embedding(input)) query = hidden.permute(1, 0, 2) context, attn_weights = self.attention(query, encoder_outputs) input_gru = torch.cat((embedded, context), dim=2) output, hidden = self.gru(input_gru, hidden) output = self.out(output) return output, hidden, attn_weights \ucc38\uace0 \uae38\uc774 \uc81c\ud55c\uc744 \ud574\uacb0\ud558\uae30 \uc704\ud574 \uc0c1\ub300\uc801 \uc704\uce58 \uc811\uadfc(relative position approach) \ubc29\uc2dd\uc744 \uc0ac\uc6a9\ud558\ub294 \ub2e4\ub978 \ud615\ud0dc\uc758 \uc5b4\ud150\uc158 \ubc29\uc2dd\ub4e4\ub3c4 \uc788\uc2b5\ub2c8\ub2e4. Effective Approaches to Attention-based Neural Machine Translation \uc5d0\uc11c \u201clocal attention\u201d \uc5d0 \ub300\ud574 \uc77d\uc5b4\ubcf4\uc138\uc694. \ud559\uc2b5# \ud559\uc2b5 \ub370\uc774\ud130 \uc900\ube44# \ud559\uc2b5\uc744 \uc704\ud574\uc11c, \uac01 \uc30d\ub9c8\ub2e4 \uc785\ub825 Tensor(\uc785\ub825 \ubb38\uc7a5\uc758 \ub2e8\uc5b4 \uc8fc\uc18c)\uc640 \ubaa9\ud45c Tensor(\ubaa9\ud45c \ubb38\uc7a5\uc758 \ub2e8\uc5b4 \uc8fc\uc18c)\uac00 \ud544\uc694\ud569\ub2c8\ub2e4. \uc774 \ubca1\ud130\ub4e4\uc744 \uc0dd\uc131\ud558\ub294 \ub3d9\uc548 \ub450 \uc2dc\ud000\uc2a4\uc5d0 EOS \ud1a0\ud070\uc744 \ucd94\uac00 \ud569\ub2c8\ub2e4. def indexesFromSentence(lang, sentence): return [lang.word2index[word] for word in sentence.split(\u0027 \u0027)] def tensorFromSentence(lang, sentence): indexes = indexesFromSentence(lang, sentence) indexes.append(EOS_token) return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1) def tensorsFromPair(pair): input_tensor = tensorFromSentence(input_lang, pair[0]) target_tensor = tensorFromSentence(output_lang, pair[1]) return (input_tensor, target_tensor) def get_dataloader(batch_size): input_lang, output_lang, pairs = prepareData(\u0027eng\u0027, \u0027fra\u0027, True) n = len(pairs) input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32) target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32) for idx, (inp, tgt) in enumerate(pairs): inp_ids = indexesFromSentence(input_lang, inp) tgt_ids = indexesFromSentence(output_lang, tgt) inp_ids.append(EOS_token) tgt_ids.append(EOS_token) input_ids[idx, :len(inp_ids)] = inp_ids target_ids[idx, :len(tgt_ids)] = tgt_ids train_data = TensorDataset(torch.LongTensor(input_ids).to(device), torch.LongTensor(target_ids).to(device)) train_sampler = RandomSampler(train_data) train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size) return input_lang, output_lang, train_dataloader \ubaa8\ub378 \ud559\uc2b5# \ud559\uc2b5\uc744 \uc704\ud574\uc11c \uc778\ucf54\ub354\uc5d0 \uc785\ub825 \ubb38\uc7a5\uc744 \ub123\uace0 \ubaa8\ub4e0 \ucd9c\ub825\uacfc \ucd5c\uc2e0 \uc740\ub2c9 \uc0c1\ud0dc\ub97c \ucd94\uc801\ud569\ub2c8\ub2e4. \uadf8\ub7f0 \ub2e4\uc74c \ub514\ucf54\ub354\uc5d0 \uccab \ubc88\uc9f8 \uc785\ub825\uc73c\ub85c \u003cSOS\u003e \ud1a0\ud070\uacfc \uc778\ucf54\ub354\uc758 \ub9c8\uc9c0\ub9c9 \uc740\ub2c9 \uc0c1\ud0dc\uac00 \uccab \ubc88\uc9f8 \uc740\ub2c9 \uc0c1\ud0dc\ub85c \uc81c\uacf5\ub429\ub2c8\ub2e4. \u201cTeacher forcing\u201d\uc740 \ub2e4\uc74c \uc785\ub825\uc73c\ub85c \ub514\ucf54\ub354\uc758 \uc608\uce21\uc744 \uc0ac\uc6a9\ud558\ub294 \ub300\uc2e0 \uc2e4\uc81c \ubaa9\ud45c \ucd9c\ub825\uc744 \ub2e4\uc74c \uc785\ub825\uc73c\ub85c \uc0ac\uc6a9\ud558\ub294 \ucee8\uc149\uc785\ub2c8\ub2e4. \u201cTeacher forcing\u201d\uc744 \uc0ac\uc6a9\ud558\uba74 \uc218\ub834\uc774 \ube68\ub9ac\ub418\uc9c0\ub9cc \ud559\uc2b5\ub41c \ub124\ud2b8\uc6cc\ud06c\uac00 \uc798\ubabb \uc0ac\uc6a9\ub420 \ub54c \ubd88\uc548\uc815\uc131\uc744 \ubcf4\uc785\ub2c8\ub2e4.. Teacher-forced \ub124\ud2b8\uc6cc\ud06c\uc758 \ucd9c\ub825\uc774 \uc77c\uad00\ub41c \ubb38\ubc95\uc73c\ub85c \uc77d\uc9c0\ub9cc \uc815\ud655\ud55c \ubc88\uc5ed\uacfc\ub294 \uac70\ub9ac\uac00 \uba40\ub2e4\ub294 \uac83\uc744 \ubcfc \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc9c1\uad00\uc801\uc73c\ub85c \ucd9c\ub825 \ubb38\ubc95\uc744 \ud45c\ud604\ud558\ub294 \ubc95\uc744 \ubc30\uc6b0\uace0 \uad50\uc0ac\uac00 \ucc98\uc74c \uba87 \ub2e8\uc5b4\ub97c \ub9d0\ud558\uba74 \uc758\ubbf8\ub97c \u201c\uc120\ud0dd\u201d \ud560 \uc218 \uc788\uc9c0\ub9cc, \ubc88\uc5ed\uc5d0\uc11c \ucc98\uc74c\uc73c\ub85c \ubb38\uc7a5\uc744 \ub9cc\ub4dc\ub294 \ubc95\uc740 \uc798 \ubc30\uc6b0\uc9c0 \ubabb\ud569\ub2c8\ub2e4. PyTorch\uc758 autograd \uac00 \uc81c\uacf5\ud558\ub294 \uc790\uc720 \ub355\ubd84\uc5d0 \uac04\ub2e8\ud55c If \ubb38\uc73c\ub85c Teacher Forcing\uc744 \uc0ac\uc6a9\ud560\uc9c0 \uc544\ub2c8\uba74 \uc0ac\uc6a9\ud558\uc9c0 \uc54a\uc744\uc9c0\ub97c \uc120\ud0dd\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ub354 \ub9ce\uc774 \uc0ac\uc6a9\ud558\ub824\uba74 teacher_forcing_ratio \ub97c \ud655\uc778\ud558\uc2ed\uc2dc\uc624. def train_epoch(dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion): total_loss = 0 for data in dataloader: input_tensor, target_tensor = data encoder_optimizer.zero_grad() decoder_optimizer.zero_grad() encoder_outputs, encoder_hidden = encoder(input_tensor) decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor) loss = criterion( decoder_outputs.view(-1, decoder_outputs.size(-1)), target_tensor.view(-1) ) loss.backward() encoder_optimizer.step() decoder_optimizer.step() total_loss += loss.item() return total_loss / len(dataloader) \uc774\uac83\uc740 \ud604\uc7ac \uc2dc\uac04\uacfc \uc9c4\ud589\ub960%\uc744 \uace0\ub824\ud574 \uacbd\uacfc\ub41c \uc2dc\uac04\uacfc \ub0a8\uc740 \uc608\uc0c1 \uc2dc\uac04\uc744 \ucd9c\ub825\ud558\ub294 \ud5ec\ud37c \ud568\uc218\uc785\ub2c8\ub2e4. import time import math def asMinutes(s): m = math.floor(s / 60) s -= m * 60 return \u0027%dm %ds\u0027 % (m, s) def timeSince(since, percent): now = time.time() s = now - since es = s / (percent) rs = es - s return \u0027%s (- %s)\u0027 % (asMinutes(s), asMinutes(rs)) \uc804\uccb4 \ud559\uc2b5 \uacfc\uc815\uc740 \ub2e4\uc74c\uacfc \uac19\uc2b5\ub2c8\ub2e4: \ud0c0\uc774\uba38 \uc2dc\uc791 optimizers\uc640 criterion \ucd08\uae30\ud654 \ud559\uc2b5 \uc30d\uc758 \uc138\ud2b8 \uc0dd\uc131 \ub3c4\uc2dd\ud654\ub97c \uc704\ud55c \ube48 \uc190\uc2e4 \ubc30\uc5f4 \uc2dc\uc791 \uadf8\ub7f0 \ub2e4\uc74c \uc6b0\ub9ac\ub294 \uc5ec\ub7ec \ubc88 train \uc744 \ud638\ucd9c\ud558\uba70 \ub54c\ub85c\ub294 \uc9c4\ud589\ub960 (\uc608\uc81c\uc758 %, \ud604\uc7ac\uae4c\uc9c0\uc758 \uc608\uc0c1 \uc2dc\uac04)\uacfc \ud3c9\uade0 \uc190\uc2e4\uc744 \ucd9c\ub825\ud569\ub2c8\ub2e4. def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001, print_every=100, plot_every=100): start = time.time() plot_losses = [] print_loss_total = 0 # Reset every print_every plot_loss_total = 0 # Reset every plot_every encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate) decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate) criterion = nn.NLLLoss() for epoch in range(1, n_epochs + 1): loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion) print_loss_total += loss plot_loss_total += loss if epoch % print_every == 0: print_loss_avg = print_loss_total / print_every print_loss_total = 0 print(\u0027%s (%d %d%%) %.4f\u0027 % (timeSince(start, epoch / n_epochs), epoch, epoch / n_epochs * 100, print_loss_avg)) if epoch % plot_every == 0: plot_loss_avg = plot_loss_total / plot_every plot_losses.append(plot_loss_avg) plot_loss_total = 0 showPlot(plot_losses) \uacb0\uacfc \ub3c4\uc2dd\ud654# matplotlib\ub85c \ud559\uc2b5 \uc911\uc5d0 \uc800\uc7a5\ub41c \uc190\uc2e4 \uac12 plot_losses \uc758 \ubc30\uc5f4\uc744 \uc0ac\uc6a9\ud558\uc5ec \ub3c4\uc2dd\ud654\ud569\ub2c8\ub2e4. import matplotlib.pyplot as plt plt.switch_backend(\u0027agg\u0027) import matplotlib.ticker as ticker import numpy as np def showPlot(points): plt.figure() fig, ax = plt.subplots() # \uc8fc\uae30\uc801\uc778 \uac04\uaca9\uc73c\ub85c \uc774 locator\uac00 tick\uc744 \uc124\uc815 loc = ticker.MultipleLocator(base=0.2) ax.yaxis.set_major_locator(loc) plt.plot(points) \ud3c9\uac00# \ud3c9\uac00\ub294 \ub300\ubd80\ubd84 \ud559\uc2b5\uacfc \ub3d9\uc77c\ud558\uc9c0\ub9cc \ubaa9\ud45c\uac00 \uc5c6\uc73c\ubbc0\ub85c \uac01 \ub2e8\uacc4\ub9c8\ub2e4 \ub514\ucf54\ub354\uc758 \uc608\uce21\uc744 \ub418\ub3cc\ub824 \uc804\ub2ec\ud569\ub2c8\ub2e4. \ub2e8\uc5b4\ub97c \uc608\uce21\ud560 \ub54c\ub9c8\ub2e4 \uadf8 \ub2e8\uc5b4\ub97c \ucd9c\ub825 \ubb38\uc790\uc5f4\uc5d0 \ucd94\uac00\ud569\ub2c8\ub2e4. \ub9cc\uc57d EOS \ud1a0\ud070\uc744 \uc608\uce21\ud558\uba74 \uac70\uae30\uc5d0\uc11c \uba48\ucda5\ub2c8\ub2e4. \ub098\uc911\uc5d0 \ub3c4\uc2dd\ud654\ub97c \uc704\ud574\uc11c \ub514\ucf54\ub354\uc758 Attention \ucd9c\ub825\uc744 \uc800\uc7a5\ud569\ub2c8\ub2e4. def evaluate(encoder, decoder, sentence, input_lang, output_lang): with torch.no_grad(): input_tensor = tensorFromSentence(input_lang, sentence) encoder_outputs, encoder_hidden = encoder(input_tensor) decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden) _, topi = decoder_outputs.topk(1) decoded_ids = topi.squeeze() decoded_words = [] for idx in decoded_ids: if idx.item() == EOS_token: decoded_words.append(\u0027\u003cEOS\u003e\u0027) break decoded_words.append(output_lang.index2word[idx.item()]) return decoded_words, decoder_attn \ud559\uc2b5 \uc138\ud2b8\uc5d0 \uc788\ub294 \uc784\uc758\uc758 \ubb38\uc7a5\uc73c\ub85c \ud3c9\uac00\ud55c \ub2e4\uc74c, \uc785\ub825(input), \ubaa9\ud45c(target) \ubc0f \ucd9c\ub825(output) \uac12\ub4e4\uc744 \ud45c\uc2dc\ud558\uc5ec \uc8fc\uad00\uc801\uc73c\ub85c \ud488\uc9c8\uc5d0 \ub300\ud574 \ud310\ub2e8\ud574\ubcfc \uc218 \uc788\uc2b5\ub2c8\ub2e4: def evaluateRandomly(encoder, decoder, n=10): for i in range(n): pair = random.choice(pairs) print(\u0027\u003e\u0027, pair[0]) print(\u0027=\u0027, pair[1]) output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang) output_sentence = \u0027 \u0027.join(output_words) print(\u0027\u003c\u0027, output_sentence) print(\u0027\u0027) \ud559\uc2b5\uacfc \ud3c9\uac00# \uc774\ub7ec\ud55c \ubaa8\ub4e0 \ud5ec\ud37c \ud568\uc218\ub97c \uc774\uc6a9\ud574\uc11c (\ucd94\uac00 \uc791\uc5c5\ucc98\ub7fc \ubcf4\uc774\uc9c0\ub9cc \uc5ec\ub7ec \uc2e4\ud5d8\uc744 \ub354 \uc27d\uac8c \uc218\ud589 \ud560 \uc218 \uc788\uc74c) \uc2e4\uc81c\ub85c \ub124\ud2b8\uc6cc\ud06c\ub97c \ucd08\uae30\ud654\ud558\uace0 \ud559\uc2b5\uc744 \uc2dc\uc791\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc785\ub825 \ubb38\uc7a5\uc774 \ub9ce\uc774 \ud544\ud130\ub9c1\ub418\uc5c8\uc74c\uc744 \uae30\uc5b5\ud558\uc2ed\uc2dc\uc624. \uc774 \uc791\uc740 \ub370\uc774\ud130 \uc138\ud2b8\uc758 \uacbd\uc6b0 256 \ud06c\uae30\uc758 \uc740\ub2c9 \ub178\ub4dc(hidden node)\uc640 \ub2e8\uc77c GRU \uacc4\uce35 \uac19\uc740 \uc0c1\ub300\uc801\uc73c\ub85c \uc791\uc740 \ub124\ud2b8\uc6cc\ud06c\ub97c \uc0ac\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. MacBook CPU\uc5d0\uc11c \uc57d 40\ubd84 \ud6c4\uc5d0 \ud569\ub9ac\uc801\uc778 \uacb0\uacfc\ub97c \uc5bb\uc744 \uac83\uc785\ub2c8\ub2e4. \ucc38\uace0 \uc774 \ub178\ud2b8\ubd81\uc744 \uc2e4\ud589\ud558\uba74 \ud559\uc2b5, \ucee4\ub110 \uc911\ub2e8, \ud3c9\uac00\ub97c \ud560 \uc218 \uc788\uace0 \ub098\uc911\uc5d0 \uc774\uc5b4\uc11c \ud559\uc2b5\uc744 \ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc778\ucf54\ub354\uc640 \ub514\ucf54\ub354\uac00 \ucd08\uae30\ud654 \ub41c \ud589\uc744 \uc8fc\uc11d \ucc98\ub9ac\ud558\uace0 trainIters \ub97c \ub2e4\uc2dc \uc2e4\ud589\ud558\uc2ed\uc2dc\uc624. hidden_size = 128 batch_size = 32 input_lang, output_lang, train_dataloader = get_dataloader(batch_size) encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device) decoder = AttnDecoderRNN(hidden_size, output_lang.n_words).to(device) train(train_dataloader, encoder, decoder, 80, print_every=5, plot_every=5) Reading lines... Read 135842 sentence pairs Trimmed to 11445 sentence pairs Counting words... Counted words: fra 4601 eng 2991 0m 34s (- 8m 42s) (5 6%) 1.5170 1m 23s (- 9m 44s) (10 12%) 0.6699 2m 10s (- 9m 25s) (15 18%) 0.3511 2m 57s (- 8m 51s) (20 25%) 0.1969 3m 46s (- 8m 17s) (25 31%) 0.1227 4m 35s (- 7m 39s) (30 37%) 0.0856 6m 2s (- 7m 45s) (35 43%) 0.0657 6m 36s (- 6m 36s) (40 50%) 0.0525 7m 9s (- 5m 34s) (45 56%) 0.0459 7m 45s (- 4m 39s) (50 62%) 0.0409 8m 28s (- 3m 51s) (55 68%) 0.0372 9m 17s (- 3m 5s) (60 75%) 0.0347 10m 7s (- 2m 20s) (65 81%) 0.0329 10m 54s (- 1m 33s) (70 87%) 0.0314 11m 43s (- 0m 46s) (75 93%) 0.0306 12m 32s (- 0m 0s) (80 100%) 0.0287 \ub4dc\ub86d\uc544\uc6c3(dropout) \ub808\uc774\uc5b4\ub4e4\uc744 \ud3c9\uac00 (eval) \ubaa8\ub4dc\ub85c \uc124\uc815\ud569\ub2c8\ub2e4. encoder.eval() decoder.eval() evaluateRandomly(encoder, decoder) \u003e il est a la maison aujourd hui = he is at home today \u003c he is at home today \u003cEOS\u003e \u003e ce sont celles qui veulent y aller = they are the ones who want to go \u003c they are the ones who want to go \u003cEOS\u003e \u003e desole si je vous ai fait peur = i m sorry if i scared you \u003c i m sorry if i scared you \u003cEOS\u003e \u003e je suis heureux de te voir ici = i m happy to see you here \u003c i m glad to see you here \u003cEOS\u003e \u003e je prends mon apres midi demain = i m taking tomorrow afternoon off \u003c i m taking tomorrow afternoon off \u003cEOS\u003e \u003e tu es tres intelligente = you re very smart \u003c you re very intelligent \u003cEOS\u003e \u003e tu es malin = you re clever \u003c you re clever \u003cEOS\u003e \u003e je ne vais pas abandonner maintenant = i m not quitting now \u003c i m not quitting now \u003cEOS\u003e \u003e nous sommes sans emploi = we re unemployed \u003c we re unemployed \u003cEOS\u003e \u003e il est canadien = he is canadian \u003c he is canadian \u003cEOS\u003e Attention \uc2dc\uac01\ud654# Attention \uba54\ucee4\ub2c8\uc998\uc758 \uc720\uc6a9\ud55c \uc18d\uc131\uc740 \ud558\ub098\ub294 \ud574\uc11d \uac00\ub2a5\uc131\uc774 \ub192\uc740 \ucd9c\ub825\uc785\ub2c8\ub2e4. \uc785\ub825 \uc2dc\ud000\uc2a4\uc758 \ud2b9\uc815 \uc778\ucf54\ub354 \ucd9c\ub825\uc5d0 \uac00\uc911\uce58\ub97c \ubd80\uc5ec\ud558\ub294 \ub370 \uc0ac\uc6a9\ub418\ubbc0\ub85c \uac01 \uc2dc\uac04 \ub2e8\uacc4\uc5d0\uc11c \ub124\ud2b8\uc6cc\ud06c\uac00 \uac00\uc7a5 \uc9d1\uc911\ub418\ub294 \uc704\uce58\ub97c \ud30c\uc545\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. Attention \ucd9c\ub825\uc744 \ud589\ub82c\ub85c \ud45c\uc2dc\ud558\uae30 \uc704\ud574\uc11c\ub294 plt.matshow(attentions) \uc744 \uadf8\ub0e5 \uc2e4\ud589\ud574\ub3c4 \ub429\ub2c8\ub2e4. \ud558\uc9c0\ub9cc \uc880 \ub354 \ub098\uc740 \uc2dc\uac01\ud654\ub97c \uc704\ud574 \ucd95(axis)\uacfc \ub77c\ubca8(label)\uc744 \ucd94\uac00\ud558\ub294 \uc57d\uac04\uc758 \uc791\uc5c5\uc744 \ub354 \ud574\ubcf4\uaca0\uc2b5\ub2c8\ub2e4: def showAttention(input_sentence, output_words, attentions): fig = plt.figure() ax = fig.add_subplot(111) cax = ax.matshow(attentions.cpu().numpy(), cmap=\u0027bone\u0027) fig.colorbar(cax) # \ucd95 \uc124\uc815 ax.set_xticklabels([\u0027\u0027] + input_sentence.split(\u0027 \u0027) + [\u0027\u003cEOS\u003e\u0027], rotation=90) ax.set_yticklabels([\u0027\u0027] + output_words) # \ub9e4 \ud2f1\ub9c8\ub2e4 \ub77c\ubca8 \ubcf4\uc5ec\uc8fc\uae30 ax.xaxis.set_major_locator(ticker.MultipleLocator(1)) ax.yaxis.set_major_locator(ticker.MultipleLocator(1)) plt.show() def evaluateAndShowAttention(input_sentence): output_words, attentions = evaluate(encoder, decoder, input_sentence, input_lang, output_lang) print(\u0027input =\u0027, input_sentence) print(\u0027output =\u0027, \u0027 \u0027.join(output_words)) showAttention(input_sentence, output_words, attentions[0, :len(output_words), :]) evaluateAndShowAttention(\u0027il n est pas aussi grand que son pere\u0027) evaluateAndShowAttention(\u0027je suis trop fatigue pour conduire\u0027) evaluateAndShowAttention(\u0027je suis desole si c est une question idiote\u0027) evaluateAndShowAttention(\u0027je suis reellement fiere de vous\u0027) input = il n est pas aussi grand que son pere output = he is not as tall as his father \u003cEOS\u003e /workspace/tutorials-kr/intermediate_source/seq2seq_translation_tutorial.py:822: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator. /workspace/tutorials-kr/intermediate_source/seq2seq_translation_tutorial.py:824: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator. input = je suis trop fatigue pour conduire output = i am too tired to drive away \u003cEOS\u003e /workspace/tutorials-kr/intermediate_source/seq2seq_translation_tutorial.py:822: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator. /workspace/tutorials-kr/intermediate_source/seq2seq_translation_tutorial.py:824: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator. input = je suis desole si c est une question idiote output = i m sorry if this is a stupid question \u003cEOS\u003e /workspace/tutorials-kr/intermediate_source/seq2seq_translation_tutorial.py:822: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator. /workspace/tutorials-kr/intermediate_source/seq2seq_translation_tutorial.py:824: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator. input = je suis reellement fiere de vous output = i m really proud of you \u003cEOS\u003e /workspace/tutorials-kr/intermediate_source/seq2seq_translation_tutorial.py:822: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator. /workspace/tutorials-kr/intermediate_source/seq2seq_translation_tutorial.py:824: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator. \uc5f0\uc2b5# \ub2e4\ub978 \ub370\uc774\ud130 \uc14b\uc744 \uc2dc\ub3c4\ud574 \ubcf4\uc2ed\uc2dc\uc624 \ub2e4\ub978 \uc5b8\uc5b4\uc30d \uc0ac\ub78c \u2192 \uae30\uacc4 (e.g. IOT \uba85\ub839\uc5b4) \ucc44\ud305 \u2192 \uc751\ub2f5 \uc9c8\ubb38 \u2192 \ub2f5\ubcc0 word2vec \ub610\ub294 GloVe \uac19\uc740 \ubbf8\ub9ac \ud559\uc2b5\ub41c word embedding \uc73c\ub85c embedding \uc744 \uad50\uccb4\ud558\uc2ed\uc2dc\uc624 \ub354 \ub9ce\uc740 \ub808\uc774\uc5b4, \uc740\ub2c9 \uc720\ub2db, \ub354 \ub9ce\uc740 \ubb38\uc7a5\uc744 \uc0ac\uc6a9\ud558\uc2ed\uc2dc\uc624. \ud559\uc2b5 \uc2dc\uac04\uacfc \uacb0\uacfc\ub97c \ube44\uad50\ud574 \ubcf4\uc2ed\uc2dc\uc624 \ub9cc\uc57d \uac19\uc740 \uad6c\ubb38 \ub450\uac1c\uc758 \uc30d\uc73c\ub85c \ub41c \ubc88\uc5ed \ud30c\uc77c\uc744 \uc774\uc6a9\ud55c\ub2e4\uba74, (I am test \\t I am test), \uc774\uac83\uc744 \uc624\ud1a0\uc778\ucf54\ub354\ub85c \uc0ac\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc774\uac83\uc744 \uc2dc\ub3c4\ud574 \ubcf4\uc2ed\uc2dc\uc624: \uc624\ud1a0\uc778\ucf54\ub354 \ud559\uc2b5 \uc778\ucf54\ub354 \ub124\ud2b8\uc6cc\ud06c \uc800\uc7a5\ud558\uae30 \uadf8 \uc0c1\ud0dc\uc5d0\uc11c \ubc88\uc5ed\uc744 \uc704\ud55c \uc0c8\ub85c\uc6b4 \ub514\ucf54\ub354 \ud559\uc2b5 Total running time of the script: (12 minutes 42.958 seconds) Download Jupyter notebook: seq2seq_translation_tutorial.ipynb Download Python source code: seq2seq_translation_tutorial.py Download zipped: seq2seq_translation_tutorial.zip",
       "author": {
         "@type": "Organization",
         "name": "PyTorch Contributors",
         "url": "https://pytorch.org"
       },
       "image": "../_static/img/pytorch_seo.png",
       "mainEntityOfPage": {
         "@type": "WebPage",
         "@id": "/intermediate/seq2seq_translation_tutorial.html"
       },
       "datePublished": "2023-01-01T00:00:00Z",
       "dateModified": "2023-01-01T00:00:00Z"
     }
 </script>
  <script>
    // Tutorials Call to action event tracking
    $("[data-behavior='call-to-action-event']").on('click', function () {
      fbq('trackCustom', "Download", {
        tutorialTitle: $('h1:first').text(),
        downloadLink: this.href,
        tutorialLink: window.location.href,
        downloadTitle: $(this).attr("data-response")
      });
      if (typeof gtag === 'function') {
        gtag('event', 'click', {
          'event_category': $(this).attr("data-response"),
          'event_label': $("h1").first().text(),
          'tutorial_link': window.location.href
        });
      }
    });
  </script>
  
  </body>
</html>