
<!DOCTYPE html>


<html lang="ko" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <meta property="article:modified_time" content="2022-11-30T07:09:41+00:00" /><meta property="og:title" content="신경망(Neural Networks)" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://tutorials.pytorch.kr/beginner/blitz/neural_networks_tutorial.html" />
<meta property="og:site_name" content="PyTorch Tutorials KR" />
<meta property="og:description" content="신경망은 torch.nn 패키지를 사용하여 생성할 수 있습니다. 지금까지 autograd 를 살펴봤는데요, nn 은 모델을 정의하고 미분하는데 autograd 를 사용합니다. nn.Module 은 계층(layer)과 output 을 반환하는 forward(input) 메서드를 포함하고 있습니다. 숫자 이미지를 분류하는 신경망을 예제로 살펴보겠습니다: convnet convnet, 이는 간단한 순전파 네트워크(Feed-forward network)입니다. 입력(input)을 받아 여러 계층에 차례로 전달한 후, 최종 출력(out..." />
<meta property="og:image" content="https://tutorials.pytorch.kr/_static/logos/logo-kr-sm-dark.png" />
<meta property="og:image:alt" content="PyTorch Tutorials KR" />
<meta name="description" content="신경망은 torch.nn 패키지를 사용하여 생성할 수 있습니다. 지금까지 autograd 를 살펴봤는데요, nn 은 모델을 정의하고 미분하는데 autograd 를 사용합니다. nn.Module 은 계층(layer)과 output 을 반환하는 forward(input) 메서드를 포함하고 있습니다. 숫자 이미지를 분류하는 신경망을 예제로 살펴보겠습니다: convnet convnet, 이는 간단한 순전파 네트워크(Feed-forward network)입니다. 입력(input)을 받아 여러 계층에 차례로 전달한 후, 최종 출력(out..." />
<meta property="og:ignore_canonical" content="true" />

    <title>신경망(Neural Networks) &#8212; 파이토치 한국어 튜토리얼 (PyTorch tutorials in Korean)</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=536c50fe" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=4d2595e5" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/katex-math.css?v=91adb8b6" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/pytorch_theme.css?v=c326296f" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/custom.css?v=097efa9c" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/custom2.css?v=b169ea90" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../_static/documentation_options.js?v=725a5b95"></script>
    <script src="../../_static/doctools.js?v=92e14aea"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/translations.js?v=b5f768d8"></script>
    <script src="../../_static/katex.min.js?v=be8ff15f"></script>
    <script src="../../_static/auto-render.min.js?v=ad136472"></script>
    <script src="../../_static/katex_autorenderer.js?v=bebc588a"></script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'beginner/blitz/neural_networks_tutorial';</script>
    <link rel="canonical" href="https://tutorials.pytorch.kr/beginner/blitz/neural_networks_tutorial.html" />
    <link rel="icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="색인" href="../../genindex.html" />
    <link rel="search" title="검색" href="../../search.html" />
    <link rel="next" title="분류기(Classifier) 학습하기" href="cifar10_tutorial.html" />
    <link rel="prev" title="torch.autograd 에 대한 간단한 소개" href="autograd_tutorial.html" />

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="ko"/>
    <meta name="docbuild:last-update" content="2022년 11월 30일"/>
<script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/2.3.1/list.min.js"></script>
<script>
  if (window.location.hostname === 'docs.pytorch.org' || window.location.hostname === 'docs-preview.pytorch.org') {
    const script = document.createElement('script');
    script.src = 'https://cmp.osano.com/16A0DbT9yDNIaQkvZ/31b1b91a-e0b6-47ea-bde2-7f2bd13dbe5c/osano.js?variant=one';
    document.head.appendChild(script);
  }
</script>
<script>
  // Cookie banner for non-LF projects
  document.addEventListener('DOMContentLoaded', function () {
    // Hide cookie banner on local environments and LF owned docs
    if (window.location.hostname === 'localhost' ||
      window.location.hostname === '0.0.0.0' ||
      window.location.hostname === '127.0.0.1' ||
      window.location.hostname === 'docs.pytorch.org' ||
      window.location.hostname === 'docs-preview.pytorch.org' ||
      window.location.hostname.startsWith('192.168.')) {
      const banner = document.querySelector('.cookie-banner-wrapper');
      if (banner) {
        banner.style.display = 'none';
      }
    }
  });
</script>
<!-- Conditional CSS for header and footer height adjustment -->

<link rel="stylesheet" type="text/css" href="../../_static/css/theme.css" crossorigin="anonymous">
<script type="text/javascript" src="../../_static/js/theme.js"></script>
<script type="text/javascript" src="../../_static/js/dropdown-menu.js"></script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Nanum+Gothic:wght@400;700&family=Nanum+Gothic+Coding:wght@400;700&family=Montserrat:wght@300;400&display=swap" rel="stylesheet">
<meta property="og:image" content="../../_static/img/pytorch_seo.png" />
<link rel="stylesheet" href="../../_static/webfonts/all.min.css" crossorigin="anonymous">
<meta http-equiv="Content-Security-Policy"
  content="default-src * 'unsafe-inline' 'unsafe-eval' data: blob:; style-src * 'unsafe-inline'; script-src * 'unsafe-inline' 'unsafe-eval' blob:;">
<meta name="pytorch_project" content="tutorials">
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=G-LZRD6GXDLF" height="0" width="0"
    style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
<!-- Google Tag Manager -->
<script>(function (w, d, s, l, i) {
    w[l] = w[l] || []; w[l].push({
      'gtm.start':
        new Date().getTime(), event: 'gtm.js'
    }); var f = d.getElementsByTagName(s)[0],
      j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : ''; j.async = true; j.src =
        'https://www.googletagmanager.com/gtm.js?id=' + i + dl; f.parentNode.insertBefore(j, f);
    j.onload = function () {
      window.dispatchEvent(new Event('gtm_loaded'));
      console.log('GTM loaded successfully');
    };
  })(window, document, 'script', 'dataLayer', 'G-LZRD6GXDLF');
</script>
<!-- End Google Tag Manager -->
<!-- Facebook Pixel Code -->
<script>
  !function (f, b, e, v, n, t, s) {
    if (f.fbq) return; n = f.fbq = function () {
      n.callMethod ?
        n.callMethod.apply(n, arguments) : n.queue.push(arguments)
    };
    if (!f._fbq) f._fbq = n; n.push = n; n.loaded = !0; n.version = '2.0';
    n.queue = []; t = b.createElement(e); t.async = !0;
    t.src = v; s = b.getElementsByTagName(e)[0];
    s.parentNode.insertBefore(t, s)
  }(window, document, 'script',
    'https://connect.facebook.net/en_US/fbevents.js');
  fbq('init', '243028289693773');
  fbq('track', 'PageView');
</script>
<script>
  document.documentElement.setAttribute('data-version', 'v2.8.0+cu128');
</script>
<noscript>
  <img height="1" width="1" src="https://www.facebook.com/tr?id=243028289693773&ev=PageView&noscript=1" />
</noscript>
<script>
  function gtag() {
    window.dataLayer.push(arguments);
  }
</script>
<!-- End Facebook Pixel Code -->
<!-- Script to Fix scrolling -->
<script>
  document.addEventListener('DOMContentLoaded', function () {
    // Fix anchor scrolling
    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener('click', function (e) {
        e.preventDefault();
        const targetId = this.getAttribute('href').substring(1);
        const targetElement = document.getElementById(targetId);

        if (targetElement) {
          const headerHeight =
            (document.querySelector('.header-holder') ? document.querySelector('.header-holder').offsetHeight : 0) +
            (document.querySelector('.bd-header') ? document.querySelector('.bd-header').offsetHeight : 0) + 20;

          const targetPosition = targetElement.getBoundingClientRect().top + window.pageYOffset - headerHeight;
          window.scrollTo({
            top: targetPosition,
            behavior: 'smooth'
          });

          // Update URL hash without scrolling
          history.pushState(null, null, '#' + targetId);
        }
      });
    });
  });
</script>

<script async src="https://cse.google.com/cse.js?cx=e65585f8c3ea1440e"></script>


  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="ko"/>
    <meta name="docbuild:last-update" content="2022년 11월 30일"/>

  </head>

<body data-feedback-url="https://github.com/PyTorchKorea/tutorials-kr" class="pytorch-body">
  
    <div class="container-fluid header-holder tutorials-header" id="header-holder">
   <div class="header-container-wrapper">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.kr/" aria-label="PyTorchKR"></a>

      <div class="main-menu">
        <ul>

          <li class="main-menu-item">
          <div id="learnDropdownButton" data-toggle="learn-dropdown" class="learn-dropdown">
              <a class="with-down-arrow">
                <span>배우기</span>
              </a>
              <div class="learn-dropdown-menu dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.kr/get-started/locally/">
                  <span class="dropdown-title">PyTorch 시작하기</span>
                </a>
                <a class="nav-dropdown-item" href="https://tutorials.pytorch.kr/beginner/basics/intro.html">
                  <span class="dropdown-title">기본 익히기</span>
                </a>
                <a class="nav-dropdown-item" href="https://tutorials.pytorch.kr/" target="_self">
                  <span class="dropdown-title">한국어 튜토리얼</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.kr/hub/">
                  <span class="dropdown-title">한국어 모델 허브</span>
                </a>
                <a class="nav-dropdown-item" href="https://docs.pytorch.org/tutorials/" target="_blank">
                  <span class="dropdown-title">Official Tutorials</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <a href="https://pytorch.kr/blog/">
              <span>블로그</span>
            </a>
          </li>

          <li class="main-menu-item">
          <div id="docsDropdownButton" data-toggle="docs-dropdown" class="docs-dropdown">
              <a class="with-down-arrow">
              <span>문서</span>
              </a>
              <div class="docs-dropdown-menu dropdown-menu">
                <a class="nav-dropdown-item" href="https://docs.pytorch.org/docs/" target="_blank">
                  <span class="dropdown-title">PyTorch API</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.kr/domains/">
                  <span class="dropdown-title">Domain API 소개</span>
                </a>
                <a class="nav-dropdown-item" href="https://tutorials.pytorch.kr/" target="_self">
                  <span class="dropdown-title">한국어 튜토리얼</span>
                </a>
                <a class="nav-dropdown-item" href="https://docs.pytorch.org/tutorials/" target="_blank">
                  <span class="dropdown-title">Official Tutorials</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
          <div id="communityDropdownButton" data-toggle="community-dropdown" class="community-dropdown">
              <a class="with-down-arrow">
              <span>커뮤니티</span>
              </a>
              <div class="community-dropdown-menu dropdown-menu">
                <a class="nav-dropdown-item" href="https://discuss.pytorch.kr/" target="_self">
                  <span class="dropdown-title">한국어 커뮤니티</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.kr/resources/">
                  <span class="dropdown-title">개발자 정보</span>
                </a>
                <a class="nav-dropdown-item" href="https://landscape.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Landscape</span>
                </a>
              </div>
            </div>
          </li>

        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu">
        <i class="fa-solid fa-ellipsis"></i>
      </a>
    </div>
  </div>
 </div>

 <!-- Begin Mobile Menu -->

<div class="mobile-main-menu">
  <div class="container-fluid">
    <div class="header-container-wrapper">
      <div class="mobile-main-menu-header-container">
        <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu">
          <i class="fa-solid fa-xmark"></i>
        </a>
      </div>
    </div>
  </div>

  <div class="mobile-main-menu-links-container">
    <div class="main-menu">
      <ul>
         <li class="resources-mobile-menu-title">
           <a>배우기</a>
         </li>
         <ul class="resources-mobile-menu-items">
           <li>
             <a href="https://pytorch.kr/get-started/locally/">PyTorch 시작하기</a>
           </li>
           <li>
             <a href="https://tutorials.pytorch.kr/beginner/basics/intro.html">기본 익히기</a>
           </li>
           <li>
             <a href="https://tutorials.pytorch.kr/">한국어 튜토리얼</a>
           </li>
           <li>
             <a href="https://pytorch.kr/hub/">한국어 모델 허브</a>
           </li>
           <li>
             <a href="https://docs.pytorch.org/tutorials/" target="_blank">Official Tutorials</a>
           </li>
        </ul>
         <li class="resources-mobile-menu-title">
           <a href="https://pytorch.kr/blog/">블로그</a>
         </li>
         <li class="resources-mobile-menu-title">
           <a>문서</a>
         </li>
         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://docs.pytorch.org/docs/" target="_blank">PyTorch API</a>
          </li>
          <li>
            <a href="https://pytorch.kr/domains/">Domain API 소개</a>
          </li>
          <li>
            <a href="https://tutorials.pytorch.kr/">한국어 튜토리얼</a>
          </li>
          <li>
            <a href="https://docs.pytorch.org/tutorials/" target="_blank">Official Tutorials</a>
          </li>
        </ul>
        <li class="resources-mobile-menu-title">
          <a>커뮤니티</a>
        </li>
         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://discuss.pytorch.kr/">한국어 커뮤니티</a>
          </li>
          <li>
            <a href="https://pytorch.kr/resources/">개발자 정보</a>
          </li>
          <li>
            <a href="https://landscape.pytorch.org/" target="_blank">Landscape</a>
          </li>
        </ul>
      </ul>
    </div>
  </div>
</div>

<!-- End Mobile Menu -->
  
  
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">
  <a href="../../index.html" class="version">v2.8.0+cu128</a>
</div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../../intro.html">
    Intro
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../compilers_index.html">
    Compilers
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../domains.html">
    Domains
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../distributed.html">
    Distributed
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../deep-dive.html">
    Deep Dive
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../extension.html">
    Extension
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../ecosystem.html">
    Ecosystem
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../recipes_index.html">
    Recipes
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
      
        <div class="navbar-item">
<div class="search-container-wrapper">
  <div id="sphinx-search" class="search-container">
    
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </div>

  <div id="google-search" class="search-container" style="display:none;">
    <div class="gcse-search-wrapper">
      <i class="fa-solid fa-magnifying-glass" aria-hidden="true"></i>
      <div class="gcse-search"></div>
    </div>
  </div>

  <div class="search-toggle-container" data-bs-title="Google Search Off" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <div class="search-toggle-inner">
      <label class="switch">
        <input type="checkbox" id="search-toggle">
        <span class="slider round"></span>
      </label>
    </div>
  </div>
</div>

<script>
  document.addEventListener('DOMContentLoaded', function() {
  // Define the search callback
  const myWebSearchStartingCallback = (gname, query) => {
    if (typeof dataLayer !== 'undefined' && query) {
      window.dataLayer = window.dataLayer || [];
      dataLayer.push({
        'event': 'google_search',
        'search_term': query,
        'event_category': 'Search',
        'event_label': 'Google Search'
      });
    }
    return '';
  };

  // Set up the GCSE search callbacks
  window.__gcse || (window.__gcse = {});
  window.__gcse.searchCallbacks = {
    web: { starting: myWebSearchStartingCallback }
  };

  if (window.location.pathname.includes('/search.html')) {
    document.body.classList.add('search-page');
  }

  // Function to reinitialize Google CSE
  function reinitializeGoogleSearch() {
    if (window.__gcse && window.__gcse.initializationCallback) {
      window.__gcse.initializationCallback();
    }
  }

  // Function to handle search toggle
  function handleSearchToggle(toggle, sphinxSearch, googleSearch) {
    if (!toggle || !sphinxSearch || !googleSearch) return;

    // Check if the URL contains /stable/ or /tutorials/
    const currentUrl = window.location.href;
    // TODO: We've had reports that the google programmable search is returning stale documentation,
    //       Simple reproduction is to turn google search on and search for multinomial which will
    //       result in returning 1.8.1 documentation.
    //       We should turn this back on when we resolve that bug.
    const shouldDefaultToGoogle = false;
    const savedPreference = localStorage.getItem('searchPreference');

    // Set initial state
    if (savedPreference === 'google' || (savedPreference === null && shouldDefaultToGoogle)) {
      toggle.checked = true;
      sphinxSearch.style.display = 'none';
      googleSearch.style.display = 'block';
      if (savedPreference === null) {
        localStorage.setItem('searchPreference', 'google');
      }
      reinitializeGoogleSearch();
    } else {
      toggle.checked = false;
      sphinxSearch.style.display = 'block';
      googleSearch.style.display = 'none';
    }

    // Update tooltip
    updateTooltip(toggle.checked);

    // Skip if already initialized
    if (toggle.hasAttribute('data-initialized')) return;
    toggle.setAttribute('data-initialized', 'true');

    toggle.addEventListener('change', function() {
      if (this.checked) {
        sphinxSearch.style.display = 'none';
        googleSearch.style.display = 'block';
        localStorage.setItem('searchPreference', 'google');
        reinitializeGoogleSearch();
        trackSearchEngineSwitch('Google');
      } else {
        sphinxSearch.style.display = 'block';
        googleSearch.style.display = 'none';
        localStorage.setItem('searchPreference', 'sphinx');
        trackSearchEngineSwitch('Sphinx');
      }

      updateTooltip(this.checked);
      updateMobileSearch();
    });
  }

  // Update tooltip based on toggle state
  function updateTooltip(isChecked) {
    const tooltipElement = document.querySelector('.search-toggle-container');
    if (!tooltipElement) return;

    tooltipElement.setAttribute('data-bs-title', isChecked ? 'Google Search On' : 'Google Search Off');

    if (bootstrap && bootstrap.Tooltip) {
      const tooltipInstance = bootstrap.Tooltip.getInstance(tooltipElement);
      if (tooltipInstance) tooltipInstance.dispose();
      new bootstrap.Tooltip(tooltipElement);
    }
  }

  // Track search engine switch
  function trackSearchEngineSwitch(engine) {
    if (typeof dataLayer !== 'undefined') {
      window.dataLayer = window.dataLayer || [];
      dataLayer.push({
        'event': 'search_engine_switch',
        'event_category': 'Search',
        'event_label': engine
      });
    }
  }

  // Function to update mobile search based on current toggle state
  function updateMobileSearch() {
    const toggle = document.getElementById('search-toggle');
    if (!toggle) return;

    const mobileSearchContainer = document.querySelector('.sidebar-header-items__end .navbar-item .search-container-wrapper');
    if (!mobileSearchContainer) return;

    const mobileSphinxSearch = mobileSearchContainer.querySelector('#sphinx-search');
    const mobileGoogleSearch = mobileSearchContainer.querySelector('#google-search');

    if (mobileSphinxSearch && mobileGoogleSearch) {
      mobileSphinxSearch.style.display = toggle.checked ? 'none' : 'block';
      mobileGoogleSearch.style.display = toggle.checked ? 'block' : 'none';

      if (toggle.checked) {
        reinitializeGoogleSearch();
      }
    }
  }

  // Initialize desktop search toggle
  const toggle = document.getElementById('search-toggle');
  const sphinxSearch = document.getElementById('sphinx-search');
  const googleSearch = document.getElementById('google-search');
  handleSearchToggle(toggle, sphinxSearch, googleSearch);

  // Set placeholder text for Google search input
  const observer = new MutationObserver(function() {
    document.querySelectorAll('.gsc-input input').forEach(input => {
      if (input && !input.hasAttribute('data-placeholder-set')) {
        input.setAttribute('placeholder', 'Search the docs ...');
        input.setAttribute('data-placeholder-set', 'true');
      }
    });
  });

  observer.observe(document.body, { childList: true, subtree: true });

  // Fix for scroll jump issue - improved approach
  function setupSearchInputHandlers(input) {
    if (input.hasAttribute('data-scroll-fixed')) return;
    input.setAttribute('data-scroll-fixed', 'true');

    let lastScrollPosition = 0;
    let isTyping = false;
    let scrollTimeout;

    // Save position before typing starts
    input.addEventListener('keydown', () => {
      lastScrollPosition = window.scrollY;
      isTyping = true;

      // Reset typing state after a short delay
      clearTimeout(scrollTimeout);
      scrollTimeout = setTimeout(() => {
        isTyping = false;
      }, 100);
    });

    // Only maintain scroll position during typing
    function maintainScroll() {
      if (document.activeElement === input && isTyping) {
        window.scrollTo(0, lastScrollPosition);
        requestAnimationFrame(maintainScroll);
      }
    }

    input.addEventListener('focus', () => {
      // Just store initial position but don't force it
      lastScrollPosition = window.scrollY;
    });

    input.addEventListener('input', () => {
      isTyping = true;
      window.scrollTo(0, lastScrollPosition);

      // Reset typing state after a short delay
      clearTimeout(scrollTimeout);
      scrollTimeout = setTimeout(() => {
        isTyping = false;
      }, 100);

      requestAnimationFrame(maintainScroll);
    });
  }

  // Apply to all search inputs and observe for new ones
  function applyToSearchInputs() {
    document.querySelectorAll('.search-container input, .gsc-input input').forEach(setupSearchInputHandlers);
  }

  applyToSearchInputs();

  const searchObserver = new MutationObserver(applyToSearchInputs);
  searchObserver.observe(document.body, { childList: true, subtree: true });

  // Watch for mobile menu creation
  const mobileMenuObserver = new MutationObserver(function(mutations) {
    for (const mutation of mutations) {
      if (!mutation.addedNodes.length) continue;

      // Style mobile search inputs
      document.querySelectorAll('.sidebar-header-items__end .navbar-item .search-container-wrapper .gsc-input input').forEach(input => {
        if (input) {
          input.setAttribute('placeholder', 'Search the docs ...');
          input.style.paddingLeft = '36px';
        }
      });

      // Check for mobile search container
      const mobileSearchContainer = document.querySelector('.sidebar-header-items__end .navbar-item .search-container-wrapper');
      if (!mobileSearchContainer) continue;

      const mobileToggle = mobileSearchContainer.querySelector('#search-toggle');
      if (mobileToggle && toggle) {
        // Sync mobile toggle with desktop toggle
        mobileToggle.checked = toggle.checked;
        updateMobileSearch();

        // Add event listener to mobile toggle if not already added
        if (!mobileToggle.hasAttribute('data-initialized')) {
          mobileToggle.setAttribute('data-initialized', 'true');
          mobileToggle.addEventListener('change', function() {
            // Sync desktop toggle with mobile toggle
            toggle.checked = this.checked;
            // Trigger change event on desktop toggle to update both
            toggle.dispatchEvent(new Event('change'));
          });
        }
      }
    }
  });

  mobileMenuObserver.observe(document.body, { childList: true, subtree: true });

  // Ensure Google CSE is properly loaded
  if (window.__gcse) {
    window.__gcse.callback = function() {
      // This will run after Google CSE is fully loaded
      if (toggle && toggle.checked) {
        reinitializeGoogleSearch();
      }
    };
  } else {
    window.__gcse = {
      callback: function() {
        if (toggle && toggle.checked) {
          reinitializeGoogleSearch();
        }
      }
    };
  }
});
</script>
</div>
      
        <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/PyTorchKorea/tutorials-kr" title="한국어 튜토리얼 GitHub 저장소" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">한국어 튜토리얼 GitHub 저장소</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discuss.pytorch.kr/" title="파이토치 한국어 커뮤니티" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">파이토치 한국어 커뮤니티</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../../intro.html">
    Intro
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../compilers_index.html">
    Compilers
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../domains.html">
    Domains
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../distributed.html">
    Distributed
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../deep-dive.html">
    Deep Dive
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../extension.html">
    Extension
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../ecosystem.html">
    Ecosystem
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../recipes_index.html">
    Recipes
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
<div class="search-container-wrapper">
  <div id="sphinx-search" class="search-container">
    
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </div>

  <div id="google-search" class="search-container" style="display:none;">
    <div class="gcse-search-wrapper">
      <i class="fa-solid fa-magnifying-glass" aria-hidden="true"></i>
      <div class="gcse-search"></div>
    </div>
  </div>

  <div class="search-toggle-container" data-bs-title="Google Search Off" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <div class="search-toggle-inner">
      <label class="switch">
        <input type="checkbox" id="search-toggle">
        <span class="slider round"></span>
      </label>
    </div>
  </div>
</div>

<script>
  document.addEventListener('DOMContentLoaded', function() {
  // Define the search callback
  const myWebSearchStartingCallback = (gname, query) => {
    if (typeof dataLayer !== 'undefined' && query) {
      window.dataLayer = window.dataLayer || [];
      dataLayer.push({
        'event': 'google_search',
        'search_term': query,
        'event_category': 'Search',
        'event_label': 'Google Search'
      });
    }
    return '';
  };

  // Set up the GCSE search callbacks
  window.__gcse || (window.__gcse = {});
  window.__gcse.searchCallbacks = {
    web: { starting: myWebSearchStartingCallback }
  };

  if (window.location.pathname.includes('/search.html')) {
    document.body.classList.add('search-page');
  }

  // Function to reinitialize Google CSE
  function reinitializeGoogleSearch() {
    if (window.__gcse && window.__gcse.initializationCallback) {
      window.__gcse.initializationCallback();
    }
  }

  // Function to handle search toggle
  function handleSearchToggle(toggle, sphinxSearch, googleSearch) {
    if (!toggle || !sphinxSearch || !googleSearch) return;

    // Check if the URL contains /stable/ or /tutorials/
    const currentUrl = window.location.href;
    // TODO: We've had reports that the google programmable search is returning stale documentation,
    //       Simple reproduction is to turn google search on and search for multinomial which will
    //       result in returning 1.8.1 documentation.
    //       We should turn this back on when we resolve that bug.
    const shouldDefaultToGoogle = false;
    const savedPreference = localStorage.getItem('searchPreference');

    // Set initial state
    if (savedPreference === 'google' || (savedPreference === null && shouldDefaultToGoogle)) {
      toggle.checked = true;
      sphinxSearch.style.display = 'none';
      googleSearch.style.display = 'block';
      if (savedPreference === null) {
        localStorage.setItem('searchPreference', 'google');
      }
      reinitializeGoogleSearch();
    } else {
      toggle.checked = false;
      sphinxSearch.style.display = 'block';
      googleSearch.style.display = 'none';
    }

    // Update tooltip
    updateTooltip(toggle.checked);

    // Skip if already initialized
    if (toggle.hasAttribute('data-initialized')) return;
    toggle.setAttribute('data-initialized', 'true');

    toggle.addEventListener('change', function() {
      if (this.checked) {
        sphinxSearch.style.display = 'none';
        googleSearch.style.display = 'block';
        localStorage.setItem('searchPreference', 'google');
        reinitializeGoogleSearch();
        trackSearchEngineSwitch('Google');
      } else {
        sphinxSearch.style.display = 'block';
        googleSearch.style.display = 'none';
        localStorage.setItem('searchPreference', 'sphinx');
        trackSearchEngineSwitch('Sphinx');
      }

      updateTooltip(this.checked);
      updateMobileSearch();
    });
  }

  // Update tooltip based on toggle state
  function updateTooltip(isChecked) {
    const tooltipElement = document.querySelector('.search-toggle-container');
    if (!tooltipElement) return;

    tooltipElement.setAttribute('data-bs-title', isChecked ? 'Google Search On' : 'Google Search Off');

    if (bootstrap && bootstrap.Tooltip) {
      const tooltipInstance = bootstrap.Tooltip.getInstance(tooltipElement);
      if (tooltipInstance) tooltipInstance.dispose();
      new bootstrap.Tooltip(tooltipElement);
    }
  }

  // Track search engine switch
  function trackSearchEngineSwitch(engine) {
    if (typeof dataLayer !== 'undefined') {
      window.dataLayer = window.dataLayer || [];
      dataLayer.push({
        'event': 'search_engine_switch',
        'event_category': 'Search',
        'event_label': engine
      });
    }
  }

  // Function to update mobile search based on current toggle state
  function updateMobileSearch() {
    const toggle = document.getElementById('search-toggle');
    if (!toggle) return;

    const mobileSearchContainer = document.querySelector('.sidebar-header-items__end .navbar-item .search-container-wrapper');
    if (!mobileSearchContainer) return;

    const mobileSphinxSearch = mobileSearchContainer.querySelector('#sphinx-search');
    const mobileGoogleSearch = mobileSearchContainer.querySelector('#google-search');

    if (mobileSphinxSearch && mobileGoogleSearch) {
      mobileSphinxSearch.style.display = toggle.checked ? 'none' : 'block';
      mobileGoogleSearch.style.display = toggle.checked ? 'block' : 'none';

      if (toggle.checked) {
        reinitializeGoogleSearch();
      }
    }
  }

  // Initialize desktop search toggle
  const toggle = document.getElementById('search-toggle');
  const sphinxSearch = document.getElementById('sphinx-search');
  const googleSearch = document.getElementById('google-search');
  handleSearchToggle(toggle, sphinxSearch, googleSearch);

  // Set placeholder text for Google search input
  const observer = new MutationObserver(function() {
    document.querySelectorAll('.gsc-input input').forEach(input => {
      if (input && !input.hasAttribute('data-placeholder-set')) {
        input.setAttribute('placeholder', 'Search the docs ...');
        input.setAttribute('data-placeholder-set', 'true');
      }
    });
  });

  observer.observe(document.body, { childList: true, subtree: true });

  // Fix for scroll jump issue - improved approach
  function setupSearchInputHandlers(input) {
    if (input.hasAttribute('data-scroll-fixed')) return;
    input.setAttribute('data-scroll-fixed', 'true');

    let lastScrollPosition = 0;
    let isTyping = false;
    let scrollTimeout;

    // Save position before typing starts
    input.addEventListener('keydown', () => {
      lastScrollPosition = window.scrollY;
      isTyping = true;

      // Reset typing state after a short delay
      clearTimeout(scrollTimeout);
      scrollTimeout = setTimeout(() => {
        isTyping = false;
      }, 100);
    });

    // Only maintain scroll position during typing
    function maintainScroll() {
      if (document.activeElement === input && isTyping) {
        window.scrollTo(0, lastScrollPosition);
        requestAnimationFrame(maintainScroll);
      }
    }

    input.addEventListener('focus', () => {
      // Just store initial position but don't force it
      lastScrollPosition = window.scrollY;
    });

    input.addEventListener('input', () => {
      isTyping = true;
      window.scrollTo(0, lastScrollPosition);

      // Reset typing state after a short delay
      clearTimeout(scrollTimeout);
      scrollTimeout = setTimeout(() => {
        isTyping = false;
      }, 100);

      requestAnimationFrame(maintainScroll);
    });
  }

  // Apply to all search inputs and observe for new ones
  function applyToSearchInputs() {
    document.querySelectorAll('.search-container input, .gsc-input input').forEach(setupSearchInputHandlers);
  }

  applyToSearchInputs();

  const searchObserver = new MutationObserver(applyToSearchInputs);
  searchObserver.observe(document.body, { childList: true, subtree: true });

  // Watch for mobile menu creation
  const mobileMenuObserver = new MutationObserver(function(mutations) {
    for (const mutation of mutations) {
      if (!mutation.addedNodes.length) continue;

      // Style mobile search inputs
      document.querySelectorAll('.sidebar-header-items__end .navbar-item .search-container-wrapper .gsc-input input').forEach(input => {
        if (input) {
          input.setAttribute('placeholder', 'Search the docs ...');
          input.style.paddingLeft = '36px';
        }
      });

      // Check for mobile search container
      const mobileSearchContainer = document.querySelector('.sidebar-header-items__end .navbar-item .search-container-wrapper');
      if (!mobileSearchContainer) continue;

      const mobileToggle = mobileSearchContainer.querySelector('#search-toggle');
      if (mobileToggle && toggle) {
        // Sync mobile toggle with desktop toggle
        mobileToggle.checked = toggle.checked;
        updateMobileSearch();

        // Add event listener to mobile toggle if not already added
        if (!mobileToggle.hasAttribute('data-initialized')) {
          mobileToggle.setAttribute('data-initialized', 'true');
          mobileToggle.addEventListener('change', function() {
            // Sync desktop toggle with mobile toggle
            toggle.checked = this.checked;
            // Trigger change event on desktop toggle to update both
            toggle.dispatchEvent(new Event('change'));
          });
        }
      }
    }
  });

  mobileMenuObserver.observe(document.body, { childList: true, subtree: true });

  // Ensure Google CSE is properly loaded
  if (window.__gcse) {
    window.__gcse.callback = function() {
      // This will run after Google CSE is fully loaded
      if (toggle && toggle.checked) {
        reinitializeGoogleSearch();
      }
    };
  } else {
    window.__gcse = {
      callback: function() {
        if (toggle && toggle.checked) {
          reinitializeGoogleSearch();
        }
      }
    };
  }
});
</script>
</div>
        
          <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/PyTorchKorea/tutorials-kr" title="한국어 튜토리얼 GitHub 저장소" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">한국어 튜토리얼 GitHub 저장소</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discuss.pytorch.kr/" title="파이토치 한국어 커뮤니티" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">파이토치 한국어 커뮤니티</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Getting Started with PyTorch</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../basics/intro.html">파이토치(PyTorch) 기본 익히기</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="simple">
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../introyt/introyt_index.html">PyTorch 소개 - YouTube 시리즈</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../introyt/introyt1_tutorial.html">PyTorch 소개</a></li>
<li class="toctree-l2"><a class="reference internal" href="../introyt/tensors_deeper_tutorial.html">Pytorch Tensor 소개</a></li>
<li class="toctree-l2"><a class="reference internal" href="../introyt/autogradyt_tutorial.html">The Fundamentals of Autograd</a></li>
<li class="toctree-l2"><a class="reference internal" href="../introyt/modelsyt_tutorial.html">Building Models with PyTorch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../introyt/tensorboardyt_tutorial.html">PyTorch TensorBoard 지원</a></li>
<li class="toctree-l2"><a class="reference internal" href="../introyt/trainingyt.html">Training with PyTorch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../introyt/captumyt.html">Model Understanding with Captum</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Learning PyTorch</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../deep_learning_60min_blitz.html">PyTorch로 딥러닝하기: 60분만에 끝장내기</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="tensor_tutorial.html">텐서(Tensor)</a></li>
<li class="toctree-l2"><a class="reference internal" href="autograd_tutorial.html"><code class="docutils literal notranslate"><span class="pre">torch.autograd</span></code> 에 대한 간단한 소개</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">신경망(Neural Networks)</a></li>
<li class="toctree-l2"><a class="reference internal" href="cifar10_tutorial.html">분류기(Classifier) 학습하기</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../pytorch_with_examples.html">예제로 배우는 파이토치(PyTorch)</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../examples_tensor/polynomial_numpy.html">준비 운동: NumPy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../examples_tensor/polynomial_tensor.html">파이토치(PyTorch): 텐서(Tensor)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../examples_autograd/polynomial_autograd.html">PyTorch: 텐서(Tensor)와 autograd</a></li>
<li class="toctree-l2"><a class="reference internal" href="../examples_autograd/polynomial_custom_function.html">PyTorch: 새 autograd Function 정의하기</a></li>
<li class="toctree-l2"><a class="reference internal" href="../examples_nn/polynomial_nn.html">PyTorch: nn</a></li>
<li class="toctree-l2"><a class="reference internal" href="../examples_nn/polynomial_optim.html">PyTorch: optim</a></li>
<li class="toctree-l2"><a class="reference internal" href="../examples_nn/polynomial_module.html">PyTorch: 사용자 정의 nn.Module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../examples_nn/dynamic_net.html">PyTorch: 제어 흐름(Control Flow) + 가중치 공유(Weight Sharing)</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../nn_tutorial.html"><cite>torch.nn</cite> 이 <em>실제로</em> 무엇인가요?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../understanding_leaf_vs_nonleaf_tutorial.html">Understanding requires_grad, retain_grad, Leaf, and Non-leaf Tensors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/nlp_from_scratch_index.html">NLP from Scratch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/tensorboard_tutorial.html">TensorBoard로 모델, 데이터, 학습 시각화하기</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/pinmem_nonblock.html">A guide on good usage of <code class="docutils literal notranslate"><span class="pre">non_blocking</span></code> and <code class="docutils literal notranslate"><span class="pre">pin_memory()</span></code> in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/visualizing_gradients_tutorial.html">Visualizing Gradients</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../../intro.html" class="nav-link">Intro</a></li>
    
    
    <li class="breadcrumb-item"><a href="../deep_learning_60min_blitz.html" class="nav-link">PyTorch로 딥러닝하기: 60분만에 끝장내기</a></li>
    
    <li class="breadcrumb-item active" aria-current="page">신경망(Neural Networks)</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
        
    </div>
</div>
</div>
      
    </div>
  
</div>
</div>
              
              
  
<div id="searchbox"></div>
  <article class="bd-article" id="pytorch-article">
    <!-- Hidden breadcrumb schema for SEO only -->
    <div style="display:none;" itemscope itemtype="https://schema.org/BreadcrumbList">
      
      <div itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <link itemprop="item" href="../../intro.html">
        <meta itemprop="name" content="Intro">
        <meta itemprop="position" content="1">
      </div>
      
      <div itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <link itemprop="item" href="../deep_learning_60min_blitz.html">
        <meta itemprop="name" content="PyTorch로 딥러닝하기: 60분만에 끝장내기">
        <meta itemprop="position" content="2">
      </div>
      
      <div itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <meta itemprop="name" content="신경망(Neural Networks)">
        <meta itemprop="position" content="3">
      </div>
    </div>

    
    <script>
      if ((window.location.href.indexOf("/unstable/") != -1) && (window.location.href.indexOf("/unstable/unstable_index") < 1)) {
        var div = '<div class="prototype-banner"><i class="fa fa-flask" aria-hidden="true"></i> <strong>Unstable feature:</strong> Not typically available in binary distributions like PyPI. Early stage for feedback and testing.</div>'
        document.addEventListener('DOMContentLoaded', function () {
          document.getElementById("pytorch-article").insertAdjacentHTML('afterBegin', div);
        });
      }
    </script>
    
    
    <div class="pytorch-call-to-action-links">
      <div id="tutorial-type">beginner/blitz/neural_networks_tutorial</div>
      <a id="colab-link" data-behavior="call-to-action-event" data-response="Run in Google Colab" target="_blank">
        <div id="google-colab-link">
          <img class="call-to-action-img" src="../../_static/img/pytorch-colab.svg" />
          <div class="call-to-action-desktop-view">Run in Google Colab</div>
          <div class="call-to-action-mobile-view">Colab</div>
        </div>
      </a>
      <a id="notebook-link" data-behavior="call-to-action-event" data-response="Download Notebook">
        <div id="download-notebook-link">
          <img class="call-to-action-notebook-img" src="../../_static/img/pytorch-download.svg" />
          <div class="call-to-action-desktop-view">Download Notebook</div>
          <div class="call-to-action-mobile-view">Notebook</div>
        </div>
      </a>
      <a id="github-link" data-behavior="call-to-action-event" data-response="View on Github" target="_blank">
        <div id="github-view-link">
          <img class="call-to-action-img" src="../../_static/img/pytorch-github.svg" />
          <div class="call-to-action-desktop-view">View on GitHub</div>
          <div class="call-to-action-mobile-view">GitHub</div>
        </div>
      </a>
    </div>
    

    
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">참고</p>
<p><a class="reference internal" href="#sphx-glr-download-beginner-blitz-neural-networks-tutorial-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code.</p>
</div>
<section class="sphx-glr-example-title" id="neural-networks">
<span id="sphx-glr-beginner-blitz-neural-networks-tutorial-py"></span><h1>신경망(Neural Networks)<a class="headerlink" href="#neural-networks" title="Link to this heading">#</a></h1>
<p>신경망은 <code class="docutils literal notranslate"><span class="pre">torch.nn</span></code> 패키지를 사용하여 생성할 수 있습니다.</p>
<p>지금까지 <code class="docutils literal notranslate"><span class="pre">autograd</span></code> 를 살펴봤는데요, <code class="docutils literal notranslate"><span class="pre">nn</span></code> 은 모델을 정의하고 미분하는데
<code class="docutils literal notranslate"><span class="pre">autograd</span></code> 를 사용합니다.
<code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> 은 계층(layer)과 <code class="docutils literal notranslate"><span class="pre">output</span></code> 을 반환하는 <code class="docutils literal notranslate"><span class="pre">forward(input)</span></code>
메서드를 포함하고 있습니다.</p>
<p>숫자 이미지를 분류하는 신경망을 예제로 살펴보겠습니다:</p>
<figure class="align-default" id="id5">
<img alt="convnet" src="../../_images/mnist.png" />
<figcaption>
<p><span class="caption-text">convnet</span><a class="headerlink" href="#id5" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>이는 간단한 순전파 네트워크(Feed-forward network)입니다. 입력(input)을 받아
여러 계층에 차례로 전달한 후, 최종 출력(output)을 제공합니다.</p>
<p>신경망의 일반적인 학습 과정은 다음과 같습니다:</p>
<ul class="simple">
<li><p>학습 가능한 매개변수(또는 가중치(weight))를 갖는 신경망을 정의합니다.</p></li>
<li><p>데이터셋(dataset) 입력을 반복합니다.</p></li>
<li><p>입력을 신경망에서 전파(process)합니다.</p></li>
<li><p>손실(loss; 출력이 정답으로부터 얼마나 떨어져 있는지)을 계산합니다.</p></li>
<li><p>변화도(gradient)를 신경망의 매개변수들에 역으로 전파합니다.</p></li>
<li><p>신경망의 가중치를 갱신합니다. 일반적으로 다음과 같은 간단한 규칙을 사용합니다:
<code class="docutils literal notranslate"><span class="pre">새로운</span> <span class="pre">가중치(weight)</span> <span class="pre">=</span> <span class="pre">가중치(weight)</span> <span class="pre">-</span> <span class="pre">학습률(learning</span> <span class="pre">rate)</span> <span class="pre">*</span> <span class="pre">변화도(gradient)</span></code></p></li>
</ul>
<section id="id1">
<h2>신경망 정의하기<a class="headerlink" href="#id1" title="Link to this heading">#</a></h2>
<p>이제 신경망을 정의해보겠습니다:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>


<span class="k">class</span><span class="w"> </span><span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># 입력 이미지 채널 1개, 출력 채널 6개, 5x5의 정사각 컨볼루션 행렬</span>
        <span class="c1"># 컨볼루션 커널 정의</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="c1"># 아핀(affine) 연산: y = Wx + b</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">16</span> <span class="o">*</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">120</span><span class="p">)</span>  <span class="c1"># 5*5은 이미지 차원에 해당</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">120</span><span class="p">,</span> <span class="mi">84</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">84</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
        <span class="c1"># 합성곱(Convolution) 레이어 c1: 입력 이미지 채널 1, 출력 채널 6,</span>
        <span class="c1"># 5x5 정사각 합성곱, 활성 함수로 RELU 사용 및 (N, 6, 28, 28)의 크기를</span>
        <span class="c1"># 갖는 Tensor를 출력 (N은 배치 크기)</span>
        <span class="n">c1</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="nb">input</span><span class="p">))</span>
        <span class="c1"># 서브샘플링(Subsampling) 레이어 s2: 2x2 격자, 순전히 기능적인 레이어로,</span>
        <span class="c1"># 이 레이어는 어떠한 매개변수도 가지지 않고 (N, 6, 14, 14) Tensor를 출력</span>
        <span class="n">s2</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">c1</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
        <span class="c1"># 합성곱(Convolution) 레이어 c3: 입력 채널 6, 출력 채널 16,</span>
        <span class="c1"># 5x5 정사각 합성곱, 활성 함수로 RELU 사용 및 (N, 16, 10, 10)의 크기를</span>
        <span class="c1"># 갖는 Tensor를 출력</span>
        <span class="n">c3</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">s2</span><span class="p">))</span>
        <span class="c1"># 서브샘플링(Subsampling) 레이어 s4: 2x2 격자, 순전히 기능적인 레이어로,</span>
        <span class="c1"># 이 레이어는 어떠한 매개변수도 가지지 않고 (N, 16, 5, 5) Tensor를 출력</span>
        <span class="n">s4</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">c3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="c1"># 평탄화(flatten) 연산: 순전히 기능적으로 동작하며, (N, 400) Tensor를 출력</span>
        <span class="n">s4</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">s4</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="c1"># 완전히 연결된 레이어 f5: (N, 400) Tensor를 입력으로 받아서</span>
        <span class="c1"># (N, 120) Tensor를 출력하며, 활성 함수로 RELU 사용</span>
        <span class="n">f5</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">s4</span><span class="p">))</span>
        <span class="c1"># 완전히 연결된 레이어 f6: (N, 120) Tensor를 입력으로 받아서</span>
        <span class="c1"># (N, 84) Tensor를 출력하며, 활성 함수로 RELU 사용</span>
        <span class="n">f6</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">f5</span><span class="p">))</span>
        <span class="c1"># 가우시안 레이어 출력: (N, 84) Tensor를 입력으로 받아서</span>
        <span class="c1"># (N, 10) Tensor를 출력</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">f6</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># (2, 2) 크기 윈도우에 대해 맥스 풀링(max pooling)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
        <span class="c1"># 크기가 제곱수라면, 하나의 숫자만을 특정(specify)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)),</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># 배치 차원을 제외한 모든 차원을 하나로 평탄화(flatten)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>


<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Net(
  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=400, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=84, bias=True)
  (fc3): Linear(in_features=84, out_features=10, bias=True)
)
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">forward</span></code> 함수만 정의하고 나면, (변화도를 계산하는) <code class="docutils literal notranslate"><span class="pre">backward</span></code> 함수는
<code class="docutils literal notranslate"><span class="pre">autograd</span></code> 를 사용하여 자동으로 정의됩니다.
<code class="docutils literal notranslate"><span class="pre">forward</span></code> 함수에서는 어떠한 Tensor 연산을 사용해도 됩니다.</p>
<p>모델의 학습 가능한 매개변수들은 <code class="docutils literal notranslate"><span class="pre">net.parameters()</span></code> 에 의해 반환됩니다.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">params</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">params</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>  <span class="c1"># conv1의 .weight</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>10
torch.Size([6, 1, 5, 5])
</pre></div>
</div>
<p>임의의 32x32 입력값을 넣어보겠습니다.</p>
<p>Note: 이 신경망(LeNet)의 예상되는 입력 크기는 32x32입니다. 이 신경망에 MNIST
데이터셋을 사용하기 위해서는, 데이터셋의 이미지 크기를 32x32로 변경해야 합니다.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>tensor([[ 0.0158, -0.0808, -0.0672,  0.0173, -0.0082,  0.1178,  0.0130, -0.0954,
          0.1304, -0.0507]], grad_fn=&lt;AddmmBackward0&gt;)
</pre></div>
</div>
<p>모든 매개변수의 변화도 버퍼(gradient buffer)를 0으로 설정하고, 무작위 값으로
역전파를 합니다:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">net</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="n">out</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">참고</p>
<p><code class="docutils literal notranslate"><span class="pre">torch.nn</span></code> 은 미니배치(mini-batch)만 지원합니다. <code class="docutils literal notranslate"><span class="pre">torch.nn</span></code> 패키지
전체는 하나의 샘플이 아닌, 샘플들의 미니배치만을 입력으로 받습니다.</p>
<p>예를 들어, <code class="docutils literal notranslate"><span class="pre">nnConv2D</span></code> 는 <code class="docutils literal notranslate"><span class="pre">nSamples</span> <span class="pre">x</span> <span class="pre">nChannels</span> <span class="pre">x</span> <span class="pre">Height</span> <span class="pre">x</span> <span class="pre">Width</span></code> 의
4차원 Tensor를 입력으로 합니다.</p>
<p>만약 하나의 샘플만 있다면, <code class="docutils literal notranslate"><span class="pre">input.unsqueeze(0)</span></code> 을 사용해서 가상의 차원을
추가합니다.</p>
</div>
<p>계속 진행하기 전에, 지금까지 살펴봤던 것들을 다시 한번 요약해보겠습니다.</p>
<dl class="simple">
<dt><strong>요약:</strong></dt><dd><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code> - <code class="docutils literal notranslate"><span class="pre">backward()</span></code> 같은 autograd 연산을 지원하는
<em>다차원 배열</em> 입니다. 또한 tensor에 대한 <em>변화도를 갖고</em> 있습니다.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> - 신경망 모듈. <em>매개변수를 캡슐화(encapsulation)하는 간편한
방법</em> 으로, GPU로 이동, 내보내기(exporting), 불러오기(loading) 등의 작업을
위한 헬퍼(helper)를 제공합니다.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">nn.Parameter</span></code> - Tensor의 한 종류로, <code class="docutils literal notranslate"><span class="pre">Module</span></code> <em>에 속성으로 할당될 때
자동으로 매개변수로 등록</em> 됩니다.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">autograd.Function</span></code> - <em>autograd 연산의 순방향과 역방향 정의</em> 를 구현합니다.
모든 <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> 연산은 하나 이상의 <code class="docutils literal notranslate"><span class="pre">Function</span></code> 노드를 생성하며, 각 노드는
<code class="docutils literal notranslate"><span class="pre">Tensor</span></code> 를 생성하고 <em>이력(history)을 인코딩</em> 하는 함수들과 연결하고 있습니다.</p></li>
</ul>
</dd>
<dt><strong>지금까지 우리가 다룬 내용은 다음과 같습니다:</strong></dt><dd><ul class="simple">
<li><p>신경망을 정의하는 것</p></li>
<li><p>입력을 처리하고 <code class="docutils literal notranslate"><span class="pre">backward</span></code> 를 호출하는 것</p></li>
</ul>
</dd>
<dt><strong>더 살펴볼 내용들은 다음과 같습니다:</strong></dt><dd><ul class="simple">
<li><p>손실을 계산하는 것</p></li>
<li><p>신경망의 가중치를 갱신하는 것</p></li>
</ul>
</dd>
</dl>
</section>
<section id="loss-function">
<h2>손실 함수 (Loss Function)<a class="headerlink" href="#loss-function" title="Link to this heading">#</a></h2>
<p>손실 함수는 (output, target)을 한 쌍(pair)의 입력으로 받아, 출력(output)이
정답(target)으로부터 얼마나 멀리 떨어져 있는지 추정하는 값을 계산합니다.</p>
<p>nn 패키지에는 여러가지의 <a class="reference external" href="http://pytorch.org/docs/nn.html#loss-functions">손실 함수들</a>
이 존재합니다.
간단한 손실 함수로는 출력과 대상간의 평균제곱오차(mean-squared error)를 계산하는
<code class="docutils literal notranslate"><span class="pre">nn.MSEloss</span></code> 가 있습니다.</p>
<p>예를 들면:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>  <span class="c1"># 예시를 위한 임의의 정답</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">target</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># 출력과 같은 shape로 만듦</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>

<span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>tensor(1.7647, grad_fn=&lt;MseLossBackward0&gt;)
</pre></div>
</div>
<p>이제 <code class="docutils literal notranslate"><span class="pre">.grad_fn</span></code> 속성을 사용하여 <code class="docutils literal notranslate"><span class="pre">loss</span></code> 를 역방향에서 따라가다 보면,
이러한 모습의 연산 그래프를 볼 수 있습니다:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>input<span class="w"> </span>-&gt;<span class="w"> </span>conv2d<span class="w"> </span>-&gt;<span class="w"> </span>relu<span class="w"> </span>-&gt;<span class="w"> </span>maxpool2d<span class="w"> </span>-&gt;<span class="w"> </span>conv2d<span class="w"> </span>-&gt;<span class="w"> </span>relu<span class="w"> </span>-&gt;<span class="w"> </span>maxpool2d
<span class="w">      </span>-&gt;<span class="w"> </span>flatten<span class="w"> </span>-&gt;<span class="w"> </span>linear<span class="w"> </span>-&gt;<span class="w"> </span>relu<span class="w"> </span>-&gt;<span class="w"> </span>linear<span class="w"> </span>-&gt;<span class="w"> </span>relu<span class="w"> </span>-&gt;<span class="w"> </span>linear
<span class="w">      </span>-&gt;<span class="w"> </span>MSELoss
<span class="w">      </span>-&gt;<span class="w"> </span>loss
</pre></div>
</div>
<p>따라서 <code class="docutils literal notranslate"><span class="pre">loss.backward()</span></code> 를 실행할 때, 전체 그래프는 신경망의 매개변수에 대해
미분되며, 그래프 내의 <code class="docutils literal notranslate"><span class="pre">requires_grad=True</span></code> 인 모든 Tensor는 변화도가
누적된 <code class="docutils literal notranslate"><span class="pre">.grad</span></code> Tensor를 갖게 됩니다.</p>
<p>설명을 위해, 역전파의 몇 단계를 따라가 보겠습니다:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">grad_fn</span><span class="p">)</span>  <span class="c1"># MSELoss</span>
<span class="nb">print</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">grad_fn</span><span class="o">.</span><span class="n">next_functions</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>  <span class="c1"># Linear</span>
<span class="nb">print</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">grad_fn</span><span class="o">.</span><span class="n">next_functions</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">next_functions</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>  <span class="c1"># ReLU</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;MseLossBackward0 object at 0x7f0d9335bd60&gt;
&lt;AddmmBackward0 object at 0x7f0d93358550&gt;
&lt;AccumulateGrad object at 0x7f0dab16b940&gt;
</pre></div>
</div>
</section>
<section id="backprop">
<h2>역전파(Backprop)<a class="headerlink" href="#backprop" title="Link to this heading">#</a></h2>
<p>오차(error)를 역전파하기 위해서는 <code class="docutils literal notranslate"><span class="pre">loss.backward()</span></code> 만 해주면 됩니다.
기존에 계산된 변화도의 값을 누적 시키고 싶지 않다면 기존에 계산된 변화도를 0으로 만드는
작업이 필요합니다.</p>
<p>이제 <code class="docutils literal notranslate"><span class="pre">loss.backward()</span></code> 를 호출하여 역전파 전과 후에 conv1의 bias 변수의 변화도를
살펴보겠습니다.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">net</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>     <span class="c1"># 모든 매개변수의 변화도 버퍼를 0으로 만듦</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;conv1.bias.grad before backward&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">conv1</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>

<span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;conv1.bias.grad after backward&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">conv1</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>conv1.bias.grad before backward
None
conv1.bias.grad after backward
tensor([ 0.0104,  0.0176, -0.0437,  0.0134, -0.0167, -0.0010])
</pre></div>
</div>
<p>지금까지 손실 함수를 어떻게 사용하는지를 살펴봤습니다.</p>
<p><strong>더 읽어보기:</strong></p>
<blockquote>
<div><p>신경망 패키지(nn package)에는 심층 신경망(deep neural network)을 구성하는
다양한 모듈과 손실 함수가 포함되어 있습니다.
전체 목록은 <a class="reference external" href="http://pytorch.org/docs/nn">이 문서</a> 에 있습니다.</p>
</div></blockquote>
<p><strong>이제 더 살펴볼 내용은 다음과 같습니다:</strong></p>
<blockquote>
<div><ul class="simple">
<li><p>신경망의 가중치를 갱신하는 것</p></li>
</ul>
</div></blockquote>
</section>
<section id="id4">
<h2>가중치 갱신<a class="headerlink" href="#id4" title="Link to this heading">#</a></h2>
<p>실제로 많이 사용되는 가장 단순한 갱신 규칙은 확률적 경사하강법(SGD; Stochastic
Gradient Descent)입니다:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 새로운 가중치 = 가중치 - 학습률 * 변화도</span>
<span class="n">weight</span> <span class="o">=</span> <span class="n">weight</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">gradient</span>
</pre></div>
</div>
<p>간단한 Python 코드로 이를 구현해볼 수 있습니다:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
    <span class="n">f</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">sub_</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span> <span class="o">*</span> <span class="n">learning_rate</span><span class="p">)</span>
</pre></div>
</div>
<p>신경망을 구성할 때 SGD, Nesterov-SGD, Adam, RMSProp 등과 같은 다양한 갱신 규칙을
사용하고 싶을 수 있습니다. 이를 위해서 <code class="docutils literal notranslate"><span class="pre">torch.optim</span></code> 라는 작은 패키지에 이러한
방법들을 모두 구현해두었습니다. 사용법은 매우 간단합니다:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">optim</span>

<span class="c1"># Optimizer를 생성합니다.</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>

<span class="c1"># 학습 과정(training loop)은 다음과 같습니다:</span>
<span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>   <span class="c1"># 변화도 버퍼를 0으로</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>    <span class="c1"># 업데이트 진행</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">참고</p>
<p><code class="docutils literal notranslate"><span class="pre">optimizer.zero_grad()</span></code> 를 사용하여 수동으로 변화도 버퍼를 0으로 설정하는
것에 유의하세요. 이는 <a class="reference internal" href="#backprop">역전파(Backprop)</a> 섹션에서 설명한 것처럼 변화도가
누적되기 때문입니다.</p>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (0 minutes 4.683 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-beginner-blitz-neural-networks-tutorial-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/c029676472d90691aa145c6fb97a61c3/neural_networks_tutorial.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">neural_networks_tutorial.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/fb69edad8880ff72cdc3687bb1dad1e6/neural_networks_tutorial.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">neural_networks_tutorial.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/11e2004e14318fb5a142762c58588ffd/neural_networks_tutorial.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">neural_networks_tutorial.zip</span></code></a></p>
</div>
</div>
</section>
</section>


                </article>
              
  </article>
  
              
              
                <footer class="bd-footer-article">
                  <div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item">
<div class="feedback">
  
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
        
    </div>
</div>

  <div class="feedback-send">
    <button class="feedback-btn"
            onclick="openGitHubIssue()"
            data-bs-title="Create a GitHub Issue"
            data-bs-placement="bottom"
            data-bs-toggle="tooltip"
            data-gtm="feedback-btn-click">Send Feedback
    </button>
  </div>
</div>

<div class="prev-next-area">
    <a class="left-prev"
       href="autograd_tutorial.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">이전</p>
        <p class="prev-next-title"><code class="docutils literal notranslate"><span class="pre">torch.autograd</span></code> 에 대한 간단한 소개</p>
      </div>
    </a>
    <a class="right-next"
       href="cifar10_tutorial.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">다음</p>
        <p class="prev-next-title">분류기(Classifier) 학습하기</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>

<div class="footer-info">
  <p class="copyright">
    
      
        © Copyright 2018-2025, PyTorch &amp; 파이토치 한국 사용자 모임(PyTorchKR).
      
      <br/>
    
  </p>

  <p class="theme-version">
    Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
  </p>
</div>
</div>
  
</div>
                </footer>
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="autograd_tutorial.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">이전</p>
        <p class="prev-next-title"><code class="docutils literal notranslate"><span class="pre">torch.autograd</span></code> 에 대한 간단한 소개</p>
      </div>
    </a>
    <a class="right-next"
       href="cifar10_tutorial.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">다음</p>
        <p class="prev-next-title">분류기(Classifier) 학습하기</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc">
<div class="sidebar-secondary-items sidebar-secondary__inner">
    
       <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">신경망 정의하기</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#loss-function">손실 함수 (Loss Function)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#backprop">역전파(Backprop)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">가중치 갱신</a></li>
</ul>
  </nav></div>
    




<div class="sidebar-secondary-item">
  <div class="sidebar-heading">PyTorch Libraries</div>
  <ul style="list-style-type: none; padding: 0; padding-bottom: 80px;">
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/ao" style="color: var(--pst-color-text-muted)">torchao</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchrec" style="color: var(--pst-color-text-muted)">torchrec</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchft" style="color: var(--pst-color-text-muted)">torchft</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchcodec" style="color: var(--pst-color-text-muted)">TorchCodec</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/vision" style="color: var(--pst-color-text-muted)">torchvision</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/executorch" style="color: var(--pst-color-text-muted)">ExecuTorch</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/xla" style="color: var(--pst-color-text-muted)">PyTorch on XLA Devices</a></li>
  
  </ul>
</div>

</div>
</div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <div class="container-fluid docs-tutorials-resources">
  <div class="container">
    <div class="row">
      <div class="col-md-4 text-center">
        <h2>PyTorchKorea @ GitHub</h2>
        <p>파이토치 한국 사용자 모임을 GitHub에서 만나보세요.</p>
        <a class="with-right-arrow" href="https://github.com/PyTorchKorea">GitHub로 이동</a>
      </div>

      <div class="col-md-4 text-center">
        <h2>한국어 튜토리얼</h2>
        <p>한국어로 번역 중인 파이토치 튜토리얼을 만나보세요.</p>
        <a class="with-right-arrow" href="https://tutorials.pytorch.kr/">튜토리얼로 이동</a>
      </div>

      <div class="col-md-4 text-center">
        <h2>한국어 커뮤니티</h2>
        <p>다른 사용자들과 의견을 나누고, 도와주세요!</p>
        <a class="with-right-arrow" href="https://discuss.pytorch.kr/">커뮤니티로 이동</a>
      </div>
    </div>
  </div>
</div>

<footer class="site-footer">
  <div class="container footer-container">
    <div class="footer-logo-wrapper">
      <a href="https://pytorch.kr/" class="footer-logo"></a>
    </div>

    <div class="footer-links-wrapper">
      <div class="footer-links-col">
        <ul>
          <li class="list-title"><a href="https://pytorch.kr/">파이토치 한국 사용자 모임</a></li>
          <li><a href="https://pytorch.kr/about">사용자 모임 소개</a></li>
          <li><a href="https://pytorch.kr/contributors">기여해주신 분들</a></li>
          <li><a href="https://pytorch.kr/resources/">리소스</a></li>
          <li><a href="https://pytorch.kr/coc">행동 강령</a></li>
        </ul>
      </div>
    </div>

    <div class="trademark-disclaimer">
      <ul>
        <li>이 사이트는 독립적인 파이토치 사용자 커뮤니티로, 최신 버전이 아니거나 잘못된 내용이 포함되어 있을 수 있습니다. This site is an independent user community and may be out of date or contain incorrect information.</li>
        <li><a href="https://pytorch.kr/coc">행동 강령</a>을 읽고 지켜주세요. PyTorch 공식 로고 사용 규정은 <a href="https://www.linuxfoundation.org/policies/">Linux Foundation의 정책</a>을 따릅니다. Please read and follow <a href="https://pytorch.kr/coc">our code of conduct</a>. All PyTorch trademark policy applicable to <a href="https://www.linuxfoundation.org/policies/">Linux Foundation's policies</a>.</li>
      </ul>
    </div>
  </div>
</footer>

<div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../_static/img/pytorch-x.svg">
  </div>
</div>
  
  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2018-2025, PyTorch &amp; 파이토치 한국 사용자 모임(PyTorchKR).
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.2.6 버전으로 생성되었습니다.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
</p></div>
      
    </div>
  
</div>

  </footer>
  <script type="application/ld+json">
    {
       "@context": "https://schema.org",
       "@type": "Article",
       "name": "\uc2e0\uacbd\ub9dd(Neural Networks)",
       "headline": "\uc2e0\uacbd\ub9dd(Neural Networks)",
       "description": "PyTorch Documentation. Explore PyTorch, an open-source machine learning library that accelerates the path from research prototyping to production deployment. Discover tutorials, API references, and guides to help you build and deploy deep learning models efficiently.",
       "url": "/beginner/blitz/neural_networks_tutorial.html",
       "articleBody": "\ucc38\uace0 Go to the end to download the full example code. \uc2e0\uacbd\ub9dd(Neural Networks)# \uc2e0\uacbd\ub9dd\uc740 torch.nn \ud328\ud0a4\uc9c0\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc0dd\uc131\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc9c0\uae08\uae4c\uc9c0 autograd \ub97c \uc0b4\ud3b4\ubd24\ub294\ub370\uc694, nn \uc740 \ubaa8\ub378\uc744 \uc815\uc758\ud558\uace0 \ubbf8\ubd84\ud558\ub294\ub370 autograd \ub97c \uc0ac\uc6a9\ud569\ub2c8\ub2e4. nn.Module \uc740 \uacc4\uce35(layer)\uacfc output \uc744 \ubc18\ud658\ud558\ub294 forward(input) \uba54\uc11c\ub4dc\ub97c \ud3ec\ud568\ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4. \uc22b\uc790 \uc774\ubbf8\uc9c0\ub97c \ubd84\ub958\ud558\ub294 \uc2e0\uacbd\ub9dd\uc744 \uc608\uc81c\ub85c \uc0b4\ud3b4\ubcf4\uaca0\uc2b5\ub2c8\ub2e4: convnet# \uc774\ub294 \uac04\ub2e8\ud55c \uc21c\uc804\ud30c \ub124\ud2b8\uc6cc\ud06c(Feed-forward network)\uc785\ub2c8\ub2e4. \uc785\ub825(input)\uc744 \ubc1b\uc544 \uc5ec\ub7ec \uacc4\uce35\uc5d0 \ucc28\ub840\ub85c \uc804\ub2ec\ud55c \ud6c4, \ucd5c\uc885 \ucd9c\ub825(output)\uc744 \uc81c\uacf5\ud569\ub2c8\ub2e4. \uc2e0\uacbd\ub9dd\uc758 \uc77c\ubc18\uc801\uc778 \ud559\uc2b5 \uacfc\uc815\uc740 \ub2e4\uc74c\uacfc \uac19\uc2b5\ub2c8\ub2e4: \ud559\uc2b5 \uac00\ub2a5\ud55c \ub9e4\uac1c\ubcc0\uc218(\ub610\ub294 \uac00\uc911\uce58(weight))\ub97c \uac16\ub294 \uc2e0\uacbd\ub9dd\uc744 \uc815\uc758\ud569\ub2c8\ub2e4. \ub370\uc774\ud130\uc14b(dataset) \uc785\ub825\uc744 \ubc18\ubcf5\ud569\ub2c8\ub2e4. \uc785\ub825\uc744 \uc2e0\uacbd\ub9dd\uc5d0\uc11c \uc804\ud30c(process)\ud569\ub2c8\ub2e4. \uc190\uc2e4(loss; \ucd9c\ub825\uc774 \uc815\ub2f5\uc73c\ub85c\ubd80\ud130 \uc5bc\ub9c8\ub098 \ub5a8\uc5b4\uc838 \uc788\ub294\uc9c0)\uc744 \uacc4\uc0b0\ud569\ub2c8\ub2e4. \ubcc0\ud654\ub3c4(gradient)\ub97c \uc2e0\uacbd\ub9dd\uc758 \ub9e4\uac1c\ubcc0\uc218\ub4e4\uc5d0 \uc5ed\uc73c\ub85c \uc804\ud30c\ud569\ub2c8\ub2e4. \uc2e0\uacbd\ub9dd\uc758 \uac00\uc911\uce58\ub97c \uac31\uc2e0\ud569\ub2c8\ub2e4. \uc77c\ubc18\uc801\uc73c\ub85c \ub2e4\uc74c\uacfc \uac19\uc740 \uac04\ub2e8\ud55c \uaddc\uce59\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4: \uc0c8\ub85c\uc6b4 \uac00\uc911\uce58(weight) = \uac00\uc911\uce58(weight) - \ud559\uc2b5\ub960(learning rate) * \ubcc0\ud654\ub3c4(gradient) \uc2e0\uacbd\ub9dd \uc815\uc758\ud558\uae30# \uc774\uc81c \uc2e0\uacbd\ub9dd\uc744 \uc815\uc758\ud574\ubcf4\uaca0\uc2b5\ub2c8\ub2e4: import torch import torch.nn as nn import torch.nn.functional as F class Net(nn.Module): def __init__(self): super(Net, self).__init__() # \uc785\ub825 \uc774\ubbf8\uc9c0 \ucc44\ub110 1\uac1c, \ucd9c\ub825 \ucc44\ub110 6\uac1c, 5x5\uc758 \uc815\uc0ac\uac01 \ucee8\ubcfc\ub8e8\uc158 \ud589\ub82c # \ucee8\ubcfc\ub8e8\uc158 \ucee4\ub110 \uc815\uc758 self.conv1 = nn.Conv2d(1, 6, 5) self.conv2 = nn.Conv2d(6, 16, 5) # \uc544\ud540(affine) \uc5f0\uc0b0: y = Wx + b self.fc1 = nn.Linear(16 * 5 * 5, 120) # 5*5\uc740 \uc774\ubbf8\uc9c0 \ucc28\uc6d0\uc5d0 \ud574\ub2f9 self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def forward(self, input): # \ud569\uc131\uacf1(Convolution) \ub808\uc774\uc5b4 c1: \uc785\ub825 \uc774\ubbf8\uc9c0 \ucc44\ub110 1, \ucd9c\ub825 \ucc44\ub110 6, # 5x5 \uc815\uc0ac\uac01 \ud569\uc131\uacf1, \ud65c\uc131 \ud568\uc218\ub85c RELU \uc0ac\uc6a9 \ubc0f (N, 6, 28, 28)\uc758 \ud06c\uae30\ub97c # \uac16\ub294 Tensor\ub97c \ucd9c\ub825 (N\uc740 \ubc30\uce58 \ud06c\uae30) c1 = F.relu(self.conv1(input)) # \uc11c\ube0c\uc0d8\ud50c\ub9c1(Subsampling) \ub808\uc774\uc5b4 s2: 2x2 \uaca9\uc790, \uc21c\uc804\ud788 \uae30\ub2a5\uc801\uc778 \ub808\uc774\uc5b4\ub85c, # \uc774 \ub808\uc774\uc5b4\ub294 \uc5b4\ub5a0\ud55c \ub9e4\uac1c\ubcc0\uc218\ub3c4 \uac00\uc9c0\uc9c0 \uc54a\uace0 (N, 6, 14, 14) Tensor\ub97c \ucd9c\ub825 s2 = F.max_pool2d(c1, (2, 2)) # \ud569\uc131\uacf1(Convolution) \ub808\uc774\uc5b4 c3: \uc785\ub825 \ucc44\ub110 6, \ucd9c\ub825 \ucc44\ub110 16, # 5x5 \uc815\uc0ac\uac01 \ud569\uc131\uacf1, \ud65c\uc131 \ud568\uc218\ub85c RELU \uc0ac\uc6a9 \ubc0f (N, 16, 10, 10)\uc758 \ud06c\uae30\ub97c # \uac16\ub294 Tensor\ub97c \ucd9c\ub825 c3 = F.relu(self.conv2(s2)) # \uc11c\ube0c\uc0d8\ud50c\ub9c1(Subsampling) \ub808\uc774\uc5b4 s4: 2x2 \uaca9\uc790, \uc21c\uc804\ud788 \uae30\ub2a5\uc801\uc778 \ub808\uc774\uc5b4\ub85c, # \uc774 \ub808\uc774\uc5b4\ub294 \uc5b4\ub5a0\ud55c \ub9e4\uac1c\ubcc0\uc218\ub3c4 \uac00\uc9c0\uc9c0 \uc54a\uace0 (N, 16, 5, 5) Tensor\ub97c \ucd9c\ub825 s4 = F.max_pool2d(c3, 2) # \ud3c9\ud0c4\ud654(flatten) \uc5f0\uc0b0: \uc21c\uc804\ud788 \uae30\ub2a5\uc801\uc73c\ub85c \ub3d9\uc791\ud558\uba70, (N, 400) Tensor\ub97c \ucd9c\ub825 s4 = torch.flatten(s4, 1) # \uc644\uc804\ud788 \uc5f0\uacb0\ub41c \ub808\uc774\uc5b4 f5: (N, 400) Tensor\ub97c \uc785\ub825\uc73c\ub85c \ubc1b\uc544\uc11c # (N, 120) Tensor\ub97c \ucd9c\ub825\ud558\uba70, \ud65c\uc131 \ud568\uc218\ub85c RELU \uc0ac\uc6a9 f5 = F.relu(self.fc1(s4)) # \uc644\uc804\ud788 \uc5f0\uacb0\ub41c \ub808\uc774\uc5b4 f6: (N, 120) Tensor\ub97c \uc785\ub825\uc73c\ub85c \ubc1b\uc544\uc11c # (N, 84) Tensor\ub97c \ucd9c\ub825\ud558\uba70, \ud65c\uc131 \ud568\uc218\ub85c RELU \uc0ac\uc6a9 f6 = F.relu(self.fc2(f5)) # \uac00\uc6b0\uc2dc\uc548 \ub808\uc774\uc5b4 \ucd9c\ub825: (N, 84) Tensor\ub97c \uc785\ub825\uc73c\ub85c \ubc1b\uc544\uc11c # (N, 10) Tensor\ub97c \ucd9c\ub825 output = self.fc3(f6) return output def forward(self, x): # (2, 2) \ud06c\uae30 \uc708\ub3c4\uc6b0\uc5d0 \ub300\ud574 \ub9e5\uc2a4 \ud480\ub9c1(max pooling) x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) # \ud06c\uae30\uac00 \uc81c\uacf1\uc218\ub77c\uba74, \ud558\ub098\uc758 \uc22b\uc790\ub9cc\uc744 \ud2b9\uc815(specify) x = F.max_pool2d(F.relu(self.conv2(x)), 2) x = torch.flatten(x, 1) # \ubc30\uce58 \ucc28\uc6d0\uc744 \uc81c\uc678\ud55c \ubaa8\ub4e0 \ucc28\uc6d0\uc744 \ud558\ub098\ub85c \ud3c9\ud0c4\ud654(flatten) x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return x net = Net() print(net) Net( (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1)) (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1)) (fc1): Linear(in_features=400, out_features=120, bias=True) (fc2): Linear(in_features=120, out_features=84, bias=True) (fc3): Linear(in_features=84, out_features=10, bias=True) ) forward \ud568\uc218\ub9cc \uc815\uc758\ud558\uace0 \ub098\uba74, (\ubcc0\ud654\ub3c4\ub97c \uacc4\uc0b0\ud558\ub294) backward \ud568\uc218\ub294 autograd \ub97c \uc0ac\uc6a9\ud558\uc5ec \uc790\ub3d9\uc73c\ub85c \uc815\uc758\ub429\ub2c8\ub2e4. forward \ud568\uc218\uc5d0\uc11c\ub294 \uc5b4\ub5a0\ud55c Tensor \uc5f0\uc0b0\uc744 \uc0ac\uc6a9\ud574\ub3c4 \ub429\ub2c8\ub2e4. \ubaa8\ub378\uc758 \ud559\uc2b5 \uac00\ub2a5\ud55c \ub9e4\uac1c\ubcc0\uc218\ub4e4\uc740 net.parameters() \uc5d0 \uc758\ud574 \ubc18\ud658\ub429\ub2c8\ub2e4. params = list(net.parameters()) print(len(params)) print(params[0].size()) # conv1\uc758 .weight 10 torch.Size([6, 1, 5, 5]) \uc784\uc758\uc758 32x32 \uc785\ub825\uac12\uc744 \ub123\uc5b4\ubcf4\uaca0\uc2b5\ub2c8\ub2e4. Note: \uc774 \uc2e0\uacbd\ub9dd(LeNet)\uc758 \uc608\uc0c1\ub418\ub294 \uc785\ub825 \ud06c\uae30\ub294 32x32\uc785\ub2c8\ub2e4. \uc774 \uc2e0\uacbd\ub9dd\uc5d0 MNIST \ub370\uc774\ud130\uc14b\uc744 \uc0ac\uc6a9\ud558\uae30 \uc704\ud574\uc11c\ub294, \ub370\uc774\ud130\uc14b\uc758 \uc774\ubbf8\uc9c0 \ud06c\uae30\ub97c 32x32\ub85c \ubcc0\uacbd\ud574\uc57c \ud569\ub2c8\ub2e4. input = torch.randn(1, 1, 32, 32) out = net(input) print(out) tensor([[ 0.0158, -0.0808, -0.0672, 0.0173, -0.0082, 0.1178, 0.0130, -0.0954, 0.1304, -0.0507]], grad_fn=\u003cAddmmBackward0\u003e) \ubaa8\ub4e0 \ub9e4\uac1c\ubcc0\uc218\uc758 \ubcc0\ud654\ub3c4 \ubc84\ud37c(gradient buffer)\ub97c 0\uc73c\ub85c \uc124\uc815\ud558\uace0, \ubb34\uc791\uc704 \uac12\uc73c\ub85c \uc5ed\uc804\ud30c\ub97c \ud569\ub2c8\ub2e4: net.zero_grad() out.backward(torch.randn(1, 10)) \ucc38\uace0 torch.nn \uc740 \ubbf8\ub2c8\ubc30\uce58(mini-batch)\ub9cc \uc9c0\uc6d0\ud569\ub2c8\ub2e4. torch.nn \ud328\ud0a4\uc9c0 \uc804\uccb4\ub294 \ud558\ub098\uc758 \uc0d8\ud50c\uc774 \uc544\ub2cc, \uc0d8\ud50c\ub4e4\uc758 \ubbf8\ub2c8\ubc30\uce58\ub9cc\uc744 \uc785\ub825\uc73c\ub85c \ubc1b\uc2b5\ub2c8\ub2e4. \uc608\ub97c \ub4e4\uc5b4, nnConv2D \ub294 nSamples x nChannels x Height x Width \uc758 4\ucc28\uc6d0 Tensor\ub97c \uc785\ub825\uc73c\ub85c \ud569\ub2c8\ub2e4. \ub9cc\uc57d \ud558\ub098\uc758 \uc0d8\ud50c\ub9cc \uc788\ub2e4\uba74, input.unsqueeze(0) \uc744 \uc0ac\uc6a9\ud574\uc11c \uac00\uc0c1\uc758 \ucc28\uc6d0\uc744 \ucd94\uac00\ud569\ub2c8\ub2e4. \uacc4\uc18d \uc9c4\ud589\ud558\uae30 \uc804\uc5d0, \uc9c0\uae08\uae4c\uc9c0 \uc0b4\ud3b4\ubd24\ub358 \uac83\ub4e4\uc744 \ub2e4\uc2dc \ud55c\ubc88 \uc694\uc57d\ud574\ubcf4\uaca0\uc2b5\ub2c8\ub2e4. \uc694\uc57d: torch.Tensor - backward() \uac19\uc740 autograd \uc5f0\uc0b0\uc744 \uc9c0\uc6d0\ud558\ub294 \ub2e4\ucc28\uc6d0 \ubc30\uc5f4 \uc785\ub2c8\ub2e4. \ub610\ud55c tensor\uc5d0 \ub300\ud55c \ubcc0\ud654\ub3c4\ub97c \uac16\uace0 \uc788\uc2b5\ub2c8\ub2e4. nn.Module - \uc2e0\uacbd\ub9dd \ubaa8\ub4c8. \ub9e4\uac1c\ubcc0\uc218\ub97c \ucea1\uc290\ud654(encapsulation)\ud558\ub294 \uac04\ud3b8\ud55c \ubc29\ubc95 \uc73c\ub85c, GPU\ub85c \uc774\ub3d9, \ub0b4\ubcf4\ub0b4\uae30(exporting), \ubd88\ub7ec\uc624\uae30(loading) \ub4f1\uc758 \uc791\uc5c5\uc744 \uc704\ud55c \ud5ec\ud37c(helper)\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4. nn.Parameter - Tensor\uc758 \ud55c \uc885\ub958\ub85c, Module \uc5d0 \uc18d\uc131\uc73c\ub85c \ud560\ub2f9\ub420 \ub54c \uc790\ub3d9\uc73c\ub85c \ub9e4\uac1c\ubcc0\uc218\ub85c \ub4f1\ub85d \ub429\ub2c8\ub2e4. autograd.Function - autograd \uc5f0\uc0b0\uc758 \uc21c\ubc29\ud5a5\uacfc \uc5ed\ubc29\ud5a5 \uc815\uc758 \ub97c \uad6c\ud604\ud569\ub2c8\ub2e4. \ubaa8\ub4e0 Tensor \uc5f0\uc0b0\uc740 \ud558\ub098 \uc774\uc0c1\uc758 Function \ub178\ub4dc\ub97c \uc0dd\uc131\ud558\uba70, \uac01 \ub178\ub4dc\ub294 Tensor \ub97c \uc0dd\uc131\ud558\uace0 \uc774\ub825(history)\uc744 \uc778\ucf54\ub529 \ud558\ub294 \ud568\uc218\ub4e4\uacfc \uc5f0\uacb0\ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4. \uc9c0\uae08\uae4c\uc9c0 \uc6b0\ub9ac\uac00 \ub2e4\ub8ec \ub0b4\uc6a9\uc740 \ub2e4\uc74c\uacfc \uac19\uc2b5\ub2c8\ub2e4: \uc2e0\uacbd\ub9dd\uc744 \uc815\uc758\ud558\ub294 \uac83 \uc785\ub825\uc744 \ucc98\ub9ac\ud558\uace0 backward \ub97c \ud638\ucd9c\ud558\ub294 \uac83 \ub354 \uc0b4\ud3b4\ubcfc \ub0b4\uc6a9\ub4e4\uc740 \ub2e4\uc74c\uacfc \uac19\uc2b5\ub2c8\ub2e4: \uc190\uc2e4\uc744 \uacc4\uc0b0\ud558\ub294 \uac83 \uc2e0\uacbd\ub9dd\uc758 \uac00\uc911\uce58\ub97c \uac31\uc2e0\ud558\ub294 \uac83 \uc190\uc2e4 \ud568\uc218 (Loss Function)# \uc190\uc2e4 \ud568\uc218\ub294 (output, target)\uc744 \ud55c \uc30d(pair)\uc758 \uc785\ub825\uc73c\ub85c \ubc1b\uc544, \ucd9c\ub825(output)\uc774 \uc815\ub2f5(target)\uc73c\ub85c\ubd80\ud130 \uc5bc\ub9c8\ub098 \uba40\ub9ac \ub5a8\uc5b4\uc838 \uc788\ub294\uc9c0 \ucd94\uc815\ud558\ub294 \uac12\uc744 \uacc4\uc0b0\ud569\ub2c8\ub2e4. nn \ud328\ud0a4\uc9c0\uc5d0\ub294 \uc5ec\ub7ec\uac00\uc9c0\uc758 \uc190\uc2e4 \ud568\uc218\ub4e4 \uc774 \uc874\uc7ac\ud569\ub2c8\ub2e4. \uac04\ub2e8\ud55c \uc190\uc2e4 \ud568\uc218\ub85c\ub294 \ucd9c\ub825\uacfc \ub300\uc0c1\uac04\uc758 \ud3c9\uade0\uc81c\uacf1\uc624\ucc28(mean-squared error)\ub97c \uacc4\uc0b0\ud558\ub294 nn.MSEloss \uac00 \uc788\uc2b5\ub2c8\ub2e4. \uc608\ub97c \ub4e4\uba74: output = net(input) target = torch.randn(10) # \uc608\uc2dc\ub97c \uc704\ud55c \uc784\uc758\uc758 \uc815\ub2f5 target = target.view(1, -1) # \ucd9c\ub825\uacfc \uac19\uc740 shape\ub85c \ub9cc\ub4e6 criterion = nn.MSELoss() loss = criterion(output, target) print(loss) tensor(1.7647, grad_fn=\u003cMseLossBackward0\u003e) \uc774\uc81c .grad_fn \uc18d\uc131\uc744 \uc0ac\uc6a9\ud558\uc5ec loss \ub97c \uc5ed\ubc29\ud5a5\uc5d0\uc11c \ub530\ub77c\uac00\ub2e4 \ubcf4\uba74, \uc774\ub7ec\ud55c \ubaa8\uc2b5\uc758 \uc5f0\uc0b0 \uadf8\ub798\ud504\ub97c \ubcfc \uc218 \uc788\uc2b5\ub2c8\ub2e4: input -\u003e conv2d -\u003e relu -\u003e maxpool2d -\u003e conv2d -\u003e relu -\u003e maxpool2d -\u003e flatten -\u003e linear -\u003e relu -\u003e linear -\u003e relu -\u003e linear -\u003e MSELoss -\u003e loss \ub530\ub77c\uc11c loss.backward() \ub97c \uc2e4\ud589\ud560 \ub54c, \uc804\uccb4 \uadf8\ub798\ud504\ub294 \uc2e0\uacbd\ub9dd\uc758 \ub9e4\uac1c\ubcc0\uc218\uc5d0 \ub300\ud574 \ubbf8\ubd84\ub418\uba70, \uadf8\ub798\ud504 \ub0b4\uc758 requires_grad=True \uc778 \ubaa8\ub4e0 Tensor\ub294 \ubcc0\ud654\ub3c4\uac00 \ub204\uc801\ub41c .grad Tensor\ub97c \uac16\uac8c \ub429\ub2c8\ub2e4. \uc124\uba85\uc744 \uc704\ud574, \uc5ed\uc804\ud30c\uc758 \uba87 \ub2e8\uacc4\ub97c \ub530\ub77c\uac00 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4: print(loss.grad_fn) # MSELoss print(loss.grad_fn.next_functions[0][0]) # Linear print(loss.grad_fn.next_functions[0][0].next_functions[0][0]) # ReLU \u003cMseLossBackward0 object at 0x7f0d9335bd60\u003e \u003cAddmmBackward0 object at 0x7f0d93358550\u003e \u003cAccumulateGrad object at 0x7f0dab16b940\u003e \uc5ed\uc804\ud30c(Backprop)# \uc624\ucc28(error)\ub97c \uc5ed\uc804\ud30c\ud558\uae30 \uc704\ud574\uc11c\ub294 loss.backward() \ub9cc \ud574\uc8fc\uba74 \ub429\ub2c8\ub2e4. \uae30\uc874\uc5d0 \uacc4\uc0b0\ub41c \ubcc0\ud654\ub3c4\uc758 \uac12\uc744 \ub204\uc801 \uc2dc\ud0a4\uace0 \uc2f6\uc9c0 \uc54a\ub2e4\uba74 \uae30\uc874\uc5d0 \uacc4\uc0b0\ub41c \ubcc0\ud654\ub3c4\ub97c 0\uc73c\ub85c \ub9cc\ub4dc\ub294 \uc791\uc5c5\uc774 \ud544\uc694\ud569\ub2c8\ub2e4. \uc774\uc81c loss.backward() \ub97c \ud638\ucd9c\ud558\uc5ec \uc5ed\uc804\ud30c \uc804\uacfc \ud6c4\uc5d0 conv1\uc758 bias \ubcc0\uc218\uc758 \ubcc0\ud654\ub3c4\ub97c \uc0b4\ud3b4\ubcf4\uaca0\uc2b5\ub2c8\ub2e4. net.zero_grad() # \ubaa8\ub4e0 \ub9e4\uac1c\ubcc0\uc218\uc758 \ubcc0\ud654\ub3c4 \ubc84\ud37c\ub97c 0\uc73c\ub85c \ub9cc\ub4e6 print(\u0027conv1.bias.grad before backward\u0027) print(net.conv1.bias.grad) loss.backward() print(\u0027conv1.bias.grad after backward\u0027) print(net.conv1.bias.grad) conv1.bias.grad before backward None conv1.bias.grad after backward tensor([ 0.0104, 0.0176, -0.0437, 0.0134, -0.0167, -0.0010]) \uc9c0\uae08\uae4c\uc9c0 \uc190\uc2e4 \ud568\uc218\ub97c \uc5b4\ub5bb\uac8c \uc0ac\uc6a9\ud558\ub294\uc9c0\ub97c \uc0b4\ud3b4\ubd24\uc2b5\ub2c8\ub2e4. \ub354 \uc77d\uc5b4\ubcf4\uae30: \uc2e0\uacbd\ub9dd \ud328\ud0a4\uc9c0(nn package)\uc5d0\ub294 \uc2ec\uce35 \uc2e0\uacbd\ub9dd(deep neural network)\uc744 \uad6c\uc131\ud558\ub294 \ub2e4\uc591\ud55c \ubaa8\ub4c8\uacfc \uc190\uc2e4 \ud568\uc218\uac00 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uc804\uccb4 \ubaa9\ub85d\uc740 \uc774 \ubb38\uc11c \uc5d0 \uc788\uc2b5\ub2c8\ub2e4. \uc774\uc81c \ub354 \uc0b4\ud3b4\ubcfc \ub0b4\uc6a9\uc740 \ub2e4\uc74c\uacfc \uac19\uc2b5\ub2c8\ub2e4: \uc2e0\uacbd\ub9dd\uc758 \uac00\uc911\uce58\ub97c \uac31\uc2e0\ud558\ub294 \uac83 \uac00\uc911\uce58 \uac31\uc2e0# \uc2e4\uc81c\ub85c \ub9ce\uc774 \uc0ac\uc6a9\ub418\ub294 \uac00\uc7a5 \ub2e8\uc21c\ud55c \uac31\uc2e0 \uaddc\uce59\uc740 \ud655\ub960\uc801 \uacbd\uc0ac\ud558\uac15\ubc95(SGD; Stochastic Gradient Descent)\uc785\ub2c8\ub2e4: # \uc0c8\ub85c\uc6b4 \uac00\uc911\uce58 = \uac00\uc911\uce58 - \ud559\uc2b5\ub960 * \ubcc0\ud654\ub3c4 weight = weight - learning_rate * gradient \uac04\ub2e8\ud55c Python \ucf54\ub4dc\ub85c \uc774\ub97c \uad6c\ud604\ud574\ubcfc \uc218 \uc788\uc2b5\ub2c8\ub2e4: learning_rate = 0.01 for f in net.parameters(): f.data.sub_(f.grad.data * learning_rate) \uc2e0\uacbd\ub9dd\uc744 \uad6c\uc131\ud560 \ub54c SGD, Nesterov-SGD, Adam, RMSProp \ub4f1\uacfc \uac19\uc740 \ub2e4\uc591\ud55c \uac31\uc2e0 \uaddc\uce59\uc744 \uc0ac\uc6a9\ud558\uace0 \uc2f6\uc744 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub97c \uc704\ud574\uc11c torch.optim \ub77c\ub294 \uc791\uc740 \ud328\ud0a4\uc9c0\uc5d0 \uc774\ub7ec\ud55c \ubc29\ubc95\ub4e4\uc744 \ubaa8\ub450 \uad6c\ud604\ud574\ub450\uc5c8\uc2b5\ub2c8\ub2e4. \uc0ac\uc6a9\ubc95\uc740 \ub9e4\uc6b0 \uac04\ub2e8\ud569\ub2c8\ub2e4: import torch.optim as optim # Optimizer\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4. optimizer = optim.SGD(net.parameters(), lr=0.01) # \ud559\uc2b5 \uacfc\uc815(training loop)\uc740 \ub2e4\uc74c\uacfc \uac19\uc2b5\ub2c8\ub2e4: optimizer.zero_grad() # \ubcc0\ud654\ub3c4 \ubc84\ud37c\ub97c 0\uc73c\ub85c output = net(input) loss = criterion(output, target) loss.backward() optimizer.step() # \uc5c5\ub370\uc774\ud2b8 \uc9c4\ud589 \ucc38\uace0 optimizer.zero_grad() \ub97c \uc0ac\uc6a9\ud558\uc5ec \uc218\ub3d9\uc73c\ub85c \ubcc0\ud654\ub3c4 \ubc84\ud37c\ub97c 0\uc73c\ub85c \uc124\uc815\ud558\ub294 \uac83\uc5d0 \uc720\uc758\ud558\uc138\uc694. \uc774\ub294 \uc5ed\uc804\ud30c(Backprop) \uc139\uc158\uc5d0\uc11c \uc124\uba85\ud55c \uac83\ucc98\ub7fc \ubcc0\ud654\ub3c4\uac00 \ub204\uc801\ub418\uae30 \ub54c\ubb38\uc785\ub2c8\ub2e4. Total running time of the script: (0 minutes 4.683 seconds) Download Jupyter notebook: neural_networks_tutorial.ipynb Download Python source code: neural_networks_tutorial.py Download zipped: neural_networks_tutorial.zip",
       "author": {
         "@type": "Organization",
         "name": "PyTorch Contributors",
         "url": "https://pytorch.org"
       },
       "image": "../../_static/img/pytorch_seo.png",
       "mainEntityOfPage": {
         "@type": "WebPage",
         "@id": "/beginner/blitz/neural_networks_tutorial.html"
       },
       "datePublished": "2023-01-01T00:00:00Z",
       "dateModified": "2023-01-01T00:00:00Z"
     }
 </script>
  <script>
    // Tutorials Call to action event tracking
    $("[data-behavior='call-to-action-event']").on('click', function () {
      fbq('trackCustom', "Download", {
        tutorialTitle: $('h1:first').text(),
        downloadLink: this.href,
        tutorialLink: window.location.href,
        downloadTitle: $(this).attr("data-response")
      });
      if (typeof gtag === 'function') {
        gtag('event', 'click', {
          'event_category': $(this).attr("data-response"),
          'event_label': $("h1").first().text(),
          'tutorial_link': window.location.href
        });
      }
    });
  </script>
  
  </body>
</html>