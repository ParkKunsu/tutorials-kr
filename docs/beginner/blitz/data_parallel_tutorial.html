
<!DOCTYPE html>


<html lang="ko" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <meta property="article:modified_time" content="2022-11-30T07:09:41+00:00" /><meta property="og:title" content="선택 사항: 데이터 병렬 처리 (Data Parallelism)" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://tutorials.pytorch.kr/beginner/blitz/data_parallel_tutorial.html" />
<meta property="og:site_name" content="PyTorch Tutorials KR" />
<meta property="og:description" content="글쓴이: Sung Kim and Jenny Kang 번역: ‘정아진 &lt; ajin-jng&gt;’ 이 튜토리얼에서는 DataParallel(데이터 병렬) 을 사용하여 여러 GPU를 사용하는 법을 배우겠습니다. PyTorch를 통해 GPU를 사용하는 것은 매우 쉽습니다. 먼저, 모델을 GPU에 넣습니다: 그 다음으로는 모든 Tensors 를 GPU로 복사합니다: ‘’my_tensor.to(device)’’ 를 호출 시 에는 ‘’my_tensor’’ 를 다시쓰는 대신 ‘’my_tensor’’ 의 또다른 복사본이 생긴다는 사실을..." />
<meta property="og:image" content="https://tutorials.pytorch.kr/_static/logos/logo-kr-sm-dark.png" />
<meta property="og:image:alt" content="PyTorch Tutorials KR" />
<meta name="description" content="글쓴이: Sung Kim and Jenny Kang 번역: ‘정아진 &lt; ajin-jng&gt;’ 이 튜토리얼에서는 DataParallel(데이터 병렬) 을 사용하여 여러 GPU를 사용하는 법을 배우겠습니다. PyTorch를 통해 GPU를 사용하는 것은 매우 쉽습니다. 먼저, 모델을 GPU에 넣습니다: 그 다음으로는 모든 Tensors 를 GPU로 복사합니다: ‘’my_tensor.to(device)’’ 를 호출 시 에는 ‘’my_tensor’’ 를 다시쓰는 대신 ‘’my_tensor’’ 의 또다른 복사본이 생긴다는 사실을..." />
<meta property="og:ignore_canonical" content="true" />

    <title>선택 사항: 데이터 병렬 처리 (Data Parallelism) &#8212; 파이토치 한국어 튜토리얼 (PyTorch tutorials in Korean)</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=536c50fe" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=4d2595e5" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/katex-math.css?v=91adb8b6" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/pytorch_theme.css?v=c326296f" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/custom.css?v=097efa9c" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/custom2.css?v=b169ea90" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../_static/documentation_options.js?v=725a5b95"></script>
    <script src="../../_static/doctools.js?v=92e14aea"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/translations.js?v=b5f768d8"></script>
    <script src="../../_static/katex.min.js?v=be8ff15f"></script>
    <script src="../../_static/auto-render.min.js?v=ad136472"></script>
    <script src="../../_static/katex_autorenderer.js?v=bebc588a"></script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'beginner/blitz/data_parallel_tutorial';</script>
    <link rel="canonical" href="https://tutorials.pytorch.kr/beginner/blitz/data_parallel_tutorial.html" />
    <link rel="icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="색인" href="../../genindex.html" />
    <link rel="search" title="검색" href="../../search.html" />

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="ko"/>
    <meta name="docbuild:last-update" content="2022년 11월 30일"/>
<script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/2.3.1/list.min.js"></script>
<script>
  if (window.location.hostname === 'docs.pytorch.org' || window.location.hostname === 'docs-preview.pytorch.org') {
    const script = document.createElement('script');
    script.src = 'https://cmp.osano.com/16A0DbT9yDNIaQkvZ/31b1b91a-e0b6-47ea-bde2-7f2bd13dbe5c/osano.js?variant=one';
    document.head.appendChild(script);
  }
</script>
<script>
  // Cookie banner for non-LF projects
  document.addEventListener('DOMContentLoaded', function () {
    // Hide cookie banner on local environments and LF owned docs
    if (window.location.hostname === 'localhost' ||
      window.location.hostname === '0.0.0.0' ||
      window.location.hostname === '127.0.0.1' ||
      window.location.hostname === 'docs.pytorch.org' ||
      window.location.hostname === 'docs-preview.pytorch.org' ||
      window.location.hostname.startsWith('192.168.')) {
      const banner = document.querySelector('.cookie-banner-wrapper');
      if (banner) {
        banner.style.display = 'none';
      }
    }
  });
</script>
<!-- Conditional CSS for header and footer height adjustment -->

<link rel="stylesheet" type="text/css" href="../../_static/css/theme.css" crossorigin="anonymous">
<script type="text/javascript" src="../../_static/js/theme.js"></script>
<script type="text/javascript" src="../../_static/js/dropdown-menu.js"></script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Nanum+Gothic:wght@400;700&family=Nanum+Gothic+Coding:wght@400;700&family=Montserrat:wght@300;400&display=swap" rel="stylesheet">
<meta property="og:image" content="../../_static/img/pytorch_seo.png" />
<link rel="stylesheet" href="../../_static/webfonts/all.min.css" crossorigin="anonymous">
<meta http-equiv="Content-Security-Policy"
  content="default-src * 'unsafe-inline' 'unsafe-eval' data: blob:; style-src * 'unsafe-inline'; script-src * 'unsafe-inline' 'unsafe-eval' blob:;">
<meta name="pytorch_project" content="tutorials">
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=G-LZRD6GXDLF" height="0" width="0"
    style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
<!-- Google Tag Manager -->
<script>(function (w, d, s, l, i) {
    w[l] = w[l] || []; w[l].push({
      'gtm.start':
        new Date().getTime(), event: 'gtm.js'
    }); var f = d.getElementsByTagName(s)[0],
      j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : ''; j.async = true; j.src =
        'https://www.googletagmanager.com/gtm.js?id=' + i + dl; f.parentNode.insertBefore(j, f);
    j.onload = function () {
      window.dispatchEvent(new Event('gtm_loaded'));
      console.log('GTM loaded successfully');
    };
  })(window, document, 'script', 'dataLayer', 'G-LZRD6GXDLF');
</script>
<!-- End Google Tag Manager -->
<!-- Facebook Pixel Code -->
<script>
  !function (f, b, e, v, n, t, s) {
    if (f.fbq) return; n = f.fbq = function () {
      n.callMethod ?
        n.callMethod.apply(n, arguments) : n.queue.push(arguments)
    };
    if (!f._fbq) f._fbq = n; n.push = n; n.loaded = !0; n.version = '2.0';
    n.queue = []; t = b.createElement(e); t.async = !0;
    t.src = v; s = b.getElementsByTagName(e)[0];
    s.parentNode.insertBefore(t, s)
  }(window, document, 'script',
    'https://connect.facebook.net/en_US/fbevents.js');
  fbq('init', '243028289693773');
  fbq('track', 'PageView');
</script>
<script>
  document.documentElement.setAttribute('data-version', 'v2.8.0+cu128');
</script>
<noscript>
  <img height="1" width="1" src="https://www.facebook.com/tr?id=243028289693773&ev=PageView&noscript=1" />
</noscript>
<script>
  function gtag() {
    window.dataLayer.push(arguments);
  }
</script>
<!-- End Facebook Pixel Code -->
<!-- Script to Fix scrolling -->
<script>
  document.addEventListener('DOMContentLoaded', function () {
    // Fix anchor scrolling
    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener('click', function (e) {
        e.preventDefault();
        const targetId = this.getAttribute('href').substring(1);
        const targetElement = document.getElementById(targetId);

        if (targetElement) {
          const headerHeight =
            (document.querySelector('.header-holder') ? document.querySelector('.header-holder').offsetHeight : 0) +
            (document.querySelector('.bd-header') ? document.querySelector('.bd-header').offsetHeight : 0) + 20;

          const targetPosition = targetElement.getBoundingClientRect().top + window.pageYOffset - headerHeight;
          window.scrollTo({
            top: targetPosition,
            behavior: 'smooth'
          });

          // Update URL hash without scrolling
          history.pushState(null, null, '#' + targetId);
        }
      });
    });
  });
</script>

<script async src="https://cse.google.com/cse.js?cx=e65585f8c3ea1440e"></script>


  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="ko"/>
    <meta name="docbuild:last-update" content="2022년 11월 30일"/>

  </head>

<body data-feedback-url="https://github.com/PyTorchKorea/tutorials-kr" class="pytorch-body">
  
    <div class="container-fluid header-holder tutorials-header" id="header-holder">
   <div class="header-container-wrapper">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.kr/" aria-label="PyTorchKR"></a>

      <div class="main-menu">
        <ul>

          <li class="main-menu-item">
          <div id="learnDropdownButton" data-toggle="learn-dropdown" class="learn-dropdown">
              <a class="with-down-arrow">
                <span>배우기</span>
              </a>
              <div class="learn-dropdown-menu dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.kr/get-started/locally/">
                  <span class="dropdown-title">PyTorch 시작하기</span>
                </a>
                <a class="nav-dropdown-item" href="https://tutorials.pytorch.kr/beginner/basics/intro.html">
                  <span class="dropdown-title">기본 익히기</span>
                </a>
                <a class="nav-dropdown-item" href="https://tutorials.pytorch.kr/" target="_self">
                  <span class="dropdown-title">한국어 튜토리얼</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.kr/hub/">
                  <span class="dropdown-title">한국어 모델 허브</span>
                </a>
                <a class="nav-dropdown-item" href="https://docs.pytorch.org/tutorials/" target="_blank">
                  <span class="dropdown-title">Official Tutorials</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <a href="https://pytorch.kr/blog/">
              <span>블로그</span>
            </a>
          </li>

          <li class="main-menu-item">
          <div id="docsDropdownButton" data-toggle="docs-dropdown" class="docs-dropdown">
              <a class="with-down-arrow">
              <span>문서</span>
              </a>
              <div class="docs-dropdown-menu dropdown-menu">
                <a class="nav-dropdown-item" href="https://docs.pytorch.org/docs/" target="_blank">
                  <span class="dropdown-title">PyTorch API</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.kr/domains/">
                  <span class="dropdown-title">Domain API 소개</span>
                </a>
                <a class="nav-dropdown-item" href="https://tutorials.pytorch.kr/" target="_self">
                  <span class="dropdown-title">한국어 튜토리얼</span>
                </a>
                <a class="nav-dropdown-item" href="https://docs.pytorch.org/tutorials/" target="_blank">
                  <span class="dropdown-title">Official Tutorials</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
          <div id="communityDropdownButton" data-toggle="community-dropdown" class="community-dropdown">
              <a class="with-down-arrow">
              <span>커뮤니티</span>
              </a>
              <div class="community-dropdown-menu dropdown-menu">
                <a class="nav-dropdown-item" href="https://discuss.pytorch.kr/" target="_self">
                  <span class="dropdown-title">한국어 커뮤니티</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.kr/resources/">
                  <span class="dropdown-title">개발자 정보</span>
                </a>
                <a class="nav-dropdown-item" href="https://landscape.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Landscape</span>
                </a>
              </div>
            </div>
          </li>

        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu">
        <i class="fa-solid fa-ellipsis"></i>
      </a>
    </div>
  </div>
 </div>

 <!-- Begin Mobile Menu -->

<div class="mobile-main-menu">
  <div class="container-fluid">
    <div class="header-container-wrapper">
      <div class="mobile-main-menu-header-container">
        <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu">
          <i class="fa-solid fa-xmark"></i>
        </a>
      </div>
    </div>
  </div>

  <div class="mobile-main-menu-links-container">
    <div class="main-menu">
      <ul>
         <li class="resources-mobile-menu-title">
           <a>배우기</a>
         </li>
         <ul class="resources-mobile-menu-items">
           <li>
             <a href="https://pytorch.kr/get-started/locally/">PyTorch 시작하기</a>
           </li>
           <li>
             <a href="https://tutorials.pytorch.kr/beginner/basics/intro.html">기본 익히기</a>
           </li>
           <li>
             <a href="https://tutorials.pytorch.kr/">한국어 튜토리얼</a>
           </li>
           <li>
             <a href="https://pytorch.kr/hub/">한국어 모델 허브</a>
           </li>
           <li>
             <a href="https://docs.pytorch.org/tutorials/" target="_blank">Official Tutorials</a>
           </li>
        </ul>
         <li class="resources-mobile-menu-title">
           <a href="https://pytorch.kr/blog/">블로그</a>
         </li>
         <li class="resources-mobile-menu-title">
           <a>문서</a>
         </li>
         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://docs.pytorch.org/docs/" target="_blank">PyTorch API</a>
          </li>
          <li>
            <a href="https://pytorch.kr/domains/">Domain API 소개</a>
          </li>
          <li>
            <a href="https://tutorials.pytorch.kr/">한국어 튜토리얼</a>
          </li>
          <li>
            <a href="https://docs.pytorch.org/tutorials/" target="_blank">Official Tutorials</a>
          </li>
        </ul>
        <li class="resources-mobile-menu-title">
          <a>커뮤니티</a>
        </li>
         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://discuss.pytorch.kr/">한국어 커뮤니티</a>
          </li>
          <li>
            <a href="https://pytorch.kr/resources/">개발자 정보</a>
          </li>
          <li>
            <a href="https://landscape.pytorch.org/" target="_blank">Landscape</a>
          </li>
        </ul>
      </ul>
    </div>
  </div>
</div>

<!-- End Mobile Menu -->
  
  
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">
  <a href="../../index.html" class="version">v2.8.0+cu128</a>
</div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../intro.html">
    Intro
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../compilers_index.html">
    Compilers
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../domains.html">
    Domains
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../distributed.html">
    Distributed
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../deep-dive.html">
    Deep Dive
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../extension.html">
    Extension
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../ecosystem.html">
    Ecosystem
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../recipes_index.html">
    Recipes
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
      
        <div class="navbar-item">
<div class="search-container-wrapper">
  <div id="sphinx-search" class="search-container">
    
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </div>

  <div id="google-search" class="search-container" style="display:none;">
    <div class="gcse-search-wrapper">
      <i class="fa-solid fa-magnifying-glass" aria-hidden="true"></i>
      <div class="gcse-search"></div>
    </div>
  </div>

  <div class="search-toggle-container" data-bs-title="Google Search Off" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <div class="search-toggle-inner">
      <label class="switch">
        <input type="checkbox" id="search-toggle">
        <span class="slider round"></span>
      </label>
    </div>
  </div>
</div>

<script>
  document.addEventListener('DOMContentLoaded', function() {
  // Define the search callback
  const myWebSearchStartingCallback = (gname, query) => {
    if (typeof dataLayer !== 'undefined' && query) {
      window.dataLayer = window.dataLayer || [];
      dataLayer.push({
        'event': 'google_search',
        'search_term': query,
        'event_category': 'Search',
        'event_label': 'Google Search'
      });
    }
    return '';
  };

  // Set up the GCSE search callbacks
  window.__gcse || (window.__gcse = {});
  window.__gcse.searchCallbacks = {
    web: { starting: myWebSearchStartingCallback }
  };

  if (window.location.pathname.includes('/search.html')) {
    document.body.classList.add('search-page');
  }

  // Function to reinitialize Google CSE
  function reinitializeGoogleSearch() {
    if (window.__gcse && window.__gcse.initializationCallback) {
      window.__gcse.initializationCallback();
    }
  }

  // Function to handle search toggle
  function handleSearchToggle(toggle, sphinxSearch, googleSearch) {
    if (!toggle || !sphinxSearch || !googleSearch) return;

    // Check if the URL contains /stable/ or /tutorials/
    const currentUrl = window.location.href;
    // TODO: We've had reports that the google programmable search is returning stale documentation,
    //       Simple reproduction is to turn google search on and search for multinomial which will
    //       result in returning 1.8.1 documentation.
    //       We should turn this back on when we resolve that bug.
    const shouldDefaultToGoogle = false;
    const savedPreference = localStorage.getItem('searchPreference');

    // Set initial state
    if (savedPreference === 'google' || (savedPreference === null && shouldDefaultToGoogle)) {
      toggle.checked = true;
      sphinxSearch.style.display = 'none';
      googleSearch.style.display = 'block';
      if (savedPreference === null) {
        localStorage.setItem('searchPreference', 'google');
      }
      reinitializeGoogleSearch();
    } else {
      toggle.checked = false;
      sphinxSearch.style.display = 'block';
      googleSearch.style.display = 'none';
    }

    // Update tooltip
    updateTooltip(toggle.checked);

    // Skip if already initialized
    if (toggle.hasAttribute('data-initialized')) return;
    toggle.setAttribute('data-initialized', 'true');

    toggle.addEventListener('change', function() {
      if (this.checked) {
        sphinxSearch.style.display = 'none';
        googleSearch.style.display = 'block';
        localStorage.setItem('searchPreference', 'google');
        reinitializeGoogleSearch();
        trackSearchEngineSwitch('Google');
      } else {
        sphinxSearch.style.display = 'block';
        googleSearch.style.display = 'none';
        localStorage.setItem('searchPreference', 'sphinx');
        trackSearchEngineSwitch('Sphinx');
      }

      updateTooltip(this.checked);
      updateMobileSearch();
    });
  }

  // Update tooltip based on toggle state
  function updateTooltip(isChecked) {
    const tooltipElement = document.querySelector('.search-toggle-container');
    if (!tooltipElement) return;

    tooltipElement.setAttribute('data-bs-title', isChecked ? 'Google Search On' : 'Google Search Off');

    if (bootstrap && bootstrap.Tooltip) {
      const tooltipInstance = bootstrap.Tooltip.getInstance(tooltipElement);
      if (tooltipInstance) tooltipInstance.dispose();
      new bootstrap.Tooltip(tooltipElement);
    }
  }

  // Track search engine switch
  function trackSearchEngineSwitch(engine) {
    if (typeof dataLayer !== 'undefined') {
      window.dataLayer = window.dataLayer || [];
      dataLayer.push({
        'event': 'search_engine_switch',
        'event_category': 'Search',
        'event_label': engine
      });
    }
  }

  // Function to update mobile search based on current toggle state
  function updateMobileSearch() {
    const toggle = document.getElementById('search-toggle');
    if (!toggle) return;

    const mobileSearchContainer = document.querySelector('.sidebar-header-items__end .navbar-item .search-container-wrapper');
    if (!mobileSearchContainer) return;

    const mobileSphinxSearch = mobileSearchContainer.querySelector('#sphinx-search');
    const mobileGoogleSearch = mobileSearchContainer.querySelector('#google-search');

    if (mobileSphinxSearch && mobileGoogleSearch) {
      mobileSphinxSearch.style.display = toggle.checked ? 'none' : 'block';
      mobileGoogleSearch.style.display = toggle.checked ? 'block' : 'none';

      if (toggle.checked) {
        reinitializeGoogleSearch();
      }
    }
  }

  // Initialize desktop search toggle
  const toggle = document.getElementById('search-toggle');
  const sphinxSearch = document.getElementById('sphinx-search');
  const googleSearch = document.getElementById('google-search');
  handleSearchToggle(toggle, sphinxSearch, googleSearch);

  // Set placeholder text for Google search input
  const observer = new MutationObserver(function() {
    document.querySelectorAll('.gsc-input input').forEach(input => {
      if (input && !input.hasAttribute('data-placeholder-set')) {
        input.setAttribute('placeholder', 'Search the docs ...');
        input.setAttribute('data-placeholder-set', 'true');
      }
    });
  });

  observer.observe(document.body, { childList: true, subtree: true });

  // Fix for scroll jump issue - improved approach
  function setupSearchInputHandlers(input) {
    if (input.hasAttribute('data-scroll-fixed')) return;
    input.setAttribute('data-scroll-fixed', 'true');

    let lastScrollPosition = 0;
    let isTyping = false;
    let scrollTimeout;

    // Save position before typing starts
    input.addEventListener('keydown', () => {
      lastScrollPosition = window.scrollY;
      isTyping = true;

      // Reset typing state after a short delay
      clearTimeout(scrollTimeout);
      scrollTimeout = setTimeout(() => {
        isTyping = false;
      }, 100);
    });

    // Only maintain scroll position during typing
    function maintainScroll() {
      if (document.activeElement === input && isTyping) {
        window.scrollTo(0, lastScrollPosition);
        requestAnimationFrame(maintainScroll);
      }
    }

    input.addEventListener('focus', () => {
      // Just store initial position but don't force it
      lastScrollPosition = window.scrollY;
    });

    input.addEventListener('input', () => {
      isTyping = true;
      window.scrollTo(0, lastScrollPosition);

      // Reset typing state after a short delay
      clearTimeout(scrollTimeout);
      scrollTimeout = setTimeout(() => {
        isTyping = false;
      }, 100);

      requestAnimationFrame(maintainScroll);
    });
  }

  // Apply to all search inputs and observe for new ones
  function applyToSearchInputs() {
    document.querySelectorAll('.search-container input, .gsc-input input').forEach(setupSearchInputHandlers);
  }

  applyToSearchInputs();

  const searchObserver = new MutationObserver(applyToSearchInputs);
  searchObserver.observe(document.body, { childList: true, subtree: true });

  // Watch for mobile menu creation
  const mobileMenuObserver = new MutationObserver(function(mutations) {
    for (const mutation of mutations) {
      if (!mutation.addedNodes.length) continue;

      // Style mobile search inputs
      document.querySelectorAll('.sidebar-header-items__end .navbar-item .search-container-wrapper .gsc-input input').forEach(input => {
        if (input) {
          input.setAttribute('placeholder', 'Search the docs ...');
          input.style.paddingLeft = '36px';
        }
      });

      // Check for mobile search container
      const mobileSearchContainer = document.querySelector('.sidebar-header-items__end .navbar-item .search-container-wrapper');
      if (!mobileSearchContainer) continue;

      const mobileToggle = mobileSearchContainer.querySelector('#search-toggle');
      if (mobileToggle && toggle) {
        // Sync mobile toggle with desktop toggle
        mobileToggle.checked = toggle.checked;
        updateMobileSearch();

        // Add event listener to mobile toggle if not already added
        if (!mobileToggle.hasAttribute('data-initialized')) {
          mobileToggle.setAttribute('data-initialized', 'true');
          mobileToggle.addEventListener('change', function() {
            // Sync desktop toggle with mobile toggle
            toggle.checked = this.checked;
            // Trigger change event on desktop toggle to update both
            toggle.dispatchEvent(new Event('change'));
          });
        }
      }
    }
  });

  mobileMenuObserver.observe(document.body, { childList: true, subtree: true });

  // Ensure Google CSE is properly loaded
  if (window.__gcse) {
    window.__gcse.callback = function() {
      // This will run after Google CSE is fully loaded
      if (toggle && toggle.checked) {
        reinitializeGoogleSearch();
      }
    };
  } else {
    window.__gcse = {
      callback: function() {
        if (toggle && toggle.checked) {
          reinitializeGoogleSearch();
        }
      }
    };
  }
});
</script>
</div>
      
        <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/PyTorchKorea/tutorials-kr" title="한국어 튜토리얼 GitHub 저장소" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">한국어 튜토리얼 GitHub 저장소</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discuss.pytorch.kr/" title="파이토치 한국어 커뮤니티" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">파이토치 한국어 커뮤니티</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../intro.html">
    Intro
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../compilers_index.html">
    Compilers
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../domains.html">
    Domains
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../distributed.html">
    Distributed
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../deep-dive.html">
    Deep Dive
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../extension.html">
    Extension
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../ecosystem.html">
    Ecosystem
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../recipes_index.html">
    Recipes
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
<div class="search-container-wrapper">
  <div id="sphinx-search" class="search-container">
    
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </div>

  <div id="google-search" class="search-container" style="display:none;">
    <div class="gcse-search-wrapper">
      <i class="fa-solid fa-magnifying-glass" aria-hidden="true"></i>
      <div class="gcse-search"></div>
    </div>
  </div>

  <div class="search-toggle-container" data-bs-title="Google Search Off" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <div class="search-toggle-inner">
      <label class="switch">
        <input type="checkbox" id="search-toggle">
        <span class="slider round"></span>
      </label>
    </div>
  </div>
</div>

<script>
  document.addEventListener('DOMContentLoaded', function() {
  // Define the search callback
  const myWebSearchStartingCallback = (gname, query) => {
    if (typeof dataLayer !== 'undefined' && query) {
      window.dataLayer = window.dataLayer || [];
      dataLayer.push({
        'event': 'google_search',
        'search_term': query,
        'event_category': 'Search',
        'event_label': 'Google Search'
      });
    }
    return '';
  };

  // Set up the GCSE search callbacks
  window.__gcse || (window.__gcse = {});
  window.__gcse.searchCallbacks = {
    web: { starting: myWebSearchStartingCallback }
  };

  if (window.location.pathname.includes('/search.html')) {
    document.body.classList.add('search-page');
  }

  // Function to reinitialize Google CSE
  function reinitializeGoogleSearch() {
    if (window.__gcse && window.__gcse.initializationCallback) {
      window.__gcse.initializationCallback();
    }
  }

  // Function to handle search toggle
  function handleSearchToggle(toggle, sphinxSearch, googleSearch) {
    if (!toggle || !sphinxSearch || !googleSearch) return;

    // Check if the URL contains /stable/ or /tutorials/
    const currentUrl = window.location.href;
    // TODO: We've had reports that the google programmable search is returning stale documentation,
    //       Simple reproduction is to turn google search on and search for multinomial which will
    //       result in returning 1.8.1 documentation.
    //       We should turn this back on when we resolve that bug.
    const shouldDefaultToGoogle = false;
    const savedPreference = localStorage.getItem('searchPreference');

    // Set initial state
    if (savedPreference === 'google' || (savedPreference === null && shouldDefaultToGoogle)) {
      toggle.checked = true;
      sphinxSearch.style.display = 'none';
      googleSearch.style.display = 'block';
      if (savedPreference === null) {
        localStorage.setItem('searchPreference', 'google');
      }
      reinitializeGoogleSearch();
    } else {
      toggle.checked = false;
      sphinxSearch.style.display = 'block';
      googleSearch.style.display = 'none';
    }

    // Update tooltip
    updateTooltip(toggle.checked);

    // Skip if already initialized
    if (toggle.hasAttribute('data-initialized')) return;
    toggle.setAttribute('data-initialized', 'true');

    toggle.addEventListener('change', function() {
      if (this.checked) {
        sphinxSearch.style.display = 'none';
        googleSearch.style.display = 'block';
        localStorage.setItem('searchPreference', 'google');
        reinitializeGoogleSearch();
        trackSearchEngineSwitch('Google');
      } else {
        sphinxSearch.style.display = 'block';
        googleSearch.style.display = 'none';
        localStorage.setItem('searchPreference', 'sphinx');
        trackSearchEngineSwitch('Sphinx');
      }

      updateTooltip(this.checked);
      updateMobileSearch();
    });
  }

  // Update tooltip based on toggle state
  function updateTooltip(isChecked) {
    const tooltipElement = document.querySelector('.search-toggle-container');
    if (!tooltipElement) return;

    tooltipElement.setAttribute('data-bs-title', isChecked ? 'Google Search On' : 'Google Search Off');

    if (bootstrap && bootstrap.Tooltip) {
      const tooltipInstance = bootstrap.Tooltip.getInstance(tooltipElement);
      if (tooltipInstance) tooltipInstance.dispose();
      new bootstrap.Tooltip(tooltipElement);
    }
  }

  // Track search engine switch
  function trackSearchEngineSwitch(engine) {
    if (typeof dataLayer !== 'undefined') {
      window.dataLayer = window.dataLayer || [];
      dataLayer.push({
        'event': 'search_engine_switch',
        'event_category': 'Search',
        'event_label': engine
      });
    }
  }

  // Function to update mobile search based on current toggle state
  function updateMobileSearch() {
    const toggle = document.getElementById('search-toggle');
    if (!toggle) return;

    const mobileSearchContainer = document.querySelector('.sidebar-header-items__end .navbar-item .search-container-wrapper');
    if (!mobileSearchContainer) return;

    const mobileSphinxSearch = mobileSearchContainer.querySelector('#sphinx-search');
    const mobileGoogleSearch = mobileSearchContainer.querySelector('#google-search');

    if (mobileSphinxSearch && mobileGoogleSearch) {
      mobileSphinxSearch.style.display = toggle.checked ? 'none' : 'block';
      mobileGoogleSearch.style.display = toggle.checked ? 'block' : 'none';

      if (toggle.checked) {
        reinitializeGoogleSearch();
      }
    }
  }

  // Initialize desktop search toggle
  const toggle = document.getElementById('search-toggle');
  const sphinxSearch = document.getElementById('sphinx-search');
  const googleSearch = document.getElementById('google-search');
  handleSearchToggle(toggle, sphinxSearch, googleSearch);

  // Set placeholder text for Google search input
  const observer = new MutationObserver(function() {
    document.querySelectorAll('.gsc-input input').forEach(input => {
      if (input && !input.hasAttribute('data-placeholder-set')) {
        input.setAttribute('placeholder', 'Search the docs ...');
        input.setAttribute('data-placeholder-set', 'true');
      }
    });
  });

  observer.observe(document.body, { childList: true, subtree: true });

  // Fix for scroll jump issue - improved approach
  function setupSearchInputHandlers(input) {
    if (input.hasAttribute('data-scroll-fixed')) return;
    input.setAttribute('data-scroll-fixed', 'true');

    let lastScrollPosition = 0;
    let isTyping = false;
    let scrollTimeout;

    // Save position before typing starts
    input.addEventListener('keydown', () => {
      lastScrollPosition = window.scrollY;
      isTyping = true;

      // Reset typing state after a short delay
      clearTimeout(scrollTimeout);
      scrollTimeout = setTimeout(() => {
        isTyping = false;
      }, 100);
    });

    // Only maintain scroll position during typing
    function maintainScroll() {
      if (document.activeElement === input && isTyping) {
        window.scrollTo(0, lastScrollPosition);
        requestAnimationFrame(maintainScroll);
      }
    }

    input.addEventListener('focus', () => {
      // Just store initial position but don't force it
      lastScrollPosition = window.scrollY;
    });

    input.addEventListener('input', () => {
      isTyping = true;
      window.scrollTo(0, lastScrollPosition);

      // Reset typing state after a short delay
      clearTimeout(scrollTimeout);
      scrollTimeout = setTimeout(() => {
        isTyping = false;
      }, 100);

      requestAnimationFrame(maintainScroll);
    });
  }

  // Apply to all search inputs and observe for new ones
  function applyToSearchInputs() {
    document.querySelectorAll('.search-container input, .gsc-input input').forEach(setupSearchInputHandlers);
  }

  applyToSearchInputs();

  const searchObserver = new MutationObserver(applyToSearchInputs);
  searchObserver.observe(document.body, { childList: true, subtree: true });

  // Watch for mobile menu creation
  const mobileMenuObserver = new MutationObserver(function(mutations) {
    for (const mutation of mutations) {
      if (!mutation.addedNodes.length) continue;

      // Style mobile search inputs
      document.querySelectorAll('.sidebar-header-items__end .navbar-item .search-container-wrapper .gsc-input input').forEach(input => {
        if (input) {
          input.setAttribute('placeholder', 'Search the docs ...');
          input.style.paddingLeft = '36px';
        }
      });

      // Check for mobile search container
      const mobileSearchContainer = document.querySelector('.sidebar-header-items__end .navbar-item .search-container-wrapper');
      if (!mobileSearchContainer) continue;

      const mobileToggle = mobileSearchContainer.querySelector('#search-toggle');
      if (mobileToggle && toggle) {
        // Sync mobile toggle with desktop toggle
        mobileToggle.checked = toggle.checked;
        updateMobileSearch();

        // Add event listener to mobile toggle if not already added
        if (!mobileToggle.hasAttribute('data-initialized')) {
          mobileToggle.setAttribute('data-initialized', 'true');
          mobileToggle.addEventListener('change', function() {
            // Sync desktop toggle with mobile toggle
            toggle.checked = this.checked;
            // Trigger change event on desktop toggle to update both
            toggle.dispatchEvent(new Event('change'));
          });
        }
      }
    }
  });

  mobileMenuObserver.observe(document.body, { childList: true, subtree: true });

  // Ensure Google CSE is properly loaded
  if (window.__gcse) {
    window.__gcse.callback = function() {
      // This will run after Google CSE is fully loaded
      if (toggle && toggle.checked) {
        reinitializeGoogleSearch();
      }
    };
  } else {
    window.__gcse = {
      callback: function() {
        if (toggle && toggle.checked) {
          reinitializeGoogleSearch();
        }
      }
    };
  }
});
</script>
</div>
        
          <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/PyTorchKorea/tutorials-kr" title="한국어 튜토리얼 GitHub 저장소" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">한국어 튜토리얼 GitHub 저장소</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discuss.pytorch.kr/" title="파이토치 한국어 커뮤니티" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">파이토치 한국어 커뮤니티</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"></div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    <li class="breadcrumb-item active" aria-current="page">선택 사항: 데이터...</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
        
    </div>
</div>
</div>
      
    </div>
  
</div>
</div>
              
              
  
<div id="searchbox"></div>
  <article class="bd-article" id="pytorch-article">
    <!-- Hidden breadcrumb schema for SEO only -->
    <div style="display:none;" itemscope itemtype="https://schema.org/BreadcrumbList">
      
      <div itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <meta itemprop="name" content="선택 사항: 데이터 병렬 처리 (Data Parallelism)">
        <meta itemprop="position" content="1">
      </div>
    </div>

    
    <script>
      if ((window.location.href.indexOf("/unstable/") != -1) && (window.location.href.indexOf("/unstable/unstable_index") < 1)) {
        var div = '<div class="prototype-banner"><i class="fa fa-flask" aria-hidden="true"></i> <strong>Unstable feature:</strong> Not typically available in binary distributions like PyPI. Early stage for feedback and testing.</div>'
        document.addEventListener('DOMContentLoaded', function () {
          document.getElementById("pytorch-article").insertAdjacentHTML('afterBegin', div);
        });
      }
    </script>
    
    
    <div class="pytorch-call-to-action-links">
      <div id="tutorial-type">beginner/blitz/data_parallel_tutorial</div>
      <a id="colab-link" data-behavior="call-to-action-event" data-response="Run in Google Colab" target="_blank">
        <div id="google-colab-link">
          <img class="call-to-action-img" src="../../_static/img/pytorch-colab.svg" />
          <div class="call-to-action-desktop-view">Run in Google Colab</div>
          <div class="call-to-action-mobile-view">Colab</div>
        </div>
      </a>
      <a id="notebook-link" data-behavior="call-to-action-event" data-response="Download Notebook">
        <div id="download-notebook-link">
          <img class="call-to-action-notebook-img" src="../../_static/img/pytorch-download.svg" />
          <div class="call-to-action-desktop-view">Download Notebook</div>
          <div class="call-to-action-mobile-view">Notebook</div>
        </div>
      </a>
      <a id="github-link" data-behavior="call-to-action-event" data-response="View on Github" target="_blank">
        <div id="github-view-link">
          <img class="call-to-action-img" src="../../_static/img/pytorch-github.svg" />
          <div class="call-to-action-desktop-view">View on GitHub</div>
          <div class="call-to-action-mobile-view">GitHub</div>
        </div>
      </a>
    </div>
    

    
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">참고</p>
<p><a class="reference internal" href="#sphx-glr-download-beginner-blitz-data-parallel-tutorial-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code.</p>
</div>
<section class="sphx-glr-example-title" id="data-parallelism">
<span id="sphx-glr-beginner-blitz-data-parallel-tutorial-py"></span><h1>선택 사항: 데이터 병렬 처리 (Data Parallelism)<a class="headerlink" href="#data-parallelism" title="Link to this heading">#</a></h1>
<p><strong>글쓴이</strong>: <a class="reference external" href="https://github.com/hunkim">Sung Kim</a> and <a class="reference external" href="https://github.com/jennykang">Jenny Kang</a>
<strong>번역</strong>: ‘정아진 &lt;<a class="github reference external" href="https://github.com/ajin-jng">ajin-jng</a>&gt;’</p>
<p>이 튜토리얼에서는 <code class="docutils literal notranslate"><span class="pre">DataParallel</span></code> (데이터 병렬) 을 사용하여 여러 GPU를 사용하는 법을 배우겠습니다.</p>
<p>PyTorch를 통해 GPU를 사용하는 것은 매우 쉽습니다. 먼저, 모델을 GPU에 넣습니다:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
<p>그 다음으로는 모든 Tensors 를 GPU로 복사합니다:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">mytensor</span> <span class="o">=</span> <span class="n">my_tensor</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
<p>‘’my_tensor.to(device)’’ 를 호출 시 에는 ‘’my_tensor’’ 를 다시쓰는 대신 ‘’my_tensor’’ 의 또다른 복사본이 생긴다는 사실을 기억하십시오.
당신은 그것을 새로운 tensor 에 소속시키고 GPU에 그 tensor를 써야합니다.</p>
<p>여러 GPU를 통해 앞과 뒤의 전파를 실행하는 것은 당연한 일 입니다.
그러나 PyTorch는 기본적 하나의 GPU만 사용합니다. <code class="docutils literal notranslate"><span class="pre">DataParallel</span></code> 을 이용하여 모델을 병렬로 실행하여 다수의 GPU 에서 쉽게 작업을 실행할 수 있습니다:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">DataParallel</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
<p>이것이 튜토리얼의 핵심입니다. 자세한 사항들에 대해서는 아래에서 살펴보겠습니다.</p>
<section id="id1">
<h2>불러오기와 매개변수<a class="headerlink" href="#id1" title="Link to this heading">#</a></h2>
<p>PyTorch 모듈을 불러오고 매개변수를 정의하십시오.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span>

<span class="c1"># 매개변수와 DataLoaders</span>
<span class="n">input_size</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">output_size</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">30</span>
<span class="n">data_size</span> <span class="o">=</span> <span class="mi">100</span>
</pre></div>
</div>
<p>기기</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="dummy">
<h2>더미(Dummy) 데이터셋<a class="headerlink" href="#dummy" title="Link to this heading">#</a></h2>
<p>더미(ramdom) 데이터셋을 만들어 봅시다. Getitem 만 구현하면 됩니다.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">RandomDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">length</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">len</span> <span class="o">=</span> <span class="n">length</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">length</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">len</span>

<span class="n">rand_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">RandomDataset</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">data_size</span><span class="p">),</span>
                         <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id2">
<h2>간단한 모델<a class="headerlink" href="#id2" title="Link to this heading">#</a></h2>
<p>데모를 위해 모델은 입력을 받고 선형 연산을 수행하며 출력을 제공합니다. 그러나 <code class="docutils literal notranslate"><span class="pre">DataParallel</span></code> 의 어떤 모델 (CNN, RNN, Capsule Net 등) 에서든 사용할 수 있습니다.</p>
<p>우리는 input과 output의 크기를 모니터링하기 위해 모델안에 print 문을 넣었습니다.
무엇이 배치 순위 (batch rank) 0 에 프린트 되는지 주의 깊게 봐주시길 바랍니다.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">Model</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="c1"># 우리의 모델</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Model</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">In Model: input size&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">.</span><span class="n">size</span><span class="p">(),</span>
              <span class="s2">&quot;output size&quot;</span><span class="p">,</span> <span class="n">output</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>

        <span class="k">return</span> <span class="n">output</span>
</pre></div>
</div>
</section>
<section id="id3">
<h2>모델과 데이터 병렬의 구현<a class="headerlink" href="#id3" title="Link to this heading">#</a></h2>
<p>이것은 이 튜토리얼의 핵심 부분입니다. 먼저, model instance 를 만들고 가지고 있는 GPU가 여러개인지 확인해야합니다.
만약 다수의 GPU를 보유중이라면, <code class="docutils literal notranslate"><span class="pre">nn.DataParallel</span></code> 을 사용하여 모델을 래핑 (wrapping) 할 수 있습니다.
그런 다음 <code class="docutils literal notranslate"><span class="pre">model.to(device)</span></code> 를 통하여 모델을 GPU에 넣을 수 있습니다.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>
<span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Let&#39;s use&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">(),</span> <span class="s2">&quot;GPUs!&quot;</span><span class="p">)</span>
  <span class="c1"># dim = 0 [30, xxx] -&gt; [10, ...], [10, ...], [10, ...] on 3 GPUs</span>
  <span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">DataParallel</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Let&#39;s use 8 GPUs!

DataParallel(
  (module): Model(
    (fc): Linear(in_features=5, out_features=2, bias=True)
  )
)
</pre></div>
</div>
</section>
<section id="id4">
<h2>모델 실행<a class="headerlink" href="#id4" title="Link to this heading">#</a></h2>
<p>이제 우리는 입력과 출력 tensor의 크기를 볼 수 있습니다</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">rand_loader</span><span class="p">:</span>
    <span class="nb">input</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Outside: input size&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">.</span><span class="n">size</span><span class="p">(),</span>
          <span class="s2">&quot;output_size&quot;</span><span class="p">,</span> <span class="n">output</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>/opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py:125: UserWarning:

Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:179.)

        In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])
        In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])
        In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])
        In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])
        In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])
        In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])
        In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])
        In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2])
Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])
        In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])
        In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])
        In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])
        In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])
        In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])
        In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])
        In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])
        In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2])
Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])
        In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])
        In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])
        In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])
        In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])
        In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])
        In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])
        In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])
        In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2])
Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])
        In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2])
        In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2])
        In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2])
        In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2])
        In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2])
Outside: input size torch.Size([10, 5]) output_size torch.Size([10, 2])
</pre></div>
</div>
</section>
<section id="id5">
<h2>결과<a class="headerlink" href="#id5" title="Link to this heading">#</a></h2>
<p>GPU가 없거나 하나인 경우 30개의 입력과 30개의 출력을 일괄 처리하면 모델이 예상대로 30을 입력받고 30을 출력합니다.
하지만 만약 당신이 다수의 GPU를 가지고 있다면, 다음과 같은 결과를 얻을 수 있습니다.</p>
<section id="gpus">
<h3>2 GPUs<a class="headerlink" href="#gpus" title="Link to this heading">#</a></h3>
<p>2개의 GPU를 갖고 있다면, 다음과 같이 표시될 것 입니다:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># on 2 GPUs</span>
Let<span class="err">&#39;</span>s<span class="w"> </span>use<span class="w"> </span><span class="m">2</span><span class="w"> </span>GPUs!
<span class="w">    </span>In<span class="w"> </span>Model:<span class="w"> </span>input<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">15</span>,<span class="w"> </span><span class="m">5</span><span class="o">])</span><span class="w"> </span>output<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">15</span>,<span class="w"> </span><span class="m">2</span><span class="o">])</span>
<span class="w">    </span>In<span class="w"> </span>Model:<span class="w"> </span>input<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">15</span>,<span class="w"> </span><span class="m">5</span><span class="o">])</span><span class="w"> </span>output<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">15</span>,<span class="w"> </span><span class="m">2</span><span class="o">])</span>
Outside:<span class="w"> </span>input<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">30</span>,<span class="w"> </span><span class="m">5</span><span class="o">])</span><span class="w"> </span>output_size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">30</span>,<span class="w"> </span><span class="m">2</span><span class="o">])</span>
<span class="w">    </span>In<span class="w"> </span>Model:<span class="w"> </span>input<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">15</span>,<span class="w"> </span><span class="m">5</span><span class="o">])</span><span class="w"> </span>output<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">15</span>,<span class="w"> </span><span class="m">2</span><span class="o">])</span>
<span class="w">    </span>In<span class="w"> </span>Model:<span class="w"> </span>input<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">15</span>,<span class="w"> </span><span class="m">5</span><span class="o">])</span><span class="w"> </span>output<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">15</span>,<span class="w"> </span><span class="m">2</span><span class="o">])</span>
Outside:<span class="w"> </span>input<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">30</span>,<span class="w"> </span><span class="m">5</span><span class="o">])</span><span class="w"> </span>output_size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">30</span>,<span class="w"> </span><span class="m">2</span><span class="o">])</span>
<span class="w">    </span>In<span class="w"> </span>Model:<span class="w"> </span>input<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">15</span>,<span class="w"> </span><span class="m">5</span><span class="o">])</span><span class="w"> </span>output<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">15</span>,<span class="w"> </span><span class="m">2</span><span class="o">])</span>
<span class="w">    </span>In<span class="w"> </span>Model:<span class="w"> </span>input<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">15</span>,<span class="w"> </span><span class="m">5</span><span class="o">])</span><span class="w"> </span>output<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">15</span>,<span class="w"> </span><span class="m">2</span><span class="o">])</span>
Outside:<span class="w"> </span>input<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">30</span>,<span class="w"> </span><span class="m">5</span><span class="o">])</span><span class="w"> </span>output_size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">30</span>,<span class="w"> </span><span class="m">2</span><span class="o">])</span>
<span class="w">    </span>In<span class="w"> </span>Model:<span class="w"> </span>input<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">5</span>,<span class="w"> </span><span class="m">5</span><span class="o">])</span><span class="w"> </span>output<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">5</span>,<span class="w"> </span><span class="m">2</span><span class="o">])</span>
<span class="w">    </span>In<span class="w"> </span>Model:<span class="w"> </span>input<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">5</span>,<span class="w"> </span><span class="m">5</span><span class="o">])</span><span class="w"> </span>output<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">5</span>,<span class="w"> </span><span class="m">2</span><span class="o">])</span>
Outside:<span class="w"> </span>input<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">10</span>,<span class="w"> </span><span class="m">5</span><span class="o">])</span><span class="w"> </span>output_size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">10</span>,<span class="w"> </span><span class="m">2</span><span class="o">])</span>
</pre></div>
</div>
</section>
<section id="id6">
<h3>3 GPUs<a class="headerlink" href="#id6" title="Link to this heading">#</a></h3>
<p>만약 당신이 3개의 GPU를 갖고 있다면, 다음과 같이 표시될 것 입니다:
.. code:: bash</p>
<blockquote>
<div><dl class="simple">
<dt>Let’s use 3 GPUs!</dt><dd><p>In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2])
In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2])
In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2])</p>
</dd>
<dt>Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])</dt><dd><p>In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2])
In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2])
In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2])</p>
</dd>
<dt>Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])</dt><dd><p>In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2])
In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2])
In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2])</p>
</dd>
<dt>Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])</dt><dd><p>In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])
In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])
In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2])</p>
</dd>
</dl>
<p>Outside: input size torch.Size([10, 5]) output_size torch.Size([10, 2])</p>
</div></blockquote>
</section>
<section id="id7">
<h3>8 GPUs<a class="headerlink" href="#id7" title="Link to this heading">#</a></h3>
<p>만약 당신이 8개의 GPU를 갖고 있다면, 다음과 같이 표시될 것 입니다:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Let<span class="err">&#39;</span>s<span class="w"> </span>use<span class="w"> </span><span class="m">8</span><span class="w"> </span>GPUs!
<span class="w">    </span>In<span class="w"> </span>Model:<span class="w"> </span>input<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">4</span>,<span class="w"> </span><span class="m">5</span><span class="o">])</span><span class="w"> </span>output<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">4</span>,<span class="w"> </span><span class="m">2</span><span class="o">])</span>
<span class="w">    </span>In<span class="w"> </span>Model:<span class="w"> </span>input<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">4</span>,<span class="w"> </span><span class="m">5</span><span class="o">])</span><span class="w"> </span>output<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">4</span>,<span class="w"> </span><span class="m">2</span><span class="o">])</span>
<span class="w">    </span>In<span class="w"> </span>Model:<span class="w"> </span>input<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">2</span>,<span class="w"> </span><span class="m">5</span><span class="o">])</span><span class="w"> </span>output<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">2</span>,<span class="w"> </span><span class="m">2</span><span class="o">])</span>
<span class="w">    </span>In<span class="w"> </span>Model:<span class="w"> </span>input<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">4</span>,<span class="w"> </span><span class="m">5</span><span class="o">])</span><span class="w"> </span>output<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">4</span>,<span class="w"> </span><span class="m">2</span><span class="o">])</span>
<span class="w">    </span>In<span class="w"> </span>Model:<span class="w"> </span>input<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">4</span>,<span class="w"> </span><span class="m">5</span><span class="o">])</span><span class="w"> </span>output<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">4</span>,<span class="w"> </span><span class="m">2</span><span class="o">])</span>
<span class="w">    </span>In<span class="w"> </span>Model:<span class="w"> </span>input<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">4</span>,<span class="w"> </span><span class="m">5</span><span class="o">])</span><span class="w"> </span>output<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">4</span>,<span class="w"> </span><span class="m">2</span><span class="o">])</span>
<span class="w">    </span>In<span class="w"> </span>Model:<span class="w"> </span>input<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">4</span>,<span class="w"> </span><span class="m">5</span><span class="o">])</span><span class="w"> </span>output<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">4</span>,<span class="w"> </span><span class="m">2</span><span class="o">])</span>
<span class="w">    </span>In<span class="w"> </span>Model:<span class="w"> </span>input<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">4</span>,<span class="w"> </span><span class="m">5</span><span class="o">])</span><span class="w"> </span>output<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">4</span>,<span class="w"> </span><span class="m">2</span><span class="o">])</span>
Outside:<span class="w"> </span>input<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">30</span>,<span class="w"> </span><span class="m">5</span><span class="o">])</span><span class="w"> </span>output_size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">30</span>,<span class="w"> </span><span class="m">2</span><span class="o">])</span>
<span class="w">    </span>In<span class="w"> </span>Model:<span class="w"> </span>input<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">4</span>,<span class="w"> </span><span class="m">5</span><span class="o">])</span><span class="w"> </span>output<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">4</span>,<span class="w"> </span><span class="m">2</span><span class="o">])</span>
<span class="w">    </span>In<span class="w"> </span>Model:<span class="w"> </span>input<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">4</span>,<span class="w"> </span><span class="m">5</span><span class="o">])</span><span class="w"> </span>output<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">4</span>,<span class="w"> </span><span class="m">2</span><span class="o">])</span>
<span class="w">    </span>In<span class="w"> </span>Model:<span class="w"> </span>input<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">4</span>,<span class="w"> </span><span class="m">5</span><span class="o">])</span><span class="w"> </span>output<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">4</span>,<span class="w"> </span><span class="m">2</span><span class="o">])</span>
<span class="w">    </span>In<span class="w"> </span>Model:<span class="w"> </span>input<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">4</span>,<span class="w"> </span><span class="m">5</span><span class="o">])</span><span class="w"> </span>output<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">4</span>,<span class="w"> </span><span class="m">2</span><span class="o">])</span>
<span class="w">    </span>In<span class="w"> </span>Model:<span class="w"> </span>input<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">4</span>,<span class="w"> </span><span class="m">5</span><span class="o">])</span><span class="w"> </span>output<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">4</span>,<span class="w"> </span><span class="m">2</span><span class="o">])</span>
<span class="w">    </span>In<span class="w"> </span>Model:<span class="w"> </span>input<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">4</span>,<span class="w"> </span><span class="m">5</span><span class="o">])</span><span class="w"> </span>output<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">4</span>,<span class="w"> </span><span class="m">2</span><span class="o">])</span>
<span class="w">    </span>In<span class="w"> </span>Model:<span class="w"> </span>input<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">2</span>,<span class="w"> </span><span class="m">5</span><span class="o">])</span><span class="w"> </span>output<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">2</span>,<span class="w"> </span><span class="m">2</span><span class="o">])</span>
<span class="w">    </span>In<span class="w"> </span>Model:<span class="w"> </span>input<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">4</span>,<span class="w"> </span><span class="m">5</span><span class="o">])</span><span class="w"> </span>output<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">4</span>,<span class="w"> </span><span class="m">2</span><span class="o">])</span>
Outside:<span class="w"> </span>input<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">30</span>,<span class="w"> </span><span class="m">5</span><span class="o">])</span><span class="w"> </span>output_size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">30</span>,<span class="w"> </span><span class="m">2</span><span class="o">])</span>
<span class="w">    </span>In<span class="w"> </span>Model:<span class="w"> </span>input<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">4</span>,<span class="w"> </span><span class="m">5</span><span class="o">])</span><span class="w"> </span>output<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">4</span>,<span class="w"> </span><span class="m">2</span><span class="o">])</span>
<span class="w">    </span>In<span class="w"> </span>Model:<span class="w"> </span>input<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">4</span>,<span class="w"> </span><span class="m">5</span><span class="o">])</span><span class="w"> </span>output<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">4</span>,<span class="w"> </span><span class="m">2</span><span class="o">])</span>
<span class="w">    </span>In<span class="w"> </span>Model:<span class="w"> </span>input<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">4</span>,<span class="w"> </span><span class="m">5</span><span class="o">])</span><span class="w"> </span>output<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">4</span>,<span class="w"> </span><span class="m">2</span><span class="o">])</span>
<span class="w">    </span>In<span class="w"> </span>Model:<span class="w"> </span>input<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">4</span>,<span class="w"> </span><span class="m">5</span><span class="o">])</span><span class="w"> </span>output<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">4</span>,<span class="w"> </span><span class="m">2</span><span class="o">])</span>
<span class="w">    </span>In<span class="w"> </span>Model:<span class="w"> </span>input<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">4</span>,<span class="w"> </span><span class="m">5</span><span class="o">])</span><span class="w"> </span>output<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">4</span>,<span class="w"> </span><span class="m">2</span><span class="o">])</span>
<span class="w">    </span>In<span class="w"> </span>Model:<span class="w"> </span>input<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">4</span>,<span class="w"> </span><span class="m">5</span><span class="o">])</span><span class="w"> </span>output<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">4</span>,<span class="w"> </span><span class="m">2</span><span class="o">])</span>
<span class="w">    </span>In<span class="w"> </span>Model:<span class="w"> </span>input<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">4</span>,<span class="w"> </span><span class="m">5</span><span class="o">])</span><span class="w"> </span>output<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">4</span>,<span class="w"> </span><span class="m">2</span><span class="o">])</span>
<span class="w">    </span>In<span class="w"> </span>Model:<span class="w"> </span>input<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">2</span>,<span class="w"> </span><span class="m">5</span><span class="o">])</span><span class="w"> </span>output<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">2</span>,<span class="w"> </span><span class="m">2</span><span class="o">])</span>
Outside:<span class="w"> </span>input<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">30</span>,<span class="w"> </span><span class="m">5</span><span class="o">])</span><span class="w"> </span>output_size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">30</span>,<span class="w"> </span><span class="m">2</span><span class="o">])</span>
<span class="w">    </span>In<span class="w"> </span>Model:<span class="w"> </span>input<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">2</span>,<span class="w"> </span><span class="m">5</span><span class="o">])</span><span class="w"> </span>output<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">2</span>,<span class="w"> </span><span class="m">2</span><span class="o">])</span>
<span class="w">    </span>In<span class="w"> </span>Model:<span class="w"> </span>input<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">2</span>,<span class="w"> </span><span class="m">5</span><span class="o">])</span><span class="w"> </span>output<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">2</span>,<span class="w"> </span><span class="m">2</span><span class="o">])</span>
<span class="w">    </span>In<span class="w"> </span>Model:<span class="w"> </span>input<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">2</span>,<span class="w"> </span><span class="m">5</span><span class="o">])</span><span class="w"> </span>output<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">2</span>,<span class="w"> </span><span class="m">2</span><span class="o">])</span>
<span class="w">    </span>In<span class="w"> </span>Model:<span class="w"> </span>input<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">2</span>,<span class="w"> </span><span class="m">5</span><span class="o">])</span><span class="w"> </span>output<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">2</span>,<span class="w"> </span><span class="m">2</span><span class="o">])</span>
<span class="w">    </span>In<span class="w"> </span>Model:<span class="w"> </span>input<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">2</span>,<span class="w"> </span><span class="m">5</span><span class="o">])</span><span class="w"> </span>output<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">2</span>,<span class="w"> </span><span class="m">2</span><span class="o">])</span>
Outside:<span class="w"> </span>input<span class="w"> </span>size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">10</span>,<span class="w"> </span><span class="m">5</span><span class="o">])</span><span class="w"> </span>output_size<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">10</span>,<span class="w"> </span><span class="m">2</span><span class="o">])</span>
</pre></div>
</div>
</section>
</section>
<section id="id8">
<h2>요약<a class="headerlink" href="#id8" title="Link to this heading">#</a></h2>
<p>DataParallel은 당신의 데이터를 자동으로 분할하고 여러 GPU에 있는 다수의 모델에 작업을 지시합니다. 각 모델이 작업을 완료하면 DataParallel은
사용자에게 결과를 반환하기 전에 모든 결과물들을 수집하여 병합합니다.</p>
<p>더 많은 정보를 알고싶다면 아래 주소를 참고하세요.
<a class="reference external" href="https://tutorials.pytorch.kr/beginner/former_torchies/parallelism_tutorial.html">https://tutorials.pytorch.kr/beginner/former_torchies/parallelism_tutorial.html</a></p>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (0 minutes 11.148 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-beginner-blitz-data-parallel-tutorial-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/7f37028fb3517ca10f3388f4bb4889b8/data_parallel_tutorial.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">data_parallel_tutorial.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/e85264945029fe236addcb864bf5f13f/data_parallel_tutorial.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">data_parallel_tutorial.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/0bf0ebd2bc2f524b57b0d2c313c08e38/data_parallel_tutorial.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">data_parallel_tutorial.zip</span></code></a></p>
</div>
</div>
</section>
</section>


                </article>
              
  </article>
  
              
              
                <footer class="bd-footer-article">
                  <div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item">
<div class="feedback">
  
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
        
    </div>
</div>

  <div class="feedback-send">
    <button class="feedback-btn"
            onclick="openGitHubIssue()"
            data-bs-title="Create a GitHub Issue"
            data-bs-placement="bottom"
            data-bs-toggle="tooltip"
            data-gtm="feedback-btn-click">Send Feedback
    </button>
  </div>
</div>

<div class="prev-next-area">
</div>

<div class="footer-info">
  <p class="copyright">
    
      
        © Copyright 2018-2025, PyTorch &amp; 파이토치 한국 사용자 모임(PyTorchKR).
      
      <br/>
    
  </p>

  <p class="theme-version">
    Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
  </p>
</div>
</div>
  
</div>
                </footer>
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc">
<div class="sidebar-secondary-items sidebar-secondary__inner">
    
       <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">불러오기와 매개변수</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dummy">더미(Dummy) 데이터셋</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">간단한 모델</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">모델과 데이터 병렬의 구현</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">모델 실행</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">결과</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gpus">2 GPUs</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">3 GPUs</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">8 GPUs</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">요약</a></li>
</ul>
  </nav></div>
    




<div class="sidebar-secondary-item">
  <div class="sidebar-heading">PyTorch Libraries</div>
  <ul style="list-style-type: none; padding: 0; padding-bottom: 80px;">
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/ao" style="color: var(--pst-color-text-muted)">torchao</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchrec" style="color: var(--pst-color-text-muted)">torchrec</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchft" style="color: var(--pst-color-text-muted)">torchft</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchcodec" style="color: var(--pst-color-text-muted)">TorchCodec</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/vision" style="color: var(--pst-color-text-muted)">torchvision</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/executorch" style="color: var(--pst-color-text-muted)">ExecuTorch</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/xla" style="color: var(--pst-color-text-muted)">PyTorch on XLA Devices</a></li>
  
  </ul>
</div>

</div>
</div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <div class="container-fluid docs-tutorials-resources">
  <div class="container">
    <div class="row">
      <div class="col-md-4 text-center">
        <h2>PyTorchKorea @ GitHub</h2>
        <p>파이토치 한국 사용자 모임을 GitHub에서 만나보세요.</p>
        <a class="with-right-arrow" href="https://github.com/PyTorchKorea">GitHub로 이동</a>
      </div>

      <div class="col-md-4 text-center">
        <h2>한국어 튜토리얼</h2>
        <p>한국어로 번역 중인 파이토치 튜토리얼을 만나보세요.</p>
        <a class="with-right-arrow" href="https://tutorials.pytorch.kr/">튜토리얼로 이동</a>
      </div>

      <div class="col-md-4 text-center">
        <h2>한국어 커뮤니티</h2>
        <p>다른 사용자들과 의견을 나누고, 도와주세요!</p>
        <a class="with-right-arrow" href="https://discuss.pytorch.kr/">커뮤니티로 이동</a>
      </div>
    </div>
  </div>
</div>

<footer class="site-footer">
  <div class="container footer-container">
    <div class="footer-logo-wrapper">
      <a href="https://pytorch.kr/" class="footer-logo"></a>
    </div>

    <div class="footer-links-wrapper">
      <div class="footer-links-col">
        <ul>
          <li class="list-title"><a href="https://pytorch.kr/">파이토치 한국 사용자 모임</a></li>
          <li><a href="https://pytorch.kr/about">사용자 모임 소개</a></li>
          <li><a href="https://pytorch.kr/contributors">기여해주신 분들</a></li>
          <li><a href="https://pytorch.kr/resources/">리소스</a></li>
          <li><a href="https://pytorch.kr/coc">행동 강령</a></li>
        </ul>
      </div>
    </div>

    <div class="trademark-disclaimer">
      <ul>
        <li>이 사이트는 독립적인 파이토치 사용자 커뮤니티로, 최신 버전이 아니거나 잘못된 내용이 포함되어 있을 수 있습니다. This site is an independent user community and may be out of date or contain incorrect information.</li>
        <li><a href="https://pytorch.kr/coc">행동 강령</a>을 읽고 지켜주세요. PyTorch 공식 로고 사용 규정은 <a href="https://www.linuxfoundation.org/policies/">Linux Foundation의 정책</a>을 따릅니다. Please read and follow <a href="https://pytorch.kr/coc">our code of conduct</a>. All PyTorch trademark policy applicable to <a href="https://www.linuxfoundation.org/policies/">Linux Foundation's policies</a>.</li>
      </ul>
    </div>
  </div>
</footer>

<div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../_static/img/pytorch-x.svg">
  </div>
</div>
  
  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2018-2025, PyTorch &amp; 파이토치 한국 사용자 모임(PyTorchKR).
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.2.6 버전으로 생성되었습니다.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
</p></div>
      
    </div>
  
</div>

  </footer>
  <script type="application/ld+json">
    {
       "@context": "https://schema.org",
       "@type": "Article",
       "name": "\uc120\ud0dd \uc0ac\ud56d: \ub370\uc774\ud130 \ubcd1\ub82c \ucc98\ub9ac (Data Parallelism)",
       "headline": "\uc120\ud0dd \uc0ac\ud56d: \ub370\uc774\ud130 \ubcd1\ub82c \ucc98\ub9ac (Data Parallelism)",
       "description": "PyTorch Documentation. Explore PyTorch, an open-source machine learning library that accelerates the path from research prototyping to production deployment. Discover tutorials, API references, and guides to help you build and deploy deep learning models efficiently.",
       "url": "/beginner/blitz/data_parallel_tutorial.html",
       "articleBody": "\ucc38\uace0 Go to the end to download the full example code. \uc120\ud0dd \uc0ac\ud56d: \ub370\uc774\ud130 \ubcd1\ub82c \ucc98\ub9ac (Data Parallelism)# \uae00\uc4f4\uc774: Sung Kim and Jenny Kang \ubc88\uc5ed: \u2018\uc815\uc544\uc9c4 \u003cajin-jng\u003e\u2019 \uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc5d0\uc11c\ub294 DataParallel (\ub370\uc774\ud130 \ubcd1\ub82c) \uc744 \uc0ac\uc6a9\ud558\uc5ec \uc5ec\ub7ec GPU\ub97c \uc0ac\uc6a9\ud558\ub294 \ubc95\uc744 \ubc30\uc6b0\uaca0\uc2b5\ub2c8\ub2e4. PyTorch\ub97c \ud1b5\ud574 GPU\ub97c \uc0ac\uc6a9\ud558\ub294 \uac83\uc740 \ub9e4\uc6b0 \uc27d\uc2b5\ub2c8\ub2e4. \uba3c\uc800, \ubaa8\ub378\uc744 GPU\uc5d0 \ub123\uc2b5\ub2c8\ub2e4: device = torch.device(\"cuda:0\") model.to(device) \uadf8 \ub2e4\uc74c\uc73c\ub85c\ub294 \ubaa8\ub4e0 Tensors \ub97c GPU\ub85c \ubcf5\uc0ac\ud569\ub2c8\ub2e4: mytensor = my_tensor.to(device) \u2018\u2019my_tensor.to(device)\u2019\u2019 \ub97c \ud638\ucd9c \uc2dc \uc5d0\ub294 \u2018\u2019my_tensor\u2019\u2019 \ub97c \ub2e4\uc2dc\uc4f0\ub294 \ub300\uc2e0 \u2018\u2019my_tensor\u2019\u2019 \uc758 \ub610\ub2e4\ub978 \ubcf5\uc0ac\ubcf8\uc774 \uc0dd\uae34\ub2e4\ub294 \uc0ac\uc2e4\uc744 \uae30\uc5b5\ud558\uc2ed\uc2dc\uc624. \ub2f9\uc2e0\uc740 \uadf8\uac83\uc744 \uc0c8\ub85c\uc6b4 tensor \uc5d0 \uc18c\uc18d\uc2dc\ud0a4\uace0 GPU\uc5d0 \uadf8 tensor\ub97c \uc368\uc57c\ud569\ub2c8\ub2e4. \uc5ec\ub7ec GPU\ub97c \ud1b5\ud574 \uc55e\uacfc \ub4a4\uc758 \uc804\ud30c\ub97c \uc2e4\ud589\ud558\ub294 \uac83\uc740 \ub2f9\uc5f0\ud55c \uc77c \uc785\ub2c8\ub2e4. \uadf8\ub7ec\ub098 PyTorch\ub294 \uae30\ubcf8\uc801 \ud558\ub098\uc758 GPU\ub9cc \uc0ac\uc6a9\ud569\ub2c8\ub2e4. DataParallel \uc744 \uc774\uc6a9\ud558\uc5ec \ubaa8\ub378\uc744 \ubcd1\ub82c\ub85c \uc2e4\ud589\ud558\uc5ec \ub2e4\uc218\uc758 GPU \uc5d0\uc11c \uc27d\uac8c \uc791\uc5c5\uc744 \uc2e4\ud589\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4: model = nn.DataParallel(model) \uc774\uac83\uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc758 \ud575\uc2ec\uc785\ub2c8\ub2e4. \uc790\uc138\ud55c \uc0ac\ud56d\ub4e4\uc5d0 \ub300\ud574\uc11c\ub294 \uc544\ub798\uc5d0\uc11c \uc0b4\ud3b4\ubcf4\uaca0\uc2b5\ub2c8\ub2e4. \ubd88\ub7ec\uc624\uae30\uc640 \ub9e4\uac1c\ubcc0\uc218# PyTorch \ubaa8\ub4c8\uc744 \ubd88\ub7ec\uc624\uace0 \ub9e4\uac1c\ubcc0\uc218\ub97c \uc815\uc758\ud558\uc2ed\uc2dc\uc624. import torch import torch.nn as nn from torch.utils.data import Dataset, DataLoader # \ub9e4\uac1c\ubcc0\uc218\uc640 DataLoaders input_size = 5 output_size = 2 batch_size = 30 data_size = 100 \uae30\uae30 device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \ub354\ubbf8(Dummy) \ub370\uc774\ud130\uc14b# \ub354\ubbf8(ramdom) \ub370\uc774\ud130\uc14b\uc744 \ub9cc\ub4e4\uc5b4 \ubd05\uc2dc\ub2e4. Getitem \ub9cc \uad6c\ud604\ud558\uba74 \ub429\ub2c8\ub2e4. class RandomDataset(Dataset): def __init__(self, size, length): self.len = length self.data = torch.randn(length, size) def __getitem__(self, index): return self.data[index] def __len__(self): return self.len rand_loader = DataLoader(dataset=RandomDataset(input_size, data_size), batch_size=batch_size, shuffle=True) \uac04\ub2e8\ud55c \ubaa8\ub378# \ub370\ubaa8\ub97c \uc704\ud574 \ubaa8\ub378\uc740 \uc785\ub825\uc744 \ubc1b\uace0 \uc120\ud615 \uc5f0\uc0b0\uc744 \uc218\ud589\ud558\uba70 \ucd9c\ub825\uc744 \uc81c\uacf5\ud569\ub2c8\ub2e4. \uadf8\ub7ec\ub098 DataParallel \uc758 \uc5b4\ub5a4 \ubaa8\ub378 (CNN, RNN, Capsule Net \ub4f1) \uc5d0\uc11c\ub4e0 \uc0ac\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc6b0\ub9ac\ub294 input\uacfc output\uc758 \ud06c\uae30\ub97c \ubaa8\ub2c8\ud130\ub9c1\ud558\uae30 \uc704\ud574 \ubaa8\ub378\uc548\uc5d0 print \ubb38\uc744 \ub123\uc5c8\uc2b5\ub2c8\ub2e4. \ubb34\uc5c7\uc774 \ubc30\uce58 \uc21c\uc704 (batch rank) 0 \uc5d0 \ud504\ub9b0\ud2b8 \ub418\ub294\uc9c0 \uc8fc\uc758 \uae4a\uac8c \ubd10\uc8fc\uc2dc\uae38 \ubc14\ub78d\ub2c8\ub2e4. class Model(nn.Module): # \uc6b0\ub9ac\uc758 \ubaa8\ub378 def __init__(self, input_size, output_size): super(Model, self).__init__() self.fc = nn.Linear(input_size, output_size) def forward(self, input): output = self.fc(input) print(\"\\tIn Model: input size\", input.size(), \"output size\", output.size()) return output \ubaa8\ub378\uacfc \ub370\uc774\ud130 \ubcd1\ub82c\uc758 \uad6c\ud604# \uc774\uac83\uc740 \uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc758 \ud575\uc2ec \ubd80\ubd84\uc785\ub2c8\ub2e4. \uba3c\uc800, model instance \ub97c \ub9cc\ub4e4\uace0 \uac00\uc9c0\uace0 \uc788\ub294 GPU\uac00 \uc5ec\ub7ec\uac1c\uc778\uc9c0 \ud655\uc778\ud574\uc57c\ud569\ub2c8\ub2e4. \ub9cc\uc57d \ub2e4\uc218\uc758 GPU\ub97c \ubcf4\uc720\uc911\uc774\ub77c\uba74, nn.DataParallel \uc744 \uc0ac\uc6a9\ud558\uc5ec \ubaa8\ub378\uc744 \ub798\ud551 (wrapping) \ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uadf8\ub7f0 \ub2e4\uc74c model.to(device) \ub97c \ud1b5\ud558\uc5ec \ubaa8\ub378\uc744 GPU\uc5d0 \ub123\uc744 \uc218 \uc788\uc2b5\ub2c8\ub2e4. model = Model(input_size, output_size) if torch.cuda.device_count() \u003e 1: print(\"Let\u0027s use\", torch.cuda.device_count(), \"GPUs!\") # dim = 0 [30, xxx] -\u003e [10, ...], [10, ...], [10, ...] on 3 GPUs model = nn.DataParallel(model) model.to(device) Let\u0027s use 8 GPUs! DataParallel( (module): Model( (fc): Linear(in_features=5, out_features=2, bias=True) ) ) \ubaa8\ub378 \uc2e4\ud589# \uc774\uc81c \uc6b0\ub9ac\ub294 \uc785\ub825\uacfc \ucd9c\ub825 tensor\uc758 \ud06c\uae30\ub97c \ubcfc \uc218 \uc788\uc2b5\ub2c8\ub2e4 for data in rand_loader: input = data.to(device) output = model(input) print(\"Outside: input size\", input.size(), \"output_size\", output.size()) /opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py:125: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:179.) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2]) In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2]) In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2]) In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2]) In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2]) Outside: input size torch.Size([10, 5]) output_size torch.Size([10, 2]) \uacb0\uacfc# GPU\uac00 \uc5c6\uac70\ub098 \ud558\ub098\uc778 \uacbd\uc6b0 30\uac1c\uc758 \uc785\ub825\uacfc 30\uac1c\uc758 \ucd9c\ub825\uc744 \uc77c\uad04 \ucc98\ub9ac\ud558\uba74 \ubaa8\ub378\uc774 \uc608\uc0c1\ub300\ub85c 30\uc744 \uc785\ub825\ubc1b\uace0 30\uc744 \ucd9c\ub825\ud569\ub2c8\ub2e4. \ud558\uc9c0\ub9cc \ub9cc\uc57d \ub2f9\uc2e0\uc774 \ub2e4\uc218\uc758 GPU\ub97c \uac00\uc9c0\uace0 \uc788\ub2e4\uba74, \ub2e4\uc74c\uacfc \uac19\uc740 \uacb0\uacfc\ub97c \uc5bb\uc744 \uc218 \uc788\uc2b5\ub2c8\ub2e4. 2 GPUs# 2\uac1c\uc758 GPU\ub97c \uac16\uace0 \uc788\ub2e4\uba74, \ub2e4\uc74c\uacfc \uac19\uc774 \ud45c\uc2dc\ub420 \uac83 \uc785\ub2c8\ub2e4: # on 2 GPUs Let\u0027s use 2 GPUs! In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2]) In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2]) In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2]) In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([5, 5]) output size torch.Size([5, 2]) In Model: input size torch.Size([5, 5]) output size torch.Size([5, 2]) Outside: input size torch.Size([10, 5]) output_size torch.Size([10, 2]) 3 GPUs# \ub9cc\uc57d \ub2f9\uc2e0\uc774 3\uac1c\uc758 GPU\ub97c \uac16\uace0 \uc788\ub2e4\uba74, \ub2e4\uc74c\uacfc \uac19\uc774 \ud45c\uc2dc\ub420 \uac83 \uc785\ub2c8\ub2e4: .. code:: bash Let\u2019s use 3 GPUs!In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2]) In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2]) In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2]) In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2]) In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2]) In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2]) In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2]) Outside: input size torch.Size([10, 5]) output_size torch.Size([10, 2]) 8 GPUs# \ub9cc\uc57d \ub2f9\uc2e0\uc774 8\uac1c\uc758 GPU\ub97c \uac16\uace0 \uc788\ub2e4\uba74, \ub2e4\uc74c\uacfc \uac19\uc774 \ud45c\uc2dc\ub420 \uac83 \uc785\ub2c8\ub2e4: Let\u0027s use 8 GPUs! In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2]) In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2]) In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2]) In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2]) In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2]) Outside: input size torch.Size([10, 5]) output_size torch.Size([10, 2]) \uc694\uc57d# DataParallel\uc740 \ub2f9\uc2e0\uc758 \ub370\uc774\ud130\ub97c \uc790\ub3d9\uc73c\ub85c \ubd84\ud560\ud558\uace0 \uc5ec\ub7ec GPU\uc5d0 \uc788\ub294 \ub2e4\uc218\uc758 \ubaa8\ub378\uc5d0 \uc791\uc5c5\uc744 \uc9c0\uc2dc\ud569\ub2c8\ub2e4. \uac01 \ubaa8\ub378\uc774 \uc791\uc5c5\uc744 \uc644\ub8cc\ud558\uba74 DataParallel\uc740 \uc0ac\uc6a9\uc790\uc5d0\uac8c \uacb0\uacfc\ub97c \ubc18\ud658\ud558\uae30 \uc804\uc5d0 \ubaa8\ub4e0 \uacb0\uacfc\ubb3c\ub4e4\uc744 \uc218\uc9d1\ud558\uc5ec \ubcd1\ud569\ud569\ub2c8\ub2e4. \ub354 \ub9ce\uc740 \uc815\ubcf4\ub97c \uc54c\uace0\uc2f6\ub2e4\uba74 \uc544\ub798 \uc8fc\uc18c\ub97c \ucc38\uace0\ud558\uc138\uc694. https://tutorials.pytorch.kr/beginner/former_torchies/parallelism_tutorial.html Total running time of the script: (0 minutes 11.148 seconds) Download Jupyter notebook: data_parallel_tutorial.ipynb Download Python source code: data_parallel_tutorial.py Download zipped: data_parallel_tutorial.zip",
       "author": {
         "@type": "Organization",
         "name": "PyTorch Contributors",
         "url": "https://pytorch.org"
       },
       "image": "../../_static/img/pytorch_seo.png",
       "mainEntityOfPage": {
         "@type": "WebPage",
         "@id": "/beginner/blitz/data_parallel_tutorial.html"
       },
       "datePublished": "2023-01-01T00:00:00Z",
       "dateModified": "2023-01-01T00:00:00Z"
     }
 </script>
  <script>
    // Tutorials Call to action event tracking
    $("[data-behavior='call-to-action-event']").on('click', function () {
      fbq('trackCustom', "Download", {
        tutorialTitle: $('h1:first').text(),
        downloadLink: this.href,
        tutorialLink: window.location.href,
        downloadTitle: $(this).attr("data-response")
      });
      if (typeof gtag === 'function') {
        gtag('event', 'click', {
          'event_category': $(this).attr("data-response"),
          'event_label': $("h1").first().text(),
          'tutorial_link': window.location.href
        });
      }
    });
  </script>
  
  </body>
</html>