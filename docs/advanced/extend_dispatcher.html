
<!DOCTYPE html>


<html lang="ko" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <meta property="article:modified_time" content="2022-11-30T07:09:41+00:00" /><meta property="og:title" content="Extending dispatcher for a new backend in C++" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://tutorials.pytorch.kr/advanced/extend_dispatcher.html" />
<meta property="og:site_name" content="PyTorch Tutorials KR" />
<meta property="og:description" content="In this tutorial we will walk through all necessary steps to extend the dispatcher to add a new device living outside pytorch/pytorch repo and maintain it to keep in sync with native PyTorch devices. Here we’ll assume that you’re familiar with how to register a dispatched operator in C++ and how ..." />
<meta property="og:image" content="https://tutorials.pytorch.kr/_static/logos/logo-kr-sm-dark.png" />
<meta property="og:image:alt" content="PyTorch Tutorials KR" />
<meta name="description" content="In this tutorial we will walk through all necessary steps to extend the dispatcher to add a new device living outside pytorch/pytorch repo and maintain it to keep in sync with native PyTorch devices. Here we’ll assume that you’re familiar with how to register a dispatched operator in C++ and how ..." />
<meta property="og:ignore_canonical" content="true" />

    <title>Extending dispatcher for a new backend in C++ &#8212; 파이토치 한국어 튜토리얼 (PyTorch tutorials in Korean)</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=536c50fe" />
    <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=4d2595e5" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/katex-math.css?v=91adb8b6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/pytorch_theme.css?v=c326296f" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css?v=097efa9c" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom2.css?v=b169ea90" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=725a5b95"></script>
    <script src="../_static/doctools.js?v=92e14aea"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/translations.js?v=b5f768d8"></script>
    <script src="../_static/katex.min.js?v=be8ff15f"></script>
    <script src="../_static/auto-render.min.js?v=ad136472"></script>
    <script src="../_static/katex_autorenderer.js?v=bebc588a"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'advanced/extend_dispatcher';</script>
    <link rel="canonical" href="https://tutorials.pytorch.kr/advanced/extend_dispatcher.html" />
    <link rel="icon" href="../_static/favicon.ico"/>
    <link rel="index" title="색인" href="../genindex.html" />
    <link rel="search" title="검색" href="../search.html" />
    <link rel="next" title="Facilitating New Backend Integration by PrivateUse1" href="privateuseone.html" />
    <link rel="prev" title="Registering a Dispatched Operator in C++" href="dispatcher.html" />

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="ko"/>
    <meta name="docbuild:last-update" content="2022년 11월 30일"/>
<script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/2.3.1/list.min.js"></script>
<script>
  if (window.location.hostname === 'docs.pytorch.org' || window.location.hostname === 'docs-preview.pytorch.org') {
    const script = document.createElement('script');
    script.src = 'https://cmp.osano.com/16A0DbT9yDNIaQkvZ/31b1b91a-e0b6-47ea-bde2-7f2bd13dbe5c/osano.js?variant=one';
    document.head.appendChild(script);
  }
</script>
<script>
  // Cookie banner for non-LF projects
  document.addEventListener('DOMContentLoaded', function () {
    // Hide cookie banner on local environments and LF owned docs
    if (window.location.hostname === 'localhost' ||
      window.location.hostname === '0.0.0.0' ||
      window.location.hostname === '127.0.0.1' ||
      window.location.hostname === 'docs.pytorch.org' ||
      window.location.hostname === 'docs-preview.pytorch.org' ||
      window.location.hostname.startsWith('192.168.')) {
      const banner = document.querySelector('.cookie-banner-wrapper');
      if (banner) {
        banner.style.display = 'none';
      }
    }
  });
</script>
<!-- Conditional CSS for header and footer height adjustment -->

<link rel="stylesheet" type="text/css" href="../_static/css/theme.css" crossorigin="anonymous">
<script type="text/javascript" src="../_static/js/theme.js"></script>
<script type="text/javascript" src="../_static/js/dropdown-menu.js"></script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Nanum+Gothic:wght@400;700&family=Nanum+Gothic+Coding:wght@400;700&family=Montserrat:wght@300;400&display=swap" rel="stylesheet">
<meta property="og:image" content="../_static/img/pytorch_seo.png" />
<link rel="stylesheet" href="../_static/webfonts/all.min.css" crossorigin="anonymous">
<meta http-equiv="Content-Security-Policy"
  content="default-src * 'unsafe-inline' 'unsafe-eval' data: blob:; style-src * 'unsafe-inline'; script-src * 'unsafe-inline' 'unsafe-eval' blob:;">
<meta name="pytorch_project" content="tutorials">
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=G-LZRD6GXDLF" height="0" width="0"
    style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
<!-- Google Tag Manager -->
<script>(function (w, d, s, l, i) {
    w[l] = w[l] || []; w[l].push({
      'gtm.start':
        new Date().getTime(), event: 'gtm.js'
    }); var f = d.getElementsByTagName(s)[0],
      j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : ''; j.async = true; j.src =
        'https://www.googletagmanager.com/gtm.js?id=' + i + dl; f.parentNode.insertBefore(j, f);
    j.onload = function () {
      window.dispatchEvent(new Event('gtm_loaded'));
      console.log('GTM loaded successfully');
    };
  })(window, document, 'script', 'dataLayer', 'G-LZRD6GXDLF');
</script>
<!-- End Google Tag Manager -->
<!-- Facebook Pixel Code -->
<script>
  !function (f, b, e, v, n, t, s) {
    if (f.fbq) return; n = f.fbq = function () {
      n.callMethod ?
        n.callMethod.apply(n, arguments) : n.queue.push(arguments)
    };
    if (!f._fbq) f._fbq = n; n.push = n; n.loaded = !0; n.version = '2.0';
    n.queue = []; t = b.createElement(e); t.async = !0;
    t.src = v; s = b.getElementsByTagName(e)[0];
    s.parentNode.insertBefore(t, s)
  }(window, document, 'script',
    'https://connect.facebook.net/en_US/fbevents.js');
  fbq('init', '243028289693773');
  fbq('track', 'PageView');
</script>
<script>
  document.documentElement.setAttribute('data-version', 'v2.8.0+cu128');
</script>
<noscript>
  <img height="1" width="1" src="https://www.facebook.com/tr?id=243028289693773&ev=PageView&noscript=1" />
</noscript>
<script>
  function gtag() {
    window.dataLayer.push(arguments);
  }
</script>
<!-- End Facebook Pixel Code -->
<!-- Script to Fix scrolling -->
<script>
  document.addEventListener('DOMContentLoaded', function () {
    // Fix anchor scrolling
    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener('click', function (e) {
        e.preventDefault();
        const targetId = this.getAttribute('href').substring(1);
        const targetElement = document.getElementById(targetId);

        if (targetElement) {
          const headerHeight =
            (document.querySelector('.header-holder') ? document.querySelector('.header-holder').offsetHeight : 0) +
            (document.querySelector('.bd-header') ? document.querySelector('.bd-header').offsetHeight : 0) + 20;

          const targetPosition = targetElement.getBoundingClientRect().top + window.pageYOffset - headerHeight;
          window.scrollTo({
            top: targetPosition,
            behavior: 'smooth'
          });

          // Update URL hash without scrolling
          history.pushState(null, null, '#' + targetId);
        }
      });
    });
  });
</script>

<script async src="https://cse.google.com/cse.js?cx=e65585f8c3ea1440e"></script>


  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="ko"/>
    <meta name="docbuild:last-update" content="2022년 11월 30일"/>

  </head>

<body data-feedback-url="https://github.com/PyTorchKorea/tutorials-kr" class="pytorch-body">
  
    <div class="container-fluid header-holder tutorials-header" id="header-holder">
   <div class="header-container-wrapper">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.kr/" aria-label="PyTorchKR"></a>

      <div class="main-menu">
        <ul>

          <li class="main-menu-item">
          <div id="learnDropdownButton" data-toggle="learn-dropdown" class="learn-dropdown">
              <a class="with-down-arrow">
                <span>배우기</span>
              </a>
              <div class="learn-dropdown-menu dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.kr/get-started/locally/">
                  <span class="dropdown-title">PyTorch 시작하기</span>
                </a>
                <a class="nav-dropdown-item" href="https://tutorials.pytorch.kr/beginner/basics/intro.html">
                  <span class="dropdown-title">기본 익히기</span>
                </a>
                <a class="nav-dropdown-item" href="https://tutorials.pytorch.kr/" target="_self">
                  <span class="dropdown-title">한국어 튜토리얼</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.kr/hub/">
                  <span class="dropdown-title">한국어 모델 허브</span>
                </a>
                <a class="nav-dropdown-item" href="https://docs.pytorch.org/tutorials/" target="_blank">
                  <span class="dropdown-title">Official Tutorials</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <a href="https://pytorch.kr/blog/">
              <span>블로그</span>
            </a>
          </li>

          <li class="main-menu-item">
          <div id="docsDropdownButton" data-toggle="docs-dropdown" class="docs-dropdown">
              <a class="with-down-arrow">
              <span>문서</span>
              </a>
              <div class="docs-dropdown-menu dropdown-menu">
                <a class="nav-dropdown-item" href="https://docs.pytorch.org/docs/" target="_blank">
                  <span class="dropdown-title">PyTorch API</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.kr/domains/">
                  <span class="dropdown-title">Domain API 소개</span>
                </a>
                <a class="nav-dropdown-item" href="https://tutorials.pytorch.kr/" target="_self">
                  <span class="dropdown-title">한국어 튜토리얼</span>
                </a>
                <a class="nav-dropdown-item" href="https://docs.pytorch.org/tutorials/" target="_blank">
                  <span class="dropdown-title">Official Tutorials</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
          <div id="communityDropdownButton" data-toggle="community-dropdown" class="community-dropdown">
              <a class="with-down-arrow">
              <span>커뮤니티</span>
              </a>
              <div class="community-dropdown-menu dropdown-menu">
                <a class="nav-dropdown-item" href="https://discuss.pytorch.kr/" target="_self">
                  <span class="dropdown-title">한국어 커뮤니티</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.kr/resources/">
                  <span class="dropdown-title">개발자 정보</span>
                </a>
                <a class="nav-dropdown-item" href="https://landscape.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Landscape</span>
                </a>
              </div>
            </div>
          </li>

        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu">
        <i class="fa-solid fa-ellipsis"></i>
      </a>
    </div>
  </div>
 </div>

 <!-- Begin Mobile Menu -->

<div class="mobile-main-menu">
  <div class="container-fluid">
    <div class="header-container-wrapper">
      <div class="mobile-main-menu-header-container">
        <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu">
          <i class="fa-solid fa-xmark"></i>
        </a>
      </div>
    </div>
  </div>

  <div class="mobile-main-menu-links-container">
    <div class="main-menu">
      <ul>
         <li class="resources-mobile-menu-title">
           <a>배우기</a>
         </li>
         <ul class="resources-mobile-menu-items">
           <li>
             <a href="https://pytorch.kr/get-started/locally/">PyTorch 시작하기</a>
           </li>
           <li>
             <a href="https://tutorials.pytorch.kr/beginner/basics/intro.html">기본 익히기</a>
           </li>
           <li>
             <a href="https://tutorials.pytorch.kr/">한국어 튜토리얼</a>
           </li>
           <li>
             <a href="https://pytorch.kr/hub/">한국어 모델 허브</a>
           </li>
           <li>
             <a href="https://docs.pytorch.org/tutorials/" target="_blank">Official Tutorials</a>
           </li>
        </ul>
         <li class="resources-mobile-menu-title">
           <a href="https://pytorch.kr/blog/">블로그</a>
         </li>
         <li class="resources-mobile-menu-title">
           <a>문서</a>
         </li>
         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://docs.pytorch.org/docs/" target="_blank">PyTorch API</a>
          </li>
          <li>
            <a href="https://pytorch.kr/domains/">Domain API 소개</a>
          </li>
          <li>
            <a href="https://tutorials.pytorch.kr/">한국어 튜토리얼</a>
          </li>
          <li>
            <a href="https://docs.pytorch.org/tutorials/" target="_blank">Official Tutorials</a>
          </li>
        </ul>
        <li class="resources-mobile-menu-title">
          <a>커뮤니티</a>
        </li>
         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://discuss.pytorch.kr/">한국어 커뮤니티</a>
          </li>
          <li>
            <a href="https://pytorch.kr/resources/">개발자 정보</a>
          </li>
          <li>
            <a href="https://landscape.pytorch.org/" target="_blank">Landscape</a>
          </li>
        </ul>
      </ul>
    </div>
  </div>
</div>

<!-- End Mobile Menu -->
  
  
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">
  <a href="../index.html" class="version">v2.8.0+cu128</a>
</div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../intro.html">
    Intro
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../compilers_index.html">
    Compilers
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../domains.html">
    Domains
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../distributed.html">
    Distributed
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../deep-dive.html">
    Deep Dive
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../extension.html">
    Extension
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../ecosystem.html">
    Ecosystem
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../recipes_index.html">
    Recipes
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
      
        <div class="navbar-item">
<div class="search-container-wrapper">
  <div id="sphinx-search" class="search-container">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </div>

  <div id="google-search" class="search-container" style="display:none;">
    <div class="gcse-search-wrapper">
      <i class="fa-solid fa-magnifying-glass" aria-hidden="true"></i>
      <div class="gcse-search"></div>
    </div>
  </div>

  <div class="search-toggle-container" data-bs-title="Google Search Off" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <div class="search-toggle-inner">
      <label class="switch">
        <input type="checkbox" id="search-toggle">
        <span class="slider round"></span>
      </label>
    </div>
  </div>
</div>

<script>
  document.addEventListener('DOMContentLoaded', function() {
  // Define the search callback
  const myWebSearchStartingCallback = (gname, query) => {
    if (typeof dataLayer !== 'undefined' && query) {
      window.dataLayer = window.dataLayer || [];
      dataLayer.push({
        'event': 'google_search',
        'search_term': query,
        'event_category': 'Search',
        'event_label': 'Google Search'
      });
    }
    return '';
  };

  // Set up the GCSE search callbacks
  window.__gcse || (window.__gcse = {});
  window.__gcse.searchCallbacks = {
    web: { starting: myWebSearchStartingCallback }
  };

  if (window.location.pathname.includes('/search.html')) {
    document.body.classList.add('search-page');
  }

  // Function to reinitialize Google CSE
  function reinitializeGoogleSearch() {
    if (window.__gcse && window.__gcse.initializationCallback) {
      window.__gcse.initializationCallback();
    }
  }

  // Function to handle search toggle
  function handleSearchToggle(toggle, sphinxSearch, googleSearch) {
    if (!toggle || !sphinxSearch || !googleSearch) return;

    // Check if the URL contains /stable/ or /tutorials/
    const currentUrl = window.location.href;
    // TODO: We've had reports that the google programmable search is returning stale documentation,
    //       Simple reproduction is to turn google search on and search for multinomial which will
    //       result in returning 1.8.1 documentation.
    //       We should turn this back on when we resolve that bug.
    const shouldDefaultToGoogle = false;
    const savedPreference = localStorage.getItem('searchPreference');

    // Set initial state
    if (savedPreference === 'google' || (savedPreference === null && shouldDefaultToGoogle)) {
      toggle.checked = true;
      sphinxSearch.style.display = 'none';
      googleSearch.style.display = 'block';
      if (savedPreference === null) {
        localStorage.setItem('searchPreference', 'google');
      }
      reinitializeGoogleSearch();
    } else {
      toggle.checked = false;
      sphinxSearch.style.display = 'block';
      googleSearch.style.display = 'none';
    }

    // Update tooltip
    updateTooltip(toggle.checked);

    // Skip if already initialized
    if (toggle.hasAttribute('data-initialized')) return;
    toggle.setAttribute('data-initialized', 'true');

    toggle.addEventListener('change', function() {
      if (this.checked) {
        sphinxSearch.style.display = 'none';
        googleSearch.style.display = 'block';
        localStorage.setItem('searchPreference', 'google');
        reinitializeGoogleSearch();
        trackSearchEngineSwitch('Google');
      } else {
        sphinxSearch.style.display = 'block';
        googleSearch.style.display = 'none';
        localStorage.setItem('searchPreference', 'sphinx');
        trackSearchEngineSwitch('Sphinx');
      }

      updateTooltip(this.checked);
      updateMobileSearch();
    });
  }

  // Update tooltip based on toggle state
  function updateTooltip(isChecked) {
    const tooltipElement = document.querySelector('.search-toggle-container');
    if (!tooltipElement) return;

    tooltipElement.setAttribute('data-bs-title', isChecked ? 'Google Search On' : 'Google Search Off');

    if (bootstrap && bootstrap.Tooltip) {
      const tooltipInstance = bootstrap.Tooltip.getInstance(tooltipElement);
      if (tooltipInstance) tooltipInstance.dispose();
      new bootstrap.Tooltip(tooltipElement);
    }
  }

  // Track search engine switch
  function trackSearchEngineSwitch(engine) {
    if (typeof dataLayer !== 'undefined') {
      window.dataLayer = window.dataLayer || [];
      dataLayer.push({
        'event': 'search_engine_switch',
        'event_category': 'Search',
        'event_label': engine
      });
    }
  }

  // Function to update mobile search based on current toggle state
  function updateMobileSearch() {
    const toggle = document.getElementById('search-toggle');
    if (!toggle) return;

    const mobileSearchContainer = document.querySelector('.sidebar-header-items__end .navbar-item .search-container-wrapper');
    if (!mobileSearchContainer) return;

    const mobileSphinxSearch = mobileSearchContainer.querySelector('#sphinx-search');
    const mobileGoogleSearch = mobileSearchContainer.querySelector('#google-search');

    if (mobileSphinxSearch && mobileGoogleSearch) {
      mobileSphinxSearch.style.display = toggle.checked ? 'none' : 'block';
      mobileGoogleSearch.style.display = toggle.checked ? 'block' : 'none';

      if (toggle.checked) {
        reinitializeGoogleSearch();
      }
    }
  }

  // Initialize desktop search toggle
  const toggle = document.getElementById('search-toggle');
  const sphinxSearch = document.getElementById('sphinx-search');
  const googleSearch = document.getElementById('google-search');
  handleSearchToggle(toggle, sphinxSearch, googleSearch);

  // Set placeholder text for Google search input
  const observer = new MutationObserver(function() {
    document.querySelectorAll('.gsc-input input').forEach(input => {
      if (input && !input.hasAttribute('data-placeholder-set')) {
        input.setAttribute('placeholder', 'Search the docs ...');
        input.setAttribute('data-placeholder-set', 'true');
      }
    });
  });

  observer.observe(document.body, { childList: true, subtree: true });

  // Fix for scroll jump issue - improved approach
  function setupSearchInputHandlers(input) {
    if (input.hasAttribute('data-scroll-fixed')) return;
    input.setAttribute('data-scroll-fixed', 'true');

    let lastScrollPosition = 0;
    let isTyping = false;
    let scrollTimeout;

    // Save position before typing starts
    input.addEventListener('keydown', () => {
      lastScrollPosition = window.scrollY;
      isTyping = true;

      // Reset typing state after a short delay
      clearTimeout(scrollTimeout);
      scrollTimeout = setTimeout(() => {
        isTyping = false;
      }, 100);
    });

    // Only maintain scroll position during typing
    function maintainScroll() {
      if (document.activeElement === input && isTyping) {
        window.scrollTo(0, lastScrollPosition);
        requestAnimationFrame(maintainScroll);
      }
    }

    input.addEventListener('focus', () => {
      // Just store initial position but don't force it
      lastScrollPosition = window.scrollY;
    });

    input.addEventListener('input', () => {
      isTyping = true;
      window.scrollTo(0, lastScrollPosition);

      // Reset typing state after a short delay
      clearTimeout(scrollTimeout);
      scrollTimeout = setTimeout(() => {
        isTyping = false;
      }, 100);

      requestAnimationFrame(maintainScroll);
    });
  }

  // Apply to all search inputs and observe for new ones
  function applyToSearchInputs() {
    document.querySelectorAll('.search-container input, .gsc-input input').forEach(setupSearchInputHandlers);
  }

  applyToSearchInputs();

  const searchObserver = new MutationObserver(applyToSearchInputs);
  searchObserver.observe(document.body, { childList: true, subtree: true });

  // Watch for mobile menu creation
  const mobileMenuObserver = new MutationObserver(function(mutations) {
    for (const mutation of mutations) {
      if (!mutation.addedNodes.length) continue;

      // Style mobile search inputs
      document.querySelectorAll('.sidebar-header-items__end .navbar-item .search-container-wrapper .gsc-input input').forEach(input => {
        if (input) {
          input.setAttribute('placeholder', 'Search the docs ...');
          input.style.paddingLeft = '36px';
        }
      });

      // Check for mobile search container
      const mobileSearchContainer = document.querySelector('.sidebar-header-items__end .navbar-item .search-container-wrapper');
      if (!mobileSearchContainer) continue;

      const mobileToggle = mobileSearchContainer.querySelector('#search-toggle');
      if (mobileToggle && toggle) {
        // Sync mobile toggle with desktop toggle
        mobileToggle.checked = toggle.checked;
        updateMobileSearch();

        // Add event listener to mobile toggle if not already added
        if (!mobileToggle.hasAttribute('data-initialized')) {
          mobileToggle.setAttribute('data-initialized', 'true');
          mobileToggle.addEventListener('change', function() {
            // Sync desktop toggle with mobile toggle
            toggle.checked = this.checked;
            // Trigger change event on desktop toggle to update both
            toggle.dispatchEvent(new Event('change'));
          });
        }
      }
    }
  });

  mobileMenuObserver.observe(document.body, { childList: true, subtree: true });

  // Ensure Google CSE is properly loaded
  if (window.__gcse) {
    window.__gcse.callback = function() {
      // This will run after Google CSE is fully loaded
      if (toggle && toggle.checked) {
        reinitializeGoogleSearch();
      }
    };
  } else {
    window.__gcse = {
      callback: function() {
        if (toggle && toggle.checked) {
          reinitializeGoogleSearch();
        }
      }
    };
  }
});
</script>
</div>
      
        <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/PyTorchKorea/tutorials-kr" title="한국어 튜토리얼 GitHub 저장소" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">한국어 튜토리얼 GitHub 저장소</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discuss.pytorch.kr/" title="파이토치 한국어 커뮤니티" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">파이토치 한국어 커뮤니티</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../intro.html">
    Intro
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../compilers_index.html">
    Compilers
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../domains.html">
    Domains
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../distributed.html">
    Distributed
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../deep-dive.html">
    Deep Dive
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../extension.html">
    Extension
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../ecosystem.html">
    Ecosystem
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../recipes_index.html">
    Recipes
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
<div class="search-container-wrapper">
  <div id="sphinx-search" class="search-container">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </div>

  <div id="google-search" class="search-container" style="display:none;">
    <div class="gcse-search-wrapper">
      <i class="fa-solid fa-magnifying-glass" aria-hidden="true"></i>
      <div class="gcse-search"></div>
    </div>
  </div>

  <div class="search-toggle-container" data-bs-title="Google Search Off" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <div class="search-toggle-inner">
      <label class="switch">
        <input type="checkbox" id="search-toggle">
        <span class="slider round"></span>
      </label>
    </div>
  </div>
</div>

<script>
  document.addEventListener('DOMContentLoaded', function() {
  // Define the search callback
  const myWebSearchStartingCallback = (gname, query) => {
    if (typeof dataLayer !== 'undefined' && query) {
      window.dataLayer = window.dataLayer || [];
      dataLayer.push({
        'event': 'google_search',
        'search_term': query,
        'event_category': 'Search',
        'event_label': 'Google Search'
      });
    }
    return '';
  };

  // Set up the GCSE search callbacks
  window.__gcse || (window.__gcse = {});
  window.__gcse.searchCallbacks = {
    web: { starting: myWebSearchStartingCallback }
  };

  if (window.location.pathname.includes('/search.html')) {
    document.body.classList.add('search-page');
  }

  // Function to reinitialize Google CSE
  function reinitializeGoogleSearch() {
    if (window.__gcse && window.__gcse.initializationCallback) {
      window.__gcse.initializationCallback();
    }
  }

  // Function to handle search toggle
  function handleSearchToggle(toggle, sphinxSearch, googleSearch) {
    if (!toggle || !sphinxSearch || !googleSearch) return;

    // Check if the URL contains /stable/ or /tutorials/
    const currentUrl = window.location.href;
    // TODO: We've had reports that the google programmable search is returning stale documentation,
    //       Simple reproduction is to turn google search on and search for multinomial which will
    //       result in returning 1.8.1 documentation.
    //       We should turn this back on when we resolve that bug.
    const shouldDefaultToGoogle = false;
    const savedPreference = localStorage.getItem('searchPreference');

    // Set initial state
    if (savedPreference === 'google' || (savedPreference === null && shouldDefaultToGoogle)) {
      toggle.checked = true;
      sphinxSearch.style.display = 'none';
      googleSearch.style.display = 'block';
      if (savedPreference === null) {
        localStorage.setItem('searchPreference', 'google');
      }
      reinitializeGoogleSearch();
    } else {
      toggle.checked = false;
      sphinxSearch.style.display = 'block';
      googleSearch.style.display = 'none';
    }

    // Update tooltip
    updateTooltip(toggle.checked);

    // Skip if already initialized
    if (toggle.hasAttribute('data-initialized')) return;
    toggle.setAttribute('data-initialized', 'true');

    toggle.addEventListener('change', function() {
      if (this.checked) {
        sphinxSearch.style.display = 'none';
        googleSearch.style.display = 'block';
        localStorage.setItem('searchPreference', 'google');
        reinitializeGoogleSearch();
        trackSearchEngineSwitch('Google');
      } else {
        sphinxSearch.style.display = 'block';
        googleSearch.style.display = 'none';
        localStorage.setItem('searchPreference', 'sphinx');
        trackSearchEngineSwitch('Sphinx');
      }

      updateTooltip(this.checked);
      updateMobileSearch();
    });
  }

  // Update tooltip based on toggle state
  function updateTooltip(isChecked) {
    const tooltipElement = document.querySelector('.search-toggle-container');
    if (!tooltipElement) return;

    tooltipElement.setAttribute('data-bs-title', isChecked ? 'Google Search On' : 'Google Search Off');

    if (bootstrap && bootstrap.Tooltip) {
      const tooltipInstance = bootstrap.Tooltip.getInstance(tooltipElement);
      if (tooltipInstance) tooltipInstance.dispose();
      new bootstrap.Tooltip(tooltipElement);
    }
  }

  // Track search engine switch
  function trackSearchEngineSwitch(engine) {
    if (typeof dataLayer !== 'undefined') {
      window.dataLayer = window.dataLayer || [];
      dataLayer.push({
        'event': 'search_engine_switch',
        'event_category': 'Search',
        'event_label': engine
      });
    }
  }

  // Function to update mobile search based on current toggle state
  function updateMobileSearch() {
    const toggle = document.getElementById('search-toggle');
    if (!toggle) return;

    const mobileSearchContainer = document.querySelector('.sidebar-header-items__end .navbar-item .search-container-wrapper');
    if (!mobileSearchContainer) return;

    const mobileSphinxSearch = mobileSearchContainer.querySelector('#sphinx-search');
    const mobileGoogleSearch = mobileSearchContainer.querySelector('#google-search');

    if (mobileSphinxSearch && mobileGoogleSearch) {
      mobileSphinxSearch.style.display = toggle.checked ? 'none' : 'block';
      mobileGoogleSearch.style.display = toggle.checked ? 'block' : 'none';

      if (toggle.checked) {
        reinitializeGoogleSearch();
      }
    }
  }

  // Initialize desktop search toggle
  const toggle = document.getElementById('search-toggle');
  const sphinxSearch = document.getElementById('sphinx-search');
  const googleSearch = document.getElementById('google-search');
  handleSearchToggle(toggle, sphinxSearch, googleSearch);

  // Set placeholder text for Google search input
  const observer = new MutationObserver(function() {
    document.querySelectorAll('.gsc-input input').forEach(input => {
      if (input && !input.hasAttribute('data-placeholder-set')) {
        input.setAttribute('placeholder', 'Search the docs ...');
        input.setAttribute('data-placeholder-set', 'true');
      }
    });
  });

  observer.observe(document.body, { childList: true, subtree: true });

  // Fix for scroll jump issue - improved approach
  function setupSearchInputHandlers(input) {
    if (input.hasAttribute('data-scroll-fixed')) return;
    input.setAttribute('data-scroll-fixed', 'true');

    let lastScrollPosition = 0;
    let isTyping = false;
    let scrollTimeout;

    // Save position before typing starts
    input.addEventListener('keydown', () => {
      lastScrollPosition = window.scrollY;
      isTyping = true;

      // Reset typing state after a short delay
      clearTimeout(scrollTimeout);
      scrollTimeout = setTimeout(() => {
        isTyping = false;
      }, 100);
    });

    // Only maintain scroll position during typing
    function maintainScroll() {
      if (document.activeElement === input && isTyping) {
        window.scrollTo(0, lastScrollPosition);
        requestAnimationFrame(maintainScroll);
      }
    }

    input.addEventListener('focus', () => {
      // Just store initial position but don't force it
      lastScrollPosition = window.scrollY;
    });

    input.addEventListener('input', () => {
      isTyping = true;
      window.scrollTo(0, lastScrollPosition);

      // Reset typing state after a short delay
      clearTimeout(scrollTimeout);
      scrollTimeout = setTimeout(() => {
        isTyping = false;
      }, 100);

      requestAnimationFrame(maintainScroll);
    });
  }

  // Apply to all search inputs and observe for new ones
  function applyToSearchInputs() {
    document.querySelectorAll('.search-container input, .gsc-input input').forEach(setupSearchInputHandlers);
  }

  applyToSearchInputs();

  const searchObserver = new MutationObserver(applyToSearchInputs);
  searchObserver.observe(document.body, { childList: true, subtree: true });

  // Watch for mobile menu creation
  const mobileMenuObserver = new MutationObserver(function(mutations) {
    for (const mutation of mutations) {
      if (!mutation.addedNodes.length) continue;

      // Style mobile search inputs
      document.querySelectorAll('.sidebar-header-items__end .navbar-item .search-container-wrapper .gsc-input input').forEach(input => {
        if (input) {
          input.setAttribute('placeholder', 'Search the docs ...');
          input.style.paddingLeft = '36px';
        }
      });

      // Check for mobile search container
      const mobileSearchContainer = document.querySelector('.sidebar-header-items__end .navbar-item .search-container-wrapper');
      if (!mobileSearchContainer) continue;

      const mobileToggle = mobileSearchContainer.querySelector('#search-toggle');
      if (mobileToggle && toggle) {
        // Sync mobile toggle with desktop toggle
        mobileToggle.checked = toggle.checked;
        updateMobileSearch();

        // Add event listener to mobile toggle if not already added
        if (!mobileToggle.hasAttribute('data-initialized')) {
          mobileToggle.setAttribute('data-initialized', 'true');
          mobileToggle.addEventListener('change', function() {
            // Sync desktop toggle with mobile toggle
            toggle.checked = this.checked;
            // Trigger change event on desktop toggle to update both
            toggle.dispatchEvent(new Event('change'));
          });
        }
      }
    }
  });

  mobileMenuObserver.observe(document.body, { childList: true, subtree: true });

  // Ensure Google CSE is properly loaded
  if (window.__gcse) {
    window.__gcse.callback = function() {
      // This will run after Google CSE is fully loaded
      if (toggle && toggle.checked) {
        reinitializeGoogleSearch();
      }
    };
  } else {
    window.__gcse = {
      callback: function() {
        if (toggle && toggle.checked) {
          reinitializeGoogleSearch();
        }
      }
    };
  }
});
</script>
</div>
        
          <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/PyTorchKorea/tutorials-kr" title="한국어 튜토리얼 GitHub 저장소" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">한국어 튜토리얼 GitHub 저장소</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discuss.pytorch.kr/" title="파이토치 한국어 커뮤니티" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">파이토치 한국어 커뮤니티</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Extending PyTorch</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="custom_ops_landing_page.html">PyTorch Custom Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="python_custom_ops.html">Custom Python Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpp_custom_ops.html">Custom C++ and CUDA Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/custom_function_double_backward_tutorial.html">Double Backward with Custom Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/custom_function_conv_bn_tutorial.html">Fusing Convolution and Batch Norm using Custom Function</a></li>
<li class="toctree-l1"><a class="reference internal" href="dispatcher.html">Registering a Dispatched Operator in C++</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Extending dispatcher for a new backend in C++</a></li>
<li class="toctree-l1"><a class="reference internal" href="privateuseone.html">Facilitating New Backend Integration by PrivateUse1</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../extension.html" class="nav-link">Extension</a></li>
    
    <li class="breadcrumb-item active" aria-current="page">Extending...</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
        
    </div>
</div>
</div>
      
    </div>
  
</div>
</div>
              
              
  
<div id="searchbox"></div>
  <article class="bd-article" id="pytorch-article">
    <!-- Hidden breadcrumb schema for SEO only -->
    <div style="display:none;" itemscope itemtype="https://schema.org/BreadcrumbList">
      
      <div itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <link itemprop="item" href="../extension.html">
        <meta itemprop="name" content="Extension">
        <meta itemprop="position" content="1">
      </div>
      
      <div itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <meta itemprop="name" content="Extending dispatcher for a new backend in C++">
        <meta itemprop="position" content="2">
      </div>
    </div>

    
    <script>
      if ((window.location.href.indexOf("/unstable/") != -1) && (window.location.href.indexOf("/unstable/unstable_index") < 1)) {
        var div = '<div class="prototype-banner"><i class="fa fa-flask" aria-hidden="true"></i> <strong>Unstable feature:</strong> Not typically available in binary distributions like PyPI. Early stage for feedback and testing.</div>'
        document.addEventListener('DOMContentLoaded', function () {
          document.getElementById("pytorch-article").insertAdjacentHTML('afterBegin', div);
        });
      }
    </script>
    
    
    <div class="pytorch-call-to-action-links">
      <div id="tutorial-type">advanced/extend_dispatcher</div>
      <a id="colab-link" data-behavior="call-to-action-event" data-response="Run in Google Colab" target="_blank">
        <div id="google-colab-link">
          <img class="call-to-action-img" src="../_static/img/pytorch-colab.svg" />
          <div class="call-to-action-desktop-view">Run in Google Colab</div>
          <div class="call-to-action-mobile-view">Colab</div>
        </div>
      </a>
      <a id="notebook-link" data-behavior="call-to-action-event" data-response="Download Notebook">
        <div id="download-notebook-link">
          <img class="call-to-action-notebook-img" src="../_static/img/pytorch-download.svg" />
          <div class="call-to-action-desktop-view">Download Notebook</div>
          <div class="call-to-action-mobile-view">Notebook</div>
        </div>
      </a>
      <a id="github-link" data-behavior="call-to-action-event" data-response="View on Github" target="_blank">
        <div id="github-view-link">
          <img class="call-to-action-img" src="../_static/img/pytorch-github.svg" />
          <div class="call-to-action-desktop-view">View on GitHub</div>
          <div class="call-to-action-mobile-view">GitHub</div>
        </div>
      </a>
    </div>
    

    
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="extending-dispatcher-for-a-new-backend-in-c">
<h1>Extending dispatcher for a new backend in C++<a class="headerlink" href="#extending-dispatcher-for-a-new-backend-in-c" title="Link to this heading">#</a></h1>
<p>In this tutorial we will walk through all necessary steps to extend the dispatcher to
add a new device living outside <code class="docutils literal notranslate"><span class="pre">pytorch/pytorch</span></code> repo and maintain it to keep in
sync with native PyTorch devices.  Here we’ll assume that you’re familiar with how
to <a class="reference external" href="dispatcher">register a dispatched operator in C++</a> and how to write a
<a class="reference external" href="cpp_autograd">custom autograd function</a>.</p>
<div class="admonition note">
<p class="admonition-title">참고</p>
<p>This tutorial touches a lot of internal components inside PyTorch which are being actively improved,
please expect changes to APIs if you decide to follow this tutorial.  We’ll keep this tutorial
up to date with the latest APIs.</p>
</div>
<section id="what-s-a-new-backend">
<h2>What’s a new backend?<a class="headerlink" href="#what-s-a-new-backend" title="Link to this heading">#</a></h2>
<p>Adding a new backend to PyTorch requires a lot of development and maintenance from backend extenders.
Before adding a new backend, let’s first consider a few common use cases and recommended solutions for them:</p>
<ul class="simple">
<li><p>If you have new algorithms for an existing PyTorch operator, send a PR to PyTorch.</p></li>
<li><p>If you want to propose a new operator, send a feature request/PR to PyTorch.</p></li>
<li><p>If you want to add support for a new device/hardware like Google TPU and customized chips, which often requires using
hardware-specific API to write kernels, follow this tutorial and add a out-of-tree backend to PyTorch.</p></li>
<li><p>If you want to add support for existing operators but with a different Tensor layout/representation
like sparse and quantized, which enforces your kernels to be written in a way that’s more efficient
given the layout/representation limitation, follow this tutorial and add a out-of-tree backend to PyTorch.</p></li>
</ul>
<p>In this tutorial we’ll mainly focus on adding a new out-of-tree device below.  Adding out-of-tree support
for a different tensor layout might share many common steps with devices, but we haven’t seen an example of
such integrations yet so it might require additional work from PyTorch to support it.</p>
</section>
<section id="get-a-dispatch-key-for-your-backend">
<h2>Get a dispatch key for your backend<a class="headerlink" href="#get-a-dispatch-key-for-your-backend" title="Link to this heading">#</a></h2>
<p>PyTorch operators are implemented in C++ and made available in Python frontend through Python bindings.
The PyTorch dispatcher divides the implementation of an operator into multiple kernels, each of which is
associated with a specific dispatch key.  Supporting a new backend in PyTorch essentially means writing
a kernel for each PyTorch operator in C++ and then registering them to a dispatch key representing your
customized backend in the dispatcher.</p>
<p>Dispatch key is your identifier in the dispatcher system. The dispatcher looks at the dispatch keys carried on
input tensors and calls the right kernel accordingly.  PyTorch provides three reserved dispatch keys
(and their corresponding Autograd keys) for prototyping out-of-tree backend extensions:</p>
<ul class="simple">
<li><p>PrivateUse1/AutogradPrivateUse1</p></li>
<li><p>PrivateUse2/AutogradPrivateUse2</p></li>
<li><p>PrivateUse3/AutogradPrivateUse3</p></li>
</ul>
<p>You can choose any of keys above to prototype your customized backend.
To create a Tensor on <code class="docutils literal notranslate"><span class="pre">PrivateUse1</span></code> backend, you need to set dispatch key in <code class="docutils literal notranslate"><span class="pre">TensorImpl</span></code> constructor.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cm">/* Example TensorImpl constructor */</span>
<span class="n">TensorImpl</span><span class="p">(</span>
<span class="w">    </span><span class="n">Storage</span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">storage</span><span class="p">,</span>
<span class="w">    </span><span class="n">DispatchKeySet</span><span class="w"> </span><span class="n">ks</span><span class="p">,</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="n">caffe2</span><span class="o">::</span><span class="n">TypeMeta</span><span class="w"> </span><span class="n">data_type</span><span class="p">);</span>

<span class="c1">// To create a TensorImpl on PrivateUse1 backend, pass in the following ks to TensorImpl creation.</span>
<span class="n">DispatchKeySet</span><span class="w"> </span><span class="n">ks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">DispatchKeySet</span><span class="p">{</span><span class="n">c10</span><span class="o">::</span><span class="n">DispatchKey</span><span class="o">::</span><span class="n">PrivateUse1</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">DispatchKey</span><span class="o">::</span><span class="n">AutogradPrivateUse1</span><span class="p">};</span>
</pre></div>
</div>
<p>Note that <code class="docutils literal notranslate"><span class="pre">TensorImpl</span></code> class above assumes your Tensor is backed by a storage like CPU/CUDA. We also
provide <code class="docutils literal notranslate"><span class="pre">OpaqueTensorImpl</span></code> for backends without a storage. And you might need to tweak/override certain
methods to fit your customized hardware.
One example in pytorch repo is <a class="reference external" href="https://github.com/pytorch/pytorch/blob/main/aten/src/ATen/native/vulkan/VulkanOpaqueTensorImpl.h">Vulkan TensorImpl</a>.</p>
<div class="admonition note">
<p class="admonition-title">참고</p>
<p>Once the prototype is done and you plan to do regular releases for your backend extension,  please feel free to
submit a PR to <code class="docutils literal notranslate"><span class="pre">pytorch/pytorch</span></code> to reserve a dedicated dispatch key for your backend.</p>
</div>
</section>
<section id="get-the-full-list-of-pytorch-operators">
<h2>Get the full list of PyTorch operators<a class="headerlink" href="#get-the-full-list-of-pytorch-operators" title="Link to this heading">#</a></h2>
<p>PyTorch provides a full list of extensible C++ operators in generated file
<code class="docutils literal notranslate"><span class="pre">build/aten/src/ATen/RegistrationDeclarations.h</span></code>.
This file is only available after building PyTorch from source.
Here’s a snippet of the file:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">Tensor</span><span class="w"> </span><span class="nf">abs</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">self</span><span class="p">);</span><span class="w"> </span><span class="c1">// {&quot;schema&quot;: &quot;aten::abs(Tensor self) -&gt; Tensor&quot;, &quot;dispatch&quot;: &quot;True&quot;, &quot;default&quot;: &quot;True&quot;}</span>
<span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">abs_</span><span class="p">(</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">self</span><span class="p">);</span><span class="w"> </span><span class="c1">// {&quot;schema&quot;: &quot;aten::abs_(Tensor(a!) self) -&gt; Tensor(a!)&quot;, &quot;dispatch&quot;: &quot;True&quot;, &quot;default&quot;: &quot;True&quot;}</span>
<span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">abs_out</span><span class="p">(</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">out</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">self</span><span class="p">);</span><span class="w"> </span><span class="c1">// {&quot;schema&quot;: &quot;aten::abs.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)&quot;, &quot;dispatch&quot;: &quot;True&quot;, &quot;default&quot;: &quot;False&quot;}</span>
<span class="n">Tensor</span><span class="w"> </span><span class="nf">absolute</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">self</span><span class="p">);</span><span class="w"> </span><span class="c1">// {&quot;schema&quot;: &quot;aten::absolute(Tensor self) -&gt; Tensor&quot;, &quot;dispatch&quot;: &quot;False&quot;, &quot;default&quot;: &quot;False&quot;}</span>
<span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">absolute_</span><span class="p">(</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">self</span><span class="p">);</span><span class="w"> </span><span class="c1">// {&quot;schema&quot;: &quot;aten::absolute_(Tensor(a!) self) -&gt; Tensor(a!)&quot;, &quot;dispatch&quot;: &quot;False&quot;, &quot;default&quot;: &quot;False&quot;}</span>
<span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">absolute_out</span><span class="p">(</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">out</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">self</span><span class="p">);</span><span class="w"> </span><span class="c1">// {&quot;schema&quot;: &quot;aten::absolute.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)&quot;, &quot;dispatch&quot;: &quot;False&quot;, &quot;default&quot;: &quot;False&quot;}</span>
<span class="n">Tensor</span><span class="w"> </span><span class="nf">angle</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">self</span><span class="p">);</span><span class="w"> </span><span class="c1">// {&quot;schema&quot;: &quot;aten::angle(Tensor self) -&gt; Tensor&quot;, &quot;dispatch&quot;: &quot;True&quot;, &quot;default&quot;: &quot;True&quot;}</span>
<span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">angle_out</span><span class="p">(</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">out</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">self</span><span class="p">);</span><span class="w"> </span><span class="c1">// {&quot;schema&quot;: &quot;aten::angle.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)&quot;, &quot;dispatch&quot;: &quot;True&quot;, &quot;default&quot;: &quot;False&quot;}</span>
<span class="n">Tensor</span><span class="w"> </span><span class="nf">sgn</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">self</span><span class="p">);</span><span class="w"> </span><span class="c1">// {&quot;schema&quot;: &quot;aten::sgn(Tensor self) -&gt; Tensor&quot;, &quot;dispatch&quot;: &quot;True&quot;, &quot;default&quot;: &quot;True&quot;}</span>
</pre></div>
</div>
<p>There’re multiple fields associated with a single operator. Let’s break it down using <code class="docutils literal notranslate"><span class="pre">abs_out</span></code> as an example:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Tensor</span> <span class="pre">&amp;</span> <span class="pre">abs_out(Tensor</span> <span class="pre">&amp;</span> <span class="pre">out,</span> <span class="pre">const</span> <span class="pre">Tensor</span> <span class="pre">&amp;</span> <span class="pre">self);</span></code> is the C++ signature of the operator, your C++
kernel should match this signature exactly.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">aten::abs.out(Tensor</span> <span class="pre">self,</span> <span class="pre">*,</span> <span class="pre">Tensor(a!)</span> <span class="pre">out)</span> <span class="pre">-&gt;</span> <span class="pre">Tensor(a!)</span></code> is the unique schema representing the operator,
which also contains aliasing and mutation annotations compared to the C++ signature.  This is the unique identifier
the dispatcher uses to find an operator.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dispatch</span></code> and <code class="docutils literal notranslate"><span class="pre">default</span></code> are boolean fields that provide information about what native PyTorch kernels
can do, thus implies whether it’s required for backend extenders to implement the kernel.
More details can be found in <a class="reference internal" href="#register-kernel"><span class="std std-ref">register kernels for the new backend</span></a>.</p></li>
</ul>
</section>
<section id="register-kernels-for-the-new-backend">
<span id="register-kernel"></span><h2>Register kernels for the new backend<a class="headerlink" href="#register-kernels-for-the-new-backend" title="Link to this heading">#</a></h2>
<p>To register your kernels to PyTorch dispatcher, you can use the
<code class="docutils literal notranslate"><span class="pre">TORCH_LIBRARY_IMPL</span></code> API described in
<a class="reference external" href="dispatcher">Registering a Dispatched Operator in C++</a>:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">TORCH_LIBRARY_IMPL</span><span class="p">(</span><span class="n">aten</span><span class="p">,</span><span class="w"> </span><span class="n">PrivateUse1</span><span class="p">,</span><span class="w"> </span><span class="n">m</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">m</span><span class="p">.</span><span class="n">impl</span><span class="p">(</span><span class="o">&lt;</span><span class="n">schema_my_op1</span><span class="o">&gt;</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">my_op1</span><span class="p">);</span>
<span class="w">  </span><span class="n">m</span><span class="p">.</span><span class="n">impl</span><span class="p">(</span><span class="o">&lt;</span><span class="n">schema_my_op2</span><span class="o">&gt;</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">my_op2</span><span class="p">);</span>
<span class="w">  </span><span class="n">m</span><span class="p">.</span><span class="n">impl</span><span class="p">(</span><span class="o">&lt;</span><span class="n">schema_my_op2_backward</span><span class="o">&gt;</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">my_op2_backward</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Now let’s zoom in and what operator requires a kernel from a customized backend and what’s
inside the kernels exactly.</p>
<p>PyTorch currently has more than 1600 operators and it’s still growing.  It’s unrealistic
for backend extensions to keep up with this speed.  Even for native backends like CPU
or CUDA, it often requires a lot of work to write dedicated kernels for every new op.</p>
<p>Fortunately, some native PyTorch kernels are written in a way that they decompose to
combination of several known operators. In other words, you only need to implement
a set of known operators (ops that require registration below) instead of all PyTorch operators.</p>
<p>PyTorch operators can be classified into two categories:</p>
<ul>
<li><p>Ops that require registration: PyTorch native implementation for these ops is backend specific
and thus it’s required to provide a kernel for customized backend.  Otherwise calling such op
on the customized backend will error out.</p>
<blockquote>
<div><ul class="simple">
<li><p>In <code class="docutils literal notranslate"><span class="pre">RegistrationDeclarations.h</span></code> these operators have <code class="docutils literal notranslate"><span class="pre">dispatch</span></code> set to True <em>and</em> <code class="docutils literal notranslate"><span class="pre">default</span></code> set to False
in the metadata found in their accompanying comments.</p></li>
</ul>
</div></blockquote>
</li>
<li><p>Registration is optional: backend extenders can skip registering to these ops without sacrificing any support.
However, if a backend extender wants to override the default kernel provided by PyTorch, they can still
register their customized kernel to their backend and the dispatcher will use it for your backend only.
For example, current implementation of PyTorch’s <code class="docutils literal notranslate"><span class="pre">max_pool2d</span></code> returns <code class="docutils literal notranslate"><span class="pre">indices</span></code> as part of forward outputs which
creates overhead in torch_xla, so torch_xla registers its own kernel for <code class="docutils literal notranslate"><span class="pre">max_pool2d</span></code> instead.</p>
<blockquote>
<div><ul class="simple">
<li><p>In <code class="docutils literal notranslate"><span class="pre">RegistrationDeclarations.h</span></code> these operators have <code class="docutils literal notranslate"><span class="pre">dispatch</span></code> set to False <em>or</em> <code class="docutils literal notranslate"><span class="pre">default</span></code> set to True
in the metadata found in their accompanying comments.</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</section>
<section id="autograd-support-for-the-new-backend">
<h2>Autograd support for the new backend<a class="headerlink" href="#autograd-support-for-the-new-backend" title="Link to this heading">#</a></h2>
<p>Gradient formulas are mostly purely mathematical and thus are general for all backends.
PyTorch often registers a kernel to alias dispatch key Autograd, which means it can be used by all backends.</p>
<p>For these operators you don’t have to worry about their derivative formulas,
you can just write forward definitions for operators in <code class="docutils literal notranslate"><span class="pre">RegistrationDeclarations.h</span></code> and PyTorch handles
backward for you automatically.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">Tensor</span><span class="w"> </span><span class="nf">my_op1</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">Tensor</span><span class="o">&amp;</span><span class="w"> </span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">Tensor</span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">// call your backend-specific APIs to implement my_op so that</span>
<span class="w">  </span><span class="c1">// it matches PyTorch&#39;s native behavior</span>
<span class="p">}</span>
<span class="n">TORCH_LIBRARY_IMPL</span><span class="p">(</span><span class="n">aten</span><span class="p">,</span><span class="w"> </span><span class="n">PrivateUse1</span><span class="p">,</span><span class="w"> </span><span class="n">m</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">m</span><span class="p">.</span><span class="n">impl</span><span class="p">(</span><span class="o">&lt;</span><span class="n">schema_my_op1</span><span class="o">&gt;</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">my_op</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
<p>In some cases, PyTorch backward kernel implementations are also device specific so that they can squeeze out
max performance out of each backend. For those operators you’ll see op_backward showing up in
<code class="docutils literal notranslate"><span class="pre">RegistrationDeclarations.h</span></code> as <em>required registration</em> as well.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">Tensor</span><span class="w"> </span><span class="nf">my_op2_backward</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">Tensor</span><span class="o">&amp;</span><span class="w"> </span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">Tensor</span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">// call your backend-specific APIs to implement my_op2_backward so that</span>
<span class="w">  </span><span class="c1">// it matches PyTorch&#39;s native behavior</span>
<span class="p">}</span>

<span class="c1">// Note backward kernel is still registered to PrivateUse1 instead of AutogradPrivateUse1.</span>
<span class="c1">// PyTorch will wrap your backward kernel with proper autograd setup and then link to it in</span>
<span class="c1">// my_op2&#39;s AutogradPrivateUse1 kernel.</span>
<span class="n">TORCH_LIBRARY_IMPL</span><span class="p">(</span><span class="n">aten</span><span class="p">,</span><span class="w"> </span><span class="n">PrivateUse1</span><span class="p">,</span><span class="w"> </span><span class="n">m</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">m</span><span class="p">.</span><span class="n">impl</span><span class="p">(</span><span class="o">&lt;</span><span class="n">schema_my_op2</span><span class="o">&gt;</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">my_op2</span><span class="p">);</span>
<span class="w">  </span><span class="n">m</span><span class="p">.</span><span class="n">impl</span><span class="p">(</span><span class="o">&lt;</span><span class="n">schema_my_op2_backward</span><span class="o">&gt;</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">my_op2_backward</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
<p>In a few <em>rare</em> cases, PyTorch’s gradient formula for certain operators may have assumptions that don’t generalize
for all backends. In those cases backend extenders can optionally override PyTorch Autograd layer by registering
a kernel from torch::autograd::Function to the corresponding dispatch key (for example, AutogradPrivateUse1 if
you’re using PrivateUse1 for your backend):</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">MyAddFunction</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="k">public</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">autograd</span><span class="o">::</span><span class="n">Function</span><span class="o">&lt;</span><span class="n">MyAddFunction</span><span class="o">&gt;</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">public</span><span class="o">:</span>
<span class="w">  </span><span class="k">static</span><span class="w"> </span><span class="n">Tensor</span><span class="w"> </span><span class="n">forward</span><span class="p">(</span><span class="n">AutogradContext</span><span class="w"> </span><span class="o">*</span><span class="n">ctx</span><span class="p">,</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">at</span><span class="o">::</span><span class="n">AutoNonVariableTypeMode</span><span class="w"> </span><span class="n">g</span><span class="p">;</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">myadd</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">static</span><span class="w"> </span><span class="n">tensor_list</span><span class="w"> </span><span class="n">backward</span><span class="p">(</span><span class="n">AutogradContext</span><span class="w"> </span><span class="o">*</span><span class="n">ctx</span><span class="p">,</span><span class="w"> </span><span class="n">tensor_list</span><span class="w"> </span><span class="n">grad_outputs</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">grad_output</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">grad_outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="p">{</span><span class="n">grad_output</span><span class="p">,</span><span class="w"> </span><span class="n">grad_output</span><span class="p">};</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">};</span>

<span class="n">Tensor</span><span class="w"> </span><span class="nf">myadd_autograd</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">Tensor</span><span class="o">&amp;</span><span class="w"> </span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">Tensor</span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">MyAddFunction</span><span class="o">::</span><span class="n">apply</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">other</span><span class="p">)[</span><span class="mi">0</span><span class="p">];</span>
<span class="p">}</span>

<span class="c1">// Register the autograd kernel to AutogradPrivateUse1</span>
<span class="n">TORCH_LIBRARY_IMPL</span><span class="p">(</span><span class="n">aten</span><span class="p">,</span><span class="w"> </span><span class="n">AutogradPrivateUse1</span><span class="p">,</span><span class="w"> </span><span class="n">m</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">m</span><span class="p">.</span><span class="n">impl</span><span class="p">(</span><span class="o">&lt;</span><span class="n">myadd_schema</span><span class="o">&gt;</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">myadd_autograd</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// Register the inference kernel to PrivateUse1</span>
<span class="n">TORCH_LIBRARY_IMPL</span><span class="p">(</span><span class="n">aten</span><span class="p">,</span><span class="w"> </span><span class="n">PrivateUse1</span><span class="p">,</span><span class="w"> </span><span class="n">m</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">m</span><span class="p">.</span><span class="n">impl</span><span class="p">(</span><span class="o">&lt;</span><span class="n">myadd_schema</span><span class="o">&gt;</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">myadd</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
<p>With this trick you have full control over both training and inference behavior for <code class="docutils literal notranslate"><span class="pre">my_add</span></code> operator in your backend.
Here’s <a class="reference external" href="https://github.com/pytorch/xla/blob/r1.7/torch_xla/csrc/aten_autograd_ops.h">an example</a> in the <code class="docutils literal notranslate"><span class="pre">pytorch/xla</span></code> repository.</p>
</section>
<section id="build-an-extension">
<h2>Build an extension<a class="headerlink" href="#build-an-extension" title="Link to this heading">#</a></h2>
<p>Out-of-tree backend is supported by adding a C++ extension to PyTorch.
Once you have kernels and registrations ready, you can build a C++ extension by
writing a <code class="docutils literal notranslate"><span class="pre">setup.py</span></code> script that uses <code class="docutils literal notranslate"><span class="pre">setuptools</span></code> to compile C++ code.  Here’s a simplified example from
<a class="reference external" href="https://github.com/pytorch/xla/blob/master/setup.py">pytorch/xla repo</a>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">setuptools</span><span class="w"> </span><span class="kn">import</span> <span class="n">setup</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.cpp_extension</span><span class="w"> </span><span class="kn">import</span> <span class="n">BuildExtension</span><span class="p">,</span> <span class="n">CppExtension</span>

<span class="n">setup</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;torch_xla&#39;</span><span class="p">,</span>
    <span class="n">ext_modules</span><span class="o">=</span><span class="p">[</span>
        <span class="n">CppExtension</span><span class="p">(</span>
            <span class="s1">&#39;_XLAC&#39;</span><span class="p">,</span>
            <span class="n">torch_xla_sources</span><span class="p">,</span>
            <span class="n">include_dirs</span><span class="o">=</span><span class="n">include_dirs</span><span class="p">,</span>
            <span class="n">extra_compile_args</span><span class="o">=</span><span class="n">extra_compile_args</span><span class="p">,</span>
            <span class="n">library_dirs</span><span class="o">=</span><span class="n">library_dirs</span><span class="p">,</span>
            <span class="n">extra_link_args</span><span class="o">=</span><span class="n">extra_link_args</span> <span class="o">+</span> \
                <span class="p">[</span><span class="n">make_relative_rpath</span><span class="p">(</span><span class="s1">&#39;torch_xla/lib&#39;</span><span class="p">)],</span>
        <span class="p">),</span>
    <span class="p">],</span>
    <span class="n">cmdclass</span><span class="o">=</span><span class="p">{</span>
        <span class="s1">&#39;build_ext&#39;</span><span class="p">:</span> <span class="n">Build</span><span class="p">,</span>  <span class="c1"># Build is a derived class of BuildExtension</span>
    <span class="p">}</span>
    <span class="c1"># more configs...</span>
<span class="p">)</span>
</pre></div>
</div>
<p>See <a class="reference external" href="https://tutorials.pytorch.kr/advanced/cpp_extension.html#building-with-setuptools">our C++ extension tutorial</a>
for more details.</p>
</section>
<section id="custom-operator-support">
<h2>Custom operator support<a class="headerlink" href="#custom-operator-support" title="Link to this heading">#</a></h2>
<p>Your new backend should work seamlessly with
<a class="reference external" href="https://pytorch.org/docs/stable/notes/extending.html">customized operators extended in python</a>
without writing any new kernels as long as the customized operator is composed of existing
PyTorch operators (which are already supported by your backend).</p>
<p>For <a class="reference external" href="cpp_autograd">custom operators extended in C++</a> they often come with a
<a class="reference external" href="https://github.com/pytorch/vision/blob/master/torchvision/csrc/ops/cuda/nms_kernel.cu">backend specific C++ kernel implementation e.g. nms kernel in torchvsion</a>
as well as <a class="reference external" href="https://github.com/pytorch/vision/blob/master/torchvision/csrc/ops/nms.cpp#L18">a customized Python API e.g. torch.ops.torchvision.nms</a>.
To support these operators, backend extenders will need to write a C++ kernel for your backend and properly
register it to the corresponding namespace in the dispatcher similar to supporting PyTorch native operators.
Alternatively you could also add a customized API in your extension e.g <code class="docutils literal notranslate"><span class="pre">torch_xla.core.functions.nms</span></code> for
these adhoc requests.</p>
</section>
<section id="jit-support">
<h2>JIT support<a class="headerlink" href="#jit-support" title="Link to this heading">#</a></h2>
<p>As we mentioned in <a class="reference external" href="dispatcher">Registering a Dispatched Operator in C++</a>, kernels registered through <cite>m.impl()</cite> API
support being called in both unboxed and boxed ways. In other words your customized backend can also work with our
JIT tracing/scripting frontend just like the in-tree backends like CPU or CUDA do.  You could potentially also write specialized optimization
passes for your backend on a JIT graph.  But we will not discuss it here since we haven’t finalized the integration point
in JIT, so the current backend support will focus on the eager frontend for now.</p>
</section>
<section id="testing-your-backend-against-native-pytorch-backends">
<h2>Testing your backend against native PyTorch backends<a class="headerlink" href="#testing-your-backend-against-native-pytorch-backends" title="Link to this heading">#</a></h2>
<p>PyTorch lets tests run on multiple device types using its <a class="reference external" href="https://github.com/pytorch/pytorch/blob/master/torch/testing/_internal/common_device_type.py">generic device type testing framework</a>.
You can find details about <a class="reference external" href="https://github.com/pytorch/pytorch/blob/5a8198eb3c594aa18352930fd21f3c25bd7b7100/torch/testing/_internal/common_device_type.py#L23">how tests use it</a>
and information about <a class="reference external" href="https://github.com/pytorch/pytorch/blob/5a8198eb3c594aa18352930fd21f3c25bd7b7100/torch/testing/_internal/common_device_type.py#L369">how to add a new device type</a>.
Once added, PyTorch tests using the generic device type testing framework will be run using your device type, too.
See <a class="reference external" href="https://github.com/pytorch/pytorch/wiki/Writing-tests-that-run-on-all-available-device-types">this Wiki page</a> for an example of how tests are instantiated.</p>
<p>Running PyTorch’s existing test suites with your device type is important to ensure correctness,
but not all PyTorch features are supported by every device type.  The generic device type testing
framework allows for considerable customization so that device types can select which tests to run,
which dtypes they support, and even which precisions to use when comparing tensors for equality.</p>
<p>An example device type that uses the generic device type testing framework and doesn’t ship with
PyTorch is XLA.  See <a class="reference external" href="https://github.com/pytorch/xla/blob/master/test/pytorch_test_base.py">its extension of the generic device type testing framework</a>,
which contains examples of block listing tests, block listing dtypes, and overriding test precision.</p>
<p>The generic device type testing framework is actively developed. To request a feature please file an
issue on PyTorch’s Github.</p>
</section>
<section id="backward-compatibility">
<h2>Backward Compatibility<a class="headerlink" href="#backward-compatibility" title="Link to this heading">#</a></h2>
<p>Currently PyTorch can’t guarantee backward compatibility for registered operators.
Operators, as well as their schemas, might be added/modified/deleted as needed.  Registered
kernels must be <em>exactly</em> the same as PyTorch version.  If PyTorch adds more parameters (
even with defaults) for an operator, your old registration won’t work until it’s updated
to match PyTorch’s new signature.</p>
<p>As a result, we <em>highly recommend</em> out-of-tree backend extenders only sync with major PyTorch
releases to minimize interruptions in development.  PyTorch is on a quarterly release cadence.
Backend extenders should join the <em>#announcement</em> channel at <a class="reference external" href="http://pytorch.slack.com/">pytorch.slack.com</a>
to get latest updates on releases.</p>
</section>
<section id="known-issues-additional-notes">
<h2>Known issues &amp; additional notes<a class="headerlink" href="#known-issues-additional-notes" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Not all test suites are device generic yet. Extensible test classes can be found by searching
<code class="docutils literal notranslate"><span class="pre">instantiate_device_type_tests</span></code> in PyTorch codebase, e.g
<code class="docutils literal notranslate"><span class="pre">TestTorchDeviceType,</span> <span class="pre">TestViewOps,</span> <span class="pre">TestTensorDeviceOps,</span> <span class="pre">TestTypePromotion</span></code> etc.</p></li>
<li><p>There’s no extension point in C++ for serializing a python Tensor object on customized backend. Currently
you can only extend it by modifying <a class="reference external" href="https://github.com/pytorch/pytorch/blob/5640b79bf8a5412a0209a919c05c811d5427cc12/torch/tensor.py#L83-L150">PyTorch Tensor __reduce_ex__ method</a>
or monkey patching in out-of-tree repository.</p></li>
<li><p>If your backend doesn’t allow direct memory access, you should pay additional attention to supporting
view ops since they’re supposed to share storage. Changes to view tensor need to propagated to its
base tensor and vice versa.</p></li>
<li><p>There’s no extension point in C++ for Optimizer if your backend doesn’t work with the native PyTorch
Optimizers, e.g. need to carry the states to be updated in backward like torch-xla. Such use cases
currently can only be done through adding customized API or monkey patching in out-of-tree repository.</p></li>
</ul>
</section>
<section id="future-work">
<h2>Future Work<a class="headerlink" href="#future-work" title="Link to this heading">#</a></h2>
<p>Making every component in PyTorch extensible for an out-of-tree backend seamless
requires a lot of changes to PyTorch internals.  Here are a few items that we’re
actively working on might improve the experience in the future:</p>
<ul class="simple">
<li><p>Improve test coverage of generic testing framework.</p></li>
<li><p>Improve <code class="docutils literal notranslate"><span class="pre">Math</span></code> kernel coverage and more comprehensive tests to make sure <code class="docutils literal notranslate"><span class="pre">Math</span></code>
kernel behavior matches other backends like <code class="docutils literal notranslate"><span class="pre">CPU/CUDA</span></code>.</p></li>
<li><p>Refactor <code class="docutils literal notranslate"><span class="pre">RegistrationDeclarations.h</span></code> to carry the minimal information and reuse
PyTorch’s codegen as much as possible.</p></li>
<li><p>Support a backend fallback kernel to automatic convert inputs to CPU and convert the
result back to the customized backend. This will allow “full” operator coverage even
though you don’t have kernels written for every operator.</p></li>
</ul>
</section>
<section id="stay-in-touch">
<h2>Stay in touch<a class="headerlink" href="#stay-in-touch" title="Link to this heading">#</a></h2>
<p>Please use <a class="reference external" href="https://dev-discuss.pytorch.org/">PyTorch dev discussions</a> for questions and discussions. If you have
any feature requests or bug reports, please <a class="reference external" href="https://github.com/pytorch/pytorch/issues">file an issue on github</a>.</p>
<p>If you’re interested in helping in any of the future work items above (e.g adding more <code class="docutils literal notranslate"><span class="pre">Math</span></code>
kernels for PyTorch operators in C++), please reach out to us through Github or Slack!</p>
</section>
</section>


                </article>
              
  </article>
  
              
              
                <footer class="bd-footer-article">
                  <div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item">
<div class="feedback">
  
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
        
    </div>
</div>

  <div class="feedback-send">
    <button class="feedback-btn"
            onclick="openGitHubIssue()"
            data-bs-title="Create a GitHub Issue"
            data-bs-placement="bottom"
            data-bs-toggle="tooltip"
            data-gtm="feedback-btn-click">Send Feedback
    </button>
  </div>
</div>

<div class="prev-next-area">
    <a class="left-prev"
       href="dispatcher.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">이전</p>
        <p class="prev-next-title">Registering a Dispatched Operator in C++</p>
      </div>
    </a>
    <a class="right-next"
       href="privateuseone.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">다음</p>
        <p class="prev-next-title">Facilitating New Backend Integration by PrivateUse1</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>

<div class="footer-info">
  <p class="copyright">
    
      
        © Copyright 2018-2025, PyTorch &amp; 파이토치 한국 사용자 모임(PyTorchKR).
      
      <br/>
    
  </p>

  <p class="theme-version">
    Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
  </p>
</div>
</div>
  
</div>
                </footer>
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="dispatcher.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">이전</p>
        <p class="prev-next-title">Registering a Dispatched Operator in C++</p>
      </div>
    </a>
    <a class="right-next"
       href="privateuseone.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">다음</p>
        <p class="prev-next-title">Facilitating New Backend Integration by PrivateUse1</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc">
<div class="sidebar-secondary-items sidebar-secondary__inner">
    
       <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-s-a-new-backend">What’s a new backend?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#get-a-dispatch-key-for-your-backend">Get a dispatch key for your backend</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#get-the-full-list-of-pytorch-operators">Get the full list of PyTorch operators</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#register-kernels-for-the-new-backend">Register kernels for the new backend</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#autograd-support-for-the-new-backend">Autograd support for the new backend</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#build-an-extension">Build an extension</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#custom-operator-support">Custom operator support</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#jit-support">JIT support</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#testing-your-backend-against-native-pytorch-backends">Testing your backend against native PyTorch backends</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#backward-compatibility">Backward Compatibility</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#known-issues-additional-notes">Known issues &amp; additional notes</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#future-work">Future Work</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stay-in-touch">Stay in touch</a></li>
</ul>
  </nav></div>
    




<div class="sidebar-secondary-item">
  <div class="sidebar-heading">PyTorch Libraries</div>
  <ul style="list-style-type: none; padding: 0; padding-bottom: 80px;">
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/ao" style="color: var(--pst-color-text-muted)">torchao</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchrec" style="color: var(--pst-color-text-muted)">torchrec</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchft" style="color: var(--pst-color-text-muted)">torchft</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchcodec" style="color: var(--pst-color-text-muted)">TorchCodec</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/vision" style="color: var(--pst-color-text-muted)">torchvision</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/executorch" style="color: var(--pst-color-text-muted)">ExecuTorch</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/xla" style="color: var(--pst-color-text-muted)">PyTorch on XLA Devices</a></li>
  
  </ul>
</div>

</div>
</div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <div class="container-fluid docs-tutorials-resources">
  <div class="container">
    <div class="row">
      <div class="col-md-4 text-center">
        <h2>PyTorchKorea @ GitHub</h2>
        <p>파이토치 한국 사용자 모임을 GitHub에서 만나보세요.</p>
        <a class="with-right-arrow" href="https://github.com/PyTorchKorea">GitHub로 이동</a>
      </div>

      <div class="col-md-4 text-center">
        <h2>한국어 튜토리얼</h2>
        <p>한국어로 번역 중인 파이토치 튜토리얼을 만나보세요.</p>
        <a class="with-right-arrow" href="https://tutorials.pytorch.kr/">튜토리얼로 이동</a>
      </div>

      <div class="col-md-4 text-center">
        <h2>한국어 커뮤니티</h2>
        <p>다른 사용자들과 의견을 나누고, 도와주세요!</p>
        <a class="with-right-arrow" href="https://discuss.pytorch.kr/">커뮤니티로 이동</a>
      </div>
    </div>
  </div>
</div>

<footer class="site-footer">
  <div class="container footer-container">
    <div class="footer-logo-wrapper">
      <a href="https://pytorch.kr/" class="footer-logo"></a>
    </div>

    <div class="footer-links-wrapper">
      <div class="footer-links-col">
        <ul>
          <li class="list-title"><a href="https://pytorch.kr/">파이토치 한국 사용자 모임</a></li>
          <li><a href="https://pytorch.kr/about">사용자 모임 소개</a></li>
          <li><a href="https://pytorch.kr/contributors">기여해주신 분들</a></li>
          <li><a href="https://pytorch.kr/resources/">리소스</a></li>
          <li><a href="https://pytorch.kr/coc">행동 강령</a></li>
        </ul>
      </div>
    </div>

    <div class="trademark-disclaimer">
      <ul>
        <li>이 사이트는 독립적인 파이토치 사용자 커뮤니티로, 최신 버전이 아니거나 잘못된 내용이 포함되어 있을 수 있습니다. This site is an independent user community and may be out of date or contain incorrect information.</li>
        <li><a href="https://pytorch.kr/coc">행동 강령</a>을 읽고 지켜주세요. PyTorch 공식 로고 사용 규정은 <a href="https://www.linuxfoundation.org/policies/">Linux Foundation의 정책</a>을 따릅니다. Please read and follow <a href="https://pytorch.kr/coc">our code of conduct</a>. All PyTorch trademark policy applicable to <a href="https://www.linuxfoundation.org/policies/">Linux Foundation's policies</a>.</li>
      </ul>
    </div>
  </div>
</footer>

<div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../_static/img/pytorch-x.svg">
  </div>
</div>
  
  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2018-2025, PyTorch &amp; 파이토치 한국 사용자 모임(PyTorchKR).
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.2.6 버전으로 생성되었습니다.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
</p></div>
      
    </div>
  
</div>

  </footer>
  <script type="application/ld+json">
    {
       "@context": "https://schema.org",
       "@type": "Article",
       "name": "Extending dispatcher for a new backend in C++",
       "headline": "Extending dispatcher for a new backend in C++",
       "description": "PyTorch Documentation. Explore PyTorch, an open-source machine learning library that accelerates the path from research prototyping to production deployment. Discover tutorials, API references, and guides to help you build and deploy deep learning models efficiently.",
       "url": "/advanced/extend_dispatcher.html",
       "articleBody": "Extending dispatcher for a new backend in C++# In this tutorial we will walk through all necessary steps to extend the dispatcher to add a new device living outside pytorch/pytorch repo and maintain it to keep in sync with native PyTorch devices. Here we\u2019ll assume that you\u2019re familiar with how to register a dispatched operator in C++ and how to write a custom autograd function. \ucc38\uace0 This tutorial touches a lot of internal components inside PyTorch which are being actively improved, please expect changes to APIs if you decide to follow this tutorial. We\u2019ll keep this tutorial up to date with the latest APIs. What\u2019s a new backend?# Adding a new backend to PyTorch requires a lot of development and maintenance from backend extenders. Before adding a new backend, let\u2019s first consider a few common use cases and recommended solutions for them: If you have new algorithms for an existing PyTorch operator, send a PR to PyTorch. If you want to propose a new operator, send a feature request/PR to PyTorch. If you want to add support for a new device/hardware like Google TPU and customized chips, which often requires using hardware-specific API to write kernels, follow this tutorial and add a out-of-tree backend to PyTorch. If you want to add support for existing operators but with a different Tensor layout/representation like sparse and quantized, which enforces your kernels to be written in a way that\u2019s more efficient given the layout/representation limitation, follow this tutorial and add a out-of-tree backend to PyTorch. In this tutorial we\u2019ll mainly focus on adding a new out-of-tree device below. Adding out-of-tree support for a different tensor layout might share many common steps with devices, but we haven\u2019t seen an example of such integrations yet so it might require additional work from PyTorch to support it. Get a dispatch key for your backend# PyTorch operators are implemented in C++ and made available in Python frontend through Python bindings. The PyTorch dispatcher divides the implementation of an operator into multiple kernels, each of which is associated with a specific dispatch key. Supporting a new backend in PyTorch essentially means writing a kernel for each PyTorch operator in C++ and then registering them to a dispatch key representing your customized backend in the dispatcher. Dispatch key is your identifier in the dispatcher system. The dispatcher looks at the dispatch keys carried on input tensors and calls the right kernel accordingly. PyTorch provides three reserved dispatch keys (and their corresponding Autograd keys) for prototyping out-of-tree backend extensions: PrivateUse1/AutogradPrivateUse1 PrivateUse2/AutogradPrivateUse2 PrivateUse3/AutogradPrivateUse3 You can choose any of keys above to prototype your customized backend. To create a Tensor on PrivateUse1 backend, you need to set dispatch key in TensorImpl constructor. /* Example TensorImpl constructor */ TensorImpl( Storage\u0026\u0026 storage, DispatchKeySet ks, const caffe2::TypeMeta data_type); // To create a TensorImpl on PrivateUse1 backend, pass in the following ks to TensorImpl creation. DispatchKeySet ks = c10::DispatchKeySet{c10::DispatchKey::PrivateUse1, c10::DispatchKey::AutogradPrivateUse1}; Note that TensorImpl class above assumes your Tensor is backed by a storage like CPU/CUDA. We also provide OpaqueTensorImpl for backends without a storage. And you might need to tweak/override certain methods to fit your customized hardware. One example in pytorch repo is Vulkan TensorImpl. \ucc38\uace0 Once the prototype is done and you plan to do regular releases for your backend extension, please feel free to submit a PR to pytorch/pytorch to reserve a dedicated dispatch key for your backend. Get the full list of PyTorch operators# PyTorch provides a full list of extensible C++ operators in generated file build/aten/src/ATen/RegistrationDeclarations.h. This file is only available after building PyTorch from source. Here\u2019s a snippet of the file: Tensor abs(const Tensor \u0026 self); // {\"schema\": \"aten::abs(Tensor self) -\u003e Tensor\", \"dispatch\": \"True\", \"default\": \"True\"} Tensor \u0026 abs_(Tensor \u0026 self); // {\"schema\": \"aten::abs_(Tensor(a!) self) -\u003e Tensor(a!)\", \"dispatch\": \"True\", \"default\": \"True\"} Tensor \u0026 abs_out(Tensor \u0026 out, const Tensor \u0026 self); // {\"schema\": \"aten::abs.out(Tensor self, *, Tensor(a!) out) -\u003e Tensor(a!)\", \"dispatch\": \"True\", \"default\": \"False\"} Tensor absolute(const Tensor \u0026 self); // {\"schema\": \"aten::absolute(Tensor self) -\u003e Tensor\", \"dispatch\": \"False\", \"default\": \"False\"} Tensor \u0026 absolute_(Tensor \u0026 self); // {\"schema\": \"aten::absolute_(Tensor(a!) self) -\u003e Tensor(a!)\", \"dispatch\": \"False\", \"default\": \"False\"} Tensor \u0026 absolute_out(Tensor \u0026 out, const Tensor \u0026 self); // {\"schema\": \"aten::absolute.out(Tensor self, *, Tensor(a!) out) -\u003e Tensor(a!)\", \"dispatch\": \"False\", \"default\": \"False\"} Tensor angle(const Tensor \u0026 self); // {\"schema\": \"aten::angle(Tensor self) -\u003e Tensor\", \"dispatch\": \"True\", \"default\": \"True\"} Tensor \u0026 angle_out(Tensor \u0026 out, const Tensor \u0026 self); // {\"schema\": \"aten::angle.out(Tensor self, *, Tensor(a!) out) -\u003e Tensor(a!)\", \"dispatch\": \"True\", \"default\": \"False\"} Tensor sgn(const Tensor \u0026 self); // {\"schema\": \"aten::sgn(Tensor self) -\u003e Tensor\", \"dispatch\": \"True\", \"default\": \"True\"} There\u2019re multiple fields associated with a single operator. Let\u2019s break it down using abs_out as an example: Tensor \u0026 abs_out(Tensor \u0026 out, const Tensor \u0026 self); is the C++ signature of the operator, your C++ kernel should match this signature exactly. aten::abs.out(Tensor self, *, Tensor(a!) out) -\u003e Tensor(a!) is the unique schema representing the operator, which also contains aliasing and mutation annotations compared to the C++ signature. This is the unique identifier the dispatcher uses to find an operator. dispatch and default are boolean fields that provide information about what native PyTorch kernels can do, thus implies whether it\u2019s required for backend extenders to implement the kernel. More details can be found in register kernels for the new backend. Register kernels for the new backend# To register your kernels to PyTorch dispatcher, you can use the TORCH_LIBRARY_IMPL API described in Registering a Dispatched Operator in C++: TORCH_LIBRARY_IMPL(aten, PrivateUse1, m) { m.impl(\u003cschema_my_op1\u003e, \u0026my_op1); m.impl(\u003cschema_my_op2\u003e, \u0026my_op2); m.impl(\u003cschema_my_op2_backward\u003e, \u0026my_op2_backward); } Now let\u2019s zoom in and what operator requires a kernel from a customized backend and what\u2019s inside the kernels exactly. PyTorch currently has more than 1600 operators and it\u2019s still growing. It\u2019s unrealistic for backend extensions to keep up with this speed. Even for native backends like CPU or CUDA, it often requires a lot of work to write dedicated kernels for every new op. Fortunately, some native PyTorch kernels are written in a way that they decompose to combination of several known operators. In other words, you only need to implement a set of known operators (ops that require registration below) instead of all PyTorch operators. PyTorch operators can be classified into two categories: Ops that require registration: PyTorch native implementation for these ops is backend specific and thus it\u2019s required to provide a kernel for customized backend. Otherwise calling such op on the customized backend will error out. In RegistrationDeclarations.h these operators have dispatch set to True and default set to False in the metadata found in their accompanying comments. Registration is optional: backend extenders can skip registering to these ops without sacrificing any support. However, if a backend extender wants to override the default kernel provided by PyTorch, they can still register their customized kernel to their backend and the dispatcher will use it for your backend only. For example, current implementation of PyTorch\u2019s max_pool2d returns indices as part of forward outputs which creates overhead in torch_xla, so torch_xla registers its own kernel for max_pool2d instead. In RegistrationDeclarations.h these operators have dispatch set to False or default set to True in the metadata found in their accompanying comments. Autograd support for the new backend# Gradient formulas are mostly purely mathematical and thus are general for all backends. PyTorch often registers a kernel to alias dispatch key Autograd, which means it can be used by all backends. For these operators you don\u2019t have to worry about their derivative formulas, you can just write forward definitions for operators in RegistrationDeclarations.h and PyTorch handles backward for you automatically. Tensor my_op1(const Tensor\u0026 self, const Tensor\u0026 other) { // call your backend-specific APIs to implement my_op so that // it matches PyTorch\u0027s native behavior } TORCH_LIBRARY_IMPL(aten, PrivateUse1, m) { m.impl(\u003cschema_my_op1\u003e, \u0026my_op); } In some cases, PyTorch backward kernel implementations are also device specific so that they can squeeze out max performance out of each backend. For those operators you\u2019ll see op_backward showing up in RegistrationDeclarations.h as required registration as well. Tensor my_op2_backward(const Tensor\u0026 self, const Tensor\u0026 other) { // call your backend-specific APIs to implement my_op2_backward so that // it matches PyTorch\u0027s native behavior } // Note backward kernel is still registered to PrivateUse1 instead of AutogradPrivateUse1. // PyTorch will wrap your backward kernel with proper autograd setup and then link to it in // my_op2\u0027s AutogradPrivateUse1 kernel. TORCH_LIBRARY_IMPL(aten, PrivateUse1, m) { m.impl(\u003cschema_my_op2\u003e, \u0026my_op2); m.impl(\u003cschema_my_op2_backward\u003e, \u0026my_op2_backward); } In a few rare cases, PyTorch\u2019s gradient formula for certain operators may have assumptions that don\u2019t generalize for all backends. In those cases backend extenders can optionally override PyTorch Autograd layer by registering a kernel from torch::autograd::Function to the corresponding dispatch key (for example, AutogradPrivateUse1 if you\u2019re using PrivateUse1 for your backend): class MyAddFunction : public torch::autograd::Function\u003cMyAddFunction\u003e { public: static Tensor forward(AutogradContext *ctx, torch::Tensor self, torch::Tensor other) { at::AutoNonVariableTypeMode g; return myadd(self, other); } static tensor_list backward(AutogradContext *ctx, tensor_list grad_outputs) { auto grad_output = grad_outputs[0]; return {grad_output, grad_output}; } }; Tensor myadd_autograd(const Tensor\u0026 self, const Tensor\u0026 other) { return MyAddFunction::apply(self, other)[0]; } // Register the autograd kernel to AutogradPrivateUse1 TORCH_LIBRARY_IMPL(aten, AutogradPrivateUse1, m) { m.impl(\u003cmyadd_schema\u003e, \u0026myadd_autograd); } // Register the inference kernel to PrivateUse1 TORCH_LIBRARY_IMPL(aten, PrivateUse1, m) { m.impl(\u003cmyadd_schema\u003e, \u0026myadd); } With this trick you have full control over both training and inference behavior for my_add operator in your backend. Here\u2019s an example in the pytorch/xla repository. Build an extension# Out-of-tree backend is supported by adding a C++ extension to PyTorch. Once you have kernels and registrations ready, you can build a C++ extension by writing a setup.py script that uses setuptools to compile C++ code. Here\u2019s a simplified example from pytorch/xla repo: from setuptools import setup from torch.utils.cpp_extension import BuildExtension, CppExtension setup( name=\u0027torch_xla\u0027, ext_modules=[ CppExtension( \u0027_XLAC\u0027, torch_xla_sources, include_dirs=include_dirs, extra_compile_args=extra_compile_args, library_dirs=library_dirs, extra_link_args=extra_link_args + \\ [make_relative_rpath(\u0027torch_xla/lib\u0027)], ), ], cmdclass={ \u0027build_ext\u0027: Build, # Build is a derived class of BuildExtension } # more configs... ) See our C++ extension tutorial for more details. Custom operator support# Your new backend should work seamlessly with customized operators extended in python without writing any new kernels as long as the customized operator is composed of existing PyTorch operators (which are already supported by your backend). For custom operators extended in C++ they often come with a backend specific C++ kernel implementation e.g. nms kernel in torchvsion as well as a customized Python API e.g. torch.ops.torchvision.nms. To support these operators, backend extenders will need to write a C++ kernel for your backend and properly register it to the corresponding namespace in the dispatcher similar to supporting PyTorch native operators. Alternatively you could also add a customized API in your extension e.g torch_xla.core.functions.nms for these adhoc requests. JIT support# As we mentioned in Registering a Dispatched Operator in C++, kernels registered through m.impl() API support being called in both unboxed and boxed ways. In other words your customized backend can also work with our JIT tracing/scripting frontend just like the in-tree backends like CPU or CUDA do. You could potentially also write specialized optimization passes for your backend on a JIT graph. But we will not discuss it here since we haven\u2019t finalized the integration point in JIT, so the current backend support will focus on the eager frontend for now. Testing your backend against native PyTorch backends# PyTorch lets tests run on multiple device types using its generic device type testing framework. You can find details about how tests use it and information about how to add a new device type. Once added, PyTorch tests using the generic device type testing framework will be run using your device type, too. See this Wiki page for an example of how tests are instantiated. Running PyTorch\u2019s existing test suites with your device type is important to ensure correctness, but not all PyTorch features are supported by every device type. The generic device type testing framework allows for considerable customization so that device types can select which tests to run, which dtypes they support, and even which precisions to use when comparing tensors for equality. An example device type that uses the generic device type testing framework and doesn\u2019t ship with PyTorch is XLA. See its extension of the generic device type testing framework, which contains examples of block listing tests, block listing dtypes, and overriding test precision. The generic device type testing framework is actively developed. To request a feature please file an issue on PyTorch\u2019s Github. Backward Compatibility# Currently PyTorch can\u2019t guarantee backward compatibility for registered operators. Operators, as well as their schemas, might be added/modified/deleted as needed. Registered kernels must be exactly the same as PyTorch version. If PyTorch adds more parameters ( even with defaults) for an operator, your old registration won\u2019t work until it\u2019s updated to match PyTorch\u2019s new signature. As a result, we highly recommend out-of-tree backend extenders only sync with major PyTorch releases to minimize interruptions in development. PyTorch is on a quarterly release cadence. Backend extenders should join the #announcement channel at pytorch.slack.com to get latest updates on releases. Known issues \u0026 additional notes# Not all test suites are device generic yet. Extensible test classes can be found by searching instantiate_device_type_tests in PyTorch codebase, e.g TestTorchDeviceType, TestViewOps, TestTensorDeviceOps, TestTypePromotion etc. There\u2019s no extension point in C++ for serializing a python Tensor object on customized backend. Currently you can only extend it by modifying PyTorch Tensor __reduce_ex__ method or monkey patching in out-of-tree repository. If your backend doesn\u2019t allow direct memory access, you should pay additional attention to supporting view ops since they\u2019re supposed to share storage. Changes to view tensor need to propagated to its base tensor and vice versa. There\u2019s no extension point in C++ for Optimizer if your backend doesn\u2019t work with the native PyTorch Optimizers, e.g. need to carry the states to be updated in backward like torch-xla. Such use cases currently can only be done through adding customized API or monkey patching in out-of-tree repository. Future Work# Making every component in PyTorch extensible for an out-of-tree backend seamless requires a lot of changes to PyTorch internals. Here are a few items that we\u2019re actively working on might improve the experience in the future: Improve test coverage of generic testing framework. Improve Math kernel coverage and more comprehensive tests to make sure Math kernel behavior matches other backends like CPU/CUDA. Refactor RegistrationDeclarations.h to carry the minimal information and reuse PyTorch\u2019s codegen as much as possible. Support a backend fallback kernel to automatic convert inputs to CPU and convert the result back to the customized backend. This will allow \u201cfull\u201d operator coverage even though you don\u2019t have kernels written for every operator. Stay in touch# Please use PyTorch dev discussions for questions and discussions. If you have any feature requests or bug reports, please file an issue on github. If you\u2019re interested in helping in any of the future work items above (e.g adding more Math kernels for PyTorch operators in C++), please reach out to us through Github or Slack!",
       "author": {
         "@type": "Organization",
         "name": "PyTorch Contributors",
         "url": "https://pytorch.org"
       },
       "image": "../_static/img/pytorch_seo.png",
       "mainEntityOfPage": {
         "@type": "WebPage",
         "@id": "/advanced/extend_dispatcher.html"
       },
       "datePublished": "2023-01-01T00:00:00Z",
       "dateModified": "2023-01-01T00:00:00Z"
     }
 </script>
  <script>
    // Tutorials Call to action event tracking
    $("[data-behavior='call-to-action-event']").on('click', function () {
      fbq('trackCustom', "Download", {
        tutorialTitle: $('h1:first').text(),
        downloadLink: this.href,
        tutorialLink: window.location.href,
        downloadTitle: $(this).attr("data-response")
      });
      if (typeof gtag === 'function') {
        gtag('event', 'click', {
          'event_category': $(this).attr("data-response"),
          'event_label': $("h1").first().text(),
          'tutorial_link': window.location.href
        });
      }
    });
  </script>
  
  </body>
</html>