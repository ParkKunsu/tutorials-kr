{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Google Colab\uc5d0\uc11c \ub178\ud2b8\ubd81\uc744 \uc2e4\ud589\ud558\uae30 \uc704\ud55c \ud301\uc740 \ub2e4\uc74c\uc744 \ucc38\uc870\ud558\uc138\uc694:\n# https://tutorials.pytorch.kr/beginner/colab \n%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# \uae30\ucd08\ubd80\ud130 \uc2dc\uc791\ud558\ub294 NLP: Sequence to Sequence \ub124\ud2b8\uc6cc\ud06c\uc640 Attention\uc744 \uc774\uc6a9\ud55c \ubc88\uc5ed\n\n**Author**: [Sean Robertson](https://github.com/spro)\n  **\ubc88\uc5ed**: [\ud669\uc131\uc218](https://github.com/adonisues)\n\n\uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc740 3\ubd80\ub85c \uad6c\uc131\ub41c \uc2dc\ub9ac\uc988\uc758 \uc77c\ubd80\uc785\ub2c8\ub2e4:\n\n* [\uae30\ucd08\ubd80\ud130 \uc2dc\uc791\ud558\ub294 NLP: \ubb38\uc790-\ub2e8\uc704 RNN\uc73c\ub85c \uc774\ub984 \ubd84\ub958\ud558\uae30](https://tutorials.pytorch.kr/intermediate/char_rnn_classification_tutorial.html)_\n* [\uae30\ucd08\ubd80\ud130 \uc2dc\uc791\ud558\ub294 NLP: \ubb38\uc790-\ub2e8\uc704 RNN\uc73c\ub85c \uc774\ub984 \uc0dd\uc131\ud558\uae30](https://tutorials.pytorch.kr/intermediate/char_rnn_generation_tutorial.html)_\n* [\uae30\ucd08\ubd80\ud130 \uc2dc\uc791\ud558\ub294 NLP: Sequence to Sequence \ub124\ud2b8\uc6cc\ud06c\uc640 Attention\uc744 \uc774\uc6a9\ud55c \ubc88\uc5ed](https://tutorials.pytorch.kr/intermediate/seq2seq_translation_tutorial.html)_\n\n\uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc740 \"\uae30\ucd08\ubd80\ud130 \uc2dc\uc791\ud558\ub294 NLP\"\uc758 \uc138\ubc88\uc9f8\uc774\uc790 \ub9c8\uc9c0\ub9c9 \ud3b8\uc73c\ub85c, NLP \ubaa8\ub378\ub9c1 \uc791\uc5c5\uc744\n\uc704\ud55c \ub370\uc774\ud130 \uc804\ucc98\ub9ac\uc5d0 \uc0ac\uc6a9\ud560 \uc790\uccb4 \ud074\ub798\uc2a4\uc640 \ud568\uc218\ub4e4\uc744 \uc791\uc131\ud574\ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n\n\uc774 \ud504\ub85c\uc81d\ud2b8\uc5d0\uc11c\ub294 \uc2e0\uacbd\ub9dd\uc774 \ubd88\uc5b4\ub97c \uc601\uc5b4\ub85c \ubc88\uc5ed\ud558\ub3c4\ub85d \uac00\ub974\uce60 \uc608\uc815\uc785\ub2c8\ub2e4.\n\n```sh\n[KEY: > input, = target, < output]\n\n> il est en train de peindre un tableau .\n= he is painting a picture .\n< he is painting a picture .\n\n> pourquoi ne pas essayer ce vin delicieux ?\n= why not try that delicious wine ?\n< why not try that delicious wine ?\n\n> elle n est pas poete mais romanciere .\n= she is not a poet but a novelist .\n< she not not a poet but a novelist .\n\n> vous etes trop maigre .\n= you re too skinny .\n< you re all alone .\n```\n... \uc131\uacf5\uc728\uc740 \ub2ec\ub77c\uc9c8 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n\ud558\ub098\uc758 \uc2dc\ud000\uc2a4\ub97c \ub2e4\ub978 \uc2dc\ud000\uc2a4\ub85c \ubc14\uafb8\ub294 \ub450 \uac1c\uc758 RNN\uc774 \ud568\uaed8 \ub3d9\uc791\ud558\ub294\n[sequence to sequence network](https://arxiv.org/abs/1409.3215)_ \uc758 \uac04\ub2e8\ud558\uc9c0\ub9cc \uac15\ub825\ud55c \uc544\uc774\ub514\uc5b4\uac00\n\uc774\uac83(\ubc88\uc5ed)\uc744 \uac00\ub2a5\ud558\uac8c \ud569\ub2c8\ub2e4. \uc778\ucf54\ub354 \ub124\ud2b8\uc6cc\ud06c\ub294 \uc785\ub825 \uc2dc\ud000\uc2a4\ub97c \ubca1\ud130\ub85c \uc555\ucd95\ud558\uace0,\n\ub514\ucf54\ub354 \ub124\ud2b8\uc6cc\ud06c\ub294 \ud574\ub2f9 \ubca1\ud130\ub97c \uc0c8\ub85c\uc6b4 \uc2dc\ud000\uc2a4\ub85c \ud3bc\uce69\ub2c8\ub2e4.\n\n.. figure:: /_static/img/seq-seq-images/seq2seq.png\n   :alt:\n\n\uc774 \ubaa8\ub378\uc744 \uac1c\uc120\ud558\uae30 \uc704\ud574 [Attention Mechanism](https://arxiv.org/abs/1409.0473)_ \uc744\n\uc0ac\uc6a9\ud558\uba74 \ub514\ucf54\ub354\uac00 \uc785\ub825 \uc2dc\ud000\uc2a4\uc758 \ud2b9\uc815 \ubc94\uc704\uc5d0 \uc9d1\uc911\ud560 \uc218 \uc788\ub3c4\ub85d \ud569\ub2c8\ub2e4.\n\n**\ucd94\ucc9c \uc790\ub8cc:**\n\n\ucd5c\uc18c\ud55c Pytorch\ub97c \uc124\uce58\ud588\uace0, Python\uc744 \uc54c\uace0, Tensor\ub97c \uc774\ud574\ud55c\ub2e4\uace0 \uac00\uc815\ud569\ub2c8\ub2e4.:\n\n-  http://pytorch.org/ \uc124\uce58 \uc548\ub0b4\ub97c \uc704\ud55c \uc790\ub8cc\n-  :doc:`/beginner/deep_learning_60min_blitz` \uc77c\ubc18\uc801\uc778 PyTorch \uc2dc\uc791\uc744 \uc704\ud55c \uc790\ub8cc\n-  :doc:`/beginner/pytorch_with_examples` \ub113\uace0 \uae4a\uc740 \ud1b5\ucc30\uc744 \uc704\ud55c \uc790\ub8cc\n-  :doc:`/beginner/former_torchies_tutorial` \uc774\uc804 Lua Torch \uc0ac\uc6a9\uc790\ub97c \uc704\ud55c \uc790\ub8cc\n\n\nSequence to Sequence \ub124\ud2b8\uc6cc\ud06c\uc640 \ub3d9\uc791 \ubc29\ubc95\uc5d0 \uad00\ud574\uc11c \uc544\ub294 \uac83\uc740 \uc720\uc6a9\ud569\ub2c8\ub2e4:\n\n-  [Learning Phrase Representations using RNN Encoder-Decoder for\n   Statistical Machine Translation](https://arxiv.org/abs/1406.1078)_\n-  [Sequence to Sequence Learning with Neural\n   Networks](https://arxiv.org/abs/1409.3215)_\n-  [Neural Machine Translation by Jointly Learning to Align and\n   Translate](https://arxiv.org/abs/1409.0473)_\n-  [A Neural Conversational Model](https://arxiv.org/abs/1506.05869)_\n\n\uc774\uc804 \ud29c\ud1a0\ub9ac\uc5bc\uc5d0 \uc788\ub294\n:doc:`/intermediate/char_rnn_classification_tutorial`\n\uc640 :doc:`/intermediate/char_rnn_generation_tutorial` \ub294\n\uac01\uac01 \uc778\ucf54\ub354, \ub514\ucf54\ub354 \ubaa8\ub378\uacfc \ube44\uc2b7\ud55c \ucee8\uc13c\uc744 \uac00\uc9c0\uae30 \ub54c\ubb38\uc5d0 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.\n\n**\uc694\uad6c \uc0ac\ud56d**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from __future__ import unicode_literals, print_function, division\nfrom io import open\nimport unicodedata\nimport re\nimport random\n\nimport torch\nimport torch.nn as nn\nfrom torch import optim\nimport torch.nn.functional as F\n\nimport numpy as np\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ub370\uc774\ud130 \ud30c\uc77c \ubd88\ub7ec\uc624\uae30\n\n\uc774 \ud504\ub85c\uc81d\ud2b8\uc758 \ub370\uc774\ud130\ub294 \uc218\ucc9c \uac1c\uc758 \uc601\uc5b4-\ud504\ub791\uc2a4\uc5b4 \ubc88\uc5ed \uc30d\uc785\ub2c8\ub2e4.\n\n[Open Data Stack Exchange](https://opendata.stackexchange.com/questions/3888/dataset-of-sentences-translated-into-many-languages)_\n\uc5d0 \uad00\ud55c \uc774 \uc9c8\ubb38\uc740 https://tatoeba.org/eng/downloads \uc5d0\uc11c \ub2e4\uc6b4 \ub85c\ub4dc\uac00 \uac00\ub2a5\ud55c\n\uacf5\uac1c \ubc88\uc5ed \uc0ac\uc774\ud2b8 https://tatoeba.org/ \ub97c \uc54c\ub824 \uc8fc\uc5c8\uc2b5\ub2c8\ub2e4. \ub354 \ub098\uc740 \ubc29\ubc95\uc73c\ub85c\n\uc5b8\uc5b4 \uc30d\uc744 \uac1c\ubcc4 \ud14d\uc2a4\ud2b8 \ud30c\uc77c\ub85c \ubd84\ud560\ud558\ub294 \ucd94\uac00 \uc791\uc5c5\uc744 \uc218\ud589\ud55c\nhttps://www.manythings.org/anki/ \uac00 \uc788\uc2b5\ub2c8\ub2e4:\n\n\uc601\uc5b4-\ud504\ub791\uc2a4\uc5b4 \uc30d\uc774 \ub108\ubb34 \ucee4\uc11c \uc800\uc7a5\uc18c\uc5d0 \ud3ec\ud568 \ud560 \uc218 \uc5c6\uae30 \ub54c\ubb38\uc5d0\n\uacc4\uc18d\ud558\uae30 \uc804\uc5d0 ``data/eng-fra.txt`` \ub85c \ub2e4\uc6b4\ub85c\ub4dc\ud558\uc2ed\uc2dc\uc624.\n\uc774 \ud30c\uc77c\uc740 \ud0ed\uc73c\ub85c \uad6c\ubd84\ub41c \ubc88\uc5ed \uc30d \ubaa9\ub85d\uc785\ub2c8\ub2e4:\n\n```sh\nI am cold.    J'ai froid.\n```\n<div class=\"alert alert-info\"><h4>Note</h4><p>[\uc5ec\uae30](https://download.pytorch.org/tutorial/data.zip)\n   \uc5d0\uc11c \ub370\uc774\ud130\ub97c \ub2e4\uc6b4 \ubc1b\uace0 \ud604\uc7ac \ub514\ub809\ud1a0\ub9ac\uc5d0 \uc555\ucd95\uc744 \ud478\uc2ed\uc2dc\uc624.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ubb38\uc790 \ub2e8\uc704 RNN \ud29c\ud1a0\ub9ac\uc5bc\uc5d0\uc11c \uc0ac\uc6a9\ub41c \ubb38\uc790 \uc778\ucf54\ub529\uacfc \uc720\uc0ac\ud558\uac8c, \uc5b8\uc5b4\uc758 \uac01\n\ub2e8\uc5b4\ub4e4\uc744 One-Hot \ubca1\ud130 \ub610\ub294 \uadf8 \ub2e8\uc5b4\uc758 \uc8fc\uc18c\uc5d0\ub9cc \ub2e8 \ud558\ub098\uc758 1\uc744 \uc81c\uc678\ud558\uace0\n\ubaa8\ub450 0\uc778 \ud070 \ubca1\ud130\ub85c \ud45c\ud604\ud569\ub2c8\ub2e4. \ud55c \uac00\uc9c0 \uc5b8\uc5b4\uc5d0 \uc788\ub294 \uc218\uc2ed \uac1c\uc758 \ubb38\uc790\uc640\n\ub2ec\ub9ac \ubc88\uc5ed\uc5d0\ub294 \uc544\uc8fc \ub9ce\uc740 \ub2e8\uc5b4\ub4e4\uc774 \uc788\uae30 \ub54c\ubb38\uc5d0 \uc778\ucf54\ub529 \ubca1\ud130\ub294 \ub9e4\uc6b0 \ub354 \ud07d\ub2c8\ub2e4.\n\uadf8\ub7ec\ub098 \uc6b0\ub9ac\ub294 \uc57d\uac04\uc758 \ud2b8\ub9ad\ub97c \uc368\uc11c \uc5b8\uc5b4 \ub2f9 \uc218\ucc9c \ub2e8\uc5b4 \ub9cc\n\uc0ac\uc6a9\ud558\ub3c4\ub85d \ub370\uc774\ud130\ub97c \ub2e4\ub4ec\uc744 \uac83\uc785\ub2c8\ub2e4.\n\n.. figure:: /_static/img/seq-seq-images/word-encoding.png\n   :alt:\n\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub098\uc911\uc5d0 \ub124\ud2b8\uc6cc\ud06c\uc758 \uc785\ub825 \ubc0f \ubaa9\ud45c\ub85c \uc0ac\uc6a9\ud558\ub824\uba74 \ub2e8\uc5b4 \ub2f9 \uace0\uc720 \ubc88\ud638\uac00\n\ud544\uc694\ud569\ub2c8\ub2e4. \uc774 \ubaa8\ub4e0 \uac83\uc744 \ucd94\uc801\ud558\uae30 \uc704\ud574 \uc6b0\ub9ac\ub294\n\ub2e8\uc5b4\u2192\uc0c9\uc778(``word2index``)\uacfc \uc0c9\uc778\u2192\ub2e8\uc5b4(``index2word``) \uc0ac\uc804,\n\uadf8\ub9ac\uace0 \ub098\uc911\uc5d0 \ud76c\uadc0 \ub2e8\uc5b4\ub97c \ub300\uccb4\ud558\ub294\ub370 \uc0ac\uc6a9\ud560 \uac01 \ub2e8\uc5b4\uc758 \ube48\ub3c4\n``word2count`` \ub97c \uac00\uc9c4 ``Lang`` \uc774\ub77c\ub294 \ud5ec\ud37c \ud074\ub798\uc2a4\ub97c \uc0ac\uc6a9\ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "SOS_token = 0\nEOS_token = 1\n\n\nclass Lang:\n    def __init__(self, name):\n        self.name = name\n        self.word2index = {}\n        self.word2count = {}\n        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n        self.n_words = 2  # SOS \uc640 EOS \ud3ec\ud568\n\n    def addSentence(self, sentence):\n        for word in sentence.split(' '):\n            self.addWord(word)\n\n    def addWord(self, word):\n        if word not in self.word2index:\n            self.word2index[word] = self.n_words\n            self.word2count[word] = 1\n            self.index2word[self.n_words] = word\n            self.n_words += 1\n        else:\n            self.word2count[word] += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud30c\uc77c\uc740 \ubaa8\ub450 \uc720\ub2c8 \ucf54\ub4dc\ub85c \ub418\uc5b4\uc788\uc5b4 \uac04\ub2e8\ud558\uac8c \ud558\uae30 \uc704\ud574 \uc720\ub2c8 \ucf54\ub4dc \ubb38\uc790\ub97c\nASCII\ub85c \ubcc0\ud658\ud558\uace0, \ubaa8\ub4e0 \ubb38\uc790\ub97c \uc18c\ubb38\uc790\ub85c \ub9cc\ub4e4\uace0, \ub300\ubd80\ubd84\uc758 \uad6c\ub450\uc810\uc744\n\uc9c0\uc6cc\uc90d\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \uc720\ub2c8 \ucf54\ub4dc \ubb38\uc790\uc5f4\uc744 \uc77c\ubc18 ASCII\ub85c \ubcc0\ud658\ud558\uc2ed\uc2dc\uc624.\n# https://stackoverflow.com/a/518232/2809427\ndef unicodeToAscii(s):\n    return ''.join(\n        c for c in unicodedata.normalize('NFD', s)\n        if unicodedata.category(c) != 'Mn'\n    )\n\n# \uc18c\ubb38\uc790, \ub2e4\ub4ec\uae30, \uadf8\ub9ac\uace0 \ubb38\uc790\uac00 \uc544\ub2cc \ubb38\uc790 \uc81c\uac70\ndef normalizeString(s):\n    s = unicodeToAscii(s.lower().strip())\n    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n    return s.strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To read the data file we will split the file into lines, and then split\nlines into pairs. The files are all English \u2192 Other Language, so if we\nwant to translate from Other Language \u2192 English I added the ``reverse``\nflag to reverse the pairs.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def readLangs(lang1, lang2, reverse=False):\n    print(\"Reading lines...\")\n\n    # \ud30c\uc77c\uc744 \uc77d\uace0 \uc904\ub85c \ubd84\ub9ac\n    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n        read().strip().split('\\n')\n\n    # \ubaa8\ub4e0 \uc904\uc744 \uc30d\uc73c\ub85c \ubd84\ub9ac\ud558\uace0 \uc815\uaddc\ud654\n    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n\n    # \uc30d\uc744 \ub4a4\uc9d1\uace0, Lang \uc778\uc2a4\ud134\uc2a4 \uc0dd\uc131\n    if reverse:\n        pairs = [list(reversed(p)) for p in pairs]\n        input_lang = Lang(lang2)\n        output_lang = Lang(lang1)\n    else:\n        input_lang = Lang(lang1)\n        output_lang = Lang(lang2)\n\n    return input_lang, output_lang, pairs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*\ub9ce\uc740* \uc608\uc81c \ubb38\uc7a5\uc774 \uc788\uace0 \uc2e0\uc18d\ud558\uac8c \ud559\uc2b5\ud558\uae30\ub97c \uc6d0\ud558\uae30 \ub54c\ubb38\uc5d0\n\ube44\uad50\uc801 \uc9e7\uace0 \uac04\ub2e8\ud55c \ubb38\uc7a5\uc73c\ub85c\ub9cc \ub370\uc774\ud130 \uc14b\uc744 \uc815\ub9ac\ud560 \uac83\uc785\ub2c8\ub2e4. \uc5ec\uae30\uc11c\n\ucd5c\ub300 \uae38\uc774\ub294 10 \ub2e8\uc5b4 (\uc885\ub8cc \ubb38\uc7a5 \ubd80\ud638 \ud3ec\ud568)\uc774\uba70 \"I am\" \ub610\ub294\n\"He is\" \ub4f1\uc758 \ud615\ud0dc\ub85c \ubc88\uc5ed\ub418\ub294 \ubb38\uc7a5\uc73c\ub85c \ud544\ud130\ub9c1\ub429\ub2c8\ub2e4.(\uc774\uc804\uc5d0\n\uc544\ud3ec\uc2a4\ud2b8\ub85c\ud53c\ub294 \ub300\uccb4 \ub428)\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH = 10\n\neng_prefixes = (\n    \"i am \", \"i m \",\n    \"he is\", \"he s \",\n    \"she is\", \"she s \",\n    \"you are\", \"you re \",\n    \"we are\", \"we re \",\n    \"they are\", \"they re \"\n)\n\ndef filterPair(p):\n    return len(p[0].split(' ')) < MAX_LENGTH and \\\n        len(p[1].split(' ')) < MAX_LENGTH and \\\n        p[1].startswith(eng_prefixes)\n\n\ndef filterPairs(pairs):\n    return [pair for pair in pairs if filterPair(pair)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub370\uc774\ud130 \uc900\ube44\ub97c \uc704\ud55c \uc804\uccb4 \uacfc\uc815:\n\n-  \ud14d\uc2a4\ud2b8 \ud30c\uc77c\uc744 \uc77d\uace0 \uc904\ub85c \ubd84\ub9ac\ud558\uace0, \uc904\uc744 \uc30d\uc73c\ub85c \ubd84\ub9ac\ud569\ub2c8\ub2e4.\n-  \ud14d\uc2a4\ud2b8\ub97c \uc815\uaddc\ud654 \ud558\uace0 \uae38\uc774\uc640 \ub0b4\uc6a9\uc73c\ub85c \ud544\ud130\ub9c1 \ud569\ub2c8\ub2e4.\n-  \uc30d\uc744 \uc774\ub8ec \ubb38\uc7a5\ub4e4\ub85c \ub2e8\uc5b4 \ub9ac\uc2a4\ud2b8\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def prepareData(lang1, lang2, reverse=False):\n    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n    print(\"Read %s sentence pairs\" % len(pairs))\n    pairs = filterPairs(pairs)\n    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n    print(\"Counting words...\")\n    for pair in pairs:\n        input_lang.addSentence(pair[0])\n        output_lang.addSentence(pair[1])\n    print(\"Counted words:\")\n    print(input_lang.name, input_lang.n_words)\n    print(output_lang.name, output_lang.n_words)\n    return input_lang, output_lang, pairs\n\n\ninput_lang, output_lang, pairs = prepareData('eng', 'fra', True)\nprint(random.choice(pairs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Seq2Seq \ubaa8\ub378\n\nRecurrent Neural Network(RNN)\ub294 \uc2dc\ud000\uc2a4\uc5d0\uc11c \uc791\ub3d9\ud558\uace0 \ub2e4\uc74c \ub2e8\uacc4\uc758\n\uc785\ub825\uc73c\ub85c \uc790\uc2e0\uc758 \ucd9c\ub825\uc744 \uc0ac\uc6a9\ud558\ub294 \ub124\ud2b8\uc6cc\ud06c\uc785\ub2c8\ub2e4.\n\n[Sequence to Sequence network](https://arxiv.org/abs/1409.3215)_, \ub610\ub294\nSeq2Seq \ub124\ud2b8\uc6cc\ud06c, \ub610\ub294 [Encoder Decoder\nnetwork](https://arxiv.org/pdf/1406.1078v3.pdf)_ \ub294 \uc778\ucf54\ub354 \ubc0f\n\ub514\ucf54\ub354\ub77c\uace0 \ud558\ub294 \ub450 \uac1c\uc758 RNN\uc73c\ub85c \uad6c\uc131\ub41c \ubaa8\ub378\uc785\ub2c8\ub2e4.\n\uc778\ucf54\ub354\ub294 \uc785\ub825 \uc2dc\ud000\uc2a4\ub97c \uc77d\uace0 \ub2e8\uc77c \ubca1\ud130\ub97c \ucd9c\ub825\ud558\uace0,\n\ub514\ucf54\ub354\ub294 \ud574\ub2f9 \ubca1\ud130\ub97c \uc77d\uc5b4 \ucd9c\ub825 \uc2dc\ud000\uc2a4\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4.\n\n.. figure:: /_static/img/seq-seq-images/seq2seq.png\n   :alt:\n\n\ubaa8\ub4e0 \uc785\ub825\uc5d0 \ud574\ub2f9\ud558\ub294 \ucd9c\ub825\uc774 \uc788\ub294 \ub2e8\uc77c RNN\uc758 \uc2dc\ud000\uc2a4 \uc608\uce21\uacfc \ub2ec\ub9ac\nSeq2Seq \ubaa8\ub378\uc740 \uc2dc\ud000\uc2a4 \uae38\uc774\uc640 \uc21c\uc11c\ub97c \uc790\uc720\ub86d\uac8c\ud558\uae30 \ub54c\ubb38\uc5d0\n\ub450 \uc5b8\uc5b4 \uc0ac\uc774\uc758 \ubc88\uc5ed\uc5d0 \uc774\uc0c1\uc801\uc785\ub2c8\ub2e4.\n\n\ub2e4\uc74c \ubb38\uc7a5 ``Je ne suis pas le chat noir`` \u2192 ``I am not the black cat``\n\ub97c \uc0b4\ud3b4 \ubd05\uc2dc\ub2e4. \uc785\ub825 \ubb38\uc7a5\uc758 \ub2e8\uc5b4 \ub300\ubd80\ubd84\uc740 \ucd9c\ub825 \ubb38\uc7a5\uc5d0\uc11c\n\uc9c1\uc5ed(``chat noir`` \uc640 ``black cat``)\ub418\uc9c0\ub9cc \uc57d\uac04 \ub2e4\ub978 \uc21c\uc11c\ub3c4 \uc788\uc2b5\ub2c8\ub2e4.\n``ne/pas`` \uad6c\uc870\ub85c \uc778\ud574 \uc785\ub825 \ubb38\uc7a5\uc5d0 \ub2e8\uc5b4\uac00 \ud558\ub098 \ub354 \uc788\uc2b5\ub2c8\ub2e4.\n\uc785\ub825 \ub2e8\uc5b4\uc758 \uc2dc\ud000\uc2a4\ub97c \uc9c1\uc5ed\ud574\uc11c \uc815\ud655\ud55c \ubc88\uc5ed\uc744 \ub9cc\ub4dc\ub294\n\uac83\uc740 \uc5b4\ub824\uc6b8 \uac83\uc785\ub2c8\ub2e4.\n\nSeq2Seq \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\uba74 \uc778\ucf54\ub354\ub294 \ud558\ub098\uc758 \ubca1\ud130\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4.\n\uc774\uc0c1\uc801\uc778 \uacbd\uc6b0\uc5d0 \uc785\ub825 \uc2dc\ud000\uc2a4\uc758 \"\uc758\ubbf8\"\ub97c \ubb38\uc7a5\uc758 N \ucc28\uc6d0 \uacf5\uac04\uc5d0 \uc788\ub294\n\ub2e8\uc77c \uc9c0\uc810\uc778 \ub2e8\uc77c \ubca1\ud130\uc73c\ub85c \uc778\ucf54\ub529\ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \uc778\ucf54\ub354\n\nSeq2Seq \ub124\ud2b8\uc6cc\ud06c\uc758 \uc778\ucf54\ub354\ub294 \uc785\ub825 \ubb38\uc7a5\uc758 \ubaa8\ub4e0 \ub2e8\uc5b4\uc5d0 \ub300\ud574 \uc5b4\ub5a4 \uac12\uc744\n\ucd9c\ub825\ud558\ub294 RNN\uc785\ub2c8\ub2e4. \ubaa8\ub4e0 \uc785\ub825 \ub2e8\uc5b4\uc5d0 \ub300\ud574 \uc778\ucf54\ub354\ub294 \ubca1\ud130\uc640\n\uc740\ub2c9 \uc0c1\ud0dc\ub97c \ucd9c\ub825\ud558\uace0 \ub2e4\uc74c \uc785\ub825 \ub2e8\uc5b4\ub97c \uc704\ud574 \uadf8 \uc740\ub2c9 \uc0c1\ud0dc\ub97c \uc0ac\uc6a9\ud569\ub2c8\ub2e4.\n\n.. figure:: /_static/img/seq-seq-images/encoder-network.png\n   :alt:\n\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class EncoderRNN(nn.Module):\n    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n        super(EncoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n\n        self.embedding = nn.Embedding(input_size, hidden_size)\n        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n        self.dropout = nn.Dropout(dropout_p)\n\n    def forward(self, input):\n        embedded = self.dropout(self.embedding(input))\n        output, hidden = self.gru(embedded)\n        return output, hidden"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \ub514\ucf54\ub354\n\n\ub514\ucf54\ub354\ub294 \uc778\ucf54\ub354 \ucd9c\ub825 \ubca1\ud130\ub97c \ubc1b\uc544\uc11c \ubc88\uc5ed\uc744 \uc0dd\uc131\ud558\uae30 \uc704\ud55c \ub2e8\uc5b4 \uc2dc\ud000\uc2a4\ub97c\n\ucd9c\ub825\ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### \uac04\ub2e8\ud55c \ub514\ucf54\ub354\n\n\uac00\uc7a5 \uac04\ub2e8\ud55c Seq2Seq \ub514\ucf54\ub354\ub294 \uc778\ucf54\ub354\uc758 \ub9c8\uc9c0\ub9c9 \ucd9c\ub825\ub9cc\uc744 \uc774\uc6a9\ud569\ub2c8\ub2e4.\n\uc774 \ub9c8\uc9c0\ub9c9 \ucd9c\ub825\uc740 \uc804\uccb4 \uc2dc\ud000\uc2a4\uc5d0\uc11c \ubb38\ub9e5\uc744 \uc778\ucf54\ub4dc\ud558\uae30 \ub54c\ubb38\uc5d0\n*\ubb38\ub9e5 \ubca1\ud130(context vector)* \ub85c \ubd88\ub9bd\ub2c8\ub2e4. \uc774 \ubb38\ub9e5 \ubca1\ud130\ub294 \ub514\ucf54\ub354\uc758 \ucd08\uae30 \uc740\ub2c9 \uc0c1\ud0dc\ub85c\n\uc0ac\uc6a9 \ub429\ub2c8\ub2e4.\n\n\ub514\ucf54\ub529\uc758 \ub9e4 \ub2e8\uacc4\uc5d0\uc11c \ub514\ucf54\ub354\uc5d0\uac8c \uc785\ub825 \ud1a0\ud070\uacfc \uc740\ub2c9 \uc0c1\ud0dc\uac00 \uc8fc\uc5b4\uc9d1\ub2c8\ub2e4.\n\ucd08\uae30 \uc785\ub825 \ud1a0\ud070\uc740 \ubb38\uc790\uc5f4-\uc2dc\uc791 (start-of-string) ``<SOS>`` \ud1a0\ud070\uc774\uace0,\n\uccab \uc740\ub2c9 \uc0c1\ud0dc\ub294 \ubb38\ub9e5 \ubca1\ud130(\uc778\ucf54\ub354\uc758 \ub9c8\uc9c0\ub9c9 \uc740\ub2c9 \uc0c1\ud0dc) \uc785\ub2c8\ub2e4.\n\n.. figure:: /_static/img/seq-seq-images/decoder-network.png\n   :alt:\n\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class DecoderRNN(nn.Module):\n    def __init__(self, hidden_size, output_size):\n        super(DecoderRNN, self).__init__()\n        self.embedding = nn.Embedding(output_size, hidden_size)\n        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n        self.out = nn.Linear(hidden_size, output_size)\n\n    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n        batch_size = encoder_outputs.size(0)\n        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n        decoder_hidden = encoder_hidden\n        decoder_outputs = []\n\n        for i in range(MAX_LENGTH):\n            decoder_output, decoder_hidden  = self.forward_step(decoder_input, decoder_hidden)\n            decoder_outputs.append(decoder_output)\n\n            if target_tensor is not None:\n                # Teacher forcing \ud3ec\ud568: \ubaa9\ud45c\ub97c \ub2e4\uc74c \uc785\ub825\uc73c\ub85c \uc804\ub2ec\n                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n            else:\n                # Teacher forcing \ubbf8\ud3ec\ud568: \uc790\uc2e0\uc758 \uc608\uce21\uc744 \ub2e4\uc74c \uc785\ub825\uc73c\ub85c \uc0ac\uc6a9\n                _, topi = decoder_output.topk(1)\n                decoder_input = topi.squeeze(-1).detach()  # \uc785\ub825\uc73c\ub85c \uc0ac\uc6a9\ud560 \ubd80\ubd84\uc744 \ud788\uc2a4\ud1a0\ub9ac\uc5d0\uc11c \ubd84\ub9ac\n\n        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n        return decoder_outputs, decoder_hidden, None   # \ud559\uc2b5 \ub8e8\ud504\uc758 \uc77c\uad00\uc131 \uc720\uc9c0\ub97c \uc704\ud574 `None` \uc744 \ucd94\uac00\ub85c \ubc18\ud658\n\n    def forward_step(self, input, hidden):\n        output = self.embedding(input)\n        output = F.relu(output)\n        output, hidden = self.gru(output, hidden)\n        output = self.out(output)\n        return output, hidden"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc774 \ubaa8\ub378\uc758 \uacb0\uacfc\ub97c \ud559\uc2b5\ud558\uace0 \uad00\ucc30\ud558\ub294 \uac83\uc744 \uad8c\uc7a5\ud558\uc9c0\ub9cc,\n\uacf5\uac04\uc744 \uc808\uc57d\ud558\uae30 \uc704\ud574 \ucd5c\uc885 \ubaa9\uc801\uc9c0\ub85c \ubc14\ub85c \uc774\ub3d9\ud574\uc11c\nAttention \uba54\ucee4\ub2c8\uc998\uc744 \uc18c\uac1c \ud560 \uac83\uc785\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Attention \ub514\ucf54\ub354\n\n\ubb38\ub9e5 \ubca1\ud130\ub9cc \uc778\ucf54\ub354\uc640 \ub514\ucf54\ub354 \uc0ac\uc774\ub85c \uc804\ub2ec \ub41c\ub2e4\uba74, \ub2e8\uc77c \ubca1\ud130\uac00 \uc804\uccb4 \ubb38\uc7a5\uc744\n\uc778\ucf54\ub529 \ud574\uc57c\ud558\ub294 \ubd80\ub2f4\uc744 \uac00\uc9c0\uac8c \ub429\ub2c8\ub2e4.\n\nAttention\uc740 \ub514\ucf54\ub354 \ub124\ud2b8\uc6cc\ud06c\uac00 \uc790\uae30 \ucd9c\ub825\uc758 \ubaa8\ub4e0 \ub2e8\uacc4\uc5d0\uc11c \uc778\ucf54\ub354 \ucd9c\ub825\uc758\n\ub2e4\ub978 \ubd80\ubd84\uc5d0 \"\uc9d1\uc911\" \ud560 \uc218 \uc788\uac8c \ud569\ub2c8\ub2e4. \uccab\uc9f8 *Attention \uac00\uc911\uce58* \uc758 \uc138\ud2b8\ub97c\n\uacc4\uc0b0\ud569\ub2c8\ub2e4. \uc774\uac83\uc740 \uac00\uc911\uce58 \uc870\ud569\uc744 \ub9cc\ub4e4\uae30 \uc704\ud574\uc11c \uc778\ucf54\ub354 \ucd9c\ub825 \ubca1\ud130\uc640\n\uacf1\ud574\uc9d1\ub2c8\ub2e4. \uadf8 \uacb0\uacfc(\ucf54\ub4dc\uc5d0\uc11c ``attn_applied``)\ub294 \uc785\ub825 \uc2dc\ud000\uc2a4\uc758\n\ud2b9\uc815 \ubd80\ubd84\uc5d0 \uad00\ud55c \uc815\ubcf4\ub97c \ud3ec\ud568\ud574\uc57c\ud558\uace0 \ub530\ub77c\uc11c \ub514\ucf54\ub354\uac00 \uc54c\ub9de\uc740 \ucd9c\ub825\n\ub2e8\uc5b4\ub97c \uc120\ud0dd\ud558\ub294 \uac83\uc744 \ub3c4\uc640\uc90d\ub2c8\ub2e4.\n\n.. figure:: https://i.imgur.com/1152PYf.png\n   :alt:\n\n\uc5b4\ud150\uc158 \uac00\uc911\uce58 \uacc4\uc0b0\uc740 \ub514\ucf54\ub354\uc758 \uc785\ub825 \ubc0f \uc740\ub2c9 \uc0c1\ud0dc\ub97c \uc785\ub825\uc73c\ub85c\n\uc0ac\uc6a9\ud558\ub294 \ub2e4\ub978 feed-forwad \uacc4\uce35\uc778 ``attn`` \uc73c\ub85c \uc218\ud589\ub429\ub2c8\ub2e4.\n\ud559\uc2b5 \ub370\uc774\ud130\uc5d0\ub294 \ubaa8\ub4e0 \ud06c\uae30\uc758 \ubb38\uc7a5\uc774 \uc788\uae30 \ub54c\ubb38\uc5d0 \uc774 \uacc4\uce35\uc744 \uc2e4\uc81c\ub85c\n\ub9cc\ub4e4\uace0 \ud559\uc2b5\uc2dc\ud0a4\ub824\uba74 \uc801\uc6a9 \ud560 \uc218 \uc788\ub294 \ucd5c\ub300 \ubb38\uc7a5 \uae38\uc774 (\uc778\ucf54\ub354 \ucd9c\ub825\uc744 \uc704\ud55c \uc785\ub825 \uae38\uc774)\ub97c\n\uc120\ud0dd\ud574\uc57c \ud569\ub2c8\ub2e4. \ucd5c\ub300 \uae38\uc774\uc758 \ubb38\uc7a5\uc740 \ubaa8\ub4e0 Attention \uac00\uc911\uce58\ub97c \uc0ac\uc6a9\ud558\uc9c0\ub9cc\n\ub354 \uc9e7\uc740 \ubb38\uc7a5\uc740 \ucc98\uc74c \uba87 \uac1c\ub9cc \uc0ac\uc6a9\ud569\ub2c8\ub2e4.\n\n.. figure:: /_static/img/seq-seq-images/attention-decoder-network.png\n   :alt:\n\n\n\ubd80\uac00\uc801 \uc5b4\ud150\uc158(Additive Attention)\uc774\ub77c\uace0\ub3c4 \uc54c\ub824\uc9c4 \ubc14\ub2e4\ub098\uc6b0 \uc5b4\ud150\uc158(Bahdanau\nAttention)\uc740 \uae30\uacc4 \ubc88\uc5ed \uc791\uc5c5\uacfc \uac19\uc740 \uc2dc\ud000\uc2a4-\ud22c-\uc2dc\ud000\uc2a4 \ubaa8\ub378\uc5d0\uc11c \uc77c\ubc18\uc801\uc73c\ub85c\n\uc0ac\uc6a9\ud558\ub294 \uc5b4\ud150\uc158 \uae30\ubc95(mechanism)\uc785\ub2c8\ub2e4. \uc774 \uc5b4\ud150\uc158 \uae30\ubc95\uc740 Bahdanau et al.\uc758 \ub17c\ubb38\uc778\n[Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/pdf/1409.0473.pdf)_\n\uc5d0\uc11c \uc18c\uac1c\ub418\uc5c8\uc2b5\ub2c8\ub2e4. \uc774 \uc5b4\ud150\uc158 \uae30\ubc95\uc740 \ud559\uc2b5\ub41c \uc815\ub82c \ubaa8\ub378(learned alignment model)\uc744\n\uc0ac\uc6a9\ud558\uc5ec \uc778\ucf54\ub354\uc640 \ub514\ucf54\ub354\uc758 \uc740\ub2c9 \uc0c1\ud0dc(hidden state) \uac04\uc758 \uc5b4\ud150\uc158 \uc810\uc218\ub97c \uacc4\uc0b0\ud569\ub2c8\ub2e4.\n\uc774\ub294 \uc815\ub82c\ub41c \uc5b4\ud150\uc158 \uc810\uc218\ub97c \uacc4\uc0b0\ud558\uae30 \uc704\ud574 feed-forward \uc2e0\uacbd\ub9dd\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4.\n\n\ub610\ub294, \ub514\ucf54\ub354\uc758 \uc740\ub2c9 \uc0c1\ud0dc\uc640 \uc778\ucf54\ub354\uc758 \uc740\ub2c9 \uc0c1\ud0dc \uc0ac\uc774\uc758 \uc5b4\ud150\uc158 \uc810\uc218\ub97c Dot-Product\ub85c\n\uacc4\uc0b0\ud558\ub294 \ub8e8\uc639 \uc5b4\ud150\uc158(Luong Attention)\uacfc \uac19\uc740 \ub2e4\ub978 \uc5b4\ud150\uc158 \uae30\ubc95\ub4e4\uc744 \uc0ac\uc6a9\ud560 \uc218\ub3c4 \uc788\uc2b5\ub2c8\ub2e4.\n\uc774\ub294 \ubc14\ub2e4\ub098\uc6b0 \uc5b4\ud150\uc158(Bahdanau Attention)\uc5d0\uc11c \uc0ac\uc6a9\ud558\ub294 \ube44\uc120\ud615 \ubcc0\ud658(non-linear transformation)\uc744\n\uc0ac\uc6a9\ud558\uc9c0\ub294 \uc54a\uc2b5\ub2c8\ub2e4.\n\n\uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc5d0\uc11c\ub294 \ubc14\ub2e4\ub098\uc6b0 \uc5b4\ud150\uc158(Bahdanau Attention)\uc744 \uc0ac\uc6a9\ud560 \uac83\uc785\ub2c8\ub2e4. \ud558\uc9c0\ub9cc \uc774\ub97c\n\ub8e8\uc639 \uc5b4\ud150\uc158(Luong Attention) \uae30\ubc95\uc73c\ub85c \ubcc0\uacbd\ud574\ubcf4\ub294 \uac83\ub3c4 \uc88b\uc740 \uc5f0\uc2b5\uc774 \ub420 \uac83\uc785\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class BahdanauAttention(nn.Module):\n    def __init__(self, hidden_size):\n        super(BahdanauAttention, self).__init__()\n        self.Wa = nn.Linear(hidden_size, hidden_size)\n        self.Ua = nn.Linear(hidden_size, hidden_size)\n        self.Va = nn.Linear(hidden_size, 1)\n\n    def forward(self, query, keys):\n        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n        scores = scores.squeeze(2).unsqueeze(1)\n\n        weights = F.softmax(scores, dim=-1)\n        context = torch.bmm(weights, keys)\n\n        return context, weights\n\nclass AttnDecoderRNN(nn.Module):\n    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n        super(AttnDecoderRNN, self).__init__()\n        self.embedding = nn.Embedding(output_size, hidden_size)\n        self.attention = BahdanauAttention(hidden_size)\n        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n        self.out = nn.Linear(hidden_size, output_size)\n        self.dropout = nn.Dropout(dropout_p)\n\n    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n        batch_size = encoder_outputs.size(0)\n        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n        decoder_hidden = encoder_hidden\n        decoder_outputs = []\n        attentions = []\n\n        for i in range(MAX_LENGTH):\n            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n                decoder_input, decoder_hidden, encoder_outputs\n            )\n            decoder_outputs.append(decoder_output)\n            attentions.append(attn_weights)\n\n            if target_tensor is not None:\n                # Teacher forcing \ud3ec\ud568: \ubaa9\ud45c\ub97c \ub2e4\uc74c \uc785\ub825\uc73c\ub85c \uc804\ub2ec\n                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n            else:\n                # Teacher forcing \ubbf8\ud3ec\ud568: \uc790\uc2e0\uc758 \uc608\uce21\uc744 \ub2e4\uc74c \uc785\ub825\uc73c\ub85c \uc0ac\uc6a9\n                _, topi = decoder_output.topk(1)\n                decoder_input = topi.squeeze(-1).detach()  # \uc785\ub825\uc73c\ub85c \uc0ac\uc6a9\ud560 \ubd80\ubd84\uc744 \ud788\uc2a4\ud1a0\ub9ac\uc5d0\uc11c \ubd84\ub9ac\n\n        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n        attentions = torch.cat(attentions, dim=1)\n\n        return decoder_outputs, decoder_hidden, attentions\n\n\n    def forward_step(self, input, hidden, encoder_outputs):\n        embedded =  self.dropout(self.embedding(input))\n\n        query = hidden.permute(1, 0, 2)\n        context, attn_weights = self.attention(query, encoder_outputs)\n        input_gru = torch.cat((embedded, context), dim=2)\n\n        output, hidden = self.gru(input_gru, hidden)\n        output = self.out(output)\n\n        return output, hidden, attn_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>\uae38\uc774 \uc81c\ud55c\uc744 \ud574\uacb0\ud558\uae30 \uc704\ud574 \uc0c1\ub300\uc801 \uc704\uce58 \uc811\uadfc(relative position approach)\n   \ubc29\uc2dd\uc744 \uc0ac\uc6a9\ud558\ub294 \ub2e4\ub978 \ud615\ud0dc\uc758 \uc5b4\ud150\uc158 \ubc29\uc2dd\ub4e4\ub3c4 \uc788\uc2b5\ub2c8\ub2e4.\n   [Effective Approaches to Attention-based Neural Machine Translation](https://arxiv.org/abs/1508.04025)_\n   \uc5d0\uc11c \"local attention\" \uc5d0 \ub300\ud574 \uc77d\uc5b4\ubcf4\uc138\uc694.</p></div>\n\n## \ud559\uc2b5\n\n### \ud559\uc2b5 \ub370\uc774\ud130 \uc900\ube44\n\n\ud559\uc2b5\uc744 \uc704\ud574\uc11c, \uac01 \uc30d\ub9c8\ub2e4 \uc785\ub825 Tensor(\uc785\ub825 \ubb38\uc7a5\uc758 \ub2e8\uc5b4 \uc8fc\uc18c)\uc640\n\ubaa9\ud45c Tensor(\ubaa9\ud45c \ubb38\uc7a5\uc758 \ub2e8\uc5b4 \uc8fc\uc18c)\uac00 \ud544\uc694\ud569\ub2c8\ub2e4. \uc774 \ubca1\ud130\ub4e4\uc744\n\uc0dd\uc131\ud558\ub294 \ub3d9\uc548 \ub450 \uc2dc\ud000\uc2a4\uc5d0 EOS \ud1a0\ud070\uc744 \ucd94\uac00 \ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def indexesFromSentence(lang, sentence):\n    return [lang.word2index[word] for word in sentence.split(' ')]\n\ndef tensorFromSentence(lang, sentence):\n    indexes = indexesFromSentence(lang, sentence)\n    indexes.append(EOS_token)\n    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n\ndef tensorsFromPair(pair):\n    input_tensor = tensorFromSentence(input_lang, pair[0])\n    target_tensor = tensorFromSentence(output_lang, pair[1])\n    return (input_tensor, target_tensor)\n\ndef get_dataloader(batch_size):\n    input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n\n    n = len(pairs)\n    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n\n    for idx, (inp, tgt) in enumerate(pairs):\n        inp_ids = indexesFromSentence(input_lang, inp)\n        tgt_ids = indexesFromSentence(output_lang, tgt)\n        inp_ids.append(EOS_token)\n        tgt_ids.append(EOS_token)\n        input_ids[idx, :len(inp_ids)] = inp_ids\n        target_ids[idx, :len(tgt_ids)] = tgt_ids\n\n    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n                               torch.LongTensor(target_ids).to(device))\n\n    train_sampler = RandomSampler(train_data)\n    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n    return input_lang, output_lang, train_dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \ubaa8\ub378 \ud559\uc2b5\n\n\ud559\uc2b5\uc744 \uc704\ud574\uc11c \uc778\ucf54\ub354\uc5d0 \uc785\ub825 \ubb38\uc7a5\uc744 \ub123\uace0 \ubaa8\ub4e0 \ucd9c\ub825\uacfc \ucd5c\uc2e0 \uc740\ub2c9 \uc0c1\ud0dc\ub97c\n\ucd94\uc801\ud569\ub2c8\ub2e4. \uadf8\ub7f0 \ub2e4\uc74c \ub514\ucf54\ub354\uc5d0 \uccab \ubc88\uc9f8 \uc785\ub825\uc73c\ub85c ``<SOS>`` \ud1a0\ud070\uacfc\n\uc778\ucf54\ub354\uc758 \ub9c8\uc9c0\ub9c9 \uc740\ub2c9 \uc0c1\ud0dc\uac00 \uccab \ubc88\uc9f8 \uc740\ub2c9 \uc0c1\ud0dc\ub85c \uc81c\uacf5\ub429\ub2c8\ub2e4.\n\n\"Teacher forcing\"\uc740 \ub2e4\uc74c \uc785\ub825\uc73c\ub85c \ub514\ucf54\ub354\uc758 \uc608\uce21\uc744 \uc0ac\uc6a9\ud558\ub294 \ub300\uc2e0\n\uc2e4\uc81c \ubaa9\ud45c \ucd9c\ub825\uc744 \ub2e4\uc74c \uc785\ub825\uc73c\ub85c \uc0ac\uc6a9\ud558\ub294 \ucee8\uc149\uc785\ub2c8\ub2e4.\n\"Teacher forcing\"\uc744 \uc0ac\uc6a9\ud558\uba74 \uc218\ub834\uc774 \ube68\ub9ac\ub418\uc9c0\ub9cc [\ud559\uc2b5\ub41c \ub124\ud2b8\uc6cc\ud06c\uac00\n\uc798\ubabb \uc0ac\uc6a9\ub420 \ub54c \ubd88\uc548\uc815\uc131\uc744 \ubcf4\uc785\ub2c8\ub2e4.](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.378.4095&rep=rep1&type=pdf)_.\n\nTeacher-forced \ub124\ud2b8\uc6cc\ud06c\uc758 \ucd9c\ub825\uc774 \uc77c\uad00\ub41c \ubb38\ubc95\uc73c\ub85c \uc77d\uc9c0\ub9cc \uc815\ud655\ud55c\n\ubc88\uc5ed\uacfc\ub294 \uac70\ub9ac\uac00 \uba40\ub2e4\ub294 \uac83\uc744 \ubcfc \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc9c1\uad00\uc801\uc73c\ub85c \ucd9c\ub825 \ubb38\ubc95\uc744\n\ud45c\ud604\ud558\ub294 \ubc95\uc744 \ubc30\uc6b0\uace0 \uad50\uc0ac\uac00 \ucc98\uc74c \uba87 \ub2e8\uc5b4\ub97c \ub9d0\ud558\uba74 \uc758\ubbf8\ub97c \"\uc120\ud0dd\" \ud560 \uc218 \uc788\uc9c0\ub9cc,\n\ubc88\uc5ed\uc5d0\uc11c \ucc98\uc74c\uc73c\ub85c \ubb38\uc7a5\uc744 \ub9cc\ub4dc\ub294 \ubc95\uc740 \uc798 \ubc30\uc6b0\uc9c0 \ubabb\ud569\ub2c8\ub2e4.\n\nPyTorch\uc758 autograd \uac00 \uc81c\uacf5\ud558\ub294 \uc790\uc720 \ub355\ubd84\uc5d0 \uac04\ub2e8\ud55c If \ubb38\uc73c\ub85c\nTeacher Forcing\uc744 \uc0ac\uc6a9\ud560\uc9c0 \uc544\ub2c8\uba74 \uc0ac\uc6a9\ud558\uc9c0 \uc54a\uc744\uc9c0\ub97c \uc120\ud0dd\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\ub354 \ub9ce\uc774 \uc0ac\uc6a9\ud558\ub824\uba74 ``teacher_forcing_ratio`` \ub97c \ud655\uc778\ud558\uc2ed\uc2dc\uc624.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n          decoder_optimizer, criterion):\n\n    total_loss = 0\n    for data in dataloader:\n        input_tensor, target_tensor = data\n\n        encoder_optimizer.zero_grad()\n        decoder_optimizer.zero_grad()\n\n        encoder_outputs, encoder_hidden = encoder(input_tensor)\n        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n\n        loss = criterion(\n            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n            target_tensor.view(-1)\n        )\n        loss.backward()\n\n        encoder_optimizer.step()\n        decoder_optimizer.step()\n\n        total_loss += loss.item()\n\n    return total_loss / len(dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc774\uac83\uc740 \ud604\uc7ac \uc2dc\uac04\uacfc \uc9c4\ud589\ub960%\uc744 \uace0\ub824\ud574 \uacbd\uacfc\ub41c \uc2dc\uac04\uacfc \ub0a8\uc740 \uc608\uc0c1\n\uc2dc\uac04\uc744 \ucd9c\ub825\ud558\ub294 \ud5ec\ud37c \ud568\uc218\uc785\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import time\nimport math\n\ndef asMinutes(s):\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\ndef timeSince(since, percent):\n    now = time.time()\n    s = now - since\n    es = s / (percent)\n    rs = es - s\n    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc804\uccb4 \ud559\uc2b5 \uacfc\uc815\uc740 \ub2e4\uc74c\uacfc \uac19\uc2b5\ub2c8\ub2e4:\n\n-  \ud0c0\uc774\uba38 \uc2dc\uc791\n-  optimizers\uc640 criterion \ucd08\uae30\ud654\n-  \ud559\uc2b5 \uc30d\uc758 \uc138\ud2b8 \uc0dd\uc131\n-  \ub3c4\uc2dd\ud654\ub97c \uc704\ud55c \ube48 \uc190\uc2e4 \ubc30\uc5f4 \uc2dc\uc791\n\n\uadf8\ub7f0 \ub2e4\uc74c \uc6b0\ub9ac\ub294 \uc5ec\ub7ec \ubc88 ``train`` \uc744 \ud638\ucd9c\ud558\uba70 \ub54c\ub85c\ub294 \uc9c4\ud589\ub960\n(\uc608\uc81c\uc758 %, \ud604\uc7ac\uae4c\uc9c0\uc758 \uc608\uc0c1 \uc2dc\uac04)\uacfc \ud3c9\uade0 \uc190\uc2e4\uc744 \ucd9c\ub825\ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n               print_every=100, plot_every=100):\n    start = time.time()\n    plot_losses = []\n    print_loss_total = 0  # Reset every print_every\n    plot_loss_total = 0  # Reset every plot_every\n\n    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n    criterion = nn.NLLLoss()\n\n    for epoch in range(1, n_epochs + 1):\n        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n        print_loss_total += loss\n        plot_loss_total += loss\n\n        if epoch % print_every == 0:\n            print_loss_avg = print_loss_total / print_every\n            print_loss_total = 0\n            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n\n        if epoch % plot_every == 0:\n            plot_loss_avg = plot_loss_total / plot_every\n            plot_losses.append(plot_loss_avg)\n            plot_loss_total = 0\n\n    showPlot(plot_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \uacb0\uacfc \ub3c4\uc2dd\ud654\n\nmatplotlib\ub85c \ud559\uc2b5 \uc911\uc5d0 \uc800\uc7a5\ub41c \uc190\uc2e4 \uac12 ``plot_losses`` \uc758 \ubc30\uc5f4\uc744\n\uc0ac\uc6a9\ud558\uc5ec \ub3c4\uc2dd\ud654\ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nplt.switch_backend('agg')\nimport matplotlib.ticker as ticker\nimport numpy as np\n\ndef showPlot(points):\n    plt.figure()\n    fig, ax = plt.subplots()\n    # \uc8fc\uae30\uc801\uc778 \uac04\uaca9\uc73c\ub85c \uc774 locator\uac00 tick\uc744 \uc124\uc815\n    loc = ticker.MultipleLocator(base=0.2)\n    ax.yaxis.set_major_locator(loc)\n    plt.plot(points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud3c9\uac00\n\n\ud3c9\uac00\ub294 \ub300\ubd80\ubd84 \ud559\uc2b5\uacfc \ub3d9\uc77c\ud558\uc9c0\ub9cc \ubaa9\ud45c\uac00 \uc5c6\uc73c\ubbc0\ub85c \uac01 \ub2e8\uacc4\ub9c8\ub2e4 \ub514\ucf54\ub354\uc758\n\uc608\uce21\uc744 \ub418\ub3cc\ub824 \uc804\ub2ec\ud569\ub2c8\ub2e4.\n\ub2e8\uc5b4\ub97c \uc608\uce21\ud560 \ub54c\ub9c8\ub2e4 \uadf8 \ub2e8\uc5b4\ub97c \ucd9c\ub825 \ubb38\uc790\uc5f4\uc5d0 \ucd94\uac00\ud569\ub2c8\ub2e4.\n\ub9cc\uc57d EOS \ud1a0\ud070\uc744 \uc608\uce21\ud558\uba74 \uac70\uae30\uc5d0\uc11c \uba48\ucda5\ub2c8\ub2e4.\n\ub098\uc911\uc5d0 \ub3c4\uc2dd\ud654\ub97c \uc704\ud574\uc11c \ub514\ucf54\ub354\uc758 Attention \ucd9c\ub825\uc744 \uc800\uc7a5\ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n    with torch.no_grad():\n        input_tensor = tensorFromSentence(input_lang, sentence)\n\n        encoder_outputs, encoder_hidden = encoder(input_tensor)\n        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n\n        _, topi = decoder_outputs.topk(1)\n        decoded_ids = topi.squeeze()\n\n        decoded_words = []\n        for idx in decoded_ids:\n            if idx.item() == EOS_token:\n                decoded_words.append('<EOS>')\n                break\n            decoded_words.append(output_lang.index2word[idx.item()])\n    return decoded_words, decoder_attn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud559\uc2b5 \uc138\ud2b8\uc5d0 \uc788\ub294 \uc784\uc758\uc758 \ubb38\uc7a5\uc73c\ub85c \ud3c9\uac00\ud55c \ub2e4\uc74c, \uc785\ub825(input), \ubaa9\ud45c(target)\n\ubc0f \ucd9c\ub825(output) \uac12\ub4e4\uc744 \ud45c\uc2dc\ud558\uc5ec \uc8fc\uad00\uc801\uc73c\ub85c \ud488\uc9c8\uc5d0 \ub300\ud574 \ud310\ub2e8\ud574\ubcfc \uc218 \uc788\uc2b5\ub2c8\ub2e4:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n    for i in range(n):\n        pair = random.choice(pairs)\n        print('>', pair[0])\n        print('=', pair[1])\n        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n        output_sentence = ' '.join(output_words)\n        print('<', output_sentence)\n        print('')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud559\uc2b5\uacfc \ud3c9\uac00\n\n\uc774\ub7ec\ud55c \ubaa8\ub4e0 \ud5ec\ud37c \ud568\uc218\ub97c \uc774\uc6a9\ud574\uc11c (\ucd94\uac00 \uc791\uc5c5\ucc98\ub7fc \ubcf4\uc774\uc9c0\ub9cc \uc5ec\ub7ec \uc2e4\ud5d8\uc744\n\ub354 \uc27d\uac8c \uc218\ud589 \ud560 \uc218 \uc788\uc74c) \uc2e4\uc81c\ub85c \ub124\ud2b8\uc6cc\ud06c\ub97c \ucd08\uae30\ud654\ud558\uace0 \ud559\uc2b5\uc744\n\uc2dc\uc791\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n\uc785\ub825 \ubb38\uc7a5\uc774 \ub9ce\uc774 \ud544\ud130\ub9c1\ub418\uc5c8\uc74c\uc744 \uae30\uc5b5\ud558\uc2ed\uc2dc\uc624. \uc774 \uc791\uc740 \ub370\uc774\ud130 \uc138\ud2b8\uc758\n\uacbd\uc6b0 256 \ud06c\uae30\uc758 \uc740\ub2c9 \ub178\ub4dc(hidden node)\uc640 \ub2e8\uc77c GRU \uacc4\uce35 \uac19\uc740 \uc0c1\ub300\uc801\uc73c\ub85c \uc791\uc740\n\ub124\ud2b8\uc6cc\ud06c\ub97c \uc0ac\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. MacBook CPU\uc5d0\uc11c \uc57d 40\ubd84 \ud6c4\uc5d0\n\ud569\ub9ac\uc801\uc778 \uacb0\uacfc\ub97c \uc5bb\uc744 \uac83\uc785\ub2c8\ub2e4.\n\n.. Note::\n   \uc774 \ub178\ud2b8\ubd81\uc744 \uc2e4\ud589\ud558\uba74 \ud559\uc2b5, \ucee4\ub110 \uc911\ub2e8, \ud3c9\uac00\ub97c \ud560 \uc218 \uc788\uace0 \ub098\uc911\uc5d0\n   \uc774\uc5b4\uc11c \ud559\uc2b5\uc744 \ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc778\ucf54\ub354\uc640 \ub514\ucf54\ub354\uac00 \ucd08\uae30\ud654 \ub41c \ud589\uc744\n   \uc8fc\uc11d \ucc98\ub9ac\ud558\uace0 ``trainIters`` \ub97c \ub2e4\uc2dc \uc2e4\ud589\ud558\uc2ed\uc2dc\uc624.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "hidden_size = 128\nbatch_size = 32\n\ninput_lang, output_lang, train_dataloader = get_dataloader(batch_size)\n\nencoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\ndecoder = AttnDecoderRNN(hidden_size, output_lang.n_words).to(device)\n\ntrain(train_dataloader, encoder, decoder, 80, print_every=5, plot_every=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub4dc\ub86d\uc544\uc6c3(dropout) \ub808\uc774\uc5b4\ub4e4\uc744 \ud3c9\uac00 (``eval``) \ubaa8\ub4dc\ub85c \uc124\uc815\ud569\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "encoder.eval()\ndecoder.eval()\nevaluateRandomly(encoder, decoder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Attention \uc2dc\uac01\ud654\n\nAttention \uba54\ucee4\ub2c8\uc998\uc758 \uc720\uc6a9\ud55c \uc18d\uc131\uc740 \ud558\ub098\ub294 \ud574\uc11d \uac00\ub2a5\uc131\uc774 \ub192\uc740 \ucd9c\ub825\uc785\ub2c8\ub2e4.\n\uc785\ub825 \uc2dc\ud000\uc2a4\uc758 \ud2b9\uc815 \uc778\ucf54\ub354 \ucd9c\ub825\uc5d0 \uac00\uc911\uce58\ub97c \ubd80\uc5ec\ud558\ub294 \ub370 \uc0ac\uc6a9\ub418\ubbc0\ub85c\n\uac01 \uc2dc\uac04 \ub2e8\uacc4\uc5d0\uc11c \ub124\ud2b8\uc6cc\ud06c\uac00 \uac00\uc7a5 \uc9d1\uc911\ub418\ub294 \uc704\uce58\ub97c \ud30c\uc545\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\nAttention \ucd9c\ub825\uc744 \ud589\ub82c\ub85c \ud45c\uc2dc\ud558\uae30 \uc704\ud574\uc11c\ub294 ``plt.matshow(attentions)`` \uc744\n\uadf8\ub0e5 \uc2e4\ud589\ud574\ub3c4 \ub429\ub2c8\ub2e4. \ud558\uc9c0\ub9cc \uc880 \ub354 \ub098\uc740 \uc2dc\uac01\ud654\ub97c \uc704\ud574 \ucd95(axis)\uacfc \ub77c\ubca8(label)\uc744\n\ucd94\uac00\ud558\ub294 \uc57d\uac04\uc758 \uc791\uc5c5\uc744 \ub354 \ud574\ubcf4\uaca0\uc2b5\ub2c8\ub2e4:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def showAttention(input_sentence, output_words, attentions):\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    cax = ax.matshow(attentions.cpu().numpy(), cmap='bone')\n    fig.colorbar(cax)\n\n    # \ucd95 \uc124\uc815\n    ax.set_xticklabels([''] + input_sentence.split(' ') +\n                       ['<EOS>'], rotation=90)\n    ax.set_yticklabels([''] + output_words)\n\n    # \ub9e4 \ud2f1\ub9c8\ub2e4 \ub77c\ubca8 \ubcf4\uc5ec\uc8fc\uae30\n    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n\n    plt.show()\n\n\ndef evaluateAndShowAttention(input_sentence):\n    output_words, attentions = evaluate(encoder, decoder, input_sentence, input_lang, output_lang)\n    print('input =', input_sentence)\n    print('output =', ' '.join(output_words))\n    showAttention(input_sentence, output_words, attentions[0, :len(output_words), :])\n\n\nevaluateAndShowAttention('il n est pas aussi grand que son pere')\n\nevaluateAndShowAttention('je suis trop fatigue pour conduire')\n\nevaluateAndShowAttention('je suis desole si c est une question idiote')\n\nevaluateAndShowAttention('je suis reellement fiere de vous')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \uc5f0\uc2b5\n\n-  \ub2e4\ub978 \ub370\uc774\ud130 \uc14b\uc744 \uc2dc\ub3c4\ud574 \ubcf4\uc2ed\uc2dc\uc624\n\n   -  \ub2e4\ub978 \uc5b8\uc5b4\uc30d\n   -  \uc0ac\ub78c \u2192 \uae30\uacc4 (e.g. IOT \uba85\ub839\uc5b4)\n   -  \ucc44\ud305 \u2192 \uc751\ub2f5\n   -  \uc9c8\ubb38 \u2192 \ub2f5\ubcc0\n\n-  ``word2vec`` \ub610\ub294 ``GloVe`` \uac19\uc740 \ubbf8\ub9ac \ud559\uc2b5\ub41c word embedding \uc73c\ub85c\n   embedding \uc744 \uad50\uccb4\ud558\uc2ed\uc2dc\uc624\n\n-  \ub354 \ub9ce\uc740 \ub808\uc774\uc5b4, \uc740\ub2c9 \uc720\ub2db, \ub354 \ub9ce\uc740 \ubb38\uc7a5\uc744 \uc0ac\uc6a9\ud558\uc2ed\uc2dc\uc624.\n   \ud559\uc2b5 \uc2dc\uac04\uacfc \uacb0\uacfc\ub97c \ube44\uad50\ud574 \ubcf4\uc2ed\uc2dc\uc624\n-  \ub9cc\uc57d \uac19\uc740 \uad6c\ubb38 \ub450\uac1c\uc758 \uc30d\uc73c\ub85c \ub41c \ubc88\uc5ed \ud30c\uc77c\uc744 \uc774\uc6a9\ud55c\ub2e4\uba74,\n   (``I am test \\t I am test``), \uc774\uac83\uc744 \uc624\ud1a0\uc778\ucf54\ub354\ub85c\n   \uc0ac\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n   \uc774\uac83\uc744 \uc2dc\ub3c4\ud574 \ubcf4\uc2ed\uc2dc\uc624:\n\n   -  \uc624\ud1a0\uc778\ucf54\ub354 \ud559\uc2b5\n   -  \uc778\ucf54\ub354 \ub124\ud2b8\uc6cc\ud06c \uc800\uc7a5\ud558\uae30\n   -  \uadf8 \uc0c1\ud0dc\uc5d0\uc11c \ubc88\uc5ed\uc744 \uc704\ud55c \uc0c8\ub85c\uc6b4 \ub514\ucf54\ub354 \ud559\uc2b5\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}