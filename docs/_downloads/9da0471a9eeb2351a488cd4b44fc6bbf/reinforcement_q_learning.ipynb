{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Google Colab\uc5d0\uc11c \ub178\ud2b8\ubd81\uc744 \uc2e4\ud589\ud558\uae30 \uc704\ud55c \ud301\uc740 \ub2e4\uc74c\uc744 \ucc38\uc870\ud558\uc138\uc694:\n# https://tutorials.pytorch.kr/beginner/colab \n%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# \uac15\ud654 \ud559\uc2b5 (DQN) \ud29c\ud1a0\ub9ac\uc5bc\n\n**Author**: [Adam Paszke](https://github.com/apaszke), [Mark Towers](https://github.com/pseudo-rnd-thoughts)\n  **\ubc88\uc5ed**: [\ud669\uc131\uc218](https://github.com/adonisues), [\ubc15\uc815\ud658](https://github.com/9bow)\n\n\uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc5d0\uc11c\ub294 [Gymnasium](https://gymnasium.farama.org)_ \uc758\nCartPole-v1 \ud0dc\uc2a4\ud06c\uc5d0\uc11c DQN (Deep Q Learning) \uc5d0\uc774\uc804\ud2b8\ub97c \ud559\uc2b5\ud558\ub294\ub370\nPyTorch\ub97c \uc0ac\uc6a9\ud558\ub294 \ubc29\ubc95\uc744 \ubcf4\uc5ec\ub4dc\ub9bd\ub2c8\ub2e4.\n\n[Deep Q Learning (DQN)](https://arxiv.org/abs/1312.5602)_ \ub17c\ubb38\uc744 \uc77d\uc5b4\ubcf4\ub294 \uac83\ub3c4 \ub3c4\uc6c0\uc774 \ub420 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n**\ud0dc\uc2a4\ud06c**\n\n\uc5d0\uc774\uc804\ud2b8\ub294 \uc5f0\uacb0\ub41c \ub9c9\ub300\uac00 \ub611\ubc14\ub85c \uc11c \uc788\ub3c4\ub85d \uce74\ud2b8\ub97c \uc67c\ucabd\uc774\ub098 \uc624\ub978\ucabd\uc73c\ub85c\n\uc6c0\uc9c1\uc774\ub294 \ub450 \uac00\uc9c0 \ub3d9\uc791 \uc911 \ud558\ub098\ub97c \uc120\ud0dd\ud574\uc57c \ud569\ub2c8\ub2e4.\n\ud658\uacbd \uc124\uc815\uacfc \ub2e4\ub978 \ub354 \uae4c\ub2e4\ub85c\uc6b4 \ud658\uacbd\uc5d0 \ub300\ud55c \uc790\uc138\ud55c \ub0b4\uc6a9\uc740\n[Gymnasium \uc6f9\uc0ac\uc774\ud2b8](https://gymnasium.farama.org/environments/classic_control/cart_pole/)_\n\uc5d0\uc11c \ucc3e\uc544\ubcfc \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n.. figure:: /_static/img/cartpole.gif\n   :alt: CartPole\n\n   CartPole\n\n\uc5d0\uc774\uc804\ud2b8\uac00 \ud604\uc7ac \ud658\uacbd \uc0c1\ud0dc\ub97c \uad00\ucc30\ud558\uace0 \ud589\ub3d9\uc744 \uc120\ud0dd\ud558\uba74,\n\ud658\uacbd\uc774 \uc0c8\ub85c\uc6b4 \uc0c1\ud0dc\ub85c *\uc804\ud658* \ub418\uace0 \uc791\uc5c5\uc758 \uacb0\uacfc\ub97c \ub098\ud0c0\ub0b4\ub294 \ubcf4\uc0c1\ub3c4 \ubc18\ud658\ub429\ub2c8\ub2e4.\n\uc774 \ud0dc\uc2a4\ud06c\uc5d0\uc11c \ub9e4 \ud0c0\uc784\uc2a4\ud15d \uc99d\uac00\ub9c8\ub2e4 \ubcf4\uc0c1\uc774 +1\uc774 \ub418\uace0, \ub9cc\uc57d \ub9c9\ub300\uac00 \ub108\ubb34 \uba40\ub9ac\n\ub5a8\uc5b4\uc9c0\uac70\ub098 \uce74\ud2b8\uac00 \uc911\uc2ec\uc5d0\uc11c 2.4 \uc720\ub2db \uc774\uc0c1 \uba40\uc5b4\uc9c0\uba74 \ud658\uacbd\uc774 \uc911\ub2e8\ub429\ub2c8\ub2e4.\n\uc774\uac83\uc740 \ub354 \uc88b\uc740 \uc2dc\ub098\ub9ac\uc624\uac00 \ub354 \uc624\ub7ab\ub3d9\uc548 \ub354 \ub9ce\uc740 \ubcf4\uc0c1\uc744 \ucd95\uc801\ud558\ub294 \uac83\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4.\n\n\uce74\ud2b8\ud3f4 \ud0dc\uc2a4\ud06c\ub294 \uc5d0\uc774\uc804\ud2b8\uc5d0 \ub300\ud55c \uc785\ub825\uc774 \ud658\uacbd \uc0c1\ud0dc(\uc704\uce58, \uc18d\ub3c4 \ub4f1)\ub97c \ub098\ud0c0\ub0b4\ub294\n4\uac1c\uc758 \uc2e4\uc81c \uac12\uc774 \ub418\ub3c4\ub85d \uc124\uacc4\ub418\uc5c8\uc2b5\ub2c8\ub2e4. \uc2a4\ucf00\uc77c\ub9c1 \uc5c6\uc774 \uc774 4\uac1c\uc758 \uc785\ub825\uc744 \ubc1b\uc544\n\uac01 \ub3d9\uc791\uc5d0 \ub300\ud574 \ud558\ub098\uc529, \ucd1d 2\uac1c\uc758 \ucd9c\ub825\uc744 \uac00\uc9c4 \uc644\uc804\ud788 \uc5f0\uacb0\ub41c \uc791\uc740 \uc2e0\uacbd\ub9dd\uc5d0 \ud1b5\uacfc\uc2dc\ud0b5\ub2c8\ub2e4.\n\uc2e0\uacbd\ub9dd\uc740 \uc8fc\uc5b4\uc9c4 \uc785\ub825\uc5d0 \ub300\ud574, \uac01 \ub3d9\uc791\uc5d0 \ub300\ud55c \uc608\uc0c1\uac12\uc744 \uc608\uce21\ud558\ub3c4\ub85d \ud6c8\ub828\ub429\ub2c8\ub2e4.\n\uac00\uc7a5 \ub192\uc740 \uc608\uce21\uac12\uc744 \uac16\ub294 \ub3d9\uc791\uc774 \uc120\ud0dd\ub429\ub2c8\ub2e4.\n\n\n**\ud328\ud0a4\uc9c0**\n\n\uba3c\uc800 \ud544\uc694\ud55c \ud328\ud0a4\uc9c0\ub97c \uac00\uc838\uc635\ub2c8\ub2e4. \uccab\uc9f8, \ud658\uacbd \uad6c\uc131\uc744 \uc704\ud574\npip\ub97c \uc0ac\uc6a9\ud574 \uc124\uce58\ud55c [gymnasium](https://gymnasium.farama.org/)_ \uc774 \ud544\uc694\ud569\ub2c8\ub2e4.\n\uc774\ub294 OpenAI Gym\ub85c\ubd80\ud130 \ud30c\uc0dd(fork)\ub41c \uac83\uc73c\ub85c, Gym v0.19\ubd80\ud130 \uac19\uc740 \ud300\uc5d0\uc11c \uc720\uc9c0\ubcf4\uc218\ub97c \ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4.\nGoogle Colab\uc5d0\uc11c \uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc744 \uc2e4\ud589\ud558\uace0 \uc788\ub2e4\uba74, \ub2e4\uc74c\uc744 \uc2e4\ud589\ud574 \uc124\uce58\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4:\n\n```bash\n%%bash\npip3 install gym[classic_control]\n```\n\ub610\ud55c PyTorch\uc5d0\uc11c \ub2e4\uc74c\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4:\n\n-  \uc2e0\uacbd\ub9dd (``torch.nn``)\n-  \ucd5c\uc801\ud654 (``torch.optim``)\n-  \uc790\ub3d9 \ubbf8\ubd84 (``torch.autograd``)\n-  \uc2dc\uac01 \ud0dc\uc2a4\ud06c\ub97c \uc704\ud55c \uc720\ud2f8\ub9ac\ud2f0\ub4e4 (``torchvision`` - [a separate\n   package](https://github.com/pytorch/vision)_).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\nimport math\nimport random\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom collections import namedtuple, deque\nfrom itertools import count\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\n\nenv = gym.make(\"CartPole-v1\")\n\n# matplotlib \uc124\uc815\nis_ipython = 'inline' in matplotlib.get_backend()\nif is_ipython:\n    from IPython import display\n\nplt.ion()\n\n# GPU\ub97c \uc0ac\uc6a9\ud558\ub294 \uacbd\uc6b0\ndevice = torch.device(\n    \"cuda\" if torch.cuda.is_available() else\n    \"mps\" if torch.backends.mps.is_available() else\n    \"cpu\"\n)\n\n\n# \ud559\uc2b5 \uc911\uc5d0 \uc7ac\ud604\uc131(reproducibility)\uc744 \ubcf4\uc7a5\ud558\uae30 \uc704\ud574, \uc544\ub798 \ucf54\ub4dc\ub97c \uc8fc\uc11d \ud574\uc81c\ud558\uc5ec\n# \ubb34\uc791\uc704 \uc2dc\ub4dc \uac12(random seed)\uc744 \uace0\uc815\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n# \uc774\ub807\uac8c \ud558\uba74 \uacb0\uacfc\uac00 \uc77c\uad00\uc131\uc788\uac8c \uc720\uc9c0\ub418\uba70, \ub514\ubc84\uae45 \ub610\ub294 \ub2e4\ub978 \uc811\uadfc \ubc29\ubc95\uc744 \ube44\uad50\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.\n#\n# \ud558\uc9c0\ub9cc \ubb34\uc791\uc704\uc131(randomness)\uc744 \ud5c8\uc6a9\ud558\ub294 \uac83\uc740 \uc2e4\uc81c\ub85c \uc720\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4,\n# \uc65c\ub0d0\ud558\uba74 \ubaa8\ub378\uc774 \ub2e4\ub978 \ud559\uc2b5 \uacbd\ub85c\ub97c \ud0d0\uc0c9\ud560 \uc218 \uc788\uae30 \ub54c\ubb38\uc785\ub2c8\ub2e4.\n\n\n# seed = 42\n# random.seed(seed)\n# torch.manual_seed(seed)\n# env.reset(seed=seed)\n# env.action_space.seed(seed)\n# env.observation_space.seed(seed)\n# if torch.cuda.is_available():\n#     torch.cuda.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \uc7ac\ud604 \uba54\ubaa8\ub9ac(Replay Memory)\n\n\uc6b0\ub9ac\ub294 DQN \ud559\uc2b5\uc744 \uc704\ud574 \uacbd\ud5d8 \uc7ac\ud604 \uba54\ubaa8\ub9ac\ub97c \uc0ac\uc6a9\ud560 \uac83\uc785\ub2c8\ub2e4.\n\uc5d0\uc774\uc804\ud2b8\uac00 \uad00\ucc30\ud55c \uc804\ud658(transition)\uc744 \uc800\uc7a5\ud558\uace0 \ub098\uc911\uc5d0 \uc774 \ub370\uc774\ud130\ub97c\n\uc7ac\uc0ac\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ubb34\uc791\uc704\ub85c \uc0d8\ud50c\ub9c1\ud558\uba74 \ubc30\uce58\ub97c \uad6c\uc131\ud558\ub294 \uc804\ud658\ub4e4\uc774\n\ube44\uc0c1\uad00(decorrelated)\ud558\uac8c \ub429\ub2c8\ub2e4. \uc774\uac83\uc774 DQN \ud559\uc2b5 \uc808\ucc28\ub97c \ud06c\uac8c \uc548\uc815\uc2dc\ud0a4\uace0\n\ud5a5\uc0c1\uc2dc\ud0a4\ub294 \uac83\uc73c\ub85c \ub098\ud0c0\ub0ac\uc2b5\ub2c8\ub2e4.\n\n\uc774\ub97c \uc704\ud574\uc11c \ub450\uac1c\uc758 \ud074\ub798\uc2a4\uac00 \ud544\uc694\ud569\ub2c8\ub2e4:\n\n-  ``Transition`` - \uc6b0\ub9ac \ud658\uacbd\uc5d0\uc11c \ub2e8\uc77c \uc804\ud658\uc744 \ub098\ud0c0\ub0b4\ub3c4\ub85d \uba85\uba85\ub41c \ud29c\ud50c.\n   \uadf8\uac83\uc740 \ud654\uba74\uc758 \ucc28\uc774\uc778 state\ub85c (state, action) \uc30d\uc744 (next_state, reward) \uacb0\uacfc\ub85c \ub9e4\ud551\ud569\ub2c8\ub2e4.\n-  ``ReplayMemory`` - \ucd5c\uadfc \uad00\ucc30\ub41c \uc804\uc774\ub97c \ubcf4\uad00 \uc720\uc9c0\ud558\ub294 \uc81c\ud55c\ub41c \ud06c\uae30\uc758 \uc21c\ud658 \ubc84\ud37c.\n   \ub610\ud55c \ud559\uc2b5\uc744 \uc704\ud55c \uc804\ud658\uc758 \ubb34\uc791\uc704 \ubc30\uce58\ub97c \uc120\ud0dd\ud558\uae30\uc704\ud55c\n   ``.sample ()`` \uba54\uc18c\ub4dc\ub97c \uad6c\ud604\ud569\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "Transition = namedtuple('Transition',\n                        ('state', 'action', 'next_state', 'reward'))\n\n\nclass ReplayMemory(object):\n\n    def __init__(self, capacity):\n        self.memory = deque([], maxlen=capacity)\n\n    def push(self, *args):\n        \"\"\"transition \uc800\uc7a5\"\"\"\n        self.memory.append(Transition(*args))\n\n    def sample(self, batch_size):\n        return random.sample(self.memory, batch_size)\n\n    def __len__(self):\n        return len(self.memory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc774\uc81c \ubaa8\ub378\uc744 \uc815\uc758\ud569\uc2dc\ub2e4. \uadf8\ub7ec\ub098 \uba3c\uc800 DQN\uc774 \ubb34\uc5c7\uc778\uc9c0 \uac04\ub2e8\ud788 \uc694\uc57d\ud574 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n\n## DQN \uc54c\uace0\ub9ac\uc998\n\n\uc6b0\ub9ac\uc758 \ud658\uacbd\uc740 \uacb0\uc815\ub860\uc801\uc774\ubbc0\ub85c \uc5ec\uae30\uc5d0 \uc81c\uc2dc\ub41c \ubaa8\ub4e0 \ubc29\uc815\uc2dd\uc740 \ub2e8\uc21c\ud654\ub97c \uc704\ud574\n\uacb0\uc815\ub860\uc801\uc73c\ub85c \uacf5\uc2dd\ud654\ub429\ub2c8\ub2e4. \uac15\ud654 \ud559\uc2b5 \uc790\ub8cc\uc740 \ud658\uacbd\uc5d0\uc11c \ud655\ub960\ub860\uc801 \uc804\ud658\uc5d0\n\ub300\ud55c \uae30\ub300\uac12(expectation)\ub3c4 \ud3ec\ud568\ud560 \uac83\uc785\ub2c8\ub2e4.\n\n\uc6b0\ub9ac\uc758 \ubaa9\ud45c\ub294 \ud560\uc778\ub41c \ub204\uc801 \ubcf4\uc0c1 (discounted cumulative reward)\uc744\n\uadf9\ub300\ud654\ud558\ub824\ub294 \uc815\ucc45(policy)\uc744 \ud559\uc2b5\ud558\ub294 \uac83\uc785\ub2c8\ub2e4.\n$R_{t_0} = \\sum_{t=t_0}^{\\infty} \\gamma^{t - t_0} r_t$, \uc5ec\uae30\uc11c\n$R_{t_0}$ \ub294 *\ubc18\ud658(return)* \uc785\ub2c8\ub2e4. \ud560\uc778 \uc0c1\uc218,\n$\\gamma$, \ub294 $0$ \uacfc $1$ \uc758 \uc0c1\uc218\uc5ec\uc57c \ud569\ub2c8\ub2e4.\n$\\gamma$ \uac00 \ub0ae\uc744\uc218\ub85d \uc5d0\uc774\uc804\ud2b8\uc5d0\uac8c\ub294 \ubd88\ud655\uc2e4\ud55c \uba3c \ubbf8\ub798\uc758 \ubcf4\uc0c1\uc740\n\uc0c1\ub2f9\ud788 \ud655\uc2e0\ud560 \uc218 \uc788\ub294 \uac00\uae4c\uc6b4 \ubbf8\ub798\uc758 \ubcf4\uc0c1\ubcf4\ub2e4 \ub35c \uc911\uc694\ud574\uc9d1\ub2c8\ub2e4.\n\ub610\ud55c, \uc5d0\uc774\uc804\ud2b8\uac00 \uc2dc\uac04\uc801\uc73c\ub85c \uac00\uae4c\uc6b4 \uc2dc\uc810\uc758 \ubcf4\uc0c1\uc744, \ub3d9\uc77c\ud55c \uc591\uc758 \uba3c \ubbf8\ub798\uc758\n\ubcf4\uc0c1\ubcf4\ub2e4 \uba3c\uc800 \uc218\uc9d1\ud558\ub3c4\ub85d \uc7a5\ub824\ud569\ub2c8\ub2e4.\n\nQ-learning\uc758 \uc8fc\uc694 \uc544\uc774\ub514\uc5b4\ub294 \ub9cc\uc77c \ud568\uc218 $Q^*: State \\times Action \\rightarrow \\mathbb{R}$ \ub97c\n\uac00\uc9c0\uace0 \uc788\ub2e4\uba74 \ubc18\ud658\uc774 \uc5b4\ub5bb\uac8c \ub420\uc9c0 \uc54c\ub824\uc904 \uc218 \uc788\uace0,\n\ub9cc\uc57d \uc8fc\uc5b4\uc9c4 \uc0c1\ud0dc(state)\uc5d0\uc11c \ud589\ub3d9(action)\uc744 \ud55c\ub2e4\uba74, \ubcf4\uc0c1\uc744 \ucd5c\ub300\ud654\ud558\ub294\n\uc815\ucc45\uc744 \uc27d\uac8c \uad6c\ucd95\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4:\n\n\\begin{align}\\pi^*(s) = \\arg\\!\\max_a \\ Q^*(s, a)\\end{align}\n\n\uadf8\ub7ec\ub098 \uc138\uacc4(world)\uc5d0 \uad00\ud55c \ubaa8\ub4e0 \uac83\uc744 \uc54c\uc9c0 \ubabb\ud558\uae30 \ub54c\ubb38\uc5d0,\n$Q^*$ \uc5d0 \ub3c4\ub2ec\ud560 \uc218 \uc5c6\uc2b5\ub2c8\ub2e4. \uadf8\ub7ec\ub098 \uc2e0\uacbd\ub9dd\uc740\n\ubc94\uc6a9 \ud568\uc218 \uadfc\uc0ac\uc790(universal function approximator)\uc774\uae30 \ub54c\ubb38\uc5d0\n\uac04\ub2e8\ud558\uac8c \uc0dd\uc131\ud558\uace0 $Q^*$ \ub97c \ub2ee\ub3c4\ub85d \ud559\uc2b5\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n\ud559\uc2b5 \uc5c5\ub370\uc774\ud2b8 \uaddc\uce59\uc73c\ub85c, \uc77c\ubd80 \uc815\ucc45\uc744 \uc704\ud55c \ubaa8\ub4e0 $Q$ \ud568\uc218\uac00\nBellman \ubc29\uc815\uc2dd\uc744 \uc900\uc218\ud55c\ub2e4\ub294 \uc0ac\uc2e4\uc744 \uc0ac\uc6a9\ud560 \uac83\uc785\ub2c8\ub2e4:\n\n\\begin{align}Q^{\\pi}(s, a) = r + \\gamma Q^{\\pi}(s', \\pi(s'))\\end{align}\n\n\ud3c9\ub4f1(equality)\uc758 \ub450 \uce21\uba74 \uc0ac\uc774\uc758 \ucc28\uc774\ub294\n\uc2dc\uac04\ucc28 \uc624\ub958(temporal difference error), $\\delta$ \uc785\ub2c8\ub2e4.:\n\n\\begin{align}\\delta = Q(s, a) - (r + \\gamma \\max_a' Q(s', a))\\end{align}\n\n\uc624\ub958\ub97c \ucd5c\uc18c\ud654\ud558\uae30 \uc704\ud574\uc11c [Huber\nloss](https://en.wikipedia.org/wiki/Huber_loss)_ \ub97c \uc0ac\uc6a9\ud569\ub2c8\ub2e4.\nHuber loss \ub294 \uc624\ub958\uac00 \uc791\uc73c\uba74 \ud3c9\uade0 \uc81c\uacf1 \uc624\ucc28( mean squared error)\uc640 \uac19\uc774\n\ub3d9\uc791\ud558\uace0 \uc624\ub958\uac00 \ud074 \ub54c\ub294 \ud3c9\uade0 \uc808\ub300 \uc624\ub958\uc640 \uc720\uc0ac\ud569\ub2c8\ub2e4.\n- \uc774\uac83\uc740 $Q$ \uc758 \ucd94\uc815\uc774 \ub9e4\uc6b0 \ud63c\ub780\uc2a4\ub7ec\uc6b8 \ub54c \uc774\uc0c1 \uac12\uc5d0 \ub354 \uac15\uac74\ud558\uac8c \ud569\ub2c8\ub2e4.\n\uc7ac\ud604 \uba54\ubaa8\ub9ac\uc5d0\uc11c \uc0d8\ud50c\ub9c1\ud55c \uc804\ud658 \ubc30\uce58 $B$ \uc5d0\uc11c \uc774\uac83\uc744 \uacc4\uc0b0\ud569\ub2c8\ub2e4:\n\n\\begin{align}\\mathcal{L} = \\frac{1}{|B|}\\sum_{(s, a, s', r) \\ \\in \\ B} \\mathcal{L}(\\delta)\\end{align}\n\n\\begin{align}\\text{where} \\quad \\mathcal{L}(\\delta) = \\begin{cases}\n     \\frac{1}{2}{\\delta^2}  & \\text{for } |\\delta| \\le 1, \\\\\n     |\\delta| - \\frac{1}{2} & \\text{otherwise.}\n   \\end{cases}\\end{align}\n\n### Q-\ub124\ud2b8\uc6cc\ud06c\n\n\uc6b0\ub9ac \ubaa8\ub378\uc740 \ud604\uc7ac\uc640 \uc774\uc804 \uc2a4\ud06c\ub9b0 \ud328\uce58\uc758 \ucc28\uc774\ub97c \ucde8\ud558\ub294\n\uc21c\uc5f0\uacb0(feed-forward) \uc2e0\uacbd\ub9dd\uc785\ub2c8\ub2e4. \ub450\uac00\uc9c0 \ucd9c\ub825 $Q(s, \\mathrm{left})$ \uc640\n$Q(s, \\mathrm{right})$ \uac00 \uc788\uc2b5\ub2c8\ub2e4. (\uc5ec\uae30\uc11c $s$ \ub294 \ub124\ud2b8\uc6cc\ud06c\uc758 \uc785\ub825\uc785\ub2c8\ub2e4)\n\uacb0\uacfc\uc801\uc73c\ub85c \ub124\ud2b8\uc6cc\ud06c\ub294 \uc8fc\uc5b4\uc9c4 \ud604\uc7ac \uc785\ub825\uc5d0\uc11c \uac01 \ud589\ub3d9\uc758 *\uae30\ub300\uac12* \uc744 \uc608\uce21\ud558\ub824\uace0 \ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class DQN(nn.Module):\n\n    def __init__(self, n_observations, n_actions):\n        super(DQN, self).__init__()\n        self.layer1 = nn.Linear(n_observations, 128)\n        self.layer2 = nn.Linear(128, 128)\n        self.layer3 = nn.Linear(128, n_actions)\n\n    # \ucd5c\uc801\ud654 \uc911\uc5d0 \ub2e4\uc74c \ud589\ub3d9\uc744 \uacb0\uc815\ud558\uae30 \uc704\ud574\uc11c \ud558\ub098\uc758 \uc694\uc18c \ub610\ub294 \ubc30\uce58\ub97c \uc774\uc6a9\ud574 \ud638\ucd10\ub429\ub2c8\ub2e4.\n    # ([[left0exp,right0exp]...]) \ub97c \ubc18\ud658\ud569\ub2c8\ub2e4.\n    def forward(self, x):\n        x = F.relu(self.layer1(x))\n        x = F.relu(self.layer2(x))\n        return self.layer3(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud559\uc2b5\n\n### \ud558\uc774\ud37c \ud30c\ub77c\ubbf8\ud130\uc640 \uc720\ud2f8\ub9ac\ud2f0\n\uc774 \uc140\uc740 \ubaa8\ub378\uacfc \ucd5c\uc801\ud654\uae30\ub97c \uc778\uc2a4\ud134\uc2a4\ud654\ud558\uace0 \uc77c\ubd80 \uc720\ud2f8\ub9ac\ud2f0\ub97c \uc815\uc758\ud569\ub2c8\ub2e4:\n\n-  ``select_action`` - Epsilon Greedy \uc815\ucc45\uc5d0 \ub530\ub77c \ud589\ub3d9\uc744 \uc120\ud0dd\ud569\ub2c8\ub2e4.\n   \uac04\ub2e8\ud788 \ub9d0\ud574\uc11c, \uac00\ub054 \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\uc5ec \ud589\ub3d9\uc744 \uc120\ud0dd\ud558\uace0 \ub54c\ub85c\ub294 \ub2e8\uc9c0 \ud558\ub098\ub97c\n   \uade0\uc77c\ud558\uac8c \uc0d8\ud50c\ub9c1\ud560 \uac83\uc785\ub2c8\ub2e4. \uc784\uc758\uc758 \uc561\uc158\uc744 \uc120\ud0dd\ud560 \ud655\ub960\uc740\n   ``EPS_START`` \uc5d0\uc11c \uc2dc\uc791\ud574\uc11c ``EPS_END`` \ub97c \ud5a5\ud574 \uc9c0\uc218\uc801\uc73c\ub85c \uac10\uc18c\ud560 \uac83\uc785\ub2c8\ub2e4.\n   ``EPS_DECAY`` \ub294 \uac10\uc1e0 \uc18d\ub3c4\ub97c \uc81c\uc5b4\ud569\ub2c8\ub2e4.\n-  ``plot_durations`` - \uc9c0\ub09c 100\uac1c \uc5d0\ud53c\uc18c\ub4dc\uc758 \ud3c9\uade0(\uacf5\uc2dd \ud3c9\uac00\uc5d0\uc11c \uc0ac\uc6a9 \ub41c \uc218\uce58)\uc5d0 \ub530\ub978\n   \uc5d0\ud53c\uc18c\ub4dc\uc758 \uc9c0\uc18d\uc744 \ub3c4\ud45c\ub85c \uadf8\ub9ac\uae30 \uc704\ud55c \ud5ec\ud37c. \ub3c4\ud45c\ub294 \uae30\ubcf8 \ud6c8\ub828 \ub8e8\ud504\uac00\n   \ud3ec\ud568\ub41c \uc140 \ubc11\uc5d0 \uc788\uc73c\uba70, \ub9e4 \uc5d0\ud53c\uc18c\ub4dc\ub9c8\ub2e4 \uc5c5\ub370\uc774\ud2b8\ub429\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# BATCH_SIZE\ub294 \ub9ac\ud50c\ub808\uc774 \ubc84\ud37c\uc5d0\uc11c \uc0d8\ud50c\ub9c1\ub41c \ud2b8\ub79c\uc9c0\uc158\uc758 \uc218\uc785\ub2c8\ub2e4.\n# GAMMA\ub294 \uc774\uc804 \uc139\uc158\uc5d0\uc11c \uc5b8\uae09\ud55c \ud560\uc778 \uacc4\uc218\uc785\ub2c8\ub2e4.\n# EPS_START\ub294 \uc5e1\uc2e4\ub860\uc758 \uc2dc\uc791 \uac12\uc785\ub2c8\ub2e4.\n# EPS_END\ub294 \uc5e1\uc2e4\ub860\uc758 \ucd5c\uc885 \uac12\uc785\ub2c8\ub2e4.\n# EPS_DECAY\ub294 \uc5e1\uc2e4\ub860\uc758 \uc9c0\uc218 \uac10\uc1e0(exponential decay) \uc18d\ub3c4 \uc81c\uc5b4\ud558\uba70, \ub192\uc744\uc218\ub85d \uac10\uc1e0 \uc18d\ub3c4\uac00 \ub290\ub9bd\ub2c8\ub2e4.\n# TAU\ub294 \ubaa9\ud45c \ub124\ud2b8\uc6cc\ud06c\uc758 \uc5c5\ub370\uc774\ud2b8 \uc18d\ub3c4\uc785\ub2c8\ub2e4.\n# LR\uc740 ``AdamW`` \uc635\ud2f0\ub9c8\uc774\uc800\uc758 \ud559\uc2b5\uc728(learning rate)\uc785\ub2c8\ub2e4.\n\nBATCH_SIZE = 128\nGAMMA = 0.99\nEPS_START = 0.9\nEPS_END = 0.01\nEPS_DECAY = 2500\nTAU = 0.005\nLR = 3e-4\n\n# gym \ud589\ub3d9 \uacf5\uac04\uc5d0\uc11c \ud589\ub3d9\uc758 \uc22b\uc790\ub97c \uc5bb\uc2b5\ub2c8\ub2e4.\nn_actions = env.action_space.n\n# \uc0c1\ud0dc \uad00\uce21 \ud69f\uc218\ub97c \uc5bb\uc2b5\ub2c8\ub2e4.\nstate, info = env.reset()\nn_observations = len(state)\n\npolicy_net = DQN(n_observations, n_actions).to(device)\ntarget_net = DQN(n_observations, n_actions).to(device)\ntarget_net.load_state_dict(policy_net.state_dict())\n\noptimizer = optim.AdamW(policy_net.parameters(), lr=LR, amsgrad=True)\nmemory = ReplayMemory(10000)\n\n\nsteps_done = 0\n\n\ndef select_action(state):\n    global steps_done\n    sample = random.random()\n    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n        math.exp(-1. * steps_done / EPS_DECAY)\n    steps_done += 1\n    if sample > eps_threshold:\n        with torch.no_grad():\n            # t.max (1)\uc740 \uac01 \ud589\uc758 \uac00\uc7a5 \ud070 \uc5f4 \uac12\uc744 \ubc18\ud658\ud569\ub2c8\ub2e4.\n            # \ucd5c\ub300 \uacb0\uacfc\uc758 \ub450\ubc88\uc9f8 \uc5f4\uc740 \ucd5c\ub300 \uc694\uc18c\uc758 \uc8fc\uc18c\uac12\uc774\ubbc0\ub85c,\n            # \uae30\ub300 \ubcf4\uc0c1\uc774 \ub354 \ud070 \ud589\ub3d9\uc744 \uc120\ud0dd\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n            return policy_net(state).max(1).indices.view(1, 1)\n    else:\n        return torch.tensor([[env.action_space.sample()]], device=device, dtype=torch.long)\n\n\nepisode_durations = []\n\n\ndef plot_durations(show_result=False):\n    plt.figure(1)\n    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n    if show_result:\n        plt.title('Result')\n    else:\n        plt.clf()\n        plt.title('Training...')\n    plt.xlabel('Episode')\n    plt.ylabel('Duration')\n    plt.plot(durations_t.numpy())\n    # 100\uac1c\uc758 \uc5d0\ud53c\uc18c\ub4dc \ud3c9\uade0\uc744 \uac00\uc838 \uc640\uc11c \ub3c4\ud45c \uadf8\ub9ac\uae30\n    if len(durations_t) >= 100:\n        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n        means = torch.cat((torch.zeros(99), means))\n        plt.plot(means.numpy())\n\n    plt.pause(0.001)  # \ub3c4\ud45c\uac00 \uc5c5\ub370\uc774\ud2b8\ub418\ub3c4\ub85d \uc7a0\uc2dc \uba48\ucda4\n    if is_ipython:\n        if not show_result:\n            display.display(plt.gcf())\n            display.clear_output(wait=True)\n        else:\n            display.display(plt.gcf())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \ud559\uc2b5 \ub8e8\ud504\n\n\ucd5c\uc885\uc801\uc73c\ub85c \ubaa8\ub378 \ud559\uc2b5\uc744 \uc704\ud55c \ucf54\ub4dc.\n\n\uc5ec\uae30\uc11c, \ucd5c\uc801\ud654\uc758 \ud55c \ub2e8\uacc4\ub97c \uc218\ud589\ud558\ub294 ``optimize_model`` \ud568\uc218\ub97c \ucc3e\uc744 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\uba3c\uc800 \ubc30\uce58 \ud558\ub098\ub97c \uc0d8\ud50c\ub9c1\ud558\uace0 \ubaa8\ub4e0 Tensor\ub97c \ud558\ub098\ub85c \uc5f0\uacb0\ud558\uace0\n$Q(s_t, a_t)$ \uc640  $V(s_{t+1}) = \\max_a Q(s_{t+1}, a)$ \ub97c \uacc4\uc0b0\ud558\uace0\n\uadf8\uac83\ub4e4\uc744 \uc190\uc2e4\ub85c \ud569\uce69\ub2c8\ub2e4. \uc6b0\ub9ac\uac00 \uc124\uc815\ud55c \uc815\uc758\uc5d0 \ub530\ub974\uba74 \ub9cc\uc57d $s$ \uac00\n\ub9c8\uc9c0\ub9c9 \uc0c1\ud0dc\ub77c\uba74 $V(s) = 0$ \uc785\ub2c8\ub2e4.\n\ub610\ud55c \uc548\uc815\uc131 \ucd94\uac00 \uc704\ud55c $V(s_{t+1})$ \uacc4\uc0b0\uc744 \uc704\ud574 \ubaa9\ud45c \ub124\ud2b8\uc6cc\ud06c\ub97c \uc0ac\uc6a9\ud569\ub2c8\ub2e4.\n\ub300\uc0c1 \ub124\ud2b8\uc6cc\ud06c\ub294 \uc774\uc804\uc5d0 \uc815\uc758\ud55c \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 ``TAU`` \uc5d0 \uc758\ud574 \uc81c\uc5b4\ub418\ub294\n[\uc18c\ud504\ud2b8 \uc5c5\ub370\uc774\ud2b8](https://arxiv.org/pdf/1509.02971.pdf)_\n\ub85c \ubaa8\ub4e0 \ub2e8\uacc4\uc5d0\uc11c \uc5c5\ub370\uc774\ud2b8\ub429\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def optimize_model():\n    if len(memory) < BATCH_SIZE:\n        return\n    transitions = memory.sample(BATCH_SIZE)\n    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n    # detailed explanation). \uc774\uac83\uc740 batch-array\uc758 Transitions\uc744 Transition\uc758 batch-arrays\ub85c\n    # \uc804\ud658\ud569\ub2c8\ub2e4.\n    batch = Transition(*zip(*transitions))\n\n    # \ucd5c\uc885\uc774 \uc544\ub2cc \uc0c1\ud0dc\uc758 \ub9c8\uc2a4\ud06c\ub97c \uacc4\uc0b0\ud558\uace0 \ubc30\uce58 \uc694\uc18c\ub97c \uc5f0\uacb0\ud569\ub2c8\ub2e4\n    # (\ucd5c\uc885 \uc0c1\ud0dc\ub294 \uc2dc\ubbac\ub808\uc774\uc158\uc774 \uc885\ub8cc \ub41c \uc774\ud6c4\uc758 \uc0c1\ud0dc)\n    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n                                          batch.next_state)), device=device, dtype=torch.bool)\n    non_final_next_states = torch.cat([s for s in batch.next_state\n                                                if s is not None])\n    state_batch = torch.cat(batch.state)\n    action_batch = torch.cat(batch.action)\n    reward_batch = torch.cat(batch.reward)\n\n    # Q(s_t, a) \uacc4\uc0b0 - \ubaa8\ub378\uc774 Q(s_t)\ub97c \uacc4\uc0b0\ud558\uace0, \ucde8\ud55c \ud589\ub3d9\uc758 \uc5f4\uc744 \uc120\ud0dd\ud569\ub2c8\ub2e4.\n    # \uc774\ub4e4\uc740 policy_net\uc5d0 \ub530\ub77c \uac01 \ubc30\uce58 \uc0c1\ud0dc\uc5d0 \ub300\ud574 \uc120\ud0dd\ub41c \ud589\ub3d9\uc785\ub2c8\ub2e4.\n    state_action_values = policy_net(state_batch).gather(1, action_batch)\n\n    # \ubaa8\ub4e0 \ub2e4\uc74c \uc0c1\ud0dc\ub97c \uc704\ud55c V(s_{t+1}) \uacc4\uc0b0\n    # non_final_next_states\uc758 \ud589\ub3d9\ub4e4\uc5d0 \ub300\ud55c \uae30\ub300\uac12\uc740 \"\uc774\uc804\" target_net\uc744 \uae30\ubc18\uc73c\ub85c \uacc4\uc0b0\ub429\ub2c8\ub2e4.\n    # max(1).values\ub85c \ucd5c\uace0\uc758 \ubcf4\uc0c1\uc744 \uc120\ud0dd\ud558\uc2ed\uc2dc\uc624.\n    # \uc774\uac83\uc740 \ub9c8\uc2a4\ud06c\ub97c \uae30\ubc18\uc73c\ub85c \ubcd1\ud569\ub418\uc5b4 \uae30\ub300 \uc0c1\ud0dc \uac12\uc744 \uac16\uac70\ub098 \uc0c1\ud0dc\uac00 \ucd5c\uc885\uc778 \uacbd\uc6b0 0\uc744 \uac16\uc2b5\ub2c8\ub2e4.\n    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n    with torch.no_grad():\n        next_state_values[non_final_mask] = target_net(non_final_next_states).max(1).values\n    # \uae30\ub300 Q \uac12 \uacc4\uc0b0\n    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n\n    # Huber \uc190\uc2e4 \uacc4\uc0b0\n    criterion = nn.SmoothL1Loss()\n    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n\n    # \ubaa8\ub378 \ucd5c\uc801\ud654\n    optimizer.zero_grad()\n    loss.backward()\n    # \ubcc0\ud654\ub3c4 \ud074\ub9ac\ud551 \ubc14\uafd4\uce58\uae30\n    torch.nn.utils.clip_grad_value_(policy_net.parameters(), 100)\n    optimizer.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc544\ub798\uc5d0\uc11c \uc8fc\uc694 \ud559\uc2b5 \ub8e8\ud504\ub97c \ucc3e\uc744 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ucc98\uc74c\uc73c\ub85c \ud658\uacbd\uc744\n\uc7ac\uc124\uc815\ud558\uace0 \ucd08\uae30 ``state`` Tensor\ub97c \uc5bb\uc2b5\ub2c8\ub2e4. \uadf8\ub7f0 \ub2e4\uc74c \ud589\ub3d9\uc744\n\uc0d8\ud50c\ub9c1\ud558\uace0, \uadf8\uac83\uc744 \uc2e4\ud589\ud558\uace0, \ub2e4\uc74c \uc0c1\ud0dc\uc640 \ubcf4\uc0c1(\ud56d\uc0c1 1)\uc744 \uad00\ucc30\ud558\uace0,\n\ubaa8\ub378\uc744 \ud55c \ubc88 \ucd5c\uc801\ud654\ud569\ub2c8\ub2e4. \uc5d0\ud53c\uc18c\ub4dc\uac00 \ub05d\ub098\uba74 (\ubaa8\ub378\uc774 \uc2e4\ud328)\n\ub8e8\ud504\ub97c \ub2e4\uc2dc \uc2dc\uc791\ud569\ub2c8\ub2e4.\n\n\uc544\ub798\uc5d0\uc11c `num_episodes` \ub294 GPU\ub97c \uc0ac\uc6a9\ud560 \uc218 \uc788\ub294 \uacbd\uc6b0 600\uc73c\ub85c,\n\uadf8\ub807\uc9c0 \uc54a\uc740 \uacbd\uc6b0 50\uac1c\uc758 \uc5d0\ud53c\uc18c\ub4dc\ub97c \uc124\uc815\ud558\uc5ec \ud559\uc2b5\uc774 \ub108\ubb34 \uc624\ub798 \uac78\ub9ac\uc9c0\ub294 \uc54a\uc2b5\ub2c8\ub2e4.\n\ud558\uc9c0\ub9cc 50\uac1c\uc758 \uc5d0\ud53c\uc18c\ub4dc\ub9cc\uc73c\ub85c\ub294 CartPole\uc5d0\uc11c \uc88b\uc740 \uc131\ub2a5\uc744 \uad00\ucc30\ud558\uae30\uc5d0\ub294 \ucda9\ubd84\uce58 \uc54a\uc2b5\ub2c8\ub2e4.\n600\uac1c\uc758 \ud559\uc2b5 \uc5d0\ud53c\uc18c\ub4dc \ub0b4\uc5d0\uc11c \ubaa8\ub378\uc774 \uc9c0\uc18d\uc801\uc73c\ub85c 500\uac1c\uc758 \uc2a4\ud15d\uc744 \ub2ec\uc131\ud558\ub294 \uac83\uc744\n\ubcfc \uc218 \uc788\uc5b4\uc57c \ud569\ub2c8\ub2e4. RL \uc5d0\uc774\uc804\ud2b8 \ud559\uc2b5 \uacfc\uc815\uc5d0\ub294 \ub178\uc774\uc988\uac00 \ub9ce\uc744 \uc218 \uc788\uc73c\ubbc0\ub85c,\n\uc218\ub834(convergence)\uc774 \uad00\ucc30\ub418\uc9c0 \uc54a\uc73c\uba74 \ud559\uc2b5\uc744 \uc7ac\uc2dc\uc791\ud558\ub294 \uac83\uc774 \ub354 \ub098\uc740 \uacb0\uacfc\ub97c \uc5bb\uc744 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available() or torch.backends.mps.is_available():\n    num_episodes = 600\nelse:\n    num_episodes = 50\n\nfor i_episode in range(num_episodes):\n    # \ud658\uacbd\uacfc \uc0c1\ud0dc \ucd08\uae30\ud654\n    state, info = env.reset()\n    state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n    for t in count():\n        action = select_action(state)\n        observation, reward, terminated, truncated, _ = env.step(action.item())\n        reward = torch.tensor([reward], device=device)\n        done = terminated or truncated\n\n        if terminated:\n            next_state = None\n        else:\n            next_state = torch.tensor(observation, dtype=torch.float32, device=device).unsqueeze(0)\n\n        # \uba54\ubaa8\ub9ac\uc5d0 \ubcc0\uc774 \uc800\uc7a5\n        memory.push(state, action, next_state, reward)\n\n        # \ub2e4\uc74c \uc0c1\ud0dc\ub85c \uc774\ub3d9\n        state = next_state\n\n        # (\uc815\ucc45 \ub124\ud2b8\uc6cc\ud06c\uc5d0\uc11c) \ucd5c\uc801\ud654 \ud55c\ub2e8\uacc4 \uc218\ud589\n        optimize_model()\n\n        # \ubaa9\ud45c \ub124\ud2b8\uc6cc\ud06c\uc758 \uac00\uc911\uce58\ub97c \uc18c\ud504\ud2b8 \uc5c5\ub370\uc774\ud2b8\n        # \u03b8\u2032 \u2190 \u03c4 \u03b8 + (1 \u2212\u03c4 )\u03b8\u2032\n        target_net_state_dict = target_net.state_dict()\n        policy_net_state_dict = policy_net.state_dict()\n        for key in policy_net_state_dict:\n            target_net_state_dict[key] = policy_net_state_dict[key]*TAU + target_net_state_dict[key]*(1-TAU)\n        target_net.load_state_dict(target_net_state_dict)\n\n        if done:\n            episode_durations.append(t + 1)\n            plot_durations()\n            break\n\nprint('Complete')\nplot_durations(show_result=True)\nplt.ioff()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub2e4\uc74c\uc740 \uc804\uccb4 \uacb0\uacfc \ub370\uc774\ud130 \ud750\ub984\uc744 \ubcf4\uc5ec\uc8fc\ub294 \ub2e4\uc774\uc5b4\uadf8\ub7a8\uc785\ub2c8\ub2e4.\n\n.. figure:: /_static/img/reinforcement_learning_diagram.jpg\n\n\ud589\ub3d9\uc740 \ubb34\uc791\uc704 \ub610\ub294 \uc815\ucc45\uc5d0 \ub530\ub77c \uc120\ud0dd\ub418\uc5b4, gym \ud658\uacbd\uc5d0\uc11c \ub2e4\uc74c \ub2e8\uacc4 \uc0d8\ud50c\uc744 \uac00\uc838\uc635\ub2c8\ub2e4.\n\uacb0\uacfc\ub97c \uc7ac\ud604 \uba54\ubaa8\ub9ac\uc5d0 \uc800\uc7a5\ud558\uace0 \ubaa8\ub4e0 \ubc18\ubcf5\uc5d0\uc11c \ucd5c\uc801\ud654 \ub2e8\uacc4\ub97c \uc2e4\ud589\ud569\ub2c8\ub2e4.\n\ucd5c\uc801\ud654\ub294 \uc7ac\ud604 \uba54\ubaa8\ub9ac\uc5d0\uc11c \ubb34\uc791\uc704 \ubc30\uce58\ub97c \uc120\ud0dd\ud558\uc5ec \uc0c8 \uc815\ucc45\uc744 \ud559\uc2b5\ud569\ub2c8\ub2e4.\n\"\uc774\uc804\"\uc758 target_net\uc740 \ucd5c\uc801\ud654\uc5d0\uc11c \uae30\ub300 Q \uac12\uc744 \uacc4\uc0b0\ud558\ub294 \ub370\uc5d0\ub3c4 \uc0ac\uc6a9\ub429\ub2c8\ub2e4.\n\ubaa9\ud45c \ub124\ud2b8\uc6cc\ud06c \uac00\uc911\uce58\uc758 \uc18c\ud504\ud2b8 \uc5c5\ub370\uc774\ud2b8\ub294 \ub9e4 \ub2e8\uacc4(step)\ub9c8\ub2e4 \uc218\ud589\ub429\ub2c8\ub2e4.\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}