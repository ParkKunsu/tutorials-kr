{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Google Colab\uc5d0\uc11c \ub178\ud2b8\ubd81\uc744 \uc2e4\ud589\ud558\uae30 \uc704\ud55c \ud301\uc740 \ub2e4\uc74c\uc744 \ucc38\uc870\ud558\uc138\uc694:\n# https://tutorials.pytorch.kr/beginner/colab \n%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Torchvision \ubaa8\ub378\uc758 \ubbf8\uc138 \uc870\uc815(Finetuning)\n\n**Author:** [Nathan Inkawhich](https://github.com/inkawhich)_\n**\ubc88\uc5ed**: [\uc1a1\ucc44\uc601](https://github.com/dudtheheaven)_\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc5d0\uc11c\ub294 1000\uac1c\uc758 \ud074\ub798\uc2a4\uc758 ImageNet \ub370\uc774\ud130\uc14b\uc5d0\uc11c\n\uc0ac\uc804 \ud559\uc2b5\ub41c [torchvision \ubaa8\ub378](https://pytorch.org/docs/stable/torchvision/models.html)_, \uc744 \ubbf8\uc138 \uc870\uc815\ud558\uace0\n\ud2b9\uc9d5\uc744 \ucd94\ucd9c\ud558\ub294 \ubc29\ubc95\uc5d0 \ub300\ud574 \uc790\uc138\ud788 \uc0b4\ud3b4\ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n\uc5ec\ub7ec \ucd5c\uc2e0 CNN \uc544\ud0a4\ud14d\ucc98\ub85c \uc791\uc5c5\ud558\ub294 \ubc29\ubc95\uc744 \uc2ec\ub3c4 \uc788\uac8c \uc0b4\ud3b4\ubcf4\uace0,\nPyTorch \ubaa8\ub378\uc744 \ubbf8\uc138 \uc870\uc815\ud560 \uc218 \uc788\ub294 \uc9c1\uad00\ub825\uc744 \ud0a4\uc6b8 \uac83\uc785\ub2c8\ub2e4.\n\uac01 \ubaa8\ub378\uc758 \uc544\ud0a4\ud14d\ucc98\uac00 \ub2e4\ub974\uae30 \ub54c\ubb38\uc5d0 \ubaa8\ub4e0 \uc2dc\ub098\ub9ac\uc624\uc5d0\uc11c \uc791\ub3d9\ud558\ub294\n\uc0c1\uc6a9\uad6c \ud615\uc2dd\uc758 \ubbf8\uc138 \uc870\uc815 \ucf54\ub4dc\ub294 \uc5c6\uc2b5\ub2c8\ub2e4.\n\uc624\ud788\ub824, \uc5f0\uad6c\uc790\uac00 \uae30\uc874\uc758 \uc544\ud0a4\ud14d\ucc98\ub97c \uc0b4\ud3b4\ubcf4\uace0 \uac01 \ubaa8\ub378\uc5d0 \ub9de\uac8c \ucee4\uc2a4\ud140 \uc870\uc815\uc744 \ud574\uc57c\ud569\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#\n# \uc774 \ubb38\uc11c\uc5d0\uc11c\ub294 \ub450 \uac00\uc9c0 \uc720\ud615\uc758 \uc804\uc774 \ud559\uc2b5\uc744 \uc218\ud589\ud569\ub2c8\ub2e4. \ubbf8\uc138 \uc870\uc815\uacfc \ud2b9\uc9d5 \ucd94\ucd9c\uc785\ub2c8\ub2e4.\n# **\ubbf8\uc138 \uc870\uc815** \uc5d0\uc11c\ub294, \uc0ac\uc804 \ud559\uc2b5\ub41c \ubaa8\ub378\ub85c \uc2dc\uc791\ud574\n# \uc0c8\ub85c\uc6b4 \uc791\uc5c5\uc744 \uc704\ud574 \ubaa8\ub378\uc758 \ub9e4\uac1c\ubcc0\uc218 *\ubaa8\ub450* \ub97c \uc5c5\ub370\uc774\ud2b8 \ud558\uc5ec \ubcf8\uc9c8\uc801\uc73c\ub85c \uc804\uccb4 \ubaa8\ub378\uc744 \uc7ac\ud559\uc2b5\ud569\ub2c8\ub2e4.\n# **\ud2b9\uc9d5 \ucd94\ucd9c**\uc5d0\uc11c\ub294, \uc0ac\uc804 \ud559\uc2b5\ub41c \ubaa8\ub378\ub85c \uc2dc\uc791\ud574\n# \uc608\uce21\uc744 \ub3c4\ucd9c\ud558\ub294 \ucd5c\uc885 \ub808\uc774\uc5b4\uc758 \uac00\uc911\uce58\ub9cc \uc5c5\ub370\uc774\ud2b8\ud569\ub2c8\ub2e4.\n# \uc0ac\uc804 \ud559\uc2b5\ub41c CNN\uc744 \uace0\uc815\ub41c \ud2b9\uc9d5 \ucd94\ucd9c\uae30(feature-extractor)\ub85c \uc0ac\uc6a9\ud558\uace0\n# \ucd9c\ub825 \ub808\uc774\uc5b4\ub9cc \ubcc0\uacbd\ud558\uae30 \ub54c\ubb38\uc5d0 \uc774\ub97c \ud2b9\uc9d5 \ucd94\ucd9c\uc774\ub77c\uace0 \ud569\ub2c8\ub2e4.\n# \uc804\uc1a1(transfer)\uc5d0 \ub300\ud55c \uc790\uc138\ud55c \uae30\uc220 \uc815\ubcf4\ub294\n#  `\uc5ec\uae30 <https://cs231n.github.io/transfer-learning/>`__ \uc640\n# `\uc5ec\uae30 <https://ruder.io/transfer-learning/>`__ \ub97c \uc7ac\uad6c\uc131\ud569\ub2c8\ub2e4.\n#\n# \uc77c\ubc18\uc801\uc73c\ub85c \ub450 \uc804\uc774 \ud559\uc2b5 \ubc29\ubc95 \ubaa8\ub450 \uba87 \uac00\uc9c0 \ub2e8\uacc4\ub97c \ub3d9\uc77c\ud558\uac8c \ub530\ub985\ub2c8\ub2e4.\n#\n# - \uc0ac\uc804 \ud6c8\ub828\ub41c \ubaa8\ub378\uc744 \ucd08\uae30\ud654\ud569\ub2c8\ub2e4.\n# - \ucd5c\uc885 \ub808\uc774\uc5b4\ub97c \uc7ac\uad6c\uc131\ud558\uc5ec \uc0c8 \ub370\uc774\ud130 \uc9d1\ud569\uc758 \ud074\ub798\uc2a4 \uc218\uc640 \ub3d9\uc77c\ud55c \uc218\uc758 \ucd9c\ub825\uc744 \uac16\ub3c4\ub85d \ud569\ub2c8\ub2e4.\n# - \uc0c8 \ub370\uc774\ud130\uc14b\uc758 \ud074\ub798\uc2a4 \uc218\uc640 \ub3d9\uc77c\ud55c \ucd9c\ub825 \uc218\ub97c \uac16\ub3c4\ub85d \ucd5c\uc885 \ub808\uc774\uc5b4\ub97c \uc7ac\uad6c\uc131\ud569\ub2c8\ub2e4.\n# - \ud6c8\ub828 \uc911\uc5d0 \uc5c5\ub370\uc774\ud2b8\ud560 \ub9e4\uac1c\ubcc0\uc218\ub97c \ucd5c\uc801\ud654 \uc54c\uace0\ub9ac\uc998\uc5d0 \ub9de\uac8c \uc815\uc758\ud569\ub2c8\ub2e4.\n# - \ud559\uc2b5 \ub2e8\uacc4\ub97c \uc2e4\ud589\ud569\ub2c8\ub2e4.\n#\n\nfrom __future__ import print_function\nfrom __future__ import division\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport copy\nprint(\"PyTorch Version: \",torch.__version__)\nprint(\"Torchvision Version: \",torchvision.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \uc785\ub825\n\n\uc2e4\ud589\uc744 \uc704\ud574 \ubcc0\uacbd\ud560 \ubaa8\ub4e0 \ub9e4\uac1c\ubcc0\uc218\ub294 \ub2e4\uc74c\uacfc \uac19\uc2b5\ub2c8\ub2e4.\n*hymenoptera_data* \ub370\uc774\ud130\uc14b\uc744 [\uc5ec\uae30](https://download.pytorch.org/tutorial/hymenoptera_data.zip)_ \uc5d0\uc11c\n\ub2e4\uc6b4\ubc1b\uc544 \uc0ac\uc6a9\ud558\uaca0\uc2b5\ub2c8\ub2e4. \uc774 \ub370\uc774\ud130\uc14b\uc5d0\ub294\n**\ubc8c** \uacfc **\uac1c\ubbf8** \ub77c\ub294 \ub450 \uac1c\uc758 \ud074\ub798\uc2a4\uac00 \ud3ec\ud568\ub418\uc5b4 \uc788\uc73c\uba70\n\uc0ac\uc6a9\uc790 \uc815\uc758 \ub370\uc774\ud130\uc14b\uc744 \uc9c1\uc811 \uc791\uc131\ud558\uc9c0 \uc54a\uace0\n[ImageFolder](https://pytorch.org/docs/stable/torchvision/datasets.html#torchvision.datasets.ImageFolder)_\n\ub370\uc774\ud130\uc14b\uc744 \uc0ac\uc6a9\ud560 \uc218 \uc788\ub3c4\ub85d \uad6c\uc870\ud654\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.\n\ub370\uc774\ud130\ub97c \ub2e4\uc6b4\ub85c\ub4dc\ud558\uace0 ``data_dir`` \uc785\ub825\uc744 \ub370\uc774\ud130\uc14b\uc758 \ub8e8\ud2b8(root) \ub514\ub809\ud1a0\ub9ac\ub85c \uc124\uc815\ud569\ub2c8\ub2e4.\n``model_name`` \uc785\ub825\uc740 \uc0ac\uc6a9\ud558\ub824\ub294 \ubaa8\ub378\uc758 \uc774\ub984\uc774\uba70\n\uc544\ub798\uc758 \ubaa9\ub85d\uc5d0\uc11c \uc120\ud0dd\ud574\uc57c \ud569\ub2c8\ub2e4.\n\n::\n\n   [resnet, alexnet, vgg, squeezenet, densenet, inception]\n\n\ub2e4\ub978 \uc785\ub825\uc740 \ub2e4\uc74c\uacfc \uac19\uc2b5\ub2c8\ub2e4. ``num_classes`` \uc740 \ub370\uc774\ud130\uc14b\uc758 \ud074\ub798\uc2a4 \uc218,\n``batch_size`` \ub294 \ud6c8\ub828\uc5d0 \uc0ac\uc6a9\ub418\ub294 \ubc30\uce58 \ud06c\uae30\ub85c\n\ubaa8\ub378\uc758 \uc131\ub2a5\uc5d0 \ub530\ub77c \uc870\uc815\ud560 \uc218 \uc788\uc73c\uba70,\n``num_epochs`` \ub294 \uc2e4\ud589\ud558\ub824\ub294 \ud6c8\ub828 \uc5d0\ud3ed \uc218,\n``feature_extract`` \ub294 \ubbf8\uc138 \uc870\uc815 \ub610\ub294 \ud2b9\uc9d5 \ucd94\ucd9c \uc5ec\ubd80\ub97c \uc815\uc758\ud558\ub294 \ubd80\uc6b8(boolean)\uc785\ub2c8\ub2e4.\n``feature_extract = False``\uc774\uba74 \ubaa8\ub378\uc774 \ubbf8\uc138 \uc870\uc815\ub418\uace0\n\ubaa8\ub4e0 \ubaa8\ub378\uc758 \ub9e4\uac1c\ubcc0\uc218\uac00 \uc5c5\ub370\uc774\ud2b8\ub429\ub2c8\ub2e4.\n``feature_extract = True``\uc778 \uacbd\uc6b0 \ub9c8\uc9c0\ub9c9 \ub808\uc774\uc5b4\uc758 \ub9e4\uac1c\ubcc0\uc218\ub9cc \uc5c5\ub370\uc774\ud2b8\ub418\uace0\n\ub2e4\ub978 \ub9e4\uac1c\ubcc0\uc218\ub294 \uace0\uc815\ub41c \uc0c1\ud0dc\ub85c \uc720\uc9c0\ub429\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \ucd5c\uc0c1\uc704 \ub370\uc774\ud130 \ub514\ub809\ud1a0\ub9ac\uc785\ub2c8\ub2e4. \uc5ec\uae30\uc11c\ub294 \ub514\ub809\ud1a0\ub9ac \ud615\uc2dd\uc774\n# ImageFolder \uad6c\uc870\ub97c \ub530\ub978\ub2e4\uace0 \uac00\uc815\ud569\ub2c8\ub2e4.\ndata_dir = \"./data/hymenoptera_data\"\n\n# [resnet, alexnet, vgg, squeezenet, densenet, inception] \uc774 \uc911 \ubaa8\ub378\uc744 \uc120\ud0dd\ud569\ub2c8\ub2e4.\nmodel_name = \"squeezenet\"\n\n# \ub370\uc774\ud130 \uc9d1\ud569\uc758 \ud074\ub798\uc2a4 \uc218\nnum_classes = 2\n\n# \ud6c8\ub828\uc744 \uc704\ud55c \ubc30\uce58 \ud06c\uae30 (\uba54\ubaa8\ub9ac \uc6a9\ub7c9\uc5d0 \ub530\ub77c \ubcc0\uacbd\ub429\ub2c8\ub2e4.)\nbatch_size = 8\n\n# \ud6c8\ub828\ud560 \uc5d0\ud3ed \uc218\nnum_epochs = 15\n\n# \ud2b9\uc9d5 \ucd94\ucd9c\uc744 \uc704\ud55c \ud50c\ub798\uadf8(flag)\uc785\ub2c8\ub2e4. False\uc77c \uacbd\uc6b0, \uc804\uccb4 \ubaa8\ub378\uc744 \ubbf8\uc138 \uc870\uc815\ud558\uace0\n# True\uc77c \uacbd\uc6b0 \uc7ac\ud615\uc131\ub41c \ub808\uc774\uc5b4\uc5b4\uc758 \ub9e4\uac1c\ubcc0\uc218\ub9cc \uc5c5\ub370\uc774\ud2b8\ud569\ub2c8\ub2e4.\nfeature_extract = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ub3c4\uc6b0\ubbf8 \ud568\uc218(Helper Functions)\n\n\ubaa8\ub378\uc744 \uc870\uc815\ud558\ub294 \ucf54\ub4dc\ub97c \uc791\uc131\ud558\uae30 \uc804\uc5d0\n\uba87 \uac00\uc9c0 \ub3c4\uc6b0\ubbf8 \ud568\uc218(Helper Functions)\ub97c \uc815\uc758\ud574 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n\n### \ubaa8\ub378 \ud6c8\ub828 \ubc0f \uac80\uc99d \ucf54\ub4dc\n\n``train_model`` \ud568\uc218\ub294 \uc8fc\uc5b4\uc9c4 \ubaa8\ub378\uc758 \ud559\uc2b5\uacfc \uac80\uc99d\uc744 \ucc98\ub9ac\ud569\ub2c8\ub2e4.\n\uc774 \ud568\uc218\ub294 PyTorch \ubaa8\ub378, \ub370\uc774\ud130\ub85c\ub354(dataloader) \ub515\uc154\ub108\ub9ac, \uc190\uc2e4 \ud568\uc218,\n\uc635\ud2f0\ub9c8\uc774\uc800, \ud6c8\ub828 \ubc0f \uac80\uc99d\uc744 \uc704\ud574 \uc815\ud574\uc9c4 \uc5d0\ud3ed \uc218,\n\uadf8\ub9ac\uace0 Inception \ubaa8\ub378\uc77c \ub54c\ub97c \ub098\ud0c0\ub0b4\ub294 \ubd80\uc6b8 \ud50c\ub798\uadf8(boolean flag)\ub97c \uc785\ub825\uc73c\ub85c \ubc1b\uc2b5\ub2c8\ub2e4.\n\uc774 \uc544\ud0a4\ud14d\ucc98\ub294 \ubcf4\uc870(auxiliary) \ucd9c\ub825\uc744 \uc0ac\uc6a9\ud558\uace0, \uc804\uccb4 \ubaa8\ub378 \uc190\uc2e4\uc740\n[\uc5ec\uae30](https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958)_ \uc5d0 \uc124\uba85\ub41c \ub300\ub85c\n\ubcf4\uc870(auxiliary) \ucd9c\ub825\uacfc \ucd5c\uc885 \ucd9c\ub825\uc744 \ubaa8\ub450 \uc874\uc911\ud558\ubbc0\ub85c\n*is_inception* \ud50c\ub798\uadf8(flag)\ub294 *Inception v3* \ubaa8\ub378\uc744 \uc218\uc6a9\ud558\ub294 \ub370 \uc0ac\uc6a9\ub429\ub2c8\ub2e4.\n\uc774 \ud568\uc218\ub294 \uc9c0\uc815\ub41c \uc5d0\ud3ed \uc218 \ub3d9\uc548 \ud559\uc2b5\ud558\uace0\n\uac01 \uc5d0\ud3ed\uc774 \ub05d\ub09c \ud6c4 \uc804\uccb4 \uac80\uc99d \ub2e8\uacc4\ub97c \uc2e4\ud589\ud569\ub2c8\ub2e4.\n\ub610\ud55c, \uac80\uc99d \uc815\ud655\ub3c4 \uce21\uba74\uc5d0\uc11c \uac00\uc7a5 \uc131\ub2a5\uc774 \uc88b\uc740 \ubaa8\ub378\uc744 \ucd94\uc801\ud558\uace0\n\ud559\uc2b5\uc774 \ub05d\ub098\uba74 \ud574\ub2f9 \ubaa8\ub378\uc744 \ubc18\ud658\ud569\ub2c8\ub2e4.\n\uac01 \uc5d0\ud3ed\uc774 \ub05d\ub098\uba74 \ud6c8\ub828 \ubc0f \uac80\uc99d \uc815\ud655\ub3c4\ub97c \ubcfc \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n    since = time.time()\n\n    val_acc_history = []\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # \uac01 \uc5d0\ud3ed\uc740 \ud559\uc2b5 \ub2e8\uacc4\uc640 \uac80\uc99d \ub2e8\uacc4\ub97c \uac16\uc2b5\ub2c8\ub2e4.\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  # \ud559\uc2b5 \ubaa8\ub4dc\ub85c \ubaa8\ub378 \uc124\uc815\n            else:\n                model.eval()   # \ud3c9\uac00 \ubaa8\ub4dc\ub85c \ubaa8\ub378 \uc124\uc815\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # \ub370\uc774\ud130\ub97c \ubc18\ubcf5\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # \ub9e4\uac1c\ubcc0\uc218 \uacbd\uc0ac\ub3c4\ub97c 0\uc73c\ub85c \uc124\uc815\n                optimizer.zero_grad()\n\n                # \uc21c\ubc29\ud5a5\n                # \ud6c8\ub828 \ud558\ub294 \ub3d9\uc548\ub9cc \uae30\ub85d\uc744 \ucd94\uc801\ud569\ub2c8\ub2e4.\n                with torch.set_grad_enabled(phase == 'train'):\n                    # \ubaa8\ub378\uc758 \ucd9c\ub825\uc744 \uac00\uc838\uc624\uace0 \uc190\uc2e4\uc744 \uacc4\uc0b0\ud569\ub2c8\ub2e4.\n                    # \ud559\uc2b5 \uc2dc \ubcf4\uc870(auxiliary) \ucd9c\ub825\uc774 \uc788\ub294 inception\uc758 \ud2b9\ubcc4\ud55c \uacbd\uc6b0\uc785\ub2c8\ub2e4.\n                    #   \ud559\uc2b5 \ubaa8\ub4dc\uc5d0\uc11c\ub294 \ucd5c\uc885 \ucd9c\ub825\uacfc \ubcf4\uc870(auxiliary) \ucd9c\ub825\uc744 \ud569\uc0b0\ud574 \uc190\uc2e4\uc744 \uacc4\uc0b0\ud558\uc9c0\ub9cc\n                    #   \ud14c\uc2a4\ud2b8\uc5d0\uc11c\ub294 \ucd5c\uc885 \ucd9c\ub825\ub9cc \uace0\ub824\ud569\ub2c8\ub2e4.\n                    if is_inception and phase == 'train':\n                        # https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958 \uc5d0\uc11c\n                        outputs, aux_outputs = model(inputs)\n                        loss1 = criterion(outputs, labels)\n                        loss2 = criterion(aux_outputs, labels)\n                        loss = loss1 + 0.4*loss2\n                    else:\n                        outputs = model(inputs)\n                        loss = criterion(outputs, labels)\n\n                    _, preds = torch.max(outputs, 1)\n\n                    # \ud559\uc2b5 \ub2e8\uacc4\uc778 \uacbd\uc6b0 \uc5ed\uc804\ud30c + \ucd5c\uc801\ud654\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # \ud1b5\uacc4\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n\n            # \ubaa8\ub378\uc744 \uae4a\uc740 \ubcf5\uc0ac(deep copy)\ud568\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n            if phase == 'val':\n                val_acc_history.append(epoch_acc)\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # \ucd5c\uace0\uc758 \ubaa8\ub378 \uac00\uc911\uce58 \ubd88\ub7ec\uc624\uae30\n    model.load_state_dict(best_model_wts)\n    return model, val_acc_history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \ubaa8\ub378 \ub9e4\uac1c\ubcc0\uc218\uc758 .requires_grad \uc18d\uc131 \uc124\uc815\n\n\uc774 \ub3c4\uc6b0\ubbf8 \ud568\uc218(Helper Functions)\ub294 \ud2b9\uc9d5 \ucd94\ucd9c \uc2dc\n\ubaa8\ub378\uc5d0 \uc788\ub294 \ub9e4\uac1c\ubcc0\uc218\uc758 ``.requires_grad`` \uc18d\uc131\uc744 False\ub85c \uc124\uc815\ud569\ub2c8\ub2e4.\n\uae30\ubcf8\uc801\uc73c\ub85c, \uc0ac\uc804 \ud559\uc2b5\ub41c \ubaa8\ub378\uc744 \uc77d\uc5b4 \ub4e4\uc77c \ub54c \ubaa8\ub4e0 \ub9e4\uac1c\ubcc0\uc218\uac00\n``.requires_grad=True``\ub85c \uc124\uc815\ub418\uc5b4 \uc788\uc73c\ubbc0\ub85c\n\ucc98\uc74c\ubd80\ud130 \ud559\uc2b5\ud558\uac70\ub098 \ubbf8\uc138 \uc870\uc815\ud558\ub294 \uacbd\uc6b0\ub77c\uba74 \uad1c\ucc2e\uc2b5\ub2c8\ub2e4.\n\uadf8\ub7ec\ub098 \ud2b9\uc9d5 \ucd94\ucd9c \uc911\uc774\uace0 \uc0c8\ub85c \ucd08\uae30\ud654\ub41c \ub808\uc774\uc5b4\uc5d0 \ub300\ud55c \uacbd\uc0ac\ub3c4\ub9cc \uacc4\uc0b0\ud558\ub824\ub294 \uacbd\uc6b0\n\ub2e4\ub978 \ubaa8\ub4e0 \ub9e4\uac1c\ubcc0\uc218\uc5d0\ub294 \uacbd\uc0ac\ub3c4\uac00 \ud544\uc694\ud558\uc9c0 \uc54a\uc544\uc57c \ud569\ub2c8\ub2e4.\n\uc774\uac83\uc740 \ub098\uc911\uc5d0 \ub354 \uc774\ud574\ub97c \ud560 \uc218 \uc788\uc744 \uac83\uc785\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def set_parameter_requires_grad(model, feature_extracting):\n    if feature_extracting:\n        for param in model.parameters():\n            param.requires_grad = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ub124\ud2b8\uc6cc\ud06c \ucd08\uae30\ud654 \ubc0f \uc7ac\uad6c\uc131\ud558\uae30\n\n\uc774\uc81c \uac00\uc7a5 \ud765\ubbf8\ub85c\uc6b4 \ubd80\ubd84\uc785\ub2c8\ub2e4.\n\uc5ec\uae30\uc11c\ub294 \uac01 \ub124\ud2b8\uc6cc\ud06c\uc758 \uc7ac\uad6c\uc131\uc744 \ucc98\ub9ac\ud569\ub2c8\ub2e4.\n\uc774 \uc808\ucc28\ub294 \uc790\ub3d9 \uc808\ucc28\uac00 \uc544\ub2c8\uba70 \uac01 \ubaa8\ub378\ub9c8\ub2e4 \uace0\uc720\ud569\ub2c8\ub2e4.\nCNN \ubaa8\ub378\uc758 \ucd5c\uc885 \ub808\uc774\uc5b4(FC layer\ub77c\uace0\ub3c4 \ubd88\ub9bc)\ub294\n\ub370\uc774\ud130\uc14b\uc758 \ucd9c\ub825 \ud074\ub798\uc2a4 \uc218\uc640 \ub3d9\uc77c\ud55c \uc218\uc758 \ub178\ub4dc\ub97c \uac00\uc9c0\uace0 \uc788\uc2b5\ub2c8\ub2e4.\n\ubaa8\ub4e0 \ubaa8\ub378\uc740 \uc774\ubbf8 ImageNet\uc5d0\uc11c \uc0ac\uc804 \ud559\uc2b5 \ub418\uc5c8\uae30 \ub54c\ubb38\uc5d0\n\uac01 \ud074\ub798\uc2a4\ub2f9 \ud558\ub098\uc758 \ub178\ub4dc\uc529 1000 \ud06c\uae30\uc758 \ucd9c\ub825 \ub808\uc774\uc5b4\ub97c \uac00\uc9c0\uace0 \uc788\uc2b5\ub2c8\ub2e4.\n\uc5ec\uae30\uc11c\uc758 \ubaa9\ud45c\ub294 \uc774\uc804\uacfc \ub3d9\uc77c\ud55c \uc218\uc758 \uc785\ub825\uc744 \uac16\uace0,\n\ub370\uc774\ud130\uc14b\uc758 \ud074\ub798\uc2a4 \uc218\uc640 \ub3d9\uc77c\ud55c \uc218\uc758 \ucd9c\ub825\uc744 \uac16\ub3c4\ub85d \ub9c8\uc9c0\ub9c9 \ub808\uc774\uc5b4\ub97c \uc7ac\uad6c\uc131\ud558\ub294 \uac83\uc785\ub2c8\ub2e4.\n\ub2e4\uc74c \uc139\uc158\uc5d0\uc11c\ub294 \uac01 \ubaa8\ub378\uc758 \uc544\ud0a4\ud14d\ucc98\ub97c\n\uac1c\ubcc4\uc801\uc73c\ub85c \ubcc0\uacbd\ud558\ub294 \ubc29\ubc95\uc5d0 \ub300\ud574 \uc124\uba85\ud558\uaca0\uc2b5\ub2c8\ub2e4.\n\ud558\uc9c0\ub9cc \uba3c\uc800, \ubbf8\uc138 \uc870\uc815\uacfc \ud2b9\uc9d5 \ucd94\ucd9c\uc758 \ucc28\uc774\uc810\uc5d0 \ub300\ud55c\n\ud55c \uac00\uc9c0 \uc911\uc694\ud55c \uc138\ubd80 \uc0ac\ud56d\uc774 \uc788\uc2b5\ub2c8\ub2e4.\n\n\ud2b9\uc9d5 \ucd94\ucd9c \uc2dc \ub9c8\uc9c0\ub9c9 \ub808\uc774\uc5b4\uc758 \ub9e4\uac1c\ubcc0\uc218\ub9cc \uc5c5\ub370\uc774\ud2b8 \ud558\uace0 \uc2f6\uc744 \ub54c\n\ub2e4\uc2dc \ub9d0\ud574, \uc7ac\uad6c\uc131\ud558\ub294 \ub808\uc774\uc5b4\uc758 \ub9e4\uac1c\ubcc0\uc218\ub9cc \uc5c5\ub370\uc774\ud2b8\ub97c \ud558\uace0 \uc2f6\uc740 \uacbd\uc6b0\uac00 \uc788\uc2b5\ub2c8\ub2e4.\n\uc774\ub7f0 \uacbd\uc6b0\uc5d0\ub294 \ubcc0\uacbd\ud558\uc9c0 \uc54a\ub294 \ub9e4\uac1c\ubcc0\uc218\uc758 \uacbd\uc0ac\ub3c4\ub97c \uacc4\uc0b0\ud560 \ud544\uc694\uac00 \uc5c6\uc73c\ubbc0\ub85c\n\ud6a8\uc728\uc131\uc744 \uc704\ud574 .requires_grad \uc18d\uc131\uc744 False\ub85c \uc124\uc815\ud569\ub2c8\ub2e4.\n\uae30\ubcf8\uc801\uc73c\ub85c \uc774 \uc18d\uc131\uc740 True\ub85c \uc124\uc815\ub418\uc5b4 \uc788\uae30 \ub54c\ubb38\uc5d0 \uc774 \uc124\uc815\uc740 \uc911\uc694\ud569\ub2c8\ub2e4.\n\uadf8\ub7f0 \ub2e4\uc74c \uc0c8 \ub808\uc774\uc5b4\ub97c \ucd08\uae30\ud654\ud560 \ub54c \uae30\ubcf8\uc801\uc73c\ub85c \uc0c8 \ub9e4\uac1c\ubcc0\uc218\uc5d0\ub294 ``.requires_grad=True`[\uac00 \uc788\uc73c\ubbc0\ub85c\n\uc0c8 \ub808\uc774\uc5b4\uc758 \ub9e4\uac1c\ubcc0\uc218\ub9cc \uc5c5\ub370\uc774\ud2b8\ub429\ub2c8\ub2e4.\n\ubbf8\uc138 \uc870\uc815\ud560 \ub54c\ub294 \ubaa8\ub4e0 .requires_grad\ub97c \uae30\ubcf8\uac12\uc778 True\ub85c \uc124\uc815\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n\ub9c8\uc9c0\ub9c9\uc73c\ub85c, inception_v3\ub294 \uc785\ub825 \ud06c\uae30\ub97c (299,299)\ub85c \uc694\uad6c\ud558\uc9c0\ub9cc,\n\ub2e4\ub978 \ubaa8\ub4e0 \ubaa8\ub378\uc740 (224,224)\ub97c \uae30\ub300\ud55c\ub2e4\ub294 \uc810\uc744 \uae30\uc5b5\ud558\uc138\uc694.\n\n### Resnet\n\nResnet\uc740 'Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)_ \ub17c\ubb38\uc5d0\uc11c \uc18c\uac1c\ub418\uc5c8\uc2b5\ub2c8\ub2e4.\nResnet18, Resnet34, Resnet50, Resnet101, and Resnet152 \ub4f1 \ub2e4\uc591\ud55c \ud06c\uae30\uc758 \uc5ec\ub7ec \uac00\uc9c0 \ubcc0\ud615\uc774 \uc788\uc73c\uba70\n\ubaa8\ub450 torchvision \ubaa8\ub378\uc5d0\uc11c \uc0ac\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\uc5ec\uae30\uc11c\ub294 \ub370\uc774\ud130\uc14b\uc774 \uc791\uace0 \ud074\ub798\uc2a4\uac00 \ub450 \uac1c \ubfd0\uc778 Resnet18\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4.\n\ubaa8\ub378\uc744 \ucd9c\ub825\ud558\uba74 \uc544\ub798 \uadf8\ub9bc\uacfc \uac19\uc774\n\ub9c8\uc9c0\ub9c9 \ub808\uc774\uc5b4\uac00 \uc644\uc804\ud788 \uc5f0\uacb0\ub41c \ub808\uc774\uc5b4\uc784\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n::\n\n   (fc): Linear(in_features=512, out_features=1000, bias=True)\n\n\uc785\ub825 \ud2b9\uc9d5\uc774 512\uac1c, \ucd9c\ub825 \ud2b9\uc9d5\uc774 2\uac1c\uc778 \uc120\ud615 \ub808\uc774\uc5b4\uac00 \ub418\ub3c4\ub85d\n``model.fc``\ub97c \ub2e4\uc2dc \ucd08\uae30\ud654\ud574\uc57c \ud569\ub2c8\ub2e4.\n\n::\n\n   model.fc = nn.Linear(512, num_classes)\n\n### Alexnet\n\nAlexnet\uc740 [ImageNet Classification with Deep\nConvolutional Neural\nNetworks](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)_ \ub17c\ubb38\uc5d0 \uc18c\uac1c\ub41c \ubc14 \uc788\uc73c\uba70\nImageNet \ub370\uc774\ud130\uc14b\uc5d0\uc11c \ucd5c\ucd08\ub85c \ub9e4\uc6b0 \uc131\uacf5\uc801\uc778 CNN\uc744 \uad6c\ud604\ud55c \ubc14 \uc788\uc2b5\ub2c8\ub2e4.\n\ubaa8\ub378\uc758 \uc544\ud0a4\ud14d\ucc98\ub97c \ucd9c\ub825\ud558\uba74 \ubaa8\ub378 \ucd9c\ub825\uc774\n\ubd84\ub958\uae30(classifier)\uc758 6\ubc88\uc9f8 \ub808\uc774\uc5b4\uc5d0\uc11c \ub098\uc624\ub294 \uac83\uc744 \ubcfc \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n::\n\n   (classifier): Sequential(\n       ...\n       (6): Linear(in_features=4096, out_features=1000, bias=True)\n    )\n\n\ub370\uc774\ud130\uc14b\uacfc \ud568\uaed8 \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\ub824\uba74 \uc774 \ub808\uc774\uc5b4\ub97c \ub2e4\uc74c\uacfc \uac19\uc774 \ub2e4\uc2dc \ucd08\uae30\ud654\ud569\ub2c8\ub2e4.\n\n::\n\n   model.classifier[6] = nn.Linear(4096,num_classes)\n\n### VGG\n\nVGG\ub294 [Very Deep Convolutional Networks for\nLarge-Scale Image Recognition](https://arxiv.org/pdf/1409.1556.pdf)_ \ub17c\ubb38\uc5d0\uc11c \uc18c\uac1c\ub418\uc5c8\uc2b5\ub2c8\ub2e4.\nTorchvision \ub2e4\uc591\ud55c \uae38\uc774\uc640 \ubc30\uce58 \uc815\uaddc\ud654 \ub808\uc774\uc5b4\uac00 \uc788\ub294\n8\uac00\uc9c0 \ubc84\uc804\uc758 VGG\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4.\n\uc5ec\uae30\uc11c\ub294 \ubc30\uce58 \uc815\uaddc\ud654 \uae30\ub2a5\uc774 \uc788\ub294 VGG-11\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4.\n\ucd9c\ub825 \ub808\uc774\uc5b4\ub294 Alexnet\uacfc \uc720\uc0ac\ud569\ub2c8\ub2e4.\n\n::\n\n   (classifier): Sequential(\n       ...\n       (6): Linear(in_features=4096, out_features=1000, bias=True)\n    )\n\n\ub530\ub77c\uc11c \ub3d9\uc77c\ud55c \uae30\uc220\uc744 \uc0ac\uc6a9\ud574 \ucd9c\ub825 \ub808\uc774\uc5b4\ub97c \uc218\uc815\ud569\ub2c8\ub2e4.\n\n::\n\n   model.classifier[6] = nn.Linear(4096,num_classes)\n\n### Squeezenet\n\nSqueeznet \uc544\ud0a4\ud14d\ucc98\ub294 [SqueezeNet:\nAlexNet-level accuracy with 50x fewer parameters and](0.5MB model\nsize <https://arxiv.org/abs/1602.07360)_ \ub17c\ubb38\uc5d0 \uc124\uba85\ub418\uc5b4 \uc788\uace0,\nAlexNet \uc218\uc900\uc758 \uc815\ud655\ub3c4\ub97c \uc81c\uacf5\ud558\uba74\uc11c\n\uc5ec\uae30\uc5d0 \ud45c\uc2dc\ub41c \ubaa8\ub378\ub4e4\uacfc\ub294 \ub2e4\ub978 \ucd9c\ub825 \uad6c\uc870\ub97c \uc0ac\uc6a9\ud569\ub2c8\ub2e4.\nTorchvision\uc5d0\ub294 \ub450 \uac00\uc9c0 \ubc84\uc804\uc758 Squeezenet\uc774 \uc788\uace0 \uc5ec\uae30\uc11c\ub294 1.0 \ubc84\uc804\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4.\n\ucd9c\ub825\uc740 \ubd84\ub958\uae30(classifier)\uc758 \uccab \ubc88\uc9f8 \ub808\uc774\uc5b4\uc778\n1x1 \ud569\uc131\uacf1 \ub808\uc774\uc5b4\uc5d0\uc11c \ub098\uc635\ub2c8\ub2e4.\n\n::\n\n   (classifier): Sequential(\n       (0): Dropout(p=0.5)\n       (1): Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1))\n       (2): ReLU(inplace)\n       (3): AvgPool2d(kernel_size=13, stride=1, padding=0)\n    )\n\n\ub124\ud2b8\uc6cc\ud06c\ub97c \uc218\uc815\ud558\uae30 \uc704\ud574 Conv2d \ub808\uc774\uc5b4\ub97c \ub2e4\uc2dc \ucd08\uae30\ud654\ud558\uc5ec\n\uae4a\uc774 2\uc758 \ud2b9\uc9d5 \ub9f5\uc744 \ub2e4\uc74c\uacfc \uac19\uc774 \ucd9c\ub825\ud569\ub2c8\ub2e4.\n\n::\n\n   model.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n\n### Densenet\n\nDensenet [Densely Connected Convolutional\nNetworks](https://arxiv.org/abs/1608.06993)_ \ub17c\ubb38\uc5d0\uc11c \uc18c\uac1c\ub418\uc5c8\uc2b5\ub2c8\ub2e4.\nTorchvision\uc5d0\ub294 4\uac00\uc9c0\uc758 \ubcc0\ud615 Densenet\uc774 \uc788\uc9c0\ub9cc\n\uc5ec\uae30\uc11c\ub294 Densenet-121\ub9cc \uc0ac\uc6a9\ud569\ub2c8\ub2e4.\n\ucd9c\ub825 \ub808\uc774\ub294 1024\uac1c\uc758 \uc785\ub825 \ud2b9\uc9d5\uc744 \uac00\uc9c4 \uc120\ud615 \ub808\uc774\uc5b4 \uc785\ub2c8\ub2e4.\n\n::\n\n   (classifier): Linear(in_features=1024, out_features=1000, bias=True)\n\n\ub124\ud2b8\uc6cc\ud06c\ub97c \uc7ac\uad6c\uc131\ud558\uae30 \uc704\ud574 \ubd84\ub958\uae30(classifier)\uc758 \uc120\ud615 \ub808\uc774\uc5b4\ub97c\n\ub2e4\uc74c\uacfc \uac19\uc774 \ub2e4\uc2dc \ucd08\uae30\ud654\ud569\ub2c8\ub2e4.\n\n::\n\n   model.classifier = nn.Linear(1024, num_classes)\n\n### Inception v3\n\n\ub9c8\uc9c0\ub9c9\uc73c\ub85c Inception v3\uc740 [Rethinking the Inception\nArchitecture for Computer\nVision](https://arxiv.org/pdf/1512.00567v1.pdf)_ \uc5d0\uc11c \ucc98\uc74c \uc124\uba85\ud588\uc2b5\ub2c8\ub2e4.\n\uc774 \ub124\ud2b8\uc6cc\ud06c\ub294 \ud559\uc2b5 \uc2dc \ub450 \uac1c\uc758 \ucd9c\ub825 \ub808\uc774\uc5b4\uac00 \uc788\ub2e4\ub294 \uc810\uc774 \ub3c5\ud2b9\ud569\ub2c8\ub2e4.\n\ub450 \ubc88\uc9f8 \ucd9c\ub825\uc740 \ubcf4\uc870(axuiliary) \ucd9c\ub825\uc73c\ub85c \uc54c\ub824\uc838 \uc788\uc73c\uba70\n\ub124\ud2b8\uc6cc\ud06c\uc758 AuxLogits \ubd80\ubd84\uc5d0 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.\n\uae30\ubcf8 \ucd9c\ub825\uc740 \ub124\ud2b8\uc6cc\ud06c \ub05d\uc5d0 \uc788\ub294 \uc120\ud615 \ub808\uc774\uc5b4\uc774\uba70\n\ud14c\uc2a4\ud2b8\ud560 \ub54c\ub294 \uae30\ubcf8 \ucd9c\ub825\ub9cc \uace0\ub824\ud569\ub2c8\ub2e4.\n\uc77d\uc5b4 \ub4e4\uc778 \ubaa8\ub378\uc758 \ubcf4\uc870(auxiliary) \ucd9c\ub825\uacfc \uae30\ubcf8 \ucd9c\ub825\uc740 \ub2e4\uc74c\uacfc \uac19\uc774 \ucd9c\ub825\ub429\ub2c8\ub2e4.\n\n::\n\n   (AuxLogits): InceptionAux(\n       ...\n       (fc): Linear(in_features=768, out_features=1000, bias=True)\n    )\n    ...\n   (fc): Linear(in_features=2048, out_features=1000, bias=True)\n\n\uc774 \ubaa8\ub378\uc744 \ubbf8\uc138 \uc870\uc815\ud558\ub824\uba74 \ub450 \ub808\uc774\uc5b4\ub97c\n\ub2e4\uc74c\uacfc \uac19\uc774 \ubaa8\ub450 \uc7ac\uad6c\uc131\ud574\uc57c \ud569\ub2c8\ub2e4.\n\n::\n\n   model.AuxLogits.fc = nn.Linear(768, num_classes)\n   model.fc = nn.Linear(2048, num_classes)\n\n\ub9ce\uc740 \ubaa8\ub378\uc774 \ube44\uc2b7\ud55c \ucd9c\ub825 \uad6c\uc870\ub97c \uac00\uc9c0\uace0 \uc788\uc9c0\ub9cc,\n\uac01\uac01\uc740 \uc57d\uac04 \ub2e4\ub974\uac8c \ucc98\ub9ac\ub418\uc5b4\uc57c \ud569\ub2c8\ub2e4.\n\ub610\ud55c, \uc7ac\uad6c\uc131\ub41c \ub124\ud2b8\uc6cc\ud06c\uc758 \ucd9c\ub825 \ubaa8\ub378 \uad6c\uc870\ub97c \ud655\uc778\ud558\uace0\n\ucd9c\ub825 \uae30\ub2a5\uc758 \uc218\uac00 \ub370\uc774\ud130\uc14b\uc758 \ud074\ub798\uc2a4 \uc218\uc640 \ub3d9\uc77c\ud55c\uc9c0 \ud655\uc778\ud574\uc57c \ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n    # \uc774 if \ubb38\uc5d0\uc11c \uc124\uc815\ud560 \ubcc0\uc218\ub97c \ucd08\uae30\ud654 \ud569\ub2c8\ub2e4.\n    # \uac01 \ubcc0\uc218\ub294 \ubaa8\ub378\uc5d0 \ub530\ub77c \ub2e4\ub985\ub2c8\ub2e4.\n    model_ft = None\n    input_size = 0\n\n    if model_name == \"resnet\":\n        \"\"\" Resnet18\n        \"\"\"\n        model_ft = models.resnet18(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        num_ftrs = model_ft.fc.in_features\n        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n        input_size = 224\n\n    elif model_name == \"alexnet\":\n        \"\"\" Alexnet\n        \"\"\"\n        model_ft = models.alexnet(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        num_ftrs = model_ft.classifier[6].in_features\n        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n        input_size = 224\n\n    elif model_name == \"vgg\":\n        \"\"\" VGG11_bn\n        \"\"\"\n        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        num_ftrs = model_ft.classifier[6].in_features\n        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n        input_size = 224\n\n    elif model_name == \"squeezenet\":\n        \"\"\" Squeezenet\n        \"\"\"\n        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n        model_ft.num_classes = num_classes\n        input_size = 224\n\n    elif model_name == \"densenet\":\n        \"\"\" Densenet\n        \"\"\"\n        model_ft = models.densenet121(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        num_ftrs = model_ft.classifier.in_features\n        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n        input_size = 224\n\n    elif model_name == \"inception\":\n        \"\"\" Inception v3\n        Be careful, expects (299,299) sized images and has auxiliary output\n        \"\"\"\n        model_ft = models.inception_v3(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        # \ubcf4\uc870 \ub124\ud2b8\uc6cc\ud06c(auxilary net) \ucc98\ub9ac\n        num_ftrs = model_ft.AuxLogits.fc.in_features\n        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n        # \uc8fc \ub124\ud2b8\uc6cc\ud06c(primary net) \ucc98\ub9ac\n        num_ftrs = model_ft.fc.in_features\n        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n        input_size = 299\n\n    else:\n        print(\"Invalid model name, exiting...\")\n        exit()\n\n    return model_ft, input_size\n\n# \uc2e4\ud589\uc744 \uc704\ud55c \ubaa8\ub378 \ucd08\uae30\ud654\nmodel_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n\n# \ubc29\uae08 \uc778\uc2a4\ud134\uc2a4\ud654\ud55c \ubaa8\ub378 \ucd9c\ub825\nprint(model_ft)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ub370\uc774\ud130 \uc77d\uc5b4 \ub4e4\uc774\uae30\n\n\uc785\ub825 \ud06c\uae30\ub97c \uc54c\uc558\uc73c\ub2c8 \uc774\uc81c \ub370\uc774\ud130 \uc804\uc774(transform), \uc774\ubbf8\uc9c0 \ub370\uc774\ud130\uc14b,\n\uadf8\ub9ac\uace0 \ub370\uc774\ud130\ub85c\ub354(dataloader)\ub97c \ucd08\uae30\ud654\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n[\uc5ec\uae30](https://pytorch.org/docs/master/torchvision/models.html)_ \uc5d0\uc11c \uc124\uba85\ub41c \ub300\ub85c\n\ubaa8\ub378\uc740 \ud558\ub4dc\ucf54\ub529(hard-coded)\ub41c \uc815\uaddc\ud654 \uac12\uc73c\ub85c \uc0ac\uc804 \ud559\uc2b5\ub418\uc5c8\uc2b5\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \ud559\uc2b5\uc744 \uc704\ud55c \ub370\uc774\ud130 \uc99d\uac15 \ubc0f \uc815\uaddc\ud654\n# \uac80\uc99d\uc744 \uc704\ud55c \uc815\uaddc\ud654\ub9cc \uc218\ud589\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.RandomResizedCrop(input_size),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize(input_size),\n        transforms.CenterCrop(input_size),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}\n\nprint(\"Initializing Datasets and Dataloaders...\")\n\n# \ud559\uc2b5 \ubc0f \uac80\uc99d \ub370\uc774\ud130\uc14b \uc0dd\uc131\nimage_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n# \ud559\uc2b5 \ubc0f \uac80\uc99d \ub370\uc774\ud130\ub85c\ub354(dataloader) \uc0dd\uc131\ndataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\n\n# \uc0ac\uc6a9 \uac00\ub2a5\ud55c GPU \ud0d0\uc9c0\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \uc635\ud2f0\ub9c8\uc774\uc800 \uc0dd\uc131\n\n\uc774\uc81c \ubaa8\ub378 \uad6c\uc870\uac00 \uc815\ud655\ud574\uc84c\uc73c\ub2c8, \ubbf8\uc138 \uc870\uc815 \ubc0f \ud2b9\uc9d5 \ucd94\ucd9c\uc744 \uc704\ud55c \ub9c8\uc9c0\ub9c9 \ub2e8\uacc4\ub294\n\uc6d0\ud558\ub294 \ub9e4\uac1c\ubcc0\uc218\ub9cc \uc5c5\ub370\uc774\ud2b8\ud558\ub294 \uc635\ud2f0\ub9c8\uc774\uc800\ub97c \uc0dd\uc131\ud558\ub294 \uac83\uc785\ub2c8\ub2e4.\n\uc0ac\uc804 \ud559\uc2b5\ub41c \ubaa8\ub378\uc744 \uc77d\uc5b4 \ub4e4\uc778 \ud6c4 \uad6c\uc870\ub97c \uc7ac\uc870\uc815\ud558\uae30 \uc804\uc5d0\n``feature_extract=True``\uc778 \uacbd\uc6b0 \ub9e4\uac1c\ubcc0\uc218\uc758\n\ubaa8\ub4e0 ``.requires_grad`` \uc18d\uc131\uc744 \uc77c\uc77c\uc774 False\ub85c \uc124\uc815\ud55c \uac83\uc744 \uae30\uc5b5\ud558\uc138\uc694.\n\uadf8\ub7ec\uba74 \uc7ac\ucd08\uae30\ud654\ub41c \ub808\uc774\uc5b4\uc758 \ud30c\ub77c\ubbf8\ud130\ub294\n\uae30\ubcf8\uc801\uc73c\ub85c ``.requires_grad=True``\ub97c \uac16\uc2b5\ub2c8\ub2e4.\n\uc774\uc81c *.requires_grad=True\uc778 \ubaa8\ub4e0 \ub9e4\uac1c\ubcc0\uc218\uac00\n\ucd5c\uc801\ud654\ub418\uc5b4\uc57c \ud55c\ub2e4\ub294 \uac83\uc744 \uc54c\uc558\uc2b5\ub2c8\ub2e4.*\n\ub2e4\uc74c\uc73c\ub85c \uc774\ub7ec\ud55c \ub9e4\uac1c\ubcc0\uc218 \ubaa9\ub85d\uc744 \ub9cc\ub4e4\uace0\n\uc774 \ubaa9\ub85d\uc744 SGD \uc54c\uace0\ub9ac\uc998 \uc0dd\uc131\uc790(constructor)\uc5d0 \uc785\ub825\ud569\ub2c8\ub2e4.\n\n\uc774\ub97c \ud655\uc778\ud558\ub824\uba74 \ucd9c\ub825\ub41c \ub9e4\uac1c\ubcc0\uc218\ub97c \ud655\uc778\ud558\uc5ec \ud559\uc2b5\ud558\uc138\uc694.\n\ubbf8\uc138 \uc870\uc815\ud560 \ub54c \uc774 \ubaa9\ub85d\uc740 \uae38\uc5b4\uc57c \ud558\uba70\n\ubaa8\ub4e0 \ubaa8\ub378\uc758 \ub9e4\uac1c\ubcc0\uc218\ub97c \ud3ec\ud568\ud574\uc57c \ud569\ub2c8\ub2e4.\n\ud558\uc9c0\ub9cc, \ud2b9\uc9d5\uc744 \ucd94\ucd9c\ud560 \ub54c\ub294 \uc774 \ubaa9\ub85d\uc774 \uc9e7\uc544\uc57c \ud558\uba70\n\uc7ac\uad6c\uc131\ub41c \ub808\uc774\uc5b4\uc758 \uac00\uc911\uce58\uc640 \ud3b8\ud5a5(bias)\ub9cc \ud3ec\ud568\ud574\uc57c \ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# GPU\ub85c \ubaa8\ub378 \uc804\uc1a1\nmodel_ft = model_ft.to(device)\n\n# \uc774 \uc2e4\ud589\uc5d0\uc11c \ucd5c\uc801\ud654/\uc5c5\ub370\uc774\ud2b8\ud560 \ub9e4\uac1c\ubcc0\uc218\ub97c \uc218\uc9d1\ud569\ub2c8\ub2e4.\n#  \ubbf8\uc138 \uc870\uc815\uc744 \ud558\ub294 \uacbd\uc6b0 \ubaa8\ub4e0 \ub9e4\uac1c\ubcc0\uc218\ub97c \uc5c5\ub370\uc774\ud2b8\ud569\ub2c8\ub2e4.\n#  \ud558\uc9c0\ub9cc, \ud2b9\uc9d5 \ucd94\ucd9c \ubc29\ubc95\uc744 \uc0ac\uc6a9\ud558\ub294 \uacbd\uc6b0\uc5d0\ub294\n#  \ubc29\uae08 \ucd08\uae30\ud654\ud55c \ub9e4\uac1c\ubcc0\uc218, \uc989 requires_grad\uac00 Ture\uc778 \ub9e4\uac1c\ubcc0\uc218\ub9cc \uc5c5\ub370\uc774\ud2b8\ud569\ub2c8\ub2e4.\n\nparams_to_update = model_ft.parameters()\nprint(\"Params to learn:\")\nif feature_extract:\n    params_to_update = []\n    for name,param in model_ft.named_parameters():\n        if param.requires_grad == True:\n            params_to_update.append(param)\n            print(\"\\t\",name)\nelse:\n    for name,param in model_ft.named_parameters():\n        if param.requires_grad == True:\n            print(\"\\t\",name)\n\n# \ubaa8\ub4e0 \ub9e4\uac1c\ubcc0\uc218\uac00 \ucd5c\uc801\ud654\ub418\uace0 \uc788\ub294\uc9c0 \ud655\uc778\ud569\ub2c8\ub2e4.\noptimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud559\uc2b5 \ubc0f \uac80\uc99d \ub2e8\uacc4 \uc2e4\ud589\n\n\ub9c8\uc9c0\ub9c9 \ub2e8\uacc4\ub294 \ubaa8\ub378\uc5d0 \ub300\ud55c \uc190\uc2e4\uc744 \uc124\uc815\ud55c \ub2e4\uc74c\n\uc124\uc815\ub41c \uc5d0\ud3ed \uc218\uc5d0 \ub300\ud574 \ud559\uc2b5 \ubc0f \uac80\uc99d \ud568\uc218(validation function)\ub97c \uc2e4\ud589\ud558\ub294 \uac83\uc785\ub2c8\ub2e4.\n\uc774 \ub2e8\uacc4\ub294 \uc5d0\ud3ed \uc218\uc5d0 \ub530\ub77c CPU\uc5d0\uc11c\ub294 \uc2dc\uac04\uc774 \uac78\ub9b4 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\ub610\ud55c, \uae30\ubcf8 \ud559\uc2b5\ub960\uc740 \ubaa8\ub4e0 \ubaa8\ub378\uc5d0 \ucd5c\uc801\uc774 \uc544\ub2c8\ubbc0\ub85c\n\ucd5c\ub300 \uc815\ud655\ub3c4\ub97c \uc5bb\uc73c\ub824\uba74 \uac01 \ubaa8\ub378\uc5d0 \ub300\ud574 \uac1c\ubcc4\uc801\uc73c\ub85c \uc870\uc815\ud574\uc57c \ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \uc190\uc2e4 \ud568\uc218 \uc124\uc815\ncriterion = nn.CrossEntropyLoss()\n\n# \ud559\uc2b5 \ubc0f \ud3c9\uac00\nmodel_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ucc98\uc74c\ubd80\ud130 \ud559\uc2b5\ub41c \ubaa8\ub378\uacfc\uc758 \ube44\uad50\n\n\uc7ac\ubbf8\ub85c, \uc804\uc774 \ud559\uc2b5\uc744 \uc0ac\uc6a9\ud558\uc9c0 \uc54a\uc744 \uacbd\uc6b0\n\ubaa8\ub378\uc774 \uc5b4\ub5bb\uac8c \ud559\uc2b5\ud558\ub294\uc9c0 \uc0b4\ud3b4\ubd05\uc2dc\ub2e4.\n\ubbf8\uc138 \uc870\uc815\uacfc \ud2b9\uc9d5 \ucd94\ucd9c\uc758 \uc131\ub2a5\uc740 \ub370\uc774\ud130\uc14b\uc5d0 \ub530\ub77c \ud06c\uac8c \ub2e4\ub974\uc9c0\ub9cc\n\uc77c\ubc18\uc801\uc73c\ub85c \ub450 \uc804\uc774 \ud559\uc2b5 \ubc29\ubc95\uc740 \ucc98\uc74c\ubd80\ud130 \ud559\uc2b5\ud55c \ubaa8\ub378\uc5d0 \ube44\ud574\n\ud559\uc2b5 \uc2dc\uac04 \ubc0f \uc804\ubc18\uc801\uc778 \uc815\ud655\ub3c4 \uce21\uba74\uc5d0\uc11c \uc720\ub9ac\ud55c \uacb0\uacfc\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \uc774 \uc2e4\ud589\uc5d0 \uc0ac\uc6a9\ub41c \ubaa8\ub378\uc758 \uc0ac\uc804 \ud559\uc2b5\ub418\uc9c0 \uc54a\uc740 \ubc84\uc804\uc744 \ucd08\uae30\ud654\ud569\ub2c8\ub2e4.\nscratch_model,_ = initialize_model(model_name, num_classes, feature_extract=False, use_pretrained=False)\nscratch_model = scratch_model.to(device)\nscratch_optimizer = optim.SGD(scratch_model.parameters(), lr=0.001, momentum=0.9)\nscratch_criterion = nn.CrossEntropyLoss()\n_,scratch_hist = train_model(scratch_model, dataloaders_dict, scratch_criterion, scratch_optimizer, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))\n\n# \uc804\uc774 \ud559\uc2b5 \ubc29\ubc95\uacfc \ucc98\uc74c\ubd80\ud130 \ud559\uc2b5\ub41c \ubaa8\ub378\uc5d0 \ub300\ud55c\n# \uac80\uc99d \uc815\ud655\ub3c4 vs. \ud559\uc2b5 \uc5d0\ud3ed \uc218\uc5d0 \ub300\ud55c \ud559\uc2b5 \uace1\uc120\uc744 \ud45c\uc2dc\ud569\ub2c8\ub2e4.\nohist = []\nshist = []\n\nohist = [h.cpu().numpy() for h in hist]\nshist = [h.cpu().numpy() for h in scratch_hist]\n\nplt.title(\"Validation Accuracy vs. Number of Training Epochs\")\nplt.xlabel(\"Training Epochs\")\nplt.ylabel(\"Validation Accuracy\")\nplt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\nplt.plot(range(1,num_epochs+1),shist,label=\"Scratch\")\nplt.ylim((0,1.))\nplt.xticks(np.arange(1, num_epochs+1, 1.0))\nplt.legend()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ucd5c\uc885 \uc0dd\uac01\uacfc \uc55e\uc73c\ub85c\uc758 \ubc29\ud5a5\n\n\ub2e4\ub978 \ubaa8\ub378 \uba87 \uac00\uc9c0\ub97c \uc2e4\ud589\ud574\ubcf4\uace0 \uc815\ud655\ub3c4\uac00 \uc5bc\ub9c8\ub098 \uc88b\uc544\uc9c0\ub294\uc9c0 \ud655\uc778\ud574 \ubcf4\uc138\uc694.\n\ub610\ud55c, \uc5ed\ubc29\ud5a5 \ud328\uc2a4\uc5d0\uc11c\ub294 \ub300\ubd80\ubd84\uc758 \ubcc0\ud654\ub3c4\ub97c \uacc4\uc0b0\ud560 \ud544\uc694\uac00 \uc5c6\uae30 \ub54c\ubb38\uc5d0\n\ud2b9\uc9d5 \ucd94\ucd9c\uc5d0 \uc2dc\uac04\uc774 \ub35c \uac78\ub9b0\ub2e4\ub294 \uc810\uc5d0 \uc8fc\ubaa9\ud558\uc138\uc694.\n\uc5ec\uae30\uc5d0\uc11c \ud560 \uc218 \uc788\ub294 \uac83\uc740 \ub9ce\uc73c\uba70 \ub2e4\uc74c\uacfc \uac19\uc774 \ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n-  \ub354 \uc5b4\ub824\uc6b4 \ub370\uc774\ud130 \uc9d1\ud569\uc73c\ub85c \uc774 \ucf54\ub4dc\ub97c \uc2e4\ud589\ud558\uace0\n   \uc804\uc774 \ud559\uc2b5\uc758 \uba87 \uac00\uc9c0 \uc774\uc810\uc744 \ub354 \ud655\uc778\ud574 \ubcf4\uc138\uc694.\n-  \uc5ec\uae30\uc5d0 \uc124\uba85\ub41c \ubc29\ubc95\uc744 \uc0ac\uc6a9\ud558\uac70\ub098 \uc804\uc774 \ud559\uc2b5\uc744 \uc0ac\uc6a9\ud558\uc5ec\n   \uc0c8\ub85c\uc6b4 domain(\uc608: NLP, \uc624\ub514\uc624 \ub4f1)\uc5d0\uc11c \ub2e4\ub978 \ubaa8\ub378\uc744 \uc5c5\ub370\uc774\ud2b8\ud569\ub2c8\ub2e4.\n-  \ubaa8\ub378\uc774 \ub9cc\uc871\ud558\uba74 ONNX \ubaa8\ub378\ub85c \ub0b4\ubcf4\ub0b4\uac70\ub098 \ud558\uc774\ube0c\ub9ac\ub4dc \ud504\ub860\ud2b8\uc5d4\ub4dc\ub97c \uc0ac\uc6a9\ud574\n   \ub354 \ube60\ub978 \uc18d\ub3c4\uc640 \ucd5c\uc801\ud654 \uae30\ud68c\ub97c \uc5bb\uc744 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}