{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Google Colab\uc5d0\uc11c \ub178\ud2b8\ubd81\uc744 \uc2e4\ud589\ud558\uae30 \uc704\ud55c \ud301\uc740 \ub2e4\uc74c\uc744 \ucc38\uc870\ud558\uc138\uc694:\n# https://tutorials.pytorch.kr/beginner/colab \n%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Custom Python Operators\n\n.. grid:: 2\n\n    .. grid-item-card:: :octicon:`mortar-board;1em;` What you will learn\n       :class-card: card-prerequisites\n\n       * How to integrate custom operators written in Python with PyTorch\n       * How to test custom operators using ``torch.library.opcheck``\n\n    .. grid-item-card:: :octicon:`list-unordered;1em;` Prerequisites\n       :class-card: card-prerequisites\n\n       * PyTorch 2.4 or later\n\nPyTorch offers a large library of operators that work on Tensors (e.g.\n``torch.add``, ``torch.sum``, etc). However, you might wish to use a new customized\noperator with PyTorch, perhaps written by a third-party library. This tutorial\nshows how to wrap Python functions so that they behave like PyTorch native\noperators. Reasons why you may wish to create a custom operator in PyTorch include:\n\n- Treating an arbitrary Python function as an opaque callable with respect\n  to ``torch.compile`` (that is, prevent ``torch.compile`` from tracing\n  into the function).\n- Adding training support to an arbitrary Python function\n\nUse :func:`torch.library.custom_op` to create Python custom operators.\nUse the C++ ``TORCH_LIBRARY`` APIs to create C++ custom operators (these\nwork in Python-less environments).\nSee the [Custom Operators Landing Page](https://tutorials.pytorch.kr/advanced/custom_ops_landing_page.html)\nfor more details.\n\nPlease note that if your operation can be expressed as a composition of\nexisting PyTorch operators, then there is usually no need to use the custom operator\nAPI -- everything (for example ``torch.compile``, training support) should\njust work.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example: Wrapping PIL's crop into a custom operator\nLet's say that we are using PIL's ``crop`` operation.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nfrom torchvision.transforms.functional import to_pil_image, pil_to_tensor\nimport PIL\nimport IPython\nimport matplotlib.pyplot as plt\n\ndef crop(pic, box):\n    img = to_pil_image(pic.cpu())\n    cropped_img = img.crop(box)\n    return pil_to_tensor(cropped_img).to(pic.device) / 255.\n\ndef display(img):\n    plt.imshow(img.numpy().transpose((1, 2, 0)))\n\nimg = torch.ones(3, 64, 64)\nimg *= torch.linspace(0, 1, steps=64) * torch.linspace(0, 1, steps=64).unsqueeze(-1)\ndisplay(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cropped_img = crop(img, (10, 10, 50, 50))\ndisplay(cropped_img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "``crop`` is not handled effectively out-of-the-box by\n``torch.compile``: ``torch.compile`` induces a\n[\"graph break\"](https://pytorch.org/docs/stable/torch.compiler_faq.html#graph-breaks)\non functions it is unable to handle and graph breaks are bad for performance.\nThe following code demonstrates this by raising an error\n(``torch.compile`` with ``fullgraph=True`` raises an error if a\ngraph break occurs).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "@torch.compile(fullgraph=True)\ndef f(img):\n    return crop(img, (10, 10, 50, 50))\n\n# The following raises an error. Uncomment the line to see it.\n# cropped_img = f(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In order to black-box ``crop`` for use with ``torch.compile``, we need to\ndo two things:\n\n1. wrap the function into a PyTorch custom operator.\n2. add a \"``FakeTensor`` kernel\" (aka \"meta kernel\") to the operator.\n   Given some ``FakeTensors`` inputs (dummy Tensors that don't have storage),\n   this function should return dummy Tensors of your choice with the correct\n   Tensor metadata (shape/strides/``dtype``/device).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from typing import Sequence\n\n# Use torch.library.custom_op to define a new custom operator.\n# If your operator mutates any input Tensors, their names must be specified\n# in the ``mutates_args`` argument.\n@torch.library.custom_op(\"mylib::crop\", mutates_args=())\ndef crop(pic: torch.Tensor, box: Sequence[int]) -> torch.Tensor:\n    img = to_pil_image(pic.cpu())\n    cropped_img = img.crop(box)\n    return (pil_to_tensor(cropped_img) / 255.).to(pic.device, pic.dtype)\n\n# Use register_fake to add a ``FakeTensor`` kernel for the operator\n@crop.register_fake\ndef _(pic, box):\n    channels = pic.shape[0]\n    x0, y0, x1, y1 = box\n    result = pic.new_empty(y1 - y0, x1 - x0, channels).permute(2, 0, 1)\n    # The result should have the same metadata (shape/strides/``dtype``/device)\n    # as running the ``crop`` function above.\n    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After this, ``crop`` now works without graph breaks:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "@torch.compile(fullgraph=True)\ndef f(img):\n    return crop(img, (10, 10, 50, 50))\n\ncropped_img = f(img)\ndisplay(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "display(cropped_img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Adding training support for crop\nUse ``torch.library.register_autograd`` to add training support for an operator.\nPrefer this over directly using ``torch.autograd.Function``; some compositions of\n``autograd.Function`` with PyTorch operator registration APIs can lead to (and\nhas led to) silent incorrectness when composed with ``torch.compile``.\n\nIf you don't need training support, there is no need to use\n``torch.library.register_autograd``.\nIf you end up training with a ``custom_op`` that doesn't have an autograd\nregistration, we'll raise an error message.\n\nThe gradient formula for ``crop`` is essentially ``PIL.paste`` (we'll leave the\nderivation as an exercise to the reader). Let's first wrap ``paste`` into a\ncustom operator:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "@torch.library.custom_op(\"mylib::paste\", mutates_args=())\ndef paste(im1: torch.Tensor, im2: torch.Tensor, coord: Sequence[int]) -> torch.Tensor:\n    assert im1.device == im2.device\n    assert im1.dtype == im2.dtype\n    im1_pil = to_pil_image(im1.cpu())\n    im2_pil = to_pil_image(im2.cpu())\n    PIL.Image.Image.paste(im1_pil, im2_pil, coord)\n    return (pil_to_tensor(im1_pil) / 255.).to(im1.device, im1.dtype)\n\n@paste.register_fake\ndef _(im1, im2, coord):\n    assert im1.device == im2.device\n    assert im1.dtype == im2.dtype\n    return torch.empty_like(im1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And now let's use ``register_autograd`` to specify the gradient formula for ``crop``:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def backward(ctx, grad_output):\n    grad_input = grad_output.new_zeros(ctx.pic_shape)\n    grad_input = paste(grad_input, grad_output, ctx.coords)\n    return grad_input, None\n\ndef setup_context(ctx, inputs, output):\n    pic, box = inputs\n    ctx.coords = box[:2]\n    ctx.pic_shape = pic.shape\n\ncrop.register_autograd(backward, setup_context=setup_context)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that the backward must be a composition of PyTorch-understood operators,\nwhich is why we wrapped paste into a custom operator instead of directly using\nPIL's paste.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "img = img.requires_grad_()\nresult = crop(img, (10, 10, 50, 50))\nresult.sum().backward()\ndisplay(img.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is the correct gradient, with 1s (white) in the cropped region and 0s\n(black) in the unused region.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Testing Python Custom operators\nUse ``torch.library.opcheck`` to test that the custom operator was registered\ncorrectly. This does not test that the gradients are mathematically correct;\nplease write separate tests for that (either manual ones or ``torch.autograd.gradcheck``).\n\nTo use ``opcheck``, pass it a set of example inputs to test against. If your\noperator supports training, then the examples should include Tensors that\nrequire grad. If your operator supports multiple devices, then the examples\nshould include Tensors from each device.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "examples = [\n    [torch.randn(3, 64, 64), [0, 0, 10, 10]],\n    [torch.randn(3, 91, 91, requires_grad=True), [10, 0, 20, 10]],\n    [torch.randn(3, 60, 60, dtype=torch.double), [3, 4, 32, 20]],\n    [torch.randn(3, 512, 512, requires_grad=True, dtype=torch.double), [3, 4, 32, 45]],\n]\n\nfor example in examples:\n    torch.library.opcheck(crop, example)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mutable Python Custom operators\nYou can also wrap a Python function that mutates its inputs into a custom\noperator.\nFunctions that mutate inputs are common because that is how many low-level\nkernels are written; for example, a kernel that computes ``sin`` may take in\nthe input and an output tensor and write ``input.sin()`` to the output tensor.\n\nWe'll use ``numpy.sin`` to demonstrate an example of a mutable Python\ncustom operator.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n\n@torch.library.custom_op(\"mylib::numpy_sin\", mutates_args={\"output\"}, device_types=\"cpu\")\ndef numpy_sin(input: torch.Tensor, output: torch.Tensor) -> None:\n    assert input.device == output.device\n    assert input.device.type == \"cpu\"\n    input_np = input.numpy()\n    output_np = output.numpy()\n    np.sin(input_np, out=output_np)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Because the operator doesn't return anything, there is no need to register\na ``FakeTensor`` kernel (meta kernel) to get it to work with ``torch.compile``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "@torch.compile(fullgraph=True)\ndef f(x):\n    out = torch.empty(3)\n    numpy_sin(x, out)\n    return out\n\nx = torch.randn(3)\ny = f(x)\nassert torch.allclose(y, x.sin())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And here's an ``opcheck`` run telling us that we did indeed register the operator correctly.\n``opcheck`` would error out if we forgot to add the output to ``mutates_args``, for example.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "example_inputs = [\n    [torch.randn(3), torch.empty(3)],\n    [torch.randn(0, 3), torch.empty(0, 3)],\n    [torch.randn(1, 2, 3, 4, dtype=torch.double), torch.empty(1, 2, 3, 4, dtype=torch.double)],\n]\n\nfor example in example_inputs:\n    torch.library.opcheck(numpy_sin, example)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\nIn this tutorial, we learned how to use ``torch.library.custom_op`` to\ncreate a custom operator in Python that works with PyTorch subsystems\nsuch as ``torch.compile`` and autograd.\n\nThis tutorial provides a basic introduction to custom operators.\nFor more detailed information, see:\n\n- [the torch.library documentation](https://pytorch.org/docs/stable/library.html)\n- [the Custom Operators Manual](https://tutorials.pytorch.kr/advanced/custom_ops_landing_page.html#the-custom-operators-manual)\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}